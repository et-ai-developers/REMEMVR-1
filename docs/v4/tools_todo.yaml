# ORANGE Tools Development Tracker
#
# Purpose: Track development of 25 ORANGE tools identified by rq_tools agents for RQ 5.8-15
# Status: All tools marked ORANGE in tools_status.tsv require TDD implementation
# Created: 2025-11-26
#
# Workflow per tool:
#   1. context_finder: Understand what tool needs to do and why
#   2. WebSearch: Research implementation approaches and existing libraries
#   3. AskUser: Clarify any ambiguities before proceeding
#   4. Implement: Add to appropriate module in ./tools (create new modules if needed)
#   5. Test: Write extensive tests in ./tests folder (TDD: write tests FIRST)
#   6. Document: Update docs/v4/tools_inventory.md with full signature and usage
#   7. Document: Update docs/v4/tools_catalog.md with one-liner
#   8. Status: Update to YELLOW in docs/v4/tools_status.tsv
#   9. Track: Mark as done=true in this file

# Priority Groups:
#   HIGH: Blocks multiple RQs (3+)
#   MEDIUM: Blocks 1-2 RQs
#   LOW: Nice-to-have validators

---

# ANALYSIS TOOLS (6 tools)

analysis_lmm:

  - name: select_lmm_random_structure_via_lrt
    module: tools.analysis_lmm
    priority: HIGH
    blocks_rqs: [5.10]
    description: "Fit 3 random structures, compare via LRT"
    requirements:
      - "Fit 3 candidate models: Full (TSVR | UID), Uncorrelated (TSVR || UID), Intercept-only (1 | UID)"
      - "Perform likelihood ratio tests (LRT) between nested models"
      - "Select best model based on LRT p-values"
      - "Return fitted models + LRT results table"
    inputs:
      - data: pd.DataFrame
      - formula: str
      - groups: str
      - reml: bool
    outputs: "Dict[selected_model: str, lrt_results: pd.DataFrame, fitted_models: Dict]"
    done: false

  - name: prepare_age_effects_plot_data
    module: tools.analysis_lmm
    priority: MEDIUM
    blocks_rqs: [5.10]
    description: "Create age tertiles, aggregate means, generate predictions"
    requirements:
      - "Create age tertiles (Young/Middle/Older) from continuous age"
      - "Aggregate observed means by domain x tertile x timepoint"
      - "Generate model predictions using LMM fitted values"
      - "Output plot-ready DataFrame (~600 rows)"
    inputs:
      - lmm_input: pd.DataFrame
      - lmm_model: MixedLMResults
      - age_effects: pd.DataFrame
      - output_path: Path
    outputs: "pd.DataFrame (plot source data)"
    done: false

  - name: compute_icc_from_variance_components
    module: tools.analysis_lmm
    priority: MEDIUM
    blocks_rqs: [5.13]
    description: "Compute 3 ICC estimates (intercept, slope_simple, slope_conditional)"
    requirements:
      - "Extract variance components from LMM cov_re matrix"
      - "Compute ICC_intercept = var_intercept / (var_intercept + residual)"
      - "Compute ICC_slope_simple = var_slope / (var_slope + residual)"
      - "Compute ICC_slope_conditional at Day 6 accounting for covariance"
      - "Return DataFrame with all 3 ICC values + interpretation"
    inputs:
      - variance_components_df: pd.DataFrame
      - method: str (simple, conditional)
      - time_point: float (e.g., 6.0 for Day 6)
    outputs: "pd.DataFrame with ICC estimates"
    done: false

  - name: test_intercept_slope_correlation_d068
    module: tools.analysis_lmm
    priority: MEDIUM
    blocks_rqs: [5.13]
    description: "Pearson correlation + D068 dual p-values"
    requirements:
      - "Extract random effects (intercepts, slopes) from LMM"
      - "Compute Pearson correlation between intercepts and slopes"
      - "Report BOTH p_uncorrected AND p_bonferroni (Decision D068)"
      - "Bonferroni correction: family_alpha / n_tests"
      - "Return Dict with r, p_uncorrected, p_bonferroni, interpretation"
    inputs:
      - random_effects_df: pd.DataFrame
      - family_alpha: float (default 0.05)
      - n_tests: int (default 15 for Chapter 5)
    outputs: "Dict[r: float, p_uncorrected: float, p_bonferroni: float, significant: bool]"
    done: false

analysis_ctt:

  - name: compute_cronbachs_alpha
    module: tools.analysis_ctt
    priority: HIGH
    blocks_rqs: [5.12]
    description: "Compute Cronbach's alpha with bootstrap CIs"
    requirements:
      - "Compute Cronbach's alpha for item set (internal consistency reliability)"
      - "Bootstrap resampling (n_bootstrap iterations, default 1000)"
      - "Compute 95% confidence intervals from bootstrap distribution"
      - "Return alpha, CI_lower, CI_upper"
      - "NOTE: This creates NEW MODULE tools/analysis_ctt.py"
    inputs:
      - data: pd.DataFrame
      - n_bootstrap: int (default 1000)
    outputs: "Dict[alpha: float, ci_lower: float, ci_upper: float, n_items: int, n_participants: int]"
    done: true
    completed_date: 2025-11-26
    test_status: "13/13 GREEN"
    notes: "Created NEW MODULE tools/analysis_ctt.py. Percentile bootstrap method (resamples participants, preserves item correlation structure). Formula: α = (k/(k-1)) × (1 - Σσ²ᵢ / σ²ₓ). For dichotomous items, mathematically equals KR-20. Handles NaN via pairwise deletion. Requires ≥2 items, ≥3 participants. CI width 0.02-0.15 for N=100. 45 min implementation time."

  - name: compare_correlations_dependent
    module: tools.analysis_ctt
    priority: HIGH
    blocks_rqs: [5.12]
    description: "Steiger's z-test for dependent correlations"
    requirements:
      - "Test if r12 differs from r13 when both share variable 1 (dependent correlations)"
      - "Use Steiger's z-test formula accounting for r23 (correlation between compared variables)"
      - "Return z-statistic, p-value, interpretation"
      - "Example: Test if r(Purified_CTT, IRT) > r(Full_CTT, IRT)"
    inputs:
      - r12: float (correlation 1-2)
      - r13: float (correlation 1-3)
      - r23: float (correlation 2-3)
      - n: int (sample size)
    outputs: "Dict[z_statistic: float, p_value: float, r_difference: float, significant: bool, interpretation: str]"
    done: true
    completed_date: 2025-11-26
    test_status: "13/13 GREEN"
    notes: "Implements Steiger (1980) equations 3 & 10 for asymptotic covariance of overlapping correlations. Fisher's z-transformation applied. Two-tailed p-value. Requires n ≥ 20, all correlations in [-1, 1]. N=100 adequate for 90% power per literature. Plain language interpretation in output. 30 min implementation time."

---

# VALIDATION TOOLS (19 tools)

validation_generic:

  - name: check_file_exists
    module: tools.validation
    priority: HIGH
    blocks_rqs: [5.8, 5.9, 5.10, 5.11, 5.12, 5.13, 5.14, 5.15]
    description: "Validate file exists (needed by 7 RQs)"
    requirements:
      - "Check file exists at path"
      - "Optionally check minimum file size (bytes)"
      - "Return Dict[valid: bool, message: str, size_bytes: int]"
    inputs:
      - file_path: Path
      - min_size_bytes: int (default 0)
    outputs: "Dict[valid: bool, message: str, size_bytes: int]"
    done: true
    completed_date: 2025-11-26
    test_status: "10/10 GREEN"
    notes: "Enhanced existing function with min_size_bytes parameter, directory detection, comprehensive tests"

  - name: validate_dataframe_structure
    module: tools.validation
    priority: MEDIUM
    blocks_rqs: [5.14]
    description: "Generic dataframe validation (rows, cols, types)"
    requirements:
      - "Check expected number of rows (exact or range)"
      - "Check expected columns present"
      - "Check column data types match expected"
      - "Return Dict[valid: bool, message: str, checks: Dict]"
    inputs:
      - file_path: Path
      - expected_rows: int (or tuple for range)
      - expected_columns: List[str]
      - column_types: Dict[str, type]
    outputs: "Dict[valid: bool, message: str, checks: Dict]"
    done: false

validation_numeric:

  - name: validate_numeric_range
    module: tools.validation
    priority: MEDIUM
    blocks_rqs: [5.9]
    description: "Validate numeric range for probability transformation"
    requirements:
      - "Check all values in data fall within [min_val, max_val]"
      - "Report any out-of-range values"
      - "Return Dict[valid: bool, message: str, out_of_range_count: int]"
    inputs:
      - data: np.ndarray or pd.Series
      - min_val: float
      - max_val: float
      - column_name: str (for error messages)
    outputs: "Dict[valid: bool, message: str, out_of_range_count: int, violations: List]"
    done: false

  - name: validate_standardization
    module: tools.validation
    priority: LOW
    blocks_rqs: [5.14]
    description: "Check z-scores mean~0, SD~1"
    requirements:
      - "Check each column has mean ≈ 0 (within tolerance)"
      - "Check each column has SD ≈ 1 (within tolerance)"
      - "Return Dict[valid: bool, message: str, mean_values: Dict, sd_values: Dict]"
    inputs:
      - df: pd.DataFrame
      - column_names: List[str]
      - tolerance: float (default 0.01)
    outputs: "Dict[valid: bool, message: str, mean_values: Dict, sd_values: Dict]"
    done: false

  - name: validate_probability_range
    module: tools.validation
    priority: LOW
    blocks_rqs: [5.9]
    description: "Validate probability transformation"
    requirements:
      - "Check all probability values in [0, 1]"
      - "Check no NaN or infinite values"
      - "Return Dict[valid: bool, message: str, violations: List]"
    inputs:
      - probability_df: pd.DataFrame
      - prob_columns: List[str]
    outputs: "Dict[valid: bool, message: str, violations: List]"
    done: false

validation_lmm:

  - name: validate_lmm_assumptions_comprehensive
    module: tools.validation
    priority: HIGH
    blocks_rqs: [5.8, 5.10, 5.15]
    description: "7 diagnostics (normality, homoscedasticity, Q-Q, ACF, linearity, outliers, convergence)"
    requirements:
      - "1. Residual normality (Shapiro-Wilk test)"
      - "2. Homoscedasticity (Breusch-Pagan test)"
      - "3. Random effects normality (Q-Q plots)"
      - "4. Autocorrelation (ACF plots, Lag-1 test)"
      - "5. Linearity within segments (partial residual plots)"
      - "6. Outlier detection (Cook's distance)"
      - "7. Convergence diagnostics"
      - "Save diagnostic plots to output_dir"
      - "Return Dict[valid: bool, diagnostics: Dict, plot_paths: List, message: str]"
    inputs:
      - lmm_result: MixedLMResults
      - data: pd.DataFrame
      - output_dir: Path
      - acf_lag1_threshold: float (default 0.1)
      - alpha: float (default 0.05)
    outputs: "Dict[valid: bool, diagnostics: Dict, plot_paths: List, message: str]"
    done: true
    completed_date: 2025-11-26
    test_status: "14/14 GREEN"
    notes: "Complete rewrite of v3.0 minimal implementation. 400+ lines production code. 7 comprehensive diagnostics with 6 diagnostic plots (qq_residuals, residuals_vs_fitted, qq_random_intercepts, qq_random_slopes, acf, cooks_distance). Partial residual CSVs for ALL predictors. Remedial action recommendations per RQ 5.8 specification. Configurable thresholds."

  - name: validate_model_convergence
    module: tools.validation
    priority: MEDIUM
    blocks_rqs: [5.13]
    description: "Validate loaded model convergence"
    requirements:
      - "Check model.converged attribute is True"
      - "Check no convergence warnings in model object"
      - "Return Dict[valid: bool, message: str]"
    inputs:
      - lmm_result: MixedLMResults
    outputs: "Dict[valid: bool, message: str, converged: bool]"
    done: false

  - name: validate_variance_positivity
    module: tools.validation
    priority: LOW
    blocks_rqs: [5.13]
    description: "Validate variance components positive"
    requirements:
      - "Check all variance values > 0"
      - "Variance components cannot be negative (estimation issue if so)"
      - "Return Dict[valid: bool, message: str, negative_components: List]"
    inputs:
      - variance_df: pd.DataFrame
      - component_col: str (column name for component names)
      - value_col: str (column name for variance values)
    outputs: "Dict[valid: bool, message: str, negative_components: List]"
    done: false

  - name: validate_icc_bounds
    module: tools.validation
    priority: LOW
    blocks_rqs: [5.13]
    description: "Validate ICC in [0,1]"
    requirements:
      - "Check all ICC values in [0, 1] range"
      - "ICC outside this range indicates computation error"
      - "Return Dict[valid: bool, message: str, out_of_bounds: List]"
    inputs:
      - icc_df: pd.DataFrame
      - icc_col: str (column name for ICC values)
    outputs: "Dict[valid: bool, message: str, out_of_bounds: List]"
    done: false

validation_data_format:

  - name: validate_data_format
    module: tools.validation
    priority: LOW
    blocks_rqs: [5.9]
    description: "Validate fixed effects table format"
    requirements:
      - "Check DataFrame has required columns"
      - "Check no missing values in required columns"
      - "Return Dict[valid: bool, message: str, missing_cols: List]"
    inputs:
      - df: pd.DataFrame
      - required_cols: List[str]
    outputs: "Dict[valid: bool, message: str, missing_cols: List]"
    done: false

  - name: validate_plot_data_completeness
    module: tools.validation
    priority: LOW
    blocks_rqs: [5.10]
    description: "Verify all domains/tertiles present"
    requirements:
      - "Check all required domains present in data"
      - "Check all required groups (e.g., age tertiles) present"
      - "Check no missing combinations (complete factorial design)"
      - "Return Dict[valid: bool, message: str, missing_domains: List, missing_groups: List]"
    inputs:
      - plot_data: pd.DataFrame
      - required_domains: List[str]
      - required_groups: List[str]
    outputs: "Dict[valid: bool, message: str, missing_domains: List, missing_groups: List]"
    done: false

validation_d068_compliance:

  - name: validate_contrasts_d068
    module: tools.validation
    priority: MEDIUM
    blocks_rqs: [5.9]
    description: "Verify D068 dual p-value reporting"
    requirements:
      - "Check contrasts DataFrame has 'p_uncorrected' column"
      - "Check contrasts DataFrame has 'p_bonferroni' or 'p_tukey' column"
      - "Decision D068: ALWAYS report both uncorrected and corrected p-values"
      - "Return Dict[valid: bool, message: str, d068_compliant: bool]"
    inputs:
      - contrasts_df: pd.DataFrame
    outputs: "Dict[valid: bool, message: str, d068_compliant: bool, missing_cols: List]"
    done: false

  - name: validate_hypothesis_test_dual_pvalues
    module: tools.validation
    priority: MEDIUM
    blocks_rqs: [5.10]
    description: "Verify 3-way interaction includes D068 dual p-values"
    requirements:
      - "Check interaction DataFrame has required terms (e.g., 'Age:Domain:Time')"
      - "Check each term has 'p_uncorrected' and 'p_bonferroni' columns"
      - "Decision D068: ALWAYS report both for hypothesis tests"
      - "Return Dict[valid: bool, missing_terms: List, d068_compliant: bool]"
    inputs:
      - interaction_df: pd.DataFrame
      - required_terms: List[str]
      - alpha_bonferroni: float
    outputs: "Dict[valid: bool, missing_terms: List, d068_compliant: bool, message: str]"
    done: false

  - name: validate_contrasts_dual_pvalues
    module: tools.validation
    priority: MEDIUM
    blocks_rqs: [5.10]
    description: "Verify post-hoc contrasts include D068 dual p-values"
    requirements:
      - "Check contrasts DataFrame has required comparisons"
      - "Check each comparison has 'p_uncorrected' and 'p_tukey' columns"
      - "Decision D068: Post-hoc contrasts use Tukey HSD correction"
      - "Return Dict[valid: bool, d068_compliant: bool, missing_comparisons: List]"
    inputs:
      - contrasts_df: pd.DataFrame
      - required_comparisons: List[str]
    outputs: "Dict[valid: bool, d068_compliant: bool, missing_comparisons: List, message: str]"
    done: false

  - name: validate_correlation_test_d068
    module: tools.validation
    priority: MEDIUM
    blocks_rqs: [5.13]
    description: "Verify correlation test includes D068 dual p-values"
    requirements:
      - "Check correlation DataFrame has 'p_uncorrected' column"
      - "Check correlation DataFrame has 'p_bonferroni' or 'p_holm' column"
      - "Decision D068: Correlation tests report both uncorrected and corrected"
      - "Return Dict[valid: bool, d068_compliant: bool, message: str]"
    inputs:
      - correlation_df: pd.DataFrame
      - required_cols: List[str] (e.g., ['p_uncorrected', 'p_bonferroni'])
    outputs: "Dict[valid: bool, d068_compliant: bool, missing_cols: List, message: str]"
    done: false

validation_effect_sizes:

  - name: validate_effect_sizes
    module: tools.validation
    priority: LOW
    blocks_rqs: [5.9]
    description: "Validate effect size bounds"
    requirements:
      - "Check Cohen's f² values are non-negative"
      - "Warn if f² > 1.0 (very large effect, may indicate issue)"
      - "Check no NaN or infinite values"
      - "Return Dict[valid: bool, message: str, warnings: List]"
    inputs:
      - effect_sizes_df: pd.DataFrame
      - f2_column: str (default 'cohens_f2')
    outputs: "Dict[valid: bool, message: str, warnings: List]"
    done: false

validation_clustering:

  - name: validate_cluster_assignment
    module: tools.validation
    priority: LOW
    blocks_rqs: [5.14]
    description: "Check cluster IDs consecutive, sizes >= threshold"
    requirements:
      - "Check all participants assigned to cluster (no missing)"
      - "Check cluster IDs are consecutive (0, 1, ..., K-1)"
      - "Check each cluster has size >= min_cluster_size"
      - "Return Dict[valid: bool, message: str, cluster_sizes: Dict]"
    inputs:
      - assignments_df: pd.DataFrame
      - n_participants: int
      - min_cluster_size: int
    outputs: "Dict[valid: bool, message: str, cluster_sizes: Dict]"
    done: false

  - name: validate_bootstrap_stability
    module: tools.validation
    priority: LOW
    blocks_rqs: [5.14]
    description: "Check Jaccard values in [0,1], mean >= threshold"
    requirements:
      - "Check all Jaccard values in [0, 1] range"
      - "Compute mean Jaccard coefficient across bootstrap iterations"
      - "Check mean >= min_jaccard_threshold (e.g., 0.75 for stability)"
      - "Compute 95% CI from bootstrap distribution"
      - "Return Dict[valid: bool, message: str, mean_jaccard: float, ci: Tuple]"
    inputs:
      - stability_df: pd.DataFrame
      - min_jaccard_threshold: float (default 0.75)
    outputs: "Dict[valid: bool, message: str, mean_jaccard: float, ci_lower: float, ci_upper: float]"
    done: false

  - name: validate_cluster_summary_stats
    module: tools.validation
    priority: LOW
    blocks_rqs: [5.14]
    description: "Check summary stats mathematically consistent"
    requirements:
      - "Check min <= mean <= max for each variable"
      - "Check SD >= 0 for each variable"
      - "Check N > 0 for each cluster"
      - "Return Dict[valid: bool, message: str, failed_checks: List]"
    inputs:
      - summary_df: pd.DataFrame
    outputs: "Dict[valid: bool, message: str, failed_checks: List]"
    done: false

---

# SUMMARY STATISTICS

total_tools: 25
done_count: 4
remaining_count: 21

by_priority:
  HIGH: 6  # Blocks multiple RQs or creates new modules
  MEDIUM: 10  # Blocks 1-2 RQs
  LOW: 9  # Nice-to-have validators

by_module:
  tools.analysis_lmm: 4
  tools.analysis_ctt: 2  # NEW MODULE
  tools.validation: 19

by_rq_blocking:
  RQ_5_8: 2 tools (check_file_exists, validate_lmm_assumptions_comprehensive)
  RQ_5_9: 6 tools (check_file_exists, validate_numeric_range, validate_data_format, validate_contrasts_d068, validate_effect_sizes, validate_probability_range)
  RQ_5_10: 7 tools (check_file_exists, select_lmm_random_structure_via_lrt, prepare_age_effects_plot_data, validate_lmm_assumptions_comprehensive, validate_hypothesis_test_dual_pvalues, validate_contrasts_dual_pvalues, validate_plot_data_completeness)
  RQ_5_11: 1 tool (check_file_exists) # RQ 5.11 succeeded with only GREEN tools
  RQ_5_12: 3 tools (check_file_exists, compute_cronbachs_alpha, compare_correlations_dependent)
  RQ_5_13: 6 tools (check_file_exists, compute_icc_from_variance_components, test_intercept_slope_correlation_d068, validate_model_convergence, validate_variance_positivity, validate_icc_bounds, validate_correlation_test_d068)
  RQ_5_14: 6 tools (check_file_exists, validate_dataframe_structure, validate_standardization, validate_cluster_assignment, validate_bootstrap_stability, validate_cluster_summary_stats)
  RQ_5_15: 2 tools (check_file_exists, validate_lmm_assumptions_comprehensive)

critical_path_rqs:
  # RQs with most tool dependencies (highest priority to unblock)
  - RQ_5_10: 7 tools
  - RQ_5_9: 6 tools
  - RQ_5_13: 6 tools
  - RQ_5_14: 6 tools
  - RQ_5_12: 3 tools (CTT module creation)
  - RQ_5_8: 2 tools
  - RQ_5_15: 2 tools
  - RQ_5_11: 1 tool (can proceed with only check_file_exists)

recommended_order:
  # Build tools in this order to maximize RQ unblocking efficiency
  phase_1_critical:
    - check_file_exists  # Unblocks ALL 8 RQs partially
    - validate_lmm_assumptions_comprehensive  # Unblocks RQ 5.8, 5.10, 5.15
    - compute_cronbachs_alpha  # Creates CTT module, unblocks RQ 5.12
    - compare_correlations_dependent  # Completes CTT module, fully unblocks RQ 5.12

  phase_2_medium_priority:
    - select_lmm_random_structure_via_lrt  # Unblocks RQ 5.10
    - prepare_age_effects_plot_data  # Unblocks RQ 5.10
    - compute_icc_from_variance_components  # Unblocks RQ 5.13
    - test_intercept_slope_correlation_d068  # Unblocks RQ 5.13
    - validate_contrasts_d068  # Unblocks RQ 5.9
    - validate_hypothesis_test_dual_pvalues  # Unblocks RQ 5.10
    - validate_contrasts_dual_pvalues  # Unblocks RQ 5.10
    - validate_correlation_test_d068  # Unblocks RQ 5.13

  phase_3_low_priority_validators:
    # These are nice-to-have but can be replaced with inline assertions
    - validate_numeric_range
    - validate_data_format
    - validate_effect_sizes
    - validate_probability_range
    - validate_model_convergence
    - validate_variance_positivity
    - validate_icc_bounds
    - validate_dataframe_structure
    - validate_standardization
    - validate_plot_data_completeness
    - validate_cluster_assignment
    - validate_bootstrap_stability
    - validate_cluster_summary_stats

estimated_effort:
  phase_1_critical: "6-8 hours (4 tools × 1.5-2 hours each)"
  phase_2_medium_priority: "12-16 hours (12 tools × 1-1.5 hours each)"
  phase_3_low_priority_validators: "6-9 hours (9 tools × 0.5-1 hour each)"
  total: "24-33 hours for all 25 tools"

  # Per-tool estimates (TDD cycle: research → test → implement → document)
  high_complexity: "2 hours (validate_lmm_assumptions_comprehensive, select_lmm_random_structure_via_lrt)"
  medium_complexity: "1.5 hours (CTT tools, ICC computation, correlation testing)"
  low_complexity: "0.5-1 hour (simple validators)"
