# ============================================================================
# ANALYSIS RECIPE - COMPLETE SPECIFICATION
# ============================================================================
# Generated: 2025-12-02
# RQ: 5.3.6 - Purified CTT Effects (Paradigms)
# Agent: rq_analysis v4.1.0
# Purpose: Self-contained recipe for g_code agent (reads ONLY this file)
# ============================================================================

metadata:
  rq_id: "5.3.6"
  rq_path: "results/ch5/5.3.6"
  total_steps: 9
  analysis_type: "CTT Purification Comparison (Full vs Purified CTT) + LMM + AIC"
  generated_by: "rq_analysis v4.1.0"
  timestamp: "2025-12-02T18:00:00Z"
  cross_rq_dependencies:
    - "RQ 5.3.1 (purified items, theta scores, TSVR mapping)"

# ============================================================================
# ANALYSIS STEPS - COMPLETE SPECIFICATIONS
# ============================================================================

steps:
  # --------------------------------------------------------------------------
  # STEP 0: Load Dependencies and Validate
  # --------------------------------------------------------------------------
  - name: "step00_load_dependencies"
    step_number: "00"
    description: "Verify RQ 5.3.1 completion and load required outputs for CTT comparison"

    analysis_call:
      type: "catalogued"
      module: "tools.validation"
      function: "check_file_exists"
      signature: "check_file_exists(file_path: Union[str, Path], min_size_bytes: int = 0) -> Dict[str, Any]"

      input_files:
        - path: "results/ch5/5.3.1/status.yaml"
          purpose: "Verify RQ 5.3.1 completion status"
          required_status: "rq_results.status = success"
        - path: "results/ch5/5.3.1/data/step02_purified_items.csv"
          purpose: "Purified items from RQ 5.3.1"
          required_columns: ["item_name", "dimension", "retained", "a", "b"]
          expected_rows_range: [40, 80]
        - path: "results/ch5/5.3.1/data/step03_theta_scores.csv"
          purpose: "IRT theta scores from RQ 5.3.1"
          required_columns: ["composite_ID", "theta_IFR", "theta_ICR", "theta_IRE", "se_IFR", "se_ICR", "se_IRE"]
          expected_rows: 400
        - path: "results/ch5/5.3.1/data/step00_tsvr_mapping.csv"
          purpose: "TSVR mapping from RQ 5.3.1"
          required_columns: ["composite_ID", "TSVR_hours", "test"]
          expected_rows: 400

      output_files:
        - path: "data/step00_dependency_validation_report.txt"
          description: "Validation report confirming all dependencies met"
          format: "Plain text report"
          minimum_size_bytes: 500

      parameters:
        files_to_check:
          - "results/ch5/5.3.1/status.yaml"
          - "results/ch5/5.3.1/data/step02_purified_items.csv"
          - "results/ch5/5.3.1/data/step03_theta_scores.csv"
          - "results/ch5/5.3.1/data/step00_tsvr_mapping.csv"
        min_size_bytes: 100

      returns:
        type: "Dict[str, Any]"
        variable_name: "dependency_check_result"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_data_format"
      signature: "validate_data_format(df: DataFrame, required_cols: List[str]) -> Dict[str, Any]"

      input_files:
        - path: "data/step00_dependency_validation_report.txt"
          source: "check_file_exists output"
          variable_name: "dependency_check_result"

      parameters:
        required_columns: ["status", "file_path", "size_bytes"]

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "All 4 required files exist"
        - "RQ 5.3.1 status.yaml shows rq_results = success"
        - "All schema validations pass"
        - "No missing values in critical columns"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step00_load_dependencies.log"
        message: "RQ 5.3.1 incomplete - run RQ 5.3.1 before RQ 5.3.6"

    log_file: "logs/step00_load_dependencies.log"

  # --------------------------------------------------------------------------
  # STEP 1: Map Items by Paradigm (Retained vs Removed)
  # --------------------------------------------------------------------------
  - name: "step01_map_items"
    step_number: "01"
    description: "Create item mapping table stratified by paradigm showing retention status and compute retention rates"

    analysis_call:
      type: "stdlib"
      operations:
        - "Load data/step00_purified_items.csv (from Step 0 dependency check)"
        - "Group items by dimension (paradigm: IFR, ICR, IRE)"
        - "Count total items per paradigm"
        - "Count retained items per paradigm (retained = TRUE)"
        - "Compute retention rate = retained / total per paradigm"
        - "Create exclusion_reason column based on a and b thresholds"
        - "Save data/step01_item_mapping.csv (one row per item)"
        - "Save data/step01_retention_summary.csv (one row per paradigm)"

      input_files:
        - path: "data/step00_purified_items.csv"
          source: "Copied from RQ 5.3.1 in Step 0"
          required_columns: ["item_name", "dimension", "retained", "a", "b"]
          variable_name: "purified_items"

      output_files:
        - path: "data/step01_item_mapping.csv"
          description: "Item mapping with retention status per paradigm"
          columns: ["item_name", "paradigm", "retained", "a", "b", "exclusion_reason"]
          expected_rows_range: [40, 80]
          variable_name: "item_mapping"
        - path: "data/step01_retention_summary.csv"
          description: "Paradigm-level retention rates"
          columns: ["paradigm", "total_items", "retained_items", "removed_items", "retention_rate"]
          expected_rows: 3
          variable_name: "retention_summary"

      parameters:
        paradigms: ["IFR", "ICR", "IRE"]
        thresholds:
          min_discrimination: 0.4
          max_difficulty: 3.0

      returns:
        type: "Tuple[pd.DataFrame, pd.DataFrame]"
        unpacking: "item_mapping, retention_summary"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_dataframe_structure"
      signature: "validate_dataframe_structure(df: DataFrame, expected_rows: Union[int, Tuple[int, int]], expected_columns: List[str], column_types: Optional[Dict[str, type]] = None) -> Dict[str, Any]"

      input_files:
        - path: "data/step01_item_mapping.csv"
          variable_name: "item_mapping"
          source: "stdlib operations output"
        - path: "data/step01_retention_summary.csv"
          variable_name: "retention_summary"
          source: "stdlib operations output"

      parameters:
        df: "item_mapping"
        expected_rows: [40, 80]
        expected_columns: ["item_name", "paradigm", "retained", "a", "b", "exclusion_reason"]

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "All 3 paradigms present (IFR, ICR, IRE)"
        - "retention_rate in [0, 1]"
        - "retained_items + removed_items = total_items for each paradigm"
        - "No NaN values in retention_rate column"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step01_map_items.log"

    log_file: "logs/step01_map_items.log"

  # --------------------------------------------------------------------------
  # STEP 2: Compute Full CTT Scores (All Items Pre-Purification)
  # --------------------------------------------------------------------------
  - name: "step02_compute_full_ctt"
    step_number: "02"
    description: "Extract raw response data for ALL paradigm items and compute Full CTT scores"

    analysis_call:
      type: "stdlib"
      operations:
        - "Load data/cache/dfData.csv (project-level raw data)"
        - "Load data/step01_item_mapping.csv (to identify all items, retained OR removed)"
        - "Map item_name to TQ_* column names in dfData.csv"
        - "Extract raw response data for all items, stratified by paradigm"
        - "Compute mean score per UID x Test x Paradigm using ALL items"
        - "Create composite DataFrame (UID, test, CTT_full_IFR, CTT_full_ICR, CTT_full_IRE)"
        - "Save data/step02_ctt_full_scores.csv"

      input_files:
        - path: "data/cache/dfData.csv"
          required_columns: ["UID", "test", "TQ_*"]
          variable_name: "raw_data"
        - path: "data/step01_item_mapping.csv"
          required_columns: ["item_name", "paradigm"]
          variable_name: "item_mapping"

      output_files:
        - path: "data/step02_ctt_full_scores.csv"
          description: "Full CTT scores using all items per paradigm"
          columns: ["UID", "test", "CTT_full_IFR", "CTT_full_ICR", "CTT_full_IRE"]
          expected_rows: 400
          variable_name: "ctt_full_scores"

      parameters:
        paradigms: ["IFR", "ICR", "IRE"]
        aggregation: "mean"  # Mean proportion correct

      returns:
        type: "pd.DataFrame"
        variable_name: "ctt_full_scores"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_numeric_range"
      signature: "validate_numeric_range(data: Union[np.ndarray, pd.Series], min_val: float, max_val: float, column_name: str) -> Dict[str, Any]"

      input_files:
        - path: "data/step02_ctt_full_scores.csv"
          variable_name: "ctt_full_scores"
          source: "stdlib operations output"

      parameters:
        data: "ctt_full_scores['CTT_full_IFR']"
        min_val: 0.0
        max_val: 1.0
        column_name: "CTT_full_IFR"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "All CTT scores in [0, 1] (proportion correct)"
        - "No NaN values in CTT score columns"
        - "No duplicate UID x test combinations"
        - "All 400 rows present (100 participants x 4 tests)"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step02_compute_full_ctt.log"

    log_file: "logs/step02_compute_full_ctt.log"

  # --------------------------------------------------------------------------
  # STEP 3: Compute Purified CTT Scores (Retained Items Only)
  # --------------------------------------------------------------------------
  - name: "step03_compute_purified_ctt"
    step_number: "03"
    description: "Extract raw response data for RETAINED items only and compute Purified CTT scores"

    analysis_call:
      type: "stdlib"
      operations:
        - "Load data/cache/dfData.csv (same as Step 2)"
        - "Load data/step01_item_mapping.csv and filter to retained = TRUE items only"
        - "Map retained item_name to TQ_* column names in dfData.csv"
        - "Extract raw response data for retained items, stratified by paradigm"
        - "Compute mean score per UID x Test x Paradigm using purified items"
        - "Create composite DataFrame (UID, test, CTT_purified_IFR, CTT_purified_ICR, CTT_purified_IRE)"
        - "Save data/step03_ctt_purified_scores.csv"

      input_files:
        - path: "data/cache/dfData.csv"
          required_columns: ["UID", "test", "TQ_*"]
          variable_name: "raw_data"
        - path: "data/step01_item_mapping.csv"
          required_columns: ["item_name", "paradigm", "retained"]
          variable_name: "item_mapping"

      output_files:
        - path: "data/step03_ctt_purified_scores.csv"
          description: "Purified CTT scores using retained items only"
          columns: ["UID", "test", "CTT_purified_IFR", "CTT_purified_ICR", "CTT_purified_IRE"]
          expected_rows: 400
          variable_name: "ctt_purified_scores"

      parameters:
        paradigms: ["IFR", "ICR", "IRE"]
        aggregation: "mean"
        filter_retained: true

      returns:
        type: "pd.DataFrame"
        variable_name: "ctt_purified_scores"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_numeric_range"
      signature: "validate_numeric_range(data: Union[np.ndarray, pd.Series], min_val: float, max_val: float, column_name: str) -> Dict[str, Any]"

      input_files:
        - path: "data/step03_ctt_purified_scores.csv"
          variable_name: "ctt_purified_scores"
          source: "stdlib operations output"

      parameters:
        data: "ctt_purified_scores['CTT_purified_IFR']"
        min_val: 0.0
        max_val: 1.0
        column_name: "CTT_purified_IFR"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "All CTT scores in [0, 1]"
        - "No NaN values in CTT score columns"
        - "All 400 rows present"
        - "No duplicate UID x test combinations"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step03_compute_purified_ctt.log"

    log_file: "logs/step03_compute_purified_ctt.log"

  # --------------------------------------------------------------------------
  # STEP 4: Reliability Assessment with Cronbach's Alpha
  # --------------------------------------------------------------------------
  - name: "step04_reliability_assessment"
    step_number: "04"
    description: "Compute Cronbach's alpha for Full and Purified CTT with bootstrap 95% CIs"

    analysis_call:
      type: "catalogued"
      module: "tools.analysis_ctt"
      function: "compute_cronbachs_alpha"
      signature: "compute_cronbachs_alpha(data: DataFrame, n_bootstrap: int = 1000) -> Dict[str, Any]"

      input_files:
        - path: "data/cache/dfData.csv"
          required_columns: ["UID", "test", "TQ_*"]
          variable_name: "raw_data"
          purpose: "Need raw item responses to compute inter-item covariances"
        - path: "data/step01_item_mapping.csv"
          required_columns: ["item_name", "paradigm", "retained"]
          variable_name: "item_mapping"
          purpose: "Identify Full vs Purified item sets per paradigm"

      output_files:
        - path: "data/step04_reliability_assessment.csv"
          description: "Cronbach's alpha with bootstrap CIs for Full and Purified CTT"
          columns: ["paradigm", "n_items_full", "n_items_purified", "alpha_full", "alpha_full_CI_lower", "alpha_full_CI_upper", "alpha_purified", "alpha_purified_CI_lower", "alpha_purified_CI_upper", "alpha_purified_SB_adjusted", "delta_alpha"]
          expected_rows: 3
          variable_name: "reliability_results"

      parameters:
        data: "raw_data"
        n_bootstrap: 10000
        ci_level: 0.95
        paradigms: ["IFR", "ICR", "IRE"]

      returns:
        type: "Dict[str, Any]"
        variable_name: "reliability_results"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_numeric_range"
      signature: "validate_numeric_range(data: Union[np.ndarray, pd.Series], min_val: float, max_val: float, column_name: str) -> Dict[str, Any]"

      input_files:
        - path: "data/step04_reliability_assessment.csv"
          variable_name: "reliability_results"
          source: "compute_cronbachs_alpha output"

      parameters:
        data: "reliability_results['alpha_full']"
        min_val: 0.0
        max_val: 1.0
        column_name: "alpha_full"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "alpha_full in [0, 1]"
        - "alpha_purified in [0, 1]"
        - "alpha_purified_SB_adjusted in [0, 1]"
        - "CI_lower <= alpha <= CI_upper for all paradigms"
        - "All 3 paradigms present (IFR, ICR, IRE)"
        - "n_items_purified <= n_items_full"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step04_reliability_assessment.log"

    log_file: "logs/step04_reliability_assessment.log"

  # --------------------------------------------------------------------------
  # STEP 5: Correlation Analysis with Steiger's Z-Test
  # --------------------------------------------------------------------------
  - name: "step05_correlation_analysis"
    step_number: "05"
    description: "Test if Purified CTT correlates more strongly with IRT theta than Full CTT (Steiger's z-test with dual p-values per D068)"

    analysis_call:
      type: "catalogued"
      module: "tools.analysis_ctt"
      function: "compare_correlations_dependent"
      signature: "compare_correlations_dependent(r12: float, r13: float, r23: float, n: int) -> Dict[str, Any]"

      input_files:
        - path: "data/step02_ctt_full_scores.csv"
          required_columns: ["UID", "test", "CTT_full_IFR", "CTT_full_ICR", "CTT_full_IRE"]
          variable_name: "ctt_full"
        - path: "data/step03_ctt_purified_scores.csv"
          required_columns: ["UID", "test", "CTT_purified_IFR", "CTT_purified_ICR", "CTT_purified_IRE"]
          variable_name: "ctt_purified"
        - path: "data/step00_theta_scores.csv"
          required_columns: ["composite_ID", "theta_IFR", "theta_ICR", "theta_IRE"]
          variable_name: "theta_scores"
          purpose: "IRT theta as convergent validity criterion"

      output_files:
        - path: "data/step05_correlation_analysis.csv"
          description: "Steiger's z-test results with dual p-values per Decision D068"
          columns: ["paradigm", "r_full", "r_purified", "delta_r", "steiger_z", "p_uncorrected", "p_bonferroni", "normality_test_p", "linearity_flag"]
          expected_rows: 3
          variable_name: "correlation_results"
        - path: "data/step05_steiger_assumptions_report.txt"
          description: "Assumption validation report for Steiger's test"
          variable_name: "assumptions_report"

      parameters:
        alpha_bonferroni: 0.05
        n_comparisons: 3
        test_direction: "one-tailed"
        hypothesis: "r_purified > r_full"
        paradigms: ["IFR", "ICR", "IRE"]

      returns:
        type: "Dict[str, Any]"
        variable_name: "correlation_results"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_contrasts_d068"
      signature: "validate_contrasts_d068(contrasts_df: DataFrame) -> Dict[str, Any]"

      input_files:
        - path: "data/step05_correlation_analysis.csv"
          variable_name: "correlation_results"
          source: "compare_correlations_dependent output"

      parameters:
        contrasts_df: "correlation_results"
        required_p_columns: ["p_uncorrected", "p_bonferroni"]

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "BOTH p_uncorrected AND p_bonferroni columns present (Decision D068)"
        - "r_full in [-1, 1]"
        - "r_purified in [-1, 1]"
        - "p_uncorrected in [0, 1]"
        - "p_bonferroni in [0, 1]"
        - "All 3 paradigms present"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step05_correlation_analysis.log"

    log_file: "logs/step05_correlation_analysis.log"

  # --------------------------------------------------------------------------
  # STEP 6: Z-Standardize Measurements
  # --------------------------------------------------------------------------
  - name: "step06_standardize_measurements"
    step_number: "06"
    description: "Grand-mean center and scale all measurements to z-scores for comparable LMM coefficients"

    analysis_call:
      type: "stdlib"
      operations:
        - "Load data/step02_ctt_full_scores.csv"
        - "Load data/step03_ctt_purified_scores.csv"
        - "Load data/step00_theta_scores.csv (from Step 0 dependency)"
        - "Load data/step00_tsvr_mapping.csv (from Step 0 dependency)"
        - "Merge theta, Full CTT, Purified CTT, TSVR on composite_ID (UID_test)"
        - "For each paradigm (IFR, ICR, IRE):"
        - "  - Compute grand mean and SD for theta_[paradigm] across 400 observations"
        - "  - Z-standardize: z_theta_[paradigm] = (theta - mean) / SD"
        - "  - Compute grand mean and SD for CTT_full_[paradigm]"
        - "  - Z-standardize: z_CTT_full_[paradigm] = (CTT_full - mean) / SD"
        - "  - Compute grand mean and SD for CTT_purified_[paradigm]"
        - "  - Z-standardize: z_CTT_purified_[paradigm] = (CTT_purified - mean) / SD"
        - "Validate: mean(z_*) ~ 0, SD(z_*) ~ 1 (tolerance 0.01)"
        - "Save data/step06_standardized_scores.csv"

      input_files:
        - path: "data/step02_ctt_full_scores.csv"
          required_columns: ["UID", "test", "CTT_full_IFR", "CTT_full_ICR", "CTT_full_IRE"]
          variable_name: "ctt_full"
        - path: "data/step03_ctt_purified_scores.csv"
          required_columns: ["UID", "test", "CTT_purified_IFR", "CTT_purified_ICR", "CTT_purified_IRE"]
          variable_name: "ctt_purified"
        - path: "data/step00_theta_scores.csv"
          required_columns: ["composite_ID", "theta_IFR", "theta_ICR", "theta_IRE"]
          variable_name: "theta_scores"
        - path: "data/step00_tsvr_mapping.csv"
          required_columns: ["composite_ID", "TSVR_hours", "test"]
          variable_name: "tsvr_mapping"

      output_files:
        - path: "data/step06_standardized_scores.csv"
          description: "Z-standardized measurements for parallel LMM fitting"
          columns: ["composite_ID", "UID", "test", "TSVR_hours", "z_theta_IFR", "z_theta_ICR", "z_theta_IRE", "z_CTT_full_IFR", "z_CTT_full_ICR", "z_CTT_full_IRE", "z_CTT_purified_IFR", "z_CTT_purified_ICR", "z_CTT_purified_IRE"]
          expected_rows: 400
          variable_name: "standardized_scores"

      parameters:
        paradigms: ["IFR", "ICR", "IRE"]
        tolerance: 0.01

      returns:
        type: "pd.DataFrame"
        variable_name: "standardized_scores"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_standardization"
      signature: "validate_standardization(df: DataFrame, column_names: List[str], tolerance: float = 0.01) -> Dict[str, Any]"

      input_files:
        - path: "data/step06_standardized_scores.csv"
          variable_name: "standardized_scores"
          source: "stdlib operations output"

      parameters:
        df: "standardized_scores"
        column_names: ["z_theta_IFR", "z_theta_ICR", "z_theta_IRE", "z_CTT_full_IFR", "z_CTT_full_ICR", "z_CTT_full_IRE", "z_CTT_purified_IFR", "z_CTT_purified_ICR", "z_CTT_purified_IRE"]
        tolerance: 0.01
        expected_mean: 0.0
        expected_sd: 1.0

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "Mean(z_*) in [-0.01, 0.01] for all 9 z-score columns"
        - "SD(z_*) in [0.99, 1.01] for all 9 z-score columns"
        - "No NaN values in z_* columns"
        - "All 400 rows present"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step06_standardize_measurements.log"

    log_file: "logs/step06_standardize_measurements.log"

  # --------------------------------------------------------------------------
  # STEP 7: Fit Parallel LMMs and Compare AIC
  # --------------------------------------------------------------------------
  - name: "step07_fit_parallel_lmms"
    step_number: "07"
    description: "Fit 9 parallel LMMs (3 paradigms x 3 measurement types) with AIC comparison"

    analysis_call:
      type: "catalogued"
      module: "tools.analysis_lmm"
      function: "fit_lmm_trajectory_tsvr"
      signature: "fit_lmm_trajectory_tsvr(theta_scores: DataFrame, tsvr_data: DataFrame, formula: str, groups: str = 'UID', re_formula: str = '~Days', reml: bool = False) -> MixedLMResults"

      input_files:
        - path: "data/step06_standardized_scores.csv"
          required_columns: ["composite_ID", "UID", "test", "TSVR_hours", "z_theta_IFR", "z_theta_ICR", "z_theta_IRE", "z_CTT_full_IFR", "z_CTT_full_ICR", "z_CTT_full_IRE", "z_CTT_purified_IFR", "z_CTT_purified_ICR", "z_CTT_purified_IRE"]
          variable_name: "standardized_scores"

      output_files:
        - path: "data/step07_lmm_model_comparison.csv"
          description: "Parallel LMM AIC comparison and coefficients"
          columns: ["paradigm", "AIC_IRT", "AIC_full", "AIC_purified", "delta_AIC_full_purified", "delta_AIC_purified_IRT", "coef_intercept_IRT", "coef_slope_IRT", "coef_intercept_full", "coef_slope_full", "coef_intercept_purified", "coef_slope_purified", "cohen_kappa", "convergence_flag_IRT", "convergence_flag_full", "convergence_flag_purified", "random_structure"]
          expected_rows: 3
          variable_name: "lmm_comparison"
        - path: "data/step07_lmm_convergence_report.txt"
          description: "LMM convergence diagnostics and LRT results if simplification needed"
          variable_name: "convergence_report"

      parameters:
        formula: "Score ~ TSVR_hours + (TSVR_hours | UID)"
        groups: "UID"
        reml: false
        convergence_fallback: "LRT-based simplification per Bates 2015"
        paradigms: ["IFR", "ICR", "IRE"]
        measurement_types: ["IRT", "Full", "Purified"]

      returns:
        type: "MixedLMResults"
        variable_name: "lmm_comparison"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_lmm_convergence"
      signature: "validate_lmm_convergence(lmm_result: MixedLMResults) -> Dict[str, Any]"

      input_files:
        - path: "data/step07_lmm_model_comparison.csv"
          variable_name: "lmm_comparison"
          source: "fit_lmm_trajectory_tsvr output"

      parameters:
        lmm_result: "lmm_comparison"
        check_convergence: true
        check_singularity: true
        min_observations: 100

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "All convergence_flag_* = TRUE for valid AIC comparison"
        - "No singular fit (random effects variance > 0)"
        - "AIC_* > 0 (valid model fit)"
        - "All 3 paradigms present"
        - "No NaN values in AIC or coefficient columns"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step07_fit_parallel_lmms.log"

    log_file: "logs/step07_fit_parallel_lmms.log"

  # --------------------------------------------------------------------------
  # STEP 8: Prepare Comparison Plot Data
  # --------------------------------------------------------------------------
  - name: "step08_prepare_plot_data"
    step_number: "08"
    description: "Create plot source CSVs for correlation comparison and AIC comparison visualizations"

    analysis_call:
      type: "stdlib"
      operations:
        - "Load data/step05_correlation_analysis.csv"
        - "Load data/step07_lmm_model_comparison.csv"
        - "Reshape correlation results to long format (3 paradigms x 2 CTT types = 6 rows)"
        - "Create correlation comparison data with columns: paradigm, ctt_type, r, CI_lower, CI_upper"
        - "Extract AIC columns from LMM comparison (3 rows: 3 paradigms)"
        - "Create AIC comparison data with columns: paradigm, AIC_IRT, AIC_full, AIC_purified, delta_AIC_full_purified"
        - "Save data/step08_correlation_comparison_data.csv"
        - "Save data/step08_aic_comparison_data.csv"

      input_files:
        - path: "data/step05_correlation_analysis.csv"
          required_columns: ["paradigm", "r_full", "r_purified"]
          variable_name: "correlation_results"
        - path: "data/step07_lmm_model_comparison.csv"
          required_columns: ["paradigm", "AIC_IRT", "AIC_full", "AIC_purified", "delta_AIC_full_purified"]
          variable_name: "lmm_comparison"

      output_files:
        - path: "data/step08_correlation_comparison_data.csv"
          description: "Plot source data for correlation comparison (grouped bar chart)"
          columns: ["paradigm", "ctt_type", "r", "CI_lower", "CI_upper"]
          expected_rows: 6
          variable_name: "correlation_plot_data"
        - path: "data/step08_aic_comparison_data.csv"
          description: "Plot source data for AIC comparison (grouped bar chart)"
          columns: ["paradigm", "AIC_IRT", "AIC_full", "AIC_purified", "delta_AIC_full_purified"]
          expected_rows: 3
          variable_name: "aic_plot_data"

      parameters:
        paradigms: ["IFR", "ICR", "IRE"]
        ctt_types: ["Full", "Purified"]

      returns:
        type: "Tuple[pd.DataFrame, pd.DataFrame]"
        unpacking: "correlation_plot_data, aic_plot_data"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_dataframe_structure"
      signature: "validate_dataframe_structure(df: DataFrame, expected_rows: Union[int, Tuple[int, int]], expected_columns: List[str], column_types: Optional[Dict[str, type]] = None) -> Dict[str, Any]"

      input_files:
        - path: "data/step08_correlation_comparison_data.csv"
          variable_name: "correlation_plot_data"
          source: "stdlib operations output"
        - path: "data/step08_aic_comparison_data.csv"
          variable_name: "aic_plot_data"
          source: "stdlib operations output"

      parameters:
        df: "correlation_plot_data"
        expected_rows: 6
        expected_columns: ["paradigm", "ctt_type", "r", "CI_lower", "CI_upper"]

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "correlation_comparison_data: 6 rows (3 paradigms x 2 CTT types)"
        - "aic_comparison_data: 3 rows (3 paradigms)"
        - "r in [-1, 1]"
        - "CI_lower <= r <= CI_upper"
        - "AIC_* > 0"
        - "No NaN values in r, CI, or AIC columns"
        - "ctt_type contains only {'Full', 'Purified'}"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step08_prepare_plot_data.log"

    log_file: "logs/step08_prepare_plot_data.log"

# ============================================================================
# END OF ANALYSIS RECIPE
# ============================================================================
