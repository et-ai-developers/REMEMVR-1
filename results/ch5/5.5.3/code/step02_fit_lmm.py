#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step02
Step Name: fit_lmm
RQ: results/ch5/5.5.3
Generated: 2025-12-04

PURPOSE:
Fit Linear Mixed Model (LMM) with full 3-way Age_c x LocationType x Time
interaction to test whether age moderates source-destination memory forgetting.
This is a null hypothesis test (H0: no age moderation effect).

EXPECTED INPUTS:
  - data/step01_lmm_input.csv
    Columns: ['composite_ID', 'UID', 'test', 'TSVR_hours', 'log_TSVR',
              'Age', 'Age_c', 'LocationType', 'theta', 'se']
    Format: Long format (800 rows = 400 observations x 2 location types)
    Expected rows: ~800

EXPECTED OUTPUTS:
  - data/step02_lmm_model.pkl
    Format: Pickled statsmodels MixedLMResults object
    Description: Fitted LMM for downstream inference
  - data/step02_lmm_summary.txt
    Format: Plain text
    Description: Model summary (convergence, AIC/BIC, fixed/random effects)
  - data/step02_fixed_effects.csv
    Columns: ['term', 'coef', 'se', 'z', 'p', 'ci_lower', 'ci_upper']
    Format: CSV table (12 rows = 1 intercept + 11 terms)
    Expected rows: ~12

VALIDATION CRITERIA:
  - Model converged (converged=True)
  - 12 fixed effects present (intercept + 11 terms)
  - All SE > 0 (positive standard errors)
  - Random variances positive (intercept variance > 0)
  - AIC and BIC finite (not NaN or inf)
  - All 800 observations used (no data loss)

g_code REASONING:
- Approach: Fit LMM using statsmodels MixedLM with formula-based specification.
  The formula includes main effects (TSVR_hours, log_TSVR, Age_c, LocationType),
  2-way interactions (TSVR:Age_c, log_TSVR:Age_c, TSVR:LocationType,
  log_TSVR:LocationType, Age_c:LocationType), and 3-way interactions
  (TSVR:Age_c:LocationType, log_TSVR:Age_c:LocationType). Random effects
  include random intercept and TSVR_hours slope per participant.

- Why this approach: Formula-based specification is readable, matches 4_analysis.yaml
  directly, and allows statsmodels to handle design matrix creation automatically.
  REML=False (ML estimation) enables model comparison via AIC/BIC for future analyses.

- Data flow:
  1. Load step01_lmm_input.csv (800 rows)
  2. Create patsy design matrices from formula
  3. Fit MixedLM with groups='UID', re_formula='~TSVR_hours'
  4. Extract convergence status, fixed effects table, variance components
  5. Save model object (.pkl), summary (.txt), fixed effects (.csv)

- Expected performance: ~10-30 seconds on CPU (800 observations, 100 groups,
  12 fixed effects, 3 random effects per group = intercept + slope + residual)

IMPLEMENTATION NOTES:
- Analysis tool: statsmodels.regression.mixed_linear_model.MixedLM
- Validation tool: tools.validation.validate_lmm_convergence
- Parameters: REML=False (ML estimation for AIC/BIC comparison),
  method='lbfgs' (optimizer), maxiter=1000 (convergence iterations)
- Fixed effects formula uses treatment coding: LocationType[T.Destination]
  means Destination vs Source (reference)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = 5.5.3/ (rqY)
#   parents[2] = ch5/ (chX)
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from statsmodels.regression.mixed_linear_model import MixedLM
from statsmodels.formula.api import mixedlm

# Import validation tool
from tools.validation import validate_lmm_convergence

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.5.3 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step02_fit_lmm.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step02_lmm_model.pkl
#   CORRECT: data/step02_fixed_effects.csv
#   WRONG:   results/lmm_model.pkl          (wrong folder + no prefix)
#   WRONG:   data/lmm_model.pkl             (missing step prefix)
#   WRONG:   logs/step02_fixed_effects.csv  (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 02: Fit LMM with 3-Way Age x LocationType x Time Interactions")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Long-format LMM input (800 rows = 400 observations x 2 location types)
        # Purpose: Fit LMM to test age moderation of source-destination forgetting

        log("[LOAD] Loading LMM input data...")
        input_path = RQ_DIR / "data" / "step01_lmm_input.csv"
        lmm_input = pd.read_csv(input_path)
        log(f"[LOADED] step01_lmm_input.csv ({len(lmm_input)} rows, {len(lmm_input.columns)} cols)")

        # Validate expected structure
        expected_cols = ['composite_ID', 'UID', 'test', 'TSVR_hours', 'log_TSVR',
                         'Age', 'Age_c', 'LocationType', 'theta', 'se']
        if list(lmm_input.columns) != expected_cols:
            raise ValueError(f"Column mismatch. Expected: {expected_cols}, Got: {list(lmm_input.columns)}")
        if len(lmm_input) != 800:
            raise ValueError(f"Expected 800 rows, got {len(lmm_input)}")
        log(f"[VALIDATION] Input structure validated: 800 rows, 10 columns")

        # =========================================================================
        # STEP 2: Fit LMM with Formula-Based Specification
        # =========================================================================
        # Tool: statsmodels.formula.api.mixedlm
        # What it does: Fits linear mixed model with specified fixed and random effects
        # Fixed effects: Main effects (TSVR_hours, log_TSVR, Age_c, LocationType),
        #                2-way interactions (TSVR:Age_c, log_TSVR:Age_c, TSVR:LocationType,
        #                log_TSVR:LocationType, Age_c:LocationType),
        #                3-way interactions (TSVR:Age_c:LocationType, log_TSVR:Age_c:LocationType)
        # Random effects: Random intercept + TSVR_hours slope per participant (UID)
        # Expected output: MixedLMResults object with 12 fixed effects

        log("[ANALYSIS] Fitting LMM with 3-way Age_c x LocationType x Time interactions...")

        # Define formula (from 4_analysis.yaml specification)
        formula = (
            "theta ~ TSVR_hours + log_TSVR + Age_c + LocationType + "
            "TSVR_hours:Age_c + log_TSVR:Age_c + "
            "TSVR_hours:LocationType + log_TSVR:LocationType + "
            "Age_c:LocationType + "
            "TSVR_hours:Age_c:LocationType + log_TSVR:Age_c:LocationType"
        )

        # Random effects formula: random intercept + TSVR_hours slope per UID
        re_formula = "~TSVR_hours"

        log(f"[FORMULA] Fixed effects: {formula}")
        log(f"[FORMULA] Random effects: {re_formula}")
        log(f"[FORMULA] Grouping variable: UID")

        # Fit model with ML estimation (REML=False for AIC/BIC comparison)
        # method='lbfgs' is default optimizer, maxiter=1000 for convergence
        lmm_model = mixedlm(
            formula=formula,
            data=lmm_input,
            groups=lmm_input['UID'],
            re_formula=re_formula
        ).fit(reml=False, method='lbfgs', maxiter=1000)

        log(f"[DONE] Model fitting complete")
        log(f"[CONVERGENCE] Converged: {lmm_model.converged}")

        # =========================================================================
        # STEP 3: Extract Model Components
        # =========================================================================
        # Extract convergence status, AIC/BIC, fixed effects, random variances

        log("[EXTRACT] Extracting model components...")

        # Fixed effects table
        # Extract fixed effect names from fe_params index
        fe_names = lmm_model.fe_params.index.tolist()
        n_fe = len(fe_names)

        # Get confidence intervals
        conf_int = lmm_model.conf_int()

        # Extract only the fixed effects portion (first n_fe rows)
        fixed_effects = pd.DataFrame({
            'term': fe_names,
            'coef': lmm_model.fe_params.values,
            'se': lmm_model.bse_fe.values,
            'z': lmm_model.tvalues.iloc[:n_fe].values,
            'p': lmm_model.pvalues.iloc[:n_fe].values,
            'ci_lower': conf_int.iloc[:n_fe, 0].values,
            'ci_upper': conf_int.iloc[:n_fe, 1].values
        })
        log(f"[EXTRACT] Fixed effects: {len(fixed_effects)} terms")

        # Model summary statistics
        aic = lmm_model.aic
        bic = lmm_model.bic
        log_likelihood = lmm_model.llf
        n_obs = lmm_model.nobs
        n_groups = len(lmm_model.model.group_labels)  # Correct way to get number of groups

        log(f"[MODEL] AIC: {aic:.2f}, BIC: {bic:.2f}, LogLik: {log_likelihood:.2f}")
        log(f"[MODEL] N observations: {n_obs}, N groups (UIDs): {n_groups}")

        # Random effects variance components
        # statsmodels stores these in cov_re (covariance matrix of random effects)
        random_effects_cov = lmm_model.cov_re
        log(f"[RANDOM] Variance components extracted")

        # =========================================================================
        # STEP 4: Save Outputs
        # =========================================================================
        # Save model object (.pkl), summary text (.txt), fixed effects table (.csv)

        log("[SAVE] Saving model outputs...")

        # Save model object using statsmodels save method (NOT pickle.load)
        # CRITICAL: Use MixedLMResults.save() method to avoid patsy/eval errors
        model_path = RQ_DIR / "data" / "step02_lmm_model.pkl"
        lmm_model.save(str(model_path))
        log(f"[SAVED] Model object: step02_lmm_model.pkl")

        # Save model summary as text
        summary_path = RQ_DIR / "data" / "step02_lmm_summary.txt"
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("LMM SUMMARY - RQ 5.5.3 Step 02\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"Model Formula:\n{formula}\n\n")
            f.write(f"Random Effects Formula:\n{re_formula}\n\n")
            f.write(f"Grouping Variable: UID\n\n")
            f.write(f"Convergence Status: {lmm_model.converged}\n")
            f.write(f"N Observations: {n_obs}\n")
            f.write(f"N Groups (UIDs): {n_groups}\n\n")
            f.write(f"Model Fit Statistics:\n")
            f.write(f"  AIC: {aic:.4f}\n")
            f.write(f"  BIC: {bic:.4f}\n")
            f.write(f"  Log-Likelihood: {log_likelihood:.4f}\n\n")
            f.write("Fixed Effects:\n")
            f.write(fixed_effects.to_string(index=False))
            f.write("\n\n")
            f.write("Random Effects Variance-Covariance Matrix:\n")
            f.write(str(random_effects_cov))
            f.write("\n\n")
            f.write("=" * 80 + "\n")
        log(f"[SAVED] Model summary: step02_lmm_summary.txt")

        # Save fixed effects table
        fixed_effects_path = RQ_DIR / "data" / "step02_fixed_effects.csv"
        fixed_effects.to_csv(fixed_effects_path, index=False, encoding='utf-8')
        log(f"[SAVED] Fixed effects table: step02_fixed_effects.csv ({len(fixed_effects)} rows)")

        # =========================================================================
        # STEP 5: Validate Model Convergence
        # =========================================================================
        # Tool: validate_lmm_convergence from tools.validation
        # Validates: Model converged successfully with positive variance components

        log("[VALIDATION] Validating model convergence...")
        validation_result = validate_lmm_convergence(lmm_model)

        # Report validation results
        if isinstance(validation_result, dict):
            for key, value in validation_result.items():
                log(f"[VALIDATION] {key}: {value}")
        else:
            log(f"[VALIDATION] {validation_result}")

        # Check if validation passed
        if validation_result.get('converged', False):
            log("[VALIDATION] Model converged successfully")
        else:
            log("[WARNING] Model did not converge - results may be unreliable")

        # Additional validation checks
        log("[VALIDATION] Checking fixed effects count...")
        if len(fixed_effects) != 12:
            log(f"[WARNING] Expected 12 fixed effects, got {len(fixed_effects)}")
        else:
            log(f"[PASS] 12 fixed effects present as expected")

        log("[VALIDATION] Checking standard errors...")
        if (fixed_effects['se'] <= 0).any():
            log(f"[WARNING] Some standard errors are non-positive")
        else:
            log(f"[PASS] All standard errors positive")

        log("[VALIDATION] Checking AIC/BIC...")
        if np.isnan(aic) or np.isnan(bic) or np.isinf(aic) or np.isinf(bic):
            log(f"[WARNING] AIC or BIC is NaN/inf")
        else:
            log(f"[PASS] AIC and BIC are finite")

        log("[SUCCESS] Step 02 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
