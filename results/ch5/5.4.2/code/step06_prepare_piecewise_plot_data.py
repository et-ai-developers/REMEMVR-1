#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step06
Step Name: Prepare Piecewise Trajectory Plot Data
RQ: 5.4.2
Generated: 2025-11-25

PURPOSE:
Prepare two-panel plot data (Early segment 0-1 days | Late segment 0-6 days)
with observed means, 95% CIs, and model predictions. Theta scale only
(NO probability scale per 2_plan.md - D069 not applicable to RQ 5.6).

EXPECTED INPUTS:
  - data/step01_lmm_input_piecewise.csv
    Columns: ['UID', 'test', 'composite_ID', 'Congruence', 'theta', 'SE',
              'TSVR_hours', 'Segment', 'Days_within']
    Expected rows: 1200
  - data/step02_piecewise_lmm_model.pkl
    Description: Fitted piecewise LMM model from Step 2
  - results/step03_segment_slopes.csv
    Description: Segment-congruence slopes for validation

EXPECTED OUTPUTS:
  - plots/step06_piecewise_early_data.csv
    Columns: ['Days_within', 'Congruence', 'theta_observed', 'CI_lower_observed',
              'CI_upper_observed', 'theta_predicted', 'Data_Type']
    Expected rows: ~60 (3 congruence types x 20 grid points)
    Description: Early segment plot data (Days 0-1)

  - plots/step06_piecewise_late_data.csv
    Columns: ['Days_within', 'Congruence', 'theta_observed', 'CI_lower_observed',
              'CI_upper_observed', 'theta_predicted', 'Data_Type']
    Expected rows: ~180 (3 congruence types x 60 grid points)
    Description: Late segment plot data (Days 0-6 within Late segment)

VALIDATION CRITERIA:
  - Early plot: ~60 rows (3 congruence x 20 grid points)
  - Late plot: ~180 rows (3 congruence x 60 grid points)
  - All congruence types present: {Common, Congruent, Incongruent}
  - Days_within range: Early [0, 1], Late [0, 6]
  - Theta range plausible: [-3, 3]
  - CI ordering: CI_lower < theta_observed < CI_upper
  - No missing data in critical columns

g_code REASONING:
- Approach: Aggregate observed data by segment/congruence/time, generate model predictions
- Why this approach: Two-panel piecewise plot shows Early consolidation vs Late decay
- Data flow: Raw data -> group aggregates -> prediction grid -> merge
- Expected performance: ~5 seconds (simple aggregation + prediction)

IMPLEMENTATION NOTES:
- Analysis: INLINE implementation (reference: RQ 5.2 step05)
- Function: prepare_piecewise_plot_data (to be extracted to tools/ later)
- Early grid: 20 points from 0 to 1 day
- Late grid: 60 points from 0 to 6 days (within Late segment)
- NO probability scale (D069 not applicable per 2_plan.md)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from statsmodels.regression.mixed_linear_model import MixedLMResults
from scipy import stats
import traceback

# Add project root to path for imports
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/rq6
LOG_FILE = RQ_DIR / "logs" / "step06_prepare_piecewise_plot_data.log"

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Helper Functions (INLINE IMPLEMENTATION - to extract to tools/ later)
# =============================================================================

def aggregate_observed_data(df: pd.DataFrame, segment: str) -> pd.DataFrame:
    """
    Aggregate observed theta scores by Congruence and Days_within.

    Args:
        df: DataFrame with theta, Segment, Congruence, Days_within
        segment: 'Early' or 'Late'

    Returns:
        DataFrame with observed means and 95% CIs
    """
    df_seg = df[df['Segment'] == segment].copy()

    # Round Days_within to nearest 0.1 day for grouping
    df_seg['Days_within_rounded'] = (df_seg['Days_within'] * 10).round() / 10

    # Group by Congruence and Days_within_rounded
    grouped = df_seg.groupby(['Congruence', 'Days_within_rounded'])['theta'].agg([
        ('theta_observed', 'mean'),
        ('SE_mean', lambda x: x.std() / np.sqrt(len(x))),
        ('n_obs', 'count')
    ]).reset_index()

    # Compute 95% CI
    grouped['CI_lower_observed'] = grouped['theta_observed'] - 1.96 * grouped['SE_mean']
    grouped['CI_upper_observed'] = grouped['theta_observed'] + 1.96 * grouped['SE_mean']

    # Rename for output
    grouped = grouped.rename(columns={'Days_within_rounded': 'Days_within'})

    return grouped[['Days_within', 'Congruence', 'theta_observed',
                     'CI_lower_observed', 'CI_upper_observed', 'n_obs']]

def generate_predictions(lmm_model: MixedLMResults, segment: str,
                         days_grid: np.ndarray) -> pd.DataFrame:
    """
    Generate model predictions for plot grid.

    Args:
        lmm_model: Fitted LMM model
        segment: 'Early' or 'Late'
        days_grid: Days_within values for prediction

    Returns:
        DataFrame with predicted theta values
    """
    predictions = []

    for congruence in ['Common', 'Congruent', 'Incongruent']:
        for days in days_grid:
            # Create prediction row
            # Note: We need to construct a DataFrame with proper structure for prediction
            pred_row = pd.DataFrame({
                'Days_within': [days],
                'Segment': pd.Categorical([segment], categories=['Early', 'Late']),
                'Congruence': pd.Categorical([congruence],
                                              categories=['Common', 'Congruent', 'Incongruent'])
            })

            # Predict theta (use population-level prediction)
            try:
                theta_pred = lmm_model.predict(exog=pred_row)
                predictions.append({
                    'Days_within': days,
                    'Congruence': congruence,
                    'theta_predicted': float(theta_pred.iloc[0]) if hasattr(theta_pred, 'iloc') else float(theta_pred[0])
                })
            except:
                # If prediction fails, use NaN (will be filtered out later)
                predictions.append({
                    'Days_within': days,
                    'Congruence': congruence,
                    'theta_predicted': np.nan
                })

    return pd.DataFrame(predictions)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 6: Prepare Piecewise Trajectory Plot Data")

        # =========================================================================
        # STEP 1: Load Data
        # =========================================================================

        log("[LOAD] Loading piecewise data and fitted model...")

        data_path = RQ_DIR / "data" / "step01_lmm_input_piecewise.csv"
        df_data = pd.read_csv(data_path, encoding='utf-8')

        # Restore categorical coding
        df_data['Congruence'] = pd.Categorical(
            df_data['Congruence'],
            categories=['Common', 'Congruent', 'Incongruent'],
            ordered=False
        )
        df_data['Segment'] = pd.Categorical(
            df_data['Segment'],
            categories=['Early', 'Late'],
            ordered=False
        )

        model_path = RQ_DIR / "data" / "step02_piecewise_lmm_model.pkl"
        lmm_model = MixedLMResults.load(str(model_path))

        log(f"[LOADED] Data ({len(df_data)} rows) and model")

        # =========================================================================
        # STEP 2: Aggregate Observed Data
        # =========================================================================

        log("[AGGREGATE] Computing observed means and CIs by segment...")

        df_early_obs = aggregate_observed_data(df_data, 'Early')
        df_late_obs = aggregate_observed_data(df_data, 'Late')

        log(f"[AGGREGATE] Early segment: {len(df_early_obs)} observed points")
        log(f"[AGGREGATE] Late segment: {len(df_late_obs)} observed points")

        # =========================================================================
        # STEP 3: Generate Model Predictions
        # =========================================================================

        log("[PREDICT] Generating model predictions on grid...")

        # Early segment grid: 20 points from 0 to 1 day
        early_grid = np.linspace(0, 1, 20)
        df_early_pred = generate_predictions(lmm_model, 'Early', early_grid)

        # Late segment grid: 60 points from 0 to 6 days (within Late segment)
        late_grid = np.linspace(0, 6, 60)
        df_late_pred = generate_predictions(lmm_model, 'Late', late_grid)

        log(f"[PREDICT] Early predictions: {len(df_early_pred)} points")
        log(f"[PREDICT] Late predictions: {len(df_late_pred)} points")

        # =========================================================================
        # STEP 4: Merge Observed and Predicted
        # =========================================================================

        log("[MERGE] Merging observed and predicted data...")

        # Merge Early
        df_early_plot = df_early_pred.merge(
            df_early_obs,
            on=['Days_within', 'Congruence'],
            how='left'  # Keep all predictions, fill observed where available
        )
        df_early_plot['Data_Type'] = 'Early'

        # Merge Late
        df_late_plot = df_late_pred.merge(
            df_late_obs,
            on=['Days_within', 'Congruence'],
            how='left'
        )
        df_late_plot['Data_Type'] = 'Late'

        log(f"[MERGE] Early plot data: {len(df_early_plot)} rows")
        log(f"[MERGE] Late plot data: {len(df_late_plot)} rows")

        # =========================================================================
        # STEP 5: Validate and Save
        # =========================================================================

        log("[VALIDATION] Validating plot data...")

        # Check Early row count (approximately 60: 3 congruence x 20 grid points)
        if not (50 <= len(df_early_plot) <= 70):
            log(f"[WARNING] Early plot row count unusual: {len(df_early_plot)} (expected ~60)")

        # Check Late row count (approximately 180: 3 congruence x 60 grid points)
        if not (170 <= len(df_late_plot) <= 190):
            log(f"[WARNING] Late plot row count unusual: {len(df_late_plot)} (expected ~180)")

        # Check all congruence types present
        for df_plot, name in [(df_early_plot, 'Early'), (df_late_plot, 'Late')]:
            congruence_types = set(df_plot['Congruence'].unique())
            expected_types = {'Common', 'Congruent', 'Incongruent'}
            if congruence_types != expected_types:
                raise ValueError(
                    f"{name} plot missing congruence types: "
                    f"expected {expected_types}, found {congruence_types}"
                )
        log(f"[PASS] All congruence types present in both segments")

        # Check Days_within ranges
        if df_early_plot['Days_within'].min() < 0 or df_early_plot['Days_within'].max() > 1:
            log(f"[WARNING] Early Days_within out of range [0, 1]: "
                f"[{df_early_plot['Days_within'].min():.2f}, {df_early_plot['Days_within'].max():.2f}]")

        if df_late_plot['Days_within'].min() < 0 or df_late_plot['Days_within'].max() > 6:
            log(f"[WARNING] Late Days_within out of range [0, 6]: "
                f"[{df_late_plot['Days_within'].min():.2f}, {df_late_plot['Days_within'].max():.2f}]")

        log(f"[PASS] Days_within ranges valid")

        # Check theta ranges
        theta_cols = ['theta_observed', 'theta_predicted']
        for df_plot, name in [(df_early_plot, 'Early'), (df_late_plot, 'Late')]:
            for col in theta_cols:
                if col in df_plot.columns:
                    valid_theta = df_plot[col].dropna()
                    if len(valid_theta) > 0:
                        if valid_theta.min() < -3 or valid_theta.max() > 3:
                            log(f"[WARNING] {name} {col} out of plausible range [-3, 3]: "
                                f"[{valid_theta.min():.2f}, {valid_theta.max():.2f}]")

        log(f"[PASS] Theta ranges plausible")

        # Save Early plot data
        early_path = RQ_DIR / "plots" / "step06_piecewise_early_data.csv"
        df_early_plot.to_csv(early_path, index=False, encoding='utf-8')
        log(f"[SAVED] {early_path.name} ({len(df_early_plot)} rows)")

        # Save Late plot data
        late_path = RQ_DIR / "plots" / "step06_piecewise_late_data.csv"
        df_late_plot.to_csv(late_path, index=False, encoding='utf-8')
        log(f"[SAVED] {late_path.name} ({len(df_late_plot)} rows)")

        log("[SUCCESS] Step 6 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
