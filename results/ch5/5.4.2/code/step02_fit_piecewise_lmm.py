#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step02
Step Name: Fit Piecewise LMM with 3-Way Interaction
RQ: results/ch5/rq6
Generated: 2025-11-25

PURPOSE:
Fit piecewise linear mixed model testing the 3-way interaction:
Days_within * Segment * Congruence. This tests whether congruence effects
differ between Early consolidation (0-24h) and Late decay (24-168h) phases.

EXPECTED INPUTS:
  - data/step01_lmm_input_piecewise.csv
    Columns: ['UID', 'test', 'composite_ID', 'Congruence', 'theta', 'SE',
              'TSVR_hours', 'Segment', 'Days_within']
    Expected rows: 1200

EXPECTED OUTPUTS:
  - data/step02_piecewise_lmm_model.pkl
    Description: Fitted piecewise LMM model object (MixedLMResults)

  - results/step02_lmm_model_summary.txt
    Description: Full model summary text (fixed effects, random effects, fit stats)

VALIDATION CRITERIA:
  - Model converged successfully (no convergence warnings)
  - No singular fit (random effects variance > 0)
  - All 11 fixed effect terms present (4 main + 5 two-way + 2 three-way)
  - Gradient norm < 0.01

g_code REASONING:
- Approach: Fit full 3-way interaction model with random slopes
- Why this approach: Tests whether congruence benefit differs across segments
- Data flow: Piecewise input -> LMM fit -> model object + summary
- Expected performance: ~10-30 seconds (100 participants, random slopes may be slow)

IMPLEMENTATION NOTES:
- Analysis tool: tools.analysis_lmm.fit_lmm_trajectory_tsvr
- Validation tool: tools.validation.validate_lmm_convergence
- Formula: theta ~ Days_within * C(Segment, Treatment('Early')) * C(Congruence, Treatment('Common'))
- Random effects: ~Days_within (random intercepts + slopes by participant)
- Note: Random slopes model at N=100 lower boundary - may need fallback to intercepts-only
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import pickle
import traceback

# Add project root to path for imports
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis and validation tools
from tools.analysis_lmm import fit_lmm_trajectory
from tools.validation import validate_lmm_convergence

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/rq6
LOG_FILE = RQ_DIR / "logs" / "step02_fit_piecewise_lmm.log"

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 2: Fit Piecewise LMM with 3-Way Interaction")

        # =========================================================================
        # STEP 1: Load Piecewise Input Data
        # =========================================================================
        # Expected: 1200 rows with Segment, Congruence, Days_within variables
        # Purpose: Input data for piecewise LMM

        log("[LOAD] Loading piecewise LMM input from Step 1...")

        input_path = RQ_DIR / "data" / "step01_lmm_input_piecewise.csv"
        df_lmm = pd.read_csv(input_path, encoding='utf-8')

        log(f"[LOADED] {input_path.name} ({len(df_lmm)} rows, {len(df_lmm.columns)} cols)")

        # Restore categorical coding (lost in CSV save/load)
        df_lmm['Congruence'] = pd.Categorical(
            df_lmm['Congruence'],
            categories=['Common', 'Congruent', 'Incongruent'],
            ordered=False
        )
        df_lmm['Segment'] = pd.Categorical(
            df_lmm['Segment'],
            categories=['Early', 'Late'],
            ordered=False
        )

        log("[CODING] Categorical coding restored (Congruence ref='Common', Segment ref='Early')")

        # =========================================================================
        # STEP 2: Fit Piecewise LMM
        # =========================================================================
        # Tool: tools.analysis_lmm.fit_lmm_trajectory_tsvr
        # Formula: theta ~ Days_within * Segment * Congruence (3-way interaction)
        # Random effects: ~Days_within (random intercepts + slopes)

        log("[ANALYSIS] Fitting piecewise LMM with 3-way interaction...")
        log("[FORMULA] theta ~ Days_within * C(Segment, Treatment('Early')) * C(Congruence, Treatment('Common'))")
        log("[RANDOM] ~Days_within (random intercepts + slopes by UID)")

        # Define formula (3-way interaction)
        formula = (
            "theta ~ Days_within * C(Segment, Treatment('Early')) * "
            "C(Congruence, Treatment('Common'))"
        )

        # Fit model using fit_lmm_trajectory (data already in long format with Days_within)
        lmm_model = fit_lmm_trajectory(
            data=df_lmm,
            formula=formula,
            groups='UID',
            re_formula='~Days_within',
            reml=False  # Use ML for model comparison
        )

        log("[DONE] Model fitting complete")

        # =========================================================================
        # STEP 3: Save Model Object
        # =========================================================================
        # Output: data/step02_piecewise_lmm_model.pkl
        # Format: Pickle (MixedLMResults object)

        log("[SAVE] Saving fitted model object...")

        model_path = RQ_DIR / "data" / "step02_piecewise_lmm_model.pkl"
        lmm_model.save(str(model_path))

        log(f"[SAVED] {model_path.name}")

        # =========================================================================
        # STEP 4: Save Model Summary
        # =========================================================================
        # Output: results/step02_lmm_model_summary.txt
        # Contains: Fixed effects, random effects, fit statistics

        log("[SAVE] Saving model summary...")

        summary_path = RQ_DIR / "results" / "step02_lmm_model_summary.txt"
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("PIECEWISE LMM MODEL SUMMARY - RQ 5.6\n")
            f.write("=" * 80 + "\n\n")
            f.write("Formula:\n")
            f.write(f"  {formula}\n\n")
            f.write("Random Effects:\n")
            f.write("  ~Days_within | UID (random intercepts + slopes)\n\n")
            f.write("Model Summary:\n")
            f.write(str(lmm_model.summary()) + "\n")

        log(f"[SAVED] {summary_path.name}")

        # =========================================================================
        # STEP 5: Validate LMM Convergence
        # =========================================================================
        # Tool: tools.validation.validate_lmm_convergence
        # Checks: Convergence, singular fit, gradient norm

        log("[VALIDATION] Validating model convergence...")

        validation_result = validate_lmm_convergence(lmm_model)

        # Report validation results
        if isinstance(validation_result, dict):
            for key, value in validation_result.items():
                log(f"[VALIDATION] {key}: {value}")

            # Check for validation failures
            if 'passed' in validation_result and not validation_result['passed']:
                raise ValueError(
                    f"Validation failed: {validation_result.get('message', 'Unknown error')}"
                )
        else:
            log(f"[VALIDATION] {validation_result}")

        # Additional checks specific to 3-way interaction model
        n_fixed_effects = len(lmm_model.fe_params)
        if n_fixed_effects != 12:
            raise ValueError(
                f"Fixed effects count incorrect: expected 12 terms "
                f"(1 intercept + 4 main + 5 two-way + 2 three-way), found {n_fixed_effects}"
            )

        log(f"[PASS] All 12 fixed effect terms present")

        log("[SUCCESS] Step 2 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
