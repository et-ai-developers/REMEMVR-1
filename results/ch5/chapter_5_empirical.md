# Chapter 5: Empirical Results

## 5.0 Introduction

[TBD: 300-500 words]

---

## 5.1 Functional Form and Individual Differences in Forgetting Trajectories

Understanding the mathematical form of forgetting trajectories is fundamental to memory theory because different functional forms imply different underlying mechanisms. Ebbinghaus (1885) proposed logarithmic forgetting—rapid initial decline followed by a gradually slowing rate—suggesting that forgetting is proportional to the logarithm of time elapsed. In contrast, Wixted and Ebbesen (1991) argued for power-law forgetting, where forgetting rate decreases proportionally with elapsed time, consistent with temporal distinctiveness and scale-invariant memory processes. Alternative forms such as linear decay (simple trace degradation) or quadratic functions (two-phase consolidation) have also been proposed.

Beyond characterizing the average trajectory, it is equally important to understand individual differences. Do all participants forget at the same rate, or do forgetting trajectories vary systematically with factors like age, cognitive ability, or memory quality? Random slope analyses quantify this heterogeneity by testing whether forgetting rates vary across individuals.

This section examines these questions using model comparison methods (§4.3.2) and variance decomposition via random effects (§4.3.1). The overarching goal is to establish the functional form of VR episodic forgetting and determine the extent of individual variability in forgetting trajectories.

---

### 5.1.1 Functional Form of Forgetting Trajectories

**Research Question:** Which functional form best describes episodic forgetting trajectories across a 6-day retention interval?

**Hypothesis:** Logarithmic model, consistent with Ebbinghaus (1885).

**Analysis:** (§4.2.1, §4.2.2, §4.3.1, §4.3.2)
Sample: N=100 participants, 400 observations (4 test sessions per participant)
IRT: Two-pass GRM with omnibus factor "All". Pass 1 calibrated 105 items; item purification excluded 37 items (discrimination a < 0.4 or difficulty |b| > 3.0), retaining 68 items (64.8%) for Pass 2 calibration. Theta range: [-2.52, 2.73].
LMM: Extended model comparison of 66 candidate models using continuous time variable (TSVR_hours, range 1-246 hours) with random intercepts by participant. Models compared via AIC (REML=False). Best model weight < 0.30 triggered model averaging across 16 competitive models (ΔAIC < 2).

**Results:**

Observed memory decline followed a characteristic forgetting pattern with rapid early loss. Theta scores dropped 1.18 SD over 6 days: from θ = 0.67 (Day 0) to θ = -0.51 (Day 6), with the steepest decline occurring in the first 24 hours (Δθ = -0.55 SD). On the probability scale (Decision D069), performance fell from 76% correct initially to 30% correct by Day 6—a 46 percentage point decline approaching near-chance performance for three-option items.

Extended model comparison (66 models) revealed extreme model selection uncertainty. The single best-fitting model, PowerLaw_04 (α = 0.4, AIC = 866.61), captured only 5.6% of the Akaike weight, indicating a 94% probability that some other model in the candidate set was superior. Power-law models dominated the top rankings: the five highest-ranked models were all power-law variants (α = 0.2 to 0.7), collectively accounting for 24% of model support. Notably, the logarithmic model—originally hypothesized as best—ranked 33rd with AIC = 869.71 (ΔAIC = +3.10, weight = 1.2%). This represents an evidence ratio of 4.7:1 against the logarithmic form in favor of the best power-law model.

Given this high model selection uncertainty, model averaging was applied across the 16 competitive models (ΔAIC < 2), which collectively accounted for 57.1% of the model weight. The effective model diversity was Shannon H' = 2.71, equivalent to 15 equally plausible models. Model-averaged predictions yielded an effective power-law exponent of α_eff = 0.410, with prediction standard errors ranging from 0.001 to 0.046 (between-model variance).

These findings contradict the original hypothesis. Rather than logarithmic forgetting (Ebbinghaus, 1885), VR episodic memories followed power-law decay (Wixted & Ebbesen, 1991). The effective exponent α_eff = 0.410 is intermediate within the typical range reported for laboratory memory tasks (α = 0.2-0.8), suggesting that immersive VR episodes occupy a middle ground between highly distinctive autobiographical events (shallow decay, α ≈ 0.2) and impoverished word lists (steep decay, α ≈ 0.6-0.8). The power-law form implies that forgetting rate decreases proportionally with elapsed time—consistent with temporal distinctiveness theory (Brown, Neath, & Chater, 2007), where recent events are compressed in memory and thus less discriminable than remote events.

The paradigm shift from logarithmic to power-law forgetting occurred for three methodological reasons. First, the original analysis used a discrete Days variable (4 unique values) that could not stably estimate fractional exponents; the extended analysis used continuous TSVR_hours (295 unique values), providing sufficient resolution for power-law estimation. Second, the original analysis tested only 5 models and omitted power-law variants entirely despite citing Wixted and Ebbesen (1991) in the hypothesis; the extended analysis tested 66 models including 12 power-law specifications. Third, the original analysis selected a single best model (logarithmic, 48% weight), ignoring 52% probability that another model was better; the extended analysis applied model averaging, acknowledging extreme uncertainty and providing robust predictions weighted across competitive alternatives.

**Figure 5.1.1a:** [functional_form_theta.png](results/ch5/5.1.1/plots/functional_form_theta.png)
*Forgetting trajectory on theta scale. Gray points show observed means at four test sessions (T1-T4). Model-averaged predictions (line) follow power-law decay with effective exponent α = 0.410. Shaded region represents ±1.96 SE (between-model uncertainty). Rapid decline in first 24 hours, followed by gradual asymptotic approach. [NOTE: Current plot shows original logarithmic model; regeneration with model-averaged predictions pending.]*

**Figure 5.1.1b:** [functional_form_probability.png](results/ch5/5.1.1/plots/functional_form_probability.png)
*Forgetting trajectory on probability scale (Decision D069). Performance declined from 76% correct (Day 0) to 30% correct (Day 6), approaching chance (33% for three-option items). Non-linear pattern consistent with power-law decay on latent theta scale. [NOTE: Regeneration with model-averaged predictions pending.]*

---

### 5.1.2 Two-Phase Forgetting: Consolidation Window Hypothesis

**Research Question:** Do episodic memory data support a two-phase model with rapid initial decline (Day 0-1) followed by slower decay (Day 1-6)?

**Hypothesis:** Piecewise model with inflection at 48 hours (one night's sleep + consolidation window) will outperform continuous models, consistent with two-phase consolidation theory (Hardt et al., 2013).

**Analysis:** (§4.2.1, §4.3.1, §4.3.2, §4.3.3, §4.5.1)
Sample: N=100, 400 observations (inherited theta scores from RQ 5.1.1).
LMM: Three-test triangulation strategy: (1) Quadratic model testing Time² significance; (2) Piecewise model (inflection 48h) vs continuous model AIC comparison; (3) Early (0-48h) vs Late (48-240h) slope ratio extraction. Bonferroni correction: α = 0.05/15 = 0.003 (correcting for 15 Chapter 5 RQs). Random intercepts by participant; random slopes attempted but failed convergence (N=100 insufficient per Bates et al., 2015). Comprehensive assumption validation (§4.3.3) performed.

**Results:**

Three independent tests triangulated evidence for two-phase forgetting. Test 1 (quadratic term significance) yielded a positive and highly significant Time² coefficient (β = 0.000054, SE = 0.00001, z = 5.415, p < 0.001, well below Bonferroni α = 0.003). This positive coefficient indicates significant deceleration in forgetting rate—memory declines rapidly initially, then slows over time, producing concave-up curvature. The effect survived stringent multiple testing correction, suggesting robust evidence for non-linear trajectory form.

Test 2 (model comparison) compared piecewise and continuous models via AIC. The piecewise model (inflection at 48 hours) yielded AIC = 873.31, while the best continuous model from RQ 5.1.1 (logarithmic) yielded AIC = 873.71 (ΔAIC = -0.40). By conventional interpretation (Burnham & Anderson, 2002), |ΔAIC| < 2 indicates equivalent models—neither piecewise nor continuous provides meaningfully superior fit. This result is theoretically ambiguous: deceleration exists (Test 1 confirmed), but data cannot distinguish whether the transition is abrupt (sharp inflection at 48h) or gradual (smooth curve).

Test 3 (slope ratio) provided the strongest evidence for two-phase structure. The piecewise model estimated Early slope (0-48h) as β = -0.432 theta units/day (SE = 0.071, 95% CI [-0.572, -0.292]) and Late slope (48-240h) as β = -0.070 theta units/day (SE = 0.026, 95% CI [-0.121, -0.018]). The slope ratio was 0.161 (95% CI [0.032, 0.291])—Late forgetting proceeded at only 16.1% the rate of Early forgetting, a 6.2-fold difference. The Segment × Time interaction was highly significant (p < 0.000002), far exceeding the Bonferroni threshold and indicating dramatically different forgetting rates across phases. Using a conservative criterion (ratio < 0.5 = Late forgetting less than half Early rate), this result provides strong quantitative support for two-phase forgetting.

A supplementary practice-effects decomposition analysis (Step 7, added 2025-12-09) revealed an important ambiguity in interpreting the two-phase pattern. The practice decomposition model segmented trajectories into Practice phase (T1→T2, first retest) and Forgetting phase (T2→T4, subsequent tests), yielding AIC = 869.86 (ΔAIC = -3.45 relative to original piecewise model, indicating superior fit). Practice phase decline was β = -0.0033 theta units/day (SE = 0.0010, p = 0.001), whereas Forgetting phase decline was β = -0.0190 theta units/day (SE = 0.0031, p < 0.001). The Phase × Time interaction was highly significant (p < 0.000002), with Forgetting phase decline 5.7 times faster than Practice phase decline. This finding suggests that the apparent deceleration in forgetting may partially reflect retrieval practice effects: initial testing (T1→T2) provides retrieval practice that masks genuine forgetting, and the practice benefit saturates after the first retest, allowing "true" forgetting rate to emerge in T2→T4 interval. Current data cannot definitively separate consolidation (biological memory stabilization) from practice saturation (methodological artifact of repeated testing), leaving the mechanism of two-phase forgetting unresolved.

Assumption validation (§4.3.3) revealed marginal violations. Both quadratic and piecewise models passed residual normality (Shapiro-Wilk p = 0.099, 0.111), random effects normality (p = 0.057, 0.056), and outlier detection (<0.5% outliers). However, both models failed homoscedasticity (Breusch-Pagan p = 0.031, 0.049, marginally below 0.05 threshold) and temporal independence (Lag-1 ACF = -0.22, exceeding |0.1| threshold). These violations can inflate Type I error rates; however, primary effects were highly significant (p < 0.001), suggesting conclusions are robust despite assumption violations.

In summary, two-phase forgetting received strong empirical support from two of three triangulation tests (Tests 1 and 3), while Test 2 was inconclusive. The 6.2-fold difference in forgetting rates (0-48h vs 48-240h) is dramatic and highly significant. However, the mechanism remains ambiguous: deceleration may reflect biological consolidation (Hardt et al., 2013), retrieval practice saturation (Roediger & Karpicke, 2006), or both processes operating in tandem. The equivalence of piecewise and continuous models (Test 2, ΔAIC = -0.40) suggests that while two distinct rates exist, the transition between phases may be gradual rather than abrupt, challenging strict interpretations of discrete consolidation windows.

**Figure 5.1.2:** [piecewise_comparison.png](results/ch5/5.1.2/plots/piecewise_comparison.png)
*Model comparison: Continuous quadratic (left panel) vs piecewise inflection at 48h (right panel). Observed means (black points with error bars) fit both models. Left: Smooth concave-up curve (red line) shows gradual deceleration. Right: Two-phase structure (blue = Early 0-48h, green = Late 48-240h) shows steep initial slope followed by shallow late slope, with visible "kink" at 48h inflection (gray dashed line). Confidence bands (shaded regions) overlap substantially despite significant interaction (p < 0.000002), reflecting equivalent AIC (ΔAIC = -0.40). Visual supports Test 1 (deceleration visible) and Test 3 (dramatically different slopes), but explains Test 2 ambiguity (no obvious inflection in raw data).*

---

### 5.1.3 Age Effects on Baseline Memory and Forgetting Rate

**Research Question:** Does age predict episodic memory baseline ability and/or forgetting rate in immersive VR environments?

**Hypothesis:** Dual-deficit hypothesis predicts: (1) older adults have lower baseline memory (negative Age effect on intercept), and (2) older adults forget faster (negative Age × Time interaction).

**Analysis:** (§4.2.1, §4.3.1, §4.3.2, §4.5.1)
Sample: N=100, age range 20-70 years (M=44.6, SD=14.5), 400 observations. IRT theta scores inherited from RQ 5.1.1. Original analysis: Single Lin+Log model with Age × Time interactions, random slopes for time by participant, Bonferroni correction (α=0.017 for 3 tests). Extended analysis: 66 functional forms tested with Age interactions, 40 converged (61%), model averaging across 17 competitive models (ΔAIC < 2), best model SquareRoot+Lin (AIC=876.02, weight=9.9%). Practice decomposition analysis: Tested Age × Phase interaction (Practice T1→T2 vs Forgetting T2→T4) to rule out practice-effect confound.

**Results:**

The dual-deficit hypothesis received no empirical support. Model-averaged estimates (40 converged models) yielded Age_c β = -0.011 (SE = 0.016, p = 0.48, 95% CI [-0.042, 0.020]) for baseline memory. This coefficient indicates that a 1 SD increase in age (~14.5 years) predicts only 0.011 lower theta units at encoding—a Cohen's d-equivalent effect size of 0.01 (trivial by conventional standards). The effect was not statistically significant and the 95% CI spanned zero symmetrically, suggesting true effect near-zero rather than underpowered detection.

Age effects on forgetting rate were similarly null. For linear time slopes, Age × Time_c β = 0.000022 (SE = 0.00044, p = 0.96, based on 11 models). For logarithmic time slopes (early rapid forgetting), Age × Time_log_c β = 0.0013 (SE = 0.0090, p = 0.89, based on 10 models). Both coefficients were near-zero with extremely wide confidence intervals, indicating no systematic relationship between age and forgetting rate. Notably, in the original single-model analysis (Lin+Log), age × time coefficients were positive (β = +0.000015, +0.001), opposite the hypothesized direction—though model averaging revealed this as a functional-form artifact with true effects centered near zero.

Random effects decomposition revealed 74.9% of total variance resided between participants (random intercept ICC = 0.749), indicating substantial individual differences in baseline memory ability. However, only 0.004% of variance resided in random slopes (ICC = 0.00004), indicating negligible individual differences in forgetting rates—all participants followed essentially parallel trajectories despite differing baselines. This pattern is inconsistent with the dual-deficit hypothesis, which predicts heterogeneous forgetting rates correlated with age.

A supplementary practice-effects decomposition ruled out methodological confounds. If younger adults benefited disproportionately from retrieval practice at T1→T2, this could spuriously flatten age-related forgetting curves. However, the Age × Phase interaction was not significant (β = -0.0045, SE = 0.0055, p = 0.41). Both young and older adults showed equivalent practice benefits (Practice phase slope β_young = +0.0014, β_old = +0.0059, p > 0.05 for both), indicating that null age effects reflect genuine age-invariance in VR episodic forgetting rather than offsetting practice artifacts.

Extreme model selection uncertainty necessitated model averaging. The best single model (SquareRoot+Lin) captured only 9.9% of Akaike weight, with 17 competitive models (ΔAIC < 2) collectively accounting for 95% of support. Effective model diversity was H' = 2.71 (equivalent to 15.0 equally plausible models). Model-averaged estimates provide robust conclusions: age effects on both baseline memory and forgetting rate are trivial in magnitude (Cohen's d < 0.01) and statistically indistinguishable from zero across all competitive functional forms.

These findings converge with the growing literature on context-supported memory (Craik & Rose, 2012). Immersive VR environments provide rich multimodal spatial and temporal cues that scaffold memory encoding and retrieval. Such environmental support may compensate for age-related declines in strategic encoding and hippocampal pattern separation, yielding age-invariant memory trajectories. Alternatively, the present sample's age range (20-70) may not capture the steepest declines, which typically emerge after age 75 (Park & Festini, 2017). Floor effects may also constrain age differences: by Day 6, all age groups approached 30% correct (near-chance for three-option items), limiting discriminability.

**Cross-reference:** These null age effects contrast sharply with cognitive battery results (RQ 5.3.X, pending), where traditional verbal and visuospatial memory tasks show robust age-related declines. This dissociation supports the hypothesis that immersive VR provides unique cognitive scaffolding absent from standard neuropsychological assessments.

**Figure 5.1.3:** [age_tertile_trajectory.png](results/ch5/5.1.3/plots/age_tertile_trajectory.png)
*Forgetting trajectories by age tertile. Individual observations (solid circles) and LMM predictions (dashed lines) for Young (green, 20-38 yrs, N=33), Middle (orange, 38-55 yrs, N=34), and Older (red, 55-70 yrs, N=33) tertiles. Substantial scatter within tertiles and overlapping distributions across all timepoints visually confirm null age effects. High between-subject variability (random intercept ICC = 74.9%) evident in 4-unit theta range at each timepoint. All tertiles show general downward trend (forgetting) but no systematic age-graded ordering. Minimal separation at Day 6 (theta ≈ -0.5 for all ages) consistent with model-averaged Age_c β = -0.011 (p = 0.48, d ≈ 0.01).*

---

### 5.1.4 Individual Differences in Forgetting Rate: A Stable Cognitive Trait?

**Research Question:** What proportion of variance in forgetting rate (slopes) is between-person (stable individual differences) vs within-person (measurement error)?

**Hypothesis:** Substantial between-person variance exists in forgetting rate (ICC > 40%), indicating forgetting rate is a stable, trait-like individual difference.

**Analysis:** (§4.3.1, §4.3.2)
Sample: N=100, 400 observations (inherited from RQ 5.1.1). Extended model comparison: 65 functional forms tested with random slopes (~1 + Time | UID), 10 competitive models (ΔAIC < 2), all power-law or fractional exponent variants. Model averaging mandatory (best weight = 5.7%, effective N models = 17.6). Variance components extracted from covariance matrices: var_intercept, var_slope, cov_int_slope, var_residual. ICCs computed: ICC_intercept = var_intercept / (var_intercept + var_residual), ICC_slope = var_slope / (var_slope + var_residual).

**Results:**

Model averaging revealed a dramatic paradigm shift in interpreting individual differences in forgetting rate. The original single-model analysis (Lin+Log, AIC rank #24, ΔAIC = 3.81, weight = 0.8%) estimated random slope variance as var_slope = 0.000157, yielding ICC_slope = 0.05%—essentially zero between-person variability. This result suggested forgetting rate was entirely noise-dominated, with no trait-like stability. However, model averaging across 10 competitive power-law models (cumulative weight = 44.9%) revealed var_slope = 0.098, a 623-fold increase. The corresponding ICC_slope = 21.61% represents a 432-fold increase from the single-model estimate, elevating forgetting rate from "pure noise" (0.05%) to "moderate trait" (21.61%) classification by conventional ICC thresholds (20-40% = moderate clustering).

The functional form sensitivity of random slope variance is striking. All 10 competitive models were power-law or fractional exponent variants (α = 0.2 to 0.7, cube root, fourth root, log-log), collectively dominating the top AIC rankings. The Lin+Log model, which formed the basis of the original single-model conclusion, ranked 24th and was not competitive (ΔAIC = 3.81). Power-law models' superior fit stems from their ability to capture scale-invariant decay: participants differ not in linear rate per hour, but in proportional decay per time interval—a fundamentally different parameterization that distributes variance differently across intercepts and slopes.

Model-averaged variance components were: var_intercept = 0.422 (SD = 0.650 theta units), var_slope = 0.098 (SD = 0.313 theta units), var_residual = 0.319 (SD = 0.565 theta units), and cov_int_slope = -0.065 (r = -0.643). The intercept-slope correlation of r = -0.643 indicates a moderate-strong compensatory mechanism: participants with high baseline memory (large positive intercepts) tended to forget more slowly (negative slopes closer to zero), explaining 41.3% of slope variance. This correlation was substantially weaker than the Lin+Log estimate (r = -0.973), which approached collinearity and was biologically implausible. The model-averaged estimate (r = -0.643) falls within typical literature ranges and allows 58.7% of slope variance to remain independent of baseline ability—consistent with consolidation processes operating partially independently of encoding quality.

The ICC_intercept = 56.95% (baseline memory ability) was 2.6 times larger than ICC_slope = 21.61% (forgetting rate), indicating that individual differences in initial encoding are more stable than differences in consolidation/forgetting. However, both ICCs exceeded 20%, qualifying both as meaningful traits. The slope SD of 0.313 theta units is not negligible: this represents a range of ±0.63 theta units (±2 SD) in forgetting rate, equivalent to a difference between fastest and slowest forgetters of 1.26 theta units over the retention interval—comparable to the total population mean decline of 1.18 theta units (Day 0 to Day 6). Thus, forgetting rate heterogeneity spans nearly the full range of population-level forgetting, indicating substantial practical significance despite "moderate" ICC classification.

The hypothesis (ICC > 40%) was not strictly supported (ICC = 21.61%), but the conclusion shifts qualitatively: forgetting rate is NOT noise-dominated (as single-model analysis suggested), but rather a stable cognitive trait of moderate strength. This finding has implications for memory intervention research: if forgetting rates are trait-like, targeting consolidation processes (e.g., sleep optimization, spaced retrieval practice) may yield individualized benefits contingent on baseline forgetting rate. Conversely, if forgetting rates were pure noise (ICC ≈ 0%), such interventions would show uniform effects across individuals.

The 432-fold discrepancy between single-model and model-averaged ICC estimates underscores the critical importance of model averaging when functional form is uncertain. Variance decomposition is extraordinarily sensitive to trajectory shape: linear models allocate variance to intercepts and residuals (treating curvature as noise), whereas power-law models allocate variance to slopes (treating curvature as individual differences in decay rate). Model averaging hedges against this sensitivity by weighting across plausible functional forms, providing robust estimates that do not hinge on arbitrary single-model selection.

**Cross-reference:** The moderate ICC_slope (21.61%) contrasts with near-zero ICC_slope in RQ 5.1.3 age models (0.004%), where age did not explain slope variance. This suggests forgetting rate heterogeneity exists but is not captured by age—consistent with multifactorial influences (genetics, sleep quality, stress, prior expertise) operating independently of chronological age.

**Figure 5.1.4:** [variance_comparison.png](results/ch5/5.1.4/plots/variance_comparison.png)
*Variance component comparison: Lin+Log single model vs model-averaged (10 competitive models). Bar chart shows 623-fold increase in var_slope (0.000157 → 0.098), 11% decrease in var_intercept (0.476 → 0.422), and 3% increase in var_residual (0.310 → 0.319). Dramatic reallocation of variance from residuals/intercepts to slopes under power-law functional forms. Lin+Log model severely underestimated between-person heterogeneity in forgetting rate by treating power-law curvature as noise rather than individual differences in decay exponent.*

---

### 5.1.5 Latent Trajectory Profiles: Clustering on Random Effects

**Research Question:** Do distinct latent subgroups exist with qualitatively different forgetting trajectory patterns?

**Hypothesis:** K=2 or K=3 clusters will emerge, reflecting "high maintainers" (high baseline, slow forgetting) vs "rapid forgetters" (average/low baseline, fast forgetting).

**Analysis:** (§4.3.1, §4.6)
Sample: N=100 (model-averaged random effects from RQ 5.1.4). Clustering variables: random intercepts (baseline ability) and random slopes (forgetting rate) extracted from 5-model average (Log, PowerLaw α=0.3/0.5, CubeRoot, SquareRoot weighted by Akaike weights). K-means algorithm tested K=1 to K=10, optimal K selection via elbow method (largest second derivative of BIC curve). Cluster quality assessed via silhouette coefficient (s > 0.50 strong, 0.25-0.50 reasonable, <0.25 poor) and bootstrap stability (100 iterations, Jaccard ≥0.75 stable, <0.60 unstable). Variables z-scored prior to clustering.

**Results:**

Extended K selection (K=1 to K=10) identified K=3 via elbow method (second derivative = 38.52, strongest curvature), remedying BIC boundary overfitting at K=10. The three-cluster solution partitioned participants into: Cluster 0 (N=25, 25%, "Low Stable"), Cluster 1 (N=44, 44%, "High Maintainers"), and Cluster 2 (N=31, 31%, "Fast Learners"). All clusters exceeded 10% size threshold, ensuring adequate representation. However, cluster quality metrics revealed substantial limitations. The silhouette coefficient (s = 0.408) indicated weak structure (range 0.25-0.50), with average participants only 41% closer to their own cluster centroid than to the nearest alternative cluster. Bootstrap stability was poor (Jaccard = 0.293, 95% CI [0.00, 0.98]), far below the 0.75 threshold for stable clustering. This instability is expected when clustering on model-averaged random effects: incorporating functional form uncertainty (5 competing models) introduces appropriate variance that destabilizes cluster boundaries—a feature rather than flaw of robust uncertainty quantification.

Cluster centers (standardized scale) revealed interpretable profiles. Cluster 0 ("Low Stable") exhibited intercept_z = -1.40 (1.4 SD below mean baseline) and slope_z = -0.29 (slightly below-average decline rate). On raw theta scale, mean intercept = -0.78 and mean slope = -0.014 (near-zero, indicating stable low performance with minimal forgetting). Cluster 1 ("High Maintainers") showed intercept_z = +0.67 (above-average baseline) and slope_z = -0.62 (well-below-average decline rate), translating to raw intercept = 0.37 and slope = -0.030 (gradual decline from high baseline). Cluster 2 ("Fast Learners") had intercept_z = +0.17 (average baseline) and slope_z = +1.10 (well-above-average rate), corresponding to raw intercept = 0.10 and slope = +0.054—notably POSITIVE, indicating improvement over time rather than forgetting.

The emergence of Cluster 2 with positive slopes challenges the universal forgetting assumption. Thirty-one percent of participants showed upward trajectories (mean slope +0.054 theta units, range +0.017 to +0.116), consistent with retrieval practice effects, delayed consolidation, or test familiarization. This bidirectional heterogeneity (Clusters 0-1 declining/stable vs Cluster 2 improving) was invisible in single-model analyses, which averaged over improvement trajectories and diluted slope variance (RQ 5.1.4 ICC_slope = 0.05% for Lin+Log vs 21.6% for model-averaged). Model averaging preserved this heterogeneity by weighting across functional forms that differ in how they allocate variance between intercepts and slopes—power-law models (which dominated the competitive set) parameterize decay as proportional rate, making individual differences in exponent appear as slope variance.

The intercept-slope pattern across clusters supports a compensatory mechanism. Cluster 1 (high baseline) exhibited the slowest decline (slope = -0.030), while Cluster 0 (low baseline) showed near-zero slope (-0.014), and Cluster 2 (average baseline) actually improved (slope = +0.054). This negative correlation (r = -0.64 from RQ 5.1.4) suggests encoding quality influences consolidation dynamics: strong initial encoding may facilitate subsequent maintenance, whereas weak encoding offers little to consolidate. However, Cluster 2's improvement trajectory indicates practice effects can override initial encoding quality—participants with average baseline theta nonetheless showed largest positive gains, possibly reflecting greater room for learning or differential engagement with repeated testing.

Clustering instability (Jaccard = 0.293) limits generalizability. Wide 95% CI [0.00, 0.98] indicates some bootstrap samples recovered original clusters perfectly while others failed completely. This extreme variability reflects model averaging's incorporation of between-model uncertainty: different functional forms (Log vs PowerLaw α=0.3 vs PowerLaw α=0.5) yield different random slope estimates, and weighting across these models propagates this uncertainty into cluster assignments. The original single-model analysis (Log-only) achieved high stability (Jaccard = 0.929) but ignored model selection uncertainty (ΔAIC = 3.81 for Log vs best power-law model). The trade-off is clear: single-model clustering yields stable but potentially misspecified profiles, whereas model-averaged clustering yields unstable but appropriately uncertain profiles.

Given weak silhouette (0.408) and poor bootstrap stability (0.293), these clusters should be interpreted as provisional latent patterns rather than robust subgroups. The three-profile structure (low/stable, high/maintain, average/improve) is theoretically plausible and aligns with cognitive reserve theory (Cluster 1) and practice effects literature (Cluster 2), but replication in independent samples is necessary. Future work could apply mixture modeling with model selection uncertainty (e.g., Bayesian finite mixture models averaging over functional forms), which formalizes the integration of clustering and trajectory shape uncertainty within a unified probabilistic framework.

**Cross-reference:** These latent profiles do not align with age (RQ 5.1.3 showed null age effects), suggesting forgetting heterogeneity arises from factors orthogonal to chronological age—possibly encoding strategies, sleep quality, stress, or genetic variation in consolidation efficiency.

**Figure 5.1.5:** [cluster_scatter.png](results/ch5/5.1.5/plots/cluster_scatter.png)
*Three-cluster solution on model-averaged random effects. Scatter plot shows participants (colored points) in 2D space of standardized random intercepts (x-axis) and slopes (y-axis). Cluster 0 (red, N=25): Low baseline (-1.4 SD), stable slope (-0.3 SD). Cluster 1 (blue, N=44): High baseline (+0.7 SD), slow decline (-0.6 SD). Cluster 2 (green, N=31): Average baseline (+0.2 SD), improvement (+1.1 SD). Black stars mark cluster centers. Moderate overlap visible (silhouette = 0.408), with clearest separation on slope dimension (Cluster 2 vertically separated from others). Weak structure and bootstrap instability (Jaccard = 0.293) indicate provisional profiles, not robust subgroups. Positive slopes in Cluster 2 reveal bidirectional heterogeneity missed by single-model analyses.*

---

## 5.2 Domain-Specific Forgetting Patterns

Episodic memory comprises distinct components corresponding to what happened, where it occurred, and when it took place (Tulving, 1983). These "What/Where/When" domains may rely on dissociable neural systems—object recognition (ventral stream), spatial navigation (hippocampal place cells, parietal cortex), and temporal sequencing (prefrontal cortex, hippocampal time cells)—raising the possibility of domain-specific forgetting trajectories. Prior research suggests temporal information decays faster than spatial or semantic content (Friedman, 1993), potentially reflecting weaker encoding or greater interference susceptibility. Conversely, environmental support theory predicts spatial information (Where) benefits from rich contextual cues in immersive VR, yielding superior retention relative to abstract temporal order (When).

This section examines domain-specific forgetting using IRT-derived ability estimates for What, Where, and When components calibrated separately. If domains rely on distinct consolidation mechanisms or differ in encoding strength, forgetting trajectories should diverge: steeper slopes for vulnerable domains, shallower slopes for resilient domains. Null domain × time interactions would instead suggest a common forgetting mechanism operating uniformly across content types, with apparent domain differences reflecting only baseline encoding quality rather than differential decay rates.

---

### 5.2.1 Domain-Specific Forgetting Trajectories (What/Where/When)

**Research Question:** Are there domain-specific differences in the rate and pattern of episodic forgetting over 6 days?

**Hypothesis:** When (temporal order) will show faster forgetting than Where (spatial location) and What (object identity), consistent with prior literature suggesting temporal information is more fragile.

**Analysis:** (§4.2.1, §4.2.2, §4.3.1, §4.3.2)
Sample: N=100, 1,200 domain-specific observations (100 participants × 4 sessions × 3 domains in long format). IRT: Three-dimensional GRM with correlated factors (What/Where/When). Two-pass calibration: Pass 1 = 105 items (29 What, 50 Where, 26 When); purification excluded 35 items (a<0.4 or |b|>3.0); Pass 2 = 70 items (19 What, 45 Where, 6 When). Domain-specific theta scores estimated. LMM: Extended model comparison (66 functional forms), model averaging across 10 competitive models (ΔAIC<2, cumulative weight=54.8%). Best single model: Recip+Log (AIC=2532.42, weight=8.9%). Original Log model demoted to rank #43 (ΔAIC=+8.91, 89:1 evidence ratio against). Random intercepts and slopes by participant.

**Results:**

Extended model comparison revealed the original logarithmic model (RQ 5.1.1 functional form) was severely misspecified for domain-specific data. The Log model ranked 43rd of 66 models tested (AIC=2541.34), with an evidence ratio of 89:1 against it in favor of the best model (Recip+Log, AIC=2532.42). The best single model captured only 8.9% of Akaike weight, with 10 competitive models (ΔAIC<2) collectively accounting for 54.8% of support. This extreme model uncertainty (effective N models = 9.45) necessitated model averaging. The dominant functional form, Recip+Log, represents a two-process forgetting mechanism: rapid initial decay via the reciprocal term [1/(t+1)] operating over 0-24 hours (consolidation failure), followed by slow asymptotic decay via the logarithmic term [log(t+1)] operating beyond 24 hours (systems consolidation). This contrasts sharply with single-process Ebbinghaus-style logarithmic forgetting, aligning instead with Rubin and Wenzel's (1996) retention function combining multiple time scales.

Model-averaged trajectories on the theta scale showed near-identical patterns across What, Where, and When domains: all declined approximately 0.86 SD from Day 0 (θ≈0.52) to Day 6 (θ≈-0.34), with prediction SE increasing from 0.004 (early) to 0.069 (late) due to functional form extrapolation uncertainty. This theta-scale equivalence suggests domains share a common forgetting mechanism when measured on the latent ability scale, contradicting the hypothesis of domain-specific decay rates. However, transformation to probability scale via domain-specific IRT parameters revealed dramatic separation: What declined from 87% to 72% (15 percentage points), Where from 59% to 41% (18 points), and When from 19% to 5% (14 points). Critically, these differences reflect baseline encoding disparities (87% vs 59% vs 19% at Day 0) rather than differential forgetting rates—all domains showed parallel theta declines, but started at vastly different levels.

The When domain results constitute a measurement failure rather than a cognitive finding. Item purification excluded 20 of 26 When items (77%) for low discrimination (a<0.4), retaining only 6 items (23.1% vs 65.5% for What, 90.0% for Where). Performance was near floor throughout (5-19% probability), precluding meaningful inference about temporal forgetting trajectories. This floor effect likely reflects task difficulty: participants encoded temporal sequences during a single 10-minute VR session but were tested days later, with no retrieval practice for temporal order (unlike repeated exposure to What/Where via environmental exploration). The When domain's failure to discriminate across ability levels renders its trajectory uninterpretable—apparent "resilience" (shallow probability decline from 19% to 5%) is an artifact of floor compression, not preserved temporal memory.

Domain-specific forgetting rates (slopes) showed minimal differentiation after model averaging, despite individual models within the competitive set exhibiting weak Domain × Time interactions. Post-hoc contrasts from the original 5-model analysis (pre-averaging) indicated When vs What differences (p<0.001, Bonferroni-corrected α=0.0011), but these effects were small (f²<0.02) and likely unstable across functional forms. The inability to robustly detect domain × time interactions despite testing 66 models suggests either (1) true effect sizes are trivially small (below detection threshold for N=100), or (2) measurement error in When domain (6-item scale) attenuates power to detect interactions. The former interpretation is consistent with common-mechanism forgetting; the latter highlights the necessity of adequate item coverage for interaction detection.

Dual-scale reporting (Decision D069) prevented misinterpretation. Theta-scale results correctly identify parallel forgetting across domains (common mechanism), while probability-scale results reveal why domains appear different in raw performance (baseline encoding disparities, not differential decay). Future VR memory paradigms should redesign When tasks to achieve floor-to-ceiling range (e.g., coarser temporal bins, explicit temporal cues during encoding, retrieval practice for sequencing) before conclusions about temporal forgetting can be drawn.

**Cross-reference:** The two-process Recip+Log functional form (RQ 5.2.1) differs from the single-process power-law form (RQ 5.1.1, omnibus "All" factor). This discrepancy may reflect: (1) domain-specific data revealing finer temporal structure (1,200 obs vs 400 obs), (2) correlated-factors IRT introducing dependencies absent in omnibus calibration, or (3) functional form being data-structure dependent (long-format domain × time interactions favor composite models). Reconciling these competing forms requires direct model comparison using identical data structure (RQ 5.2.X pending).

**Figure 5.2.1a:** [trajectory_theta.png](results/ch5/5.2.1/plots/trajectory_theta.png)
*Domain-specific forgetting on theta scale (model-averaged, 10 models). What (blue), Where (green), When (orange) show near-identical trajectories: all decline ~0.86 SD from θ≈0.52 (Day 0) to θ≈-0.34 (Day 6). Shaded bands = ±1.96 SE from model averaging, widening over time (early SE=0.004, late SE=0.069) due to functional form extrapolation uncertainty. Scatter points = individual observations (N=1,200). Pattern supports common forgetting mechanism on latent ability scale.*

**Figure 5.2.1b:** [trajectory_probability.png](results/ch5/5.2.1/plots/trajectory_probability.png)
*Domain-specific forgetting on probability scale. What (blue): 87%→72% (high retention, clinically meaningful). Where (green): 59%→41% (moderate retention, approaching chance). When (orange): 19%→5% (FLOOR EFFECT, measurement failure). Clear domain separation reflects baseline encoding disparities (87% vs 59% vs 19% at Day 0), NOT differential forgetting rates. When domain's 77% item exclusion (6/26 retained) and floor compression (5-19% throughout) render trajectory uninterpretable. Dual-scale reporting (Decision D069) prevents misattribution of baseline differences to forgetting mechanisms.*

---

### 5.2.2 Domain-Specific Consolidation: Sleep-Dependent Spatial Memory Advantage?

**Research Question:** Do memory domains (What/Where) show different rates of forgetting during the early consolidation window (Day 0-1) versus later decay (Day 1-6)?

**Hypothesis:** Spatial memory (Where) should show greater consolidation benefit than object identity (What) due to hippocampal-dependent replay during sleep (Wilson & McNaughton, 1994; Rasch & Born, 2013).

**Analysis:** (§4.2.1, §4.3.1, §4.5.1)
Sample: N=100, 800 observations (100 participants × 4 tests × 2 domains). Theta scores inherited from RQ 5.2.1 domain-specific calibration. When domain excluded due to floor effect (RQ 5.2.1: 77% item exclusion, 5-19% probability). LMM piecewise model: theta ~ Days_within × Segment × Domain, with Early segment (Days 0-1) vs Late segment (Days 1-6). Random intercepts and slopes by participant. Bonferroni correction: α = 0.05/3 = 0.0167 (3 planned contrasts). Treatment coding: What = reference domain, Early = reference segment.

**Results:**

The two-phase forgetting pattern observed in omnibus analyses (RQ 5.1.2) replicated robustly within both domains. What domain showed Early slope β = -0.456 theta units/day (SE = 0.059, 95% CI [-0.573, -0.340]) declining to Late slope β = -0.071 (SE = 0.025, 95% CI [-0.121, -0.021]), an 84.4% reduction in forgetting rate. Where domain exhibited nearly identical dynamics: Early slope β = -0.433 (SE = 0.059, 95% CI [-0.549, -0.317]) declining to Late slope β = -0.085 (SE = 0.025, 95% CI [-0.134, -0.035]), an 80.4% reduction. The Segment × Time interaction was highly significant for both domains (p < 0.001), confirming that consolidation benefits are substantial and domain-general.

The critical three-way interaction (Days_within × Segment × Domain) tested whether spatial memory received preferential consolidation relative to object memory. This interaction was not significant (β = -0.037, SE = 0.087, z = -0.43, p = 0.671), failing to survive even liberal significance thresholds, let alone Bonferroni correction (α = 0.0167). Planned contrasts quantified domain differences within each segment: Where vs What in Early segment yielded β = 0.023 (SE = 0.084, p = 0.782, d = 0.029, 95% CI [-0.165, 0.223]), and in Late segment β = -0.014 (SE = 0.036, p = 0.699, d = -0.054, 95% CI [-0.248, 0.140]). All effect sizes were negligible (|d| < 0.06), with confidence intervals spanning zero symmetrically.

Consolidation benefit indices—defined as the magnitude of forgetting rate reduction from Early to Late segments—revealed a numerically opposite pattern to the hypothesis. What domain showed consolidation benefit of 0.385 theta units (95% CI [0.259, 0.512]), while Where showed 0.348 theta units (95% CI [0.222, 0.474]). Although this 0.037 difference was not significant (CIs overlap substantially), the direction contradicts hippocampal replay theory, which predicts spatial memories should benefit disproportionately from sleep consolidation. The observed pattern suggests either (1) hippocampal replay operates equivalently across What/Where domains in immersive VR (domain-general consolidation), or (2) VR's integrated object-location encoding weakens domain dissociability relative to unimodal laboratory tasks.

On the probability scale (Decision D069), domain trajectories were nearly superimposed. What declined from 65% correct (Day 0) to 48% (Day 6), a 17 percentage point drop. Where declined from 67% to 49%, an 18 point drop. The 1 percentage point separation at Day 6 is clinically and practically negligible—far below the threshold for differential assessment utility. Both domains remained well above chance (33% for three-option items) throughout the retention interval, indicating adequate measurement range despite substantial forgetting.

These findings converge with RQ 5.2.1's domain-general forgetting rates on the theta scale, now extended to test sleep-dependent consolidation mechanisms. The null three-way interaction (p = 0.671) and negligible effect sizes (|d| < 0.06) provide strong evidence against domain-specific consolidation in VR episodic memory. This contrasts with rodent studies showing preferential hippocampal replay of spatial trajectories during slow-wave sleep (Wilson & McNaughton, 1994). The discrepancy may reflect species differences, task complexity (integrated multi-domain episodes vs isolated spatial navigation), or VR-specific encoding that binds object identity and location into unified representations resistant to selective consolidation.

**Cross-reference:** RQ 5.1.2 identified two-phase forgetting with 6.2-fold rate reduction but left mechanism ambiguous (consolidation vs practice saturation). RQ 5.2.2 confirms the consolidation interpretation operates uniformly across What/Where domains, ruling out spatially selective replay as the dominant mechanism in immersive VR contexts.

**Figure 5.2.2a:** [piecewise_trajectory_theta.png](results/ch5/5.2.2/plots/piecewise_trajectory_theta.png)
*Piecewise domain-specific forgetting on theta scale. What (blue) and Where (green) show nearly parallel trajectories with clear two-phase structure: steep Early slopes (What β=-0.456, Where β=-0.433) transition to shallow Late slopes (What β=-0.071, Where β=-0.085) around 24 hours. Three-way interaction nonsignificant (p=0.671), indicating domain-general consolidation. Minimal vertical separation reflects baseline encoding equivalence after excluding When domain floor effect (RQ 5.2.1). [NOTE: Current plot outdated with 3 domains; regeneration with 2 domains pending (Step 16).]*

**Figure 5.2.2b:** [piecewise_trajectory_probability.png](results/ch5/5.2.2/plots/piecewise_trajectory_probability.png)
*Piecewise domain-specific forgetting on probability scale. What (blue): 65%→48% (17 point decline). Where (green): 67%→49% (18 point decline). Trajectories nearly superimposed (1 percentage point separation at Day 6), confirming negligible domain-specific consolidation effects. Both domains remain well above chance (33%, dotted line) throughout retention interval. Dual-scale reporting (Decision D069) shows equivalent consolidation benefits across domains despite theoretical predictions of spatial advantage. [NOTE: Plot regeneration pending.]*

---

### 5.2.3 Domain-Specific Age Effects: Hippocampal Aging Hypothesis

**Research Question:** Does the effect of age on forgetting rate vary by memory domain (What vs Where)?

**Hypothesis:** Hippocampal aging hypothesis (Raz et al., 2005) predicts greater age-related vulnerability in spatial memory (Where, hippocampal-dependent) compared to object identity (What, perirhinal-dependent).

**Analysis:** (§4.2.1, §4.3.1, §4.3.2, §4.5.1)
Sample: N=100, age range 20-70 years (M=44.6, SD=14.5), 800 observations (100 × 4 tests × 2 domains). Theta scores inherited from RQ 5.2.1. When domain excluded (floor effect). LMM with Age × Domain × Time three-way interactions, random intercepts by participant. Two time transformations tested: (1) Original Log-only model (TSVR_hours + log_TSVR, AIC=1549.27), (2) ROOT-updated Recip+Log model (recip_TSVR + log_TSVR, AIC=1466.20, ΔAIC=-83.07, converged with random slopes). Age continuous, grand-mean centered. Treatment coding: What=reference domain. Bonferroni correction: α=0.05/2=0.025 for two omnibus three-way interaction tests.

**Results:**

The hippocampal aging hypothesis received no empirical support across two functional forms differing dramatically in model fit. In the original Log-only model, both three-way Age × Domain × Time interactions were nonsignificant: TSVR_hours × Age_c × Where yielded β = -0.00006 (SE = 0.00009, z = -0.683, p = 0.495), and log_TSVR × Age_c × Where yielded β = 0.00246 (SE = 0.00317, z = 0.776, p = 0.438). Neither approached the Bonferroni threshold (α = 0.025), with p-values exceeding 0.4. The ROOT-updated Recip+Log model—which improved fit by ΔAIC = -83.07 and converged successfully with random slopes—replicated these null findings: recip_TSVR × Age_c × Where β = -0.0263 (SE = 0.0336, p = 0.432), and log_TSVR × Age_c × Where β = -0.0026 (SE = 0.0042, p = 0.545). Functional form sensitivity, which profoundly affected variance components (RQ 5.1.4: 623-fold increase) and best-fitting trajectory shape (RQ 5.1.1: power-law vs logarithmic), had no impact on the age × domain interaction conclusion—both models converged on robust null effects.

Domain-specific age slopes, evaluated at Day 3 (TSVR = 72 hours), were trivially small and statistically indistinguishable from zero. What domain showed age slope β = -0.000014 (SE = 0.000041, z = -0.336, p = 0.737, 95% CI [-0.000094, 0.000066]), while Where domain showed β = 0.000014 (SE = 0.000041, z = 0.336, p = 0.737, 95% CI [-0.000066, 0.000094]). The slopes were identical in magnitude (0.000014 theta units per year) but opposite in sign—likely reflecting numerical noise rather than true opposing trends. Over a 50-year age span (20 to 70 years), these slopes predict a cumulative decline of 0.035 SD (0.000014 × 50 years ÷ 0.80 residual SD), functionally negligible compared to the 1.18 SD population-level forgetting observed over 6 days (RQ 5.1.1).

These findings converge with RQ 5.1.3's omnibus null age effects (Age_c β = -0.011, p = 0.48, d = 0.01) to triangulate strong evidence against age-related memory decline in immersive VR contexts. RQ 5.1.3 tested age effects aggregated across all domains; RQ 5.2.3 tested whether age effects differ between What and Where domains specifically. Both analyses yielded null results with nearly identical effect sizes (|d| < 0.02), suggesting that VR episodic memory is not only age-invariant overall but also exhibits domain-general age-invariance—no differential vulnerability emerges for spatial vs object memory. This contradicts dual-process theory (Yonelinas, 2002), which predicts recollection (hippocampal, spatial) should decline faster with age than familiarity (perirhinal, object).

The discrepancy with neuroanatomical aging literature (Raz et al., 2005: 5% hippocampal volume decline per decade) may reflect: (1) functional compensation via entorhinal cortex or parahippocampal regions, (2) VR's rich multimodal encoding reducing reliance on isolated hippocampal processes, or (3) floor effects constraining age differences at Day 6 (performance approached 33% chance level for all ages in RQ 5.1.3). Alternatively, the present age range (20-70) may precede the steepest cognitive declines, which typically emerge after age 75 (Park & Festini, 2017). However, the near-zero slopes (β ≈ 0.00001) with symmetrical confidence intervals spanning zero suggest true null effects rather than underpowered detection—power analyses for RQ 5.1.3 (N=100, 400 obs) indicated adequate sensitivity for medium effects (d ≥ 0.50).

The robustness of null findings across Log-only (AIC=1549.27) and Recip+Log (AIC=1466.20) functional forms provides strong evidence against domain-specific age effects. Model comparison (ΔAIC = -83.07) decisively favors Recip+Log, yet both models reached identical substantive conclusions (p > 0.4 for three-way interactions). This functional form insensitivity contrasts sharply with variance decomposition (RQ 5.1.4: 432-fold ICC change) and trajectory interpretation (RQ 5.1.1: logarithmic vs power-law), where functional form was determinative. The pattern suggests age effects—when present—should replicate across plausible functional forms, whereas their absence indicates true null effects robust to model misspecification.

**Cross-reference:** These domain-general age effects align with RQ 5.2.2's domain-general consolidation (three-way p=0.671) and RQ 5.2.1's domain-general forgetting rates (parallel theta declines), forming a convergent pattern: immersive VR episodic memory exhibits domain-general mechanisms for forgetting, consolidation, and aging—contrary to predictions from domain-specific neural substrates.

**Figure 5.2.3:** [age_effects_by_domain.png](results/ch5/5.2.3/plots/age_effects_by_domain.png)
*Age effects on forgetting by domain. Two panels: What (left) and Where (right). Each panel shows forgetting trajectories for age tertiles: Young (green, 20-38 yrs), Middle (orange, 38-55 yrs), Older (red, 55-70 yrs). All tertiles exhibit declining trajectories over 0-250 hours, but lines overlap extensively within each domain (visualizing null three-way Age×Domain×Time interactions, p>0.4). Age slopes nearly zero (What β=-0.000014, Where β=+0.000014, p=0.737) with identical magnitude across domains. Substantial individual variability (scatter) evident at all ages. Pattern supports domain-general age-invariance in VR episodic memory. [NOTE: Current plot includes 3 domains (outdated); regeneration with 2 domains pending.]*

---

### 5.2.4 Convergent Validity: IRT Theta vs CTT Mean Scores

**Research Question:** Do IRT theta scores and CTT mean scores yield the same conclusions about domain-specific forgetting trajectories?

**Hypothesis:** IRT and CTT should converge at static measurement (r > 0.90 for within-domain correlations) but diverge in detecting individual differences in forgetting rates (IRT superior).

**Analysis:** (§4.2.1, §4.3.1, §4.3.2)
Sample: N=100, 800 observations (100 × 4 tests × 2 domains). IRT theta scores from RQ 5.2.1 (64 purified items: 17 What, 47 Where). CTT scores: unweighted mean of same 64 dichotomized items. Two LMM specifications tested: (1) Original Log-only model (score ~ log_TSVR × domain + (log_TSVR | UID)), (2) ROOT-updated Recip+Log model (score ~ recip_TSVR + log_TSVR + interactions + (recip_TSVR | UID)). Pearson correlations computed separately for What, Where, and Overall, with Holm-Bonferroni correction for multiple testing (3 comparisons).

**Results:**

Static convergence between IRT and CTT was exceptional. What domain yielded r = 0.906 (95% CI [0.887, 0.922], p < 0.001), exceeding the stringent 0.90 threshold for near-perfect correspondence. Where domain showed even tighter convergence (r = 0.970, 95% CI [0.963, 0.975], p < 0.001), the highest observed across all analyses. Overall correlation aggregating both domains reached r = 0.792 (95% CI [0.765, 0.817], p < 0.001), exceeding the liberal 0.70 threshold but falling below 0.90 due to between-domain baseline differences (What baseline θ ≈ 0.6 vs Where θ ≈ 0.6 on IRT scale, but What CTT ≈ 0.75 vs Where CTT ≈ 0.60). These correlations survived Holm-Bonferroni correction, indicating robust static convergence—IRT theta and CTT mean scores measure the same latent construct at individual timepoints, differing primarily in scaling (IRT unbounded ±2 SD vs CTT bounded 0-1 proportion).

Dynamic convergence—testing whether methods detect individual differences in forgetting rates—revealed critical functional form sensitivity. In the original Log-only model (AIC_IRT = 1546.92), IRT detected modest individual differences in forgetting rates (random slope variance = 0.021, SD = 0.145 theta units per log-hour), while CTT detected none (variance = 0.000, boundary estimate, indicating convergence failure). This suggested IRT's superiority for trajectory-level inference. However, ROOT model comparison (RQ 5.2.1: Recip+Log outperformed Log-only by ΔAIC = -8.91) prompted re-analysis. The Recip+Log model improved fit for both methods (IRT ΔAIC = -86.60, CTT ΔAIC = -56.21) and dramatically increased detected individual differences: IRT variance increased 71.8-fold (0.021 → 1.507, SD = 1.228), while CTT variance moved off boundary (0.000 → 0.022, SD = 0.148). CTT now detected individual variation—previously masked by Log-only misspecification—but IRT remained 68× more sensitive (variance ratio 1.507/0.022 = 68.5).

This functional form sensitivity parallels RQ 5.1.4's 623-fold ICC increase when shifting from linear to power-law models. Log-only specifications systematically underestimate individual differences by treating two-process forgetting (rapid consolidation failure via reciprocal term, slow systems consolidation via logarithmic term) as single-process decay. The Recip+Log form aligns with Rubin and Wenzel's (1996) retention function combining multiple time scales, capturing both early steep decline (0-24h, β_recip dominant) and late asymptotic decay (24-240h, β_log dominant). IRT's greater sensitivity (68× larger variance) likely reflects its ability to weight items by discrimination (a parameters), down-weighting noisy items that inflate CTT measurement error. CTT weights all items equally, conflating encoding quality with forgetting dynamics.

Coefficient agreement analysis revealed 75% raw agreement (3 of 4 fixed effects) but only moderate Cohen's κ = 0.500, below the 0.60 threshold for substantial agreement. The critical disagreement concerned domain main effects: IRT estimated Where vs What baseline difference as β = 0.069 (SE = 0.077, p = 0.369, nonsignificant), while CTT estimated β = -0.171 (SE = 0.017, p < 0.001, highly significant, indicating Where performed 17 percentage points lower than What). This discrepancy reflects scaling: IRT places What and Where on commensurate theta scales via correlated-factors calibration (RQ 5.2.1), whereas CTT's proportion-correct metric is sensitive to item difficulty distributions—Where items may be inherently harder (more discrimination variance, lower mean difficulty), producing spurious domain differences absent from IRT's difficulty-adjusted scale.

These findings support hybrid recommendations for VR memory assessment: IRT theta scores provide superior person-specific trajectory inference (68× greater sensitivity to forgetting rate heterogeneity) and valid cross-domain comparisons (difficulty-adjusted scaling), making them optimal for research applications testing individual differences or domain-specific mechanisms. CTT mean scores provide adequate static measurement (r > 0.90 within-domain convergence) and computational simplicity, making them suitable for clinical screening where single-timepoint assessment suffices. However, CTT's boundary estimate in Log-only models (variance = 0.000) illustrates a critical pitfall: methodological conclusions about "what CTT can detect" depend crucially on functional form specification. Proper two-process forgetting models (Recip+Log) allow CTT to detect individual differences—albeit less sensitively than IRT—challenging prior claims that CTT cannot capture dynamics.

**Cross-reference:** RQ 5.1.4 demonstrated 432-fold ICC increase when model averaging across power-law variants vs single linear model. RQ 5.2.4 extends this lesson to measurement theory: functional form misspecification (Log-only) masked individual differences for BOTH IRT and CTT, with CTT hitting boundary (complete masking) and IRT showing 71.8× underestimation. Proper functional form is prerequisite for valid inference about individual differences, regardless of measurement framework.

**Figure 5.2.4a:** [scatterplot_irt_ctt.png](results/ch5/5.2.4/plots/scatterplot_irt_ctt.png)
*IRT-CTT static convergence by domain. Left panel: What domain (r=0.906, near-perfect). Right panel: Where domain (r=0.970, highest observed). Scatterplots show IRT theta (x-axis, -2.5 to +2.5 SD) vs CTT proportion correct (y-axis, 0.0 to 1.0). Strong positive linear relationships with tight scatter around regression lines confirm exceptional static convergence (both r > 0.90). Where domain's tighter fit (smaller residual variance) explains higher correlation. Ceiling effects at CTT=1.0 visible (perfect accuracy compression). Pattern validates using IRT or CTT for single-timepoint assessment but highlights need for IRT in trajectory analyses.*

**Figure 5.2.4b:** [trajectory_comparison.png](results/ch5/5.2.4/plots/trajectory_comparison.png)
*IRT vs CTT forgetting trajectories over 0-160 hours. Two panels (What, Where), each showing IRT (circles, theta scale) and CTT (squares, proportion scale). Both methods capture qualitative pattern: consolidation boost (T1→T2 increase) followed by forgetting (T2→T4 decline). IRT trajectories show wider 95% CIs reflecting individual differences (Log-only: Var=0.021; Recip+Log: Var=1.507). CTT trajectories show narrower CIs (Log-only: Var=0.000 boundary; Recip+Log: Var=0.022). Scaling differences evident: IRT unbounded (±2 SD range) vs CTT bounded (0-1 range). Domain similarity: IRT shows parallel What/Where trajectories; CTT shows more separation (domain main effect disagreement, p<0.001 for CTT vs p=0.369 for IRT).*

---

### 5.2.5 Purification Effects: Does Item Quality Improve CTT-IRT Convergence?

**Research Question:** Does IRT purification (excluding poor-quality items) improve convergence between CTT mean scores and IRT theta scores?

**Hypothesis:** Purified CTT scores should show stronger correlations with IRT theta than Full CTT scores, because purification removes low-discrimination items that add noise to CTT sums.

**Analysis:** (§4.2.1, §4.2.2, §4.3.1, §4.3.2)
Sample: N=100, 400 observations (inherited from RQ 5.2.1). IRT purification: 105 items → 69 items (65.7% retention overall; What 65.5%, Where 90.0%, When 19.2%). Full CTT scores: unweighted mean of all 105 dichotomized items. Purified CTT scores: unweighted mean of 69 purified items. Convergence assessed via Pearson correlations computed separately per domain, tested with Steiger's z-test for dependent correlations (Bonferroni correction: α=0.05/3=0.0167). Parallel LMMs: All three measurement types (Full CTT, Purified CTT, IRT theta) fit with identical formulas to test trajectory fit. Two functional forms tested: (1) Original Log-only model with random slopes, (2) ROOT-updated Recip+Log model with random intercepts only.

**Results:**

The hypothesis received partial support contingent on domain-specific item pool quality. What domain showed purification benefit: correlation with IRT increased from r = 0.879 (Full CTT) to r = 0.906 (Purified CTT), a significant improvement (Δr = +0.027, Steiger's z = 10.06, p < .001, surviving Bonferroni correction). Where domain exhibited similar improvement: r = 0.940 → r = 0.955 (Δr = +0.015, z = 14.22, p < .001 Bonferroni-corrected), achieving the highest correlation observed across all convergence analyses (r = 0.955 represents near-perfect static measurement agreement). Both What and Where purification effects were statistically robust and theoretically meaningful—removing low-discrimination items reduced measurement error, tightening CTT-IRT correspondence.

The When domain exhibited a dramatically different pattern. Full CTT-IRT correlation was catastrophically low (r = 0.451), reflecting severe measurement failure in the 26-item temporal order pool. Purification appeared to rescue convergence (r = 0.838, Δr = +0.388, z = 2.09), representing an 86% increase in shared variance. However, this improvement failed to survive Bonferroni correction (p = .037 uncorrected, p = .111 corrected), and the apparent benefit is illusory: purification excluded 21 of 26 When items (81%), retaining only 5 items—an item pool far too sparse for reliable measurement (Cronbach's α = 0.616, 95% CI [0.551, 0.674]). The Δr = +0.388 reflects Full CTT's catastrophic failure rather than Purified CTT's success. When domain requires item redesign (coarser temporal bins, explicit sequencing cues during encoding), not just threshold adjustment.

Reliability assessment via Cronbach's alpha confirmed purification did not degrade internal consistency. What domain alpha remained stable (0.712 → 0.702, Δα = -0.010, 95% CIs overlap), as did Where domain (0.821 → 0.829, Δα = +0.007). When domain showed apparent improvement (0.575 → 0.616, Δα = +0.041), but this is an artifact of the 5-item pool—alpha estimates are unstable and unreliable with fewer than 10 items (Cortina, 1993). The critical finding is that What and Where purification preserved reliability while improving IRT convergence, indicating successful noise reduction without information loss.

Parallel LMM trajectory analysis revealed a purification-trajectory paradox. In the original Log-only model, purified CTT showed paradoxically worse trajectory fit than Full CTT: AIC rankings were IRT theta (1655.06, best) < Full CTT (1780.06, ΔAIC = +125.0) < Purified CTT (1812.26, ΔAIC = +157.2, worst). This counterintuitive ordering—better static correlations (r increased) but worse dynamic fit (AIC increased)—suggests that purification, by reducing item coverage, sacrifices the breadth of measurement needed for trajectory modeling. Full CTT's 105 items provide redundancy that buffers against idiosyncratic item-time interactions; Purified CTT's 69 items are more psychometrically pure but less robust to missing the nuances of forgetting dynamics.

The ROOT-updated Recip+Log model analysis (added 2025-12-10) dramatically amplified this paradox. While Full CTT and IRT theta both converged successfully (AIC: Full CTT 1789.15, IRT 1683.32), Purified CTT FAILED to converge—yielding a singular covariance matrix, indicating insufficient data to estimate random effects parameters. This convergence failure occurs because the Recip+Log model represents two-process forgetting (rapid consolidation failure via reciprocal term 0-24h, slow systems consolidation via logarithmic term 24-240h), requiring sufficient item-level variance to discriminate between early and late phases. Purified CTT's sparse item pools—especially When domain's 5 items—lack this variance, causing the optimizer to encounter a boundary solution where random slope variance collapses to zero. The pattern is clear: static measurement improves with purification (correlations increase), but dynamic measurement degrades (convergence fails), demonstrating a fundamental trade-off between item quality and item quantity for trajectory inference.

The IRT theta model showed robust superiority across both functional forms. In Log-only models, IRT outperformed both CTT variants by ΔAIC = 125-157, representing evidence ratios exceeding 10^27:1 in favor of IRT (Burnham & Anderson, 2002). In Recip+Log models, the IRT advantage increased: ΔAIC = +106 for Full CTT, while Purified CTT could not be evaluated due to convergence failure. This pattern confirms RQ 5.2.4's conclusion that IRT's discrimination-weighted scoring provides superior trajectory-level inference—a finding that holds regardless of functional form or purification status.

These findings carry methodological implications for VR memory assessment. Item purification improves CTT for single-timepoint cross-sectional measurement (r > 0.90 convergence with IRT for What/Where), making Purified CTT suitable for clinical screening where simplicity and interpretability matter. However, purification WORSENS CTT for longitudinal trajectory analysis, where model convergence failures expose item pool sparsity. IRT purification thus serves a dual purpose: (1) it identifies and removes low-quality items that should be redesigned (When domain's 77% exclusion rate signals fundamental task difficulty issues), and (2) it provides theta scores that support both static and dynamic inference without the purification-trajectory trade-off that afflicts CTT. The lesson is that CTT cannot salvage catastrophically poor item pools (<25% retention)—such scenarios require item redesign, not threshold adjustment.

**Cross-reference:** RQ 5.2.4 demonstrated 68× greater IRT sensitivity to individual differences in forgetting rates (random slope variance ratio 1.507/0.022). RQ 5.2.5 extends this by showing purification creates a static-dynamic dissociation for CTT: better correlations (static) but worse/non-convergent trajectory fit (dynamic). This dissociation does not occur for IRT, which maintains superior performance across both static and dynamic domains after purification.

**Figure 5.2.5a:** [correlation_comparison.png](results/ch5/5.2.5/plots/correlation_comparison.png)
*CTT-IRT correlation comparison by domain. Grouped bar chart: Blue = Full CTT, Orange = Purified CTT. What domain: Both >0.70, purified higher (r=0.906 vs 0.879, Δr=+0.027, p<.001 Bonferroni). Where domain: Both >0.90 (excellent), minimal visual gap (r=0.955 vs 0.940, Δr=+0.015, p<.001 Bonferroni). When domain: Large gap—Full CTT r=0.451 (catastrophic), Purified CTT r=0.838 (improvement not significant after correction, p=.111). Reference lines at r=0.70 (adequate) and r=0.90 (excellent). Asterisks mark Bonferroni-significant improvements (What, Where only). Pattern demonstrates domain-general purification benefit for What/Where, but When domain's improvement reflects Full CTT failure rather than Purified CTT success.*

**Figure 5.2.5b:** [aic_comparison.png](results/ch5/5.2.5/plots/aic_comparison.png)
*AIC comparison for parallel LMMs (Log-only model). Bar chart of ΔAIC relative to IRT theta baseline (0.0). Full CTT: ΔAIC = +125 (worse fit than IRT by 125 AIC units). Purified CTT: ΔAIC = +157 (worst fit, 32 AIC units worse than Full CTT). IRT theta: ΔAIC = 0.0 (reference, best fit). Reference lines: Black at ΔAIC=0.0 (IRT), orange dashed at ±2 (weak evidence), red dashed at ±10 (strong evidence). Paradoxical ordering: Purified CTT has better static correlations (Fig 5.2.5a) but worse dynamic trajectory fit, demonstrating purification-trajectory trade-off. IRT theta avoids this trade-off—superior fit for both static and dynamic inference.*

---

### 5.2.6 Domain-Specific Variance Decomposition: Trait-Like Forgetting?

**Research Question:** What proportion of variance in forgetting rate is between-person versus within-person for each memory domain (What, Where)?

**Hypothesis:** Forgetting rate is a stable trait-like individual difference (ICC_slope ≥ 0.40) in both domains, with Where domain showing higher ICC than What domain due to hippocampal-dependent recollection processes.

**Analysis:** (§4.2.1, §4.3.1, §4.4.2)
Sample: N=100, 800 observations (100 × 4 tests × 2 domains). Theta scores inherited from RQ 5.2.1. When domain excluded (floor effect). Domain-stratified LMMs: separate models per domain with formula theta ~ TSVR_hours + (TSVR_hours | UID). Random intercepts and slopes by participant. Bonferroni correction: α=0.01/2=0.005 for intercept-slope correlations (2 domains). ICC computed three ways: ICC_intercept (baseline variance proportion), ICC_slope_simple (slope variance ignoring covariance), ICC_slope_conditional (Day 6 variance accounting for intercept-slope correlation).

**Results:**

The hypothesis received strong support: both What and Where domains exhibited substantial between-person variance in forgetting outcomes. ICC_slope_conditional at Day 6 (144 hours post-encoding) reached 0.518 for What domain and 0.531 for Where domain, both exceeding the 0.40 threshold for "substantial" clustering by conventional ICC interpretation (Cicchetti, 1994). This indicates that approximately 52% of theta variance at the end of the retention interval reflects stable individual differences in memory consolidation, with the remaining 48% attributable to within-person fluctuation (measurement error, state-dependent factors, stochastic encoding variation). Forgetting rate is not noise-dominated but rather a meaningful cognitive trait with moderate-to-strong stability across the 6-day window.

The domain-specific ICC estimates revealed minimal practical differences. Where domain's ICC_slope_conditional (0.531) exceeded What domain (0.518) by only 1.3 percentage points—a difference so small as to suggest domain-general mechanisms for individual differences in forgetting. This null domain differentiation contrasts with theoretical predictions that hippocampal-dependent spatial memory (Where) should show greater individual variability due to reliance on pattern separation and consolidation processes known to exhibit high between-person variance (Stark et al., 2019). The pattern instead supports a general memory ability factor (g-factor) operating equivalently across What and Where domains in immersive VR contexts.

The ICC paradox—ICC_slope_simple < 0.02 versus ICC_slope_conditional > 0.50—requires careful interpretation. Simple slope ICC (0.008 for What, 0.011 for Where) computes the proportion of slope variance in isolation, ignoring intercept-slope correlations. With only 4 timepoints, slope estimation is unreliable when treated independently; nearly all variance appears residual. However, conditional ICC accounts for the joint distribution of intercepts and slopes at a specific timepoint (Day 6), incorporating the intercept-slope covariance. This reveals that high baseline performers (large positive intercepts) tend to maintain that advantage over time, even if their absolute forgetting rates (slopes) are similar to low performers. The conditional ICC thus captures the cumulative individual differences manifest at Day 6, whereas simple slope ICC artificially isolates a component with poor reliability in sparse longitudinal data.

Intercept-slope correlations tested the Fan Effect hypothesis: do high baseline performers show slower forgetting (negative correlation) or faster forgetting (positive correlation, regression to mean)? Where domain exhibited a significant negative correlation (r = -0.316, p_uncorrected = 0.001, p_bonferroni = 0.003), surviving stringent Bonferroni correction (α = 0.005). This indicates that participants with high spatial memory at Day 0 maintained their advantage more effectively than low performers—a pattern consistent with encoding quality facilitating subsequent consolidation. In contrast, What domain showed a positive trend (r = +0.272, p_uncorrected = 0.006) that failed Bonferroni correction (p_bonferroni = 0.012), suggesting no reliable relationship between object memory baseline and forgetting rate. This domain dissociation may reflect differential reliance on hippocampal consolidation: Where memory benefits from sleep-dependent spatial replay (Wilson & McNaughton, 1994), which preferentially strengthens already-strong spatial traces (Fan Effect), whereas What memory relies more on perirhinal familiarity processes less sensitive to encoding quality (Yonelinas, 2002).

Variance component decomposition quantified the sources of individual differences. What domain allocated 50.9% of total variance to random intercepts (baseline ability), 0.8% to random slopes (forgetting rate per se), and 48.3% to residuals (within-person noise). Where domain showed a similar partition: 56.7% intercepts, 1.1% slopes, 43.2% residuals. The dominance of intercept variance (50-57%) over slope variance (0.8-1.1%) indicates that stable individual differences primarily reflect encoding quality rather than consolidation efficiency. However, the ICC_slope_conditional metric (52-53%) reveals that by Day 6, intercept and slope contributions combine to produce substantial trait-like stability—individual differences in "who remembers well" at Day 6 are highly predictable from baseline ability, even if forgetting rates themselves vary minimally.

Cross-domain correlations among random effects (extracted for RQ 5.2.7 clustering) revealed extreme intercept correlation (r = 0.961) and strong slope correlation (r = 0.773) between What and Where domains. This near-unity intercept correlation suggests a powerful general episodic memory factor (g_episodic) dominating domain-specific variance: participants good at remembering object identity are almost perfectly predictive of spatial memory ability. The lower but still substantial slope correlation (r = 0.773) indicates moderate domain-general forgetting—individuals who forget objects quickly also tend to forget locations quickly, though with more domain-specific deviation than at baseline. This pattern aligns with hierarchical memory models where a superordinate g-factor explains 90%+ variance in baseline ability, with domain-specific factors contributing residual variance for forgetting dynamics.

These findings extend RQ 5.1.4's omnibus analysis (ICC_slope = 21.6% aggregated across all domains) by showing domain-stratified ICCs are 2.4-fold higher (52-53%). This amplification likely reflects reduced measurement error when domains are calibrated separately (RQ 5.2.1 domain-specific IRT) versus aggregated into an omnibus "All" factor (RQ 5.1.1). Domain-specific theta scores isolate What and Where variance more cleanly, reducing within-domain heterogeneity that inflates residual variance in omnibus models. The lesson: ICC estimates are sensitive to measurement granularity—domain-specific calibration reveals individual differences masked by omnibus aggregation.

**Cross-reference:** RQ 5.1.4 reported ICC_slope = 21.6% for omnibus "All" factor, contrasting with RQ 5.2.6's domain-specific ICCs of 52-53%. This discrepancy reflects measurement precision: domain-stratified IRT (RQ 5.2.1) reduces noise, revealing stronger trait-like variance. Both analyses converge on forgetting as a meaningful individual difference, differing only in magnitude. The Where domain's Fan Effect (r = -0.316) aligns with RQ 5.2.2's null consolidation advantage—spatial memory does not consolidate faster overall, but high spatial performers maintain advantages via quality-dependent replay.

**Figure 5.2.6:** [domain_icc_barplot.png](results/ch5/5.2.6/plots/domain_icc_barplot.png)
*Domain-specific ICC_slope_conditional at Day 6. Bar chart: What domain ICC = 0.518 (green bar), Where domain ICC = 0.531 (green bar), both exceeding dashed threshold line at ICC = 0.40 (substantial clustering). Y-axis spans 0.0-1.0, with threshold clearly marked. Minimal separation (1.3 percentage points) indicates domain-general trait-like forgetting. When domain absent (noted with annotation: "excluded due to floor effect"). Both ICCs above 0.50 indicate that majority of Day 6 variance is between-person (stable individual differences) rather than within-person (noise). Pattern supports forgetting as meaningful cognitive trait with moderate-to-strong stability, operant equivalently across object and spatial memory domains in immersive VR contexts.*

---

### 5.2.7 Latent Trajectory Profiles: Domain-Based Clustering

**Research Question:** Do distinct latent subgroups exist with qualitatively different forgetting trajectory patterns across What and Where domains?

**Hypothesis:** K=3-4 clusters will emerge, reflecting prototypical profiles: "High Maintainers" (high baseline, slow forgetting), "Average Decliners" (average baseline, typical forgetting), and "Rapid Forgetters" (low baseline, fast forgetting).

**Analysis:** (§4.3.1, §4.6)
Sample: N=100 participants. Clustering variables: 4 random effects per participant (What intercept, What slope, Where intercept, Where slope) extracted from RQ 5.2.6 model-averaged estimates (17-model ensemble weighted by Akaike weights). When domain excluded (floor effect, RQ 5.2.1). K-means algorithm tested K=1 to K=6, optimal K selected via BIC with parsimony rule (when ΔBIC < 2.0 between adjacent K, select smaller K). Variables z-scored prior to clustering. Cluster quality assessed via silhouette coefficient (cohesion), Davies-Bouldin index (separation), and bootstrap Jaccard stability (100 iterations, 80% subsampling).

**Results:**

The hypothesis received partial support: K=4 clusters emerged, identifying four prototypical trajectory profiles. BIC comparison revealed K=4 (BIC=91.86) and K=5 (BIC=91.86) as equivalent models (ΔBIC=0.001), triggering the parsimony rule that selected K=4 (fewer clusters preferred when fit equivalent). This differs from the original Log-only analysis (RQ 5.1.5, which selected K=5 with clear BIC minimum), suggesting that model averaging—by smoothing random effects across 17 competing functional forms—reduces spurious sub-clustering driven by single-model noise. All four clusters exceeded the 10% minimum size threshold (Cluster 0: N=36, 36%; Cluster 1: N=28, 28%; Cluster 2: N=17, 17%; Cluster 3: N=19, 19%), ensuring adequate representation without degenerate singleton clusters.

Cluster quality metrics revealed a stable-but-fuzzy structure. Bootstrap Jaccard stability was high (0.871, 95% CI [0.756, 1.000]), exceeding the 0.75 threshold for stable clustering—participants were reliably assigned to the same clusters across 100 resampling iterations, demonstrating robustness despite model averaging uncertainty. Davies-Bouldin index was 0.952 (threshold: <1.0 = good separation), indicating that cluster centroids were well-separated in the 4-dimensional What/Where intercept-slope space—the four prototypical profiles occupy distinct regions. However, silhouette coefficient was only 0.352 (threshold: >0.50 = strong, >0.40 = acceptable), indicating weak cohesion—the average participant was only 35% closer to their own cluster centroid than to the nearest neighboring cluster. This apparent contradiction (high stability, good centroid separation, but poor cohesion) reflects the nature of individual differences: prototypical profiles are distinct and replicable, but individual participants occupy a continuous distribution with substantial overlap between clusters. The clusters should thus be interpreted as "fuzzy prototypes" rather than discrete categories—useful for characterizing典型 trajectory patterns but not reflecting hard boundaries in the population.

The four cluster profiles revealed theoretically meaningful heterogeneity in baseline ability and trajectory dynamics. **Cluster 0 ("Average Decliners," 36%, largest group)** exhibited average baseline memory (What θ=0.284, Where θ=0.256, both near grand mean) with declining trajectories in both domains (What slope=-0.036 theta/day, Where slope=-0.028/day). This profile represents classic Ebbinghaus forgetting: reasonable encoding quality followed by gradual decay over 6 days, capturing the modal population pattern. **Cluster 1 ("Below-Average Improvers," 28%, second largest)** showed below-average baseline (What θ=-0.207, Where θ=-0.202) but surprising improvement trajectories (What slope=+0.037/day, Where slope=+0.039/day, both positive). This profile—representing 28% of the sample—challenges the universal forgetting assumption: nearly one-third of participants showed upward memory trajectories, consistent with retrieval practice effects (testing effect; Roediger & Karpicke, 2006) or sleep-dependent consolidation preferentially benefiting initially weak traces.

**Cluster 2 ("Low-Baseline Dissociators," 17%, smallest group)** revealed the most theoretically striking pattern: severely impaired baseline memory in both domains (What θ=-0.815, Where θ=-0.850, approximately 0.8 SD below population mean) combined with domain-dissociated trajectories—What memory was stable or improving (slope=+0.011/day, near-zero decline), while Where memory declined substantially (slope=-0.039/day, steepest decline of any cluster). This domain-selective consolidation pattern suggests differential plasticity across memory systems: perirhinal-dependent object recognition (What) retained consolidation capacity despite severe encoding deficits, whereas hippocampal-dependent spatial memory (Where) showed progressive decay. This dissociation occurred exclusively in the low-baseline group—high-ability individuals (Cluster 3) showed no such domain-specific vulnerability—indicating that consolidation failures may emerge selectively in spatial memory when encoding resources are limited. The finding has clinical relevance: low-memory individuals may benefit disproportionately from spatial rehearsal interventions targeting hippocampal consolidation.

**Cluster 3 ("High Maintainers," 19%)** exhibited superior baseline memory (What θ=0.497, Where θ=0.573, approximately 0.5 SD above population mean) with stable or improving trajectories (What slope=+0.004/day, near-zero; Where slope=+0.030/day, improving). This profile represents the "cognitive reserve" phenotype: strong initial encoding combined with preserved or enhanced consolidation, consistent with high cognitive capacity protecting against forgetting. Notably, Where memory improved more than What memory in this cluster (slope difference=+0.026/day), suggesting that high-baseline spatial encoding may facilitate sleep-dependent hippocampal replay—participants who encoded spatial layouts robustly at Day 0 showed continued strengthening across subsequent days, possibly reflecting offline consolidation during intervening sleep periods.

Cross-domain patterns revealed strong What-Where coupling with selective dissociation. The near-unity intercept correlation (r≈0.85, visually estimated from scatter matrix, quantified in RQ 5.2.6 as r=0.961) manifested as parallel baseline profiles across all four clusters—no cluster showed domain-selective baseline impairment (What≈Where for all clusters). This aligns with RQ 5.2.6's finding of a dominant general episodic memory factor (g_episodic) explaining 92% shared baseline variance. However, slope patterns revealed moderate What-Where correlation (r≈0.75), with Cluster 2's domain dissociation (What improving, Where declining) as the critical exception. This suggests that while baseline memory ability is highly domain-general (shared encoding quality), forgetting dynamics allow for domain-specific consolidation failures—particularly in individuals with limited cognitive resources (Cluster 2's low baseline).

An unexpected finding was the prevalence of improving memory trajectories. Aggregating across clusters, 47% of participants showed positive slopes in at least one domain: Cluster 1 (28%) improved in both domains, Cluster 3 (19%) showed stable What and improving Where. This is substantially higher than anticipated under traditional forgetting models (Ebbinghaus predicts universal decay). Three mechanisms may contribute: (1) **Retrieval practice effects**—four test sessions over 6 days provided repeated retrieval opportunities, known to strengthen memories (testing effect); (2) **Sleep consolidation**—participants slept three nights during the retention interval, allowing hippocampal replay to stabilize or enhance initially encoded traces (Wamsley, 2019); (3) **Model averaging artifact**—the 17-model ensemble was dominated by power-law models (ranks #1-5, cumulative weight 60%), which parameterize decay as proportional rate and may produce shallower or positive slopes compared to the logarithmic model (rank #10, 3.4% weight). The true proportion of "improvers" thus remains uncertain—falling between the lower bound of 28% (Cluster 1 only, robust across models) and upper bound of 47% (Clusters 1+3 combined, may include model averaging optimism).

These findings extend RQ 5.2.6's variance decomposition by identifying four prototypical patterns underlying the observed ICC_slope_conditional of 52-53%. RQ 5.2.6 demonstrated that forgetting rates are trait-like (substantial between-person variance); RQ 5.2.7 characterizes the qualitative structure of that variance: declining (Cluster 0, 36%), improving (Clusters 1+3, 47%), and domain-dissociated (Cluster 2, 17%). The fuzzy cluster boundaries (silhouette=0.352) combined with high stability (Jaccard=0.871) suggest these profiles represent peaks in a continuous distribution rather than discrete subpopulations—consistent with recent proposals that individual differences in cognition are better conceptualized as continuous dimensions with prototypical "attractors" rather than categorical types (Hedge et al., 2018).

**Cross-reference:** RQ 5.1.5 clustered omnibus "All" factor random effects (2 variables: intercept, slope) and identified K=3 profiles with 45% improvers. RQ 5.2.7 clustered domain-specific random effects (4 variables: What/Where intercepts and slopes) and identified K=4 profiles with 47% improvers. The additional cluster (K=4 vs K=3) captures Cluster 2's domain dissociation, which was invisible in omnibus analysis. Improver prevalence is similar (45% vs 47%), suggesting domain aggregation does not obscure improvement trajectories—consistent with high What-Where slope correlation (r=0.773, RQ 5.2.6).

**Figure 5.2.7a:** [bic_elbow.png](results/ch5/5.2.7/plots/bic_elbow.png)
*K-means model selection via BIC. Left panel: Elbow curve showing inertia (within-cluster sum of squares) declining monotonically from 396.0 (K=1) to 84.9 (K=6), with no clear inflection point. Right panel: BIC values showing minimum at K=4 (BIC=91.86) and K=5 (BIC=91.86, ΔBIC=0.001), followed by increase at K=6 (BIC=94.14). Red dashed line marks selected K=4. Black annotation highlights parsimony rule: when ΔBIC<2.0, smaller K preferred. Pattern demonstrates model averaging impact—original Log-only analysis selected K=5 with clear BIC minimum, whereas model-averaged random effects yield equivalent fit at K=4, triggering parsimony rule.*

**Figure 5.2.7b:** [cluster_scatter_matrix.png](results/ch5/5.2.7/plots/cluster_scatter_matrix.png)
*4×4 scatter matrix showing all pairwise relationships among clustering variables (What/Where intercepts and slopes). Points (N=100) colored by cluster: Blue (C0, Average Decliners, N=36), Orange (C1, Below-Average Improvers, N=28), Green (C2, Low-Baseline Dissociators, N=17), Red (C3, High Maintainers, N=19). Large black X markers show cluster centroids (N=4). Top-left quadrant (intercept vs intercept): Strong positive correlation (r≈0.85), with C2 (green) bottom-left (low baseline both domains), C3 (red) top-right (high baseline both domains), C0+C1 centered. Bottom-right quadrant (slope vs slope): Bimodal distribution visible—declining mode (C0 left, negative slopes) vs improving mode (C1+C3 right, positive slopes). Diagonal histograms reveal bimodal slope distributions (two peaks: negative and positive). Cluster separation: Centroids well-separated (explains Davies-Bouldin=0.952), but substantial member overlap visible (explains Silhouette=0.352). Green line (C2) crosses y=0 in slope panels, visualizing domain dissociation (What improving, Where declining).*

**Figure 5.2.7c:** [cluster_profiles.png](results/ch5/5.2.7/plots/cluster_profiles.png)
*Cluster profiles via parallel coordinates. Left panel (Baseline): Four horizontal lines show What/Where intercepts per cluster—C2 (green) lowest (-0.82 theta, severely impaired), C1 (orange) below-average (-0.20 theta), C0 (blue) average (0.27 theta), C3 (red) highest (0.54 theta, superior). All lines parallel (no crossing), confirming domain-general baseline ability. Right panel (Trajectories): Slope profiles reveal heterogeneity—C0 (blue) below zero (declining both domains), C1 (orange) above zero (improving both), C2 (green) CROSSES y=0 (What positive, Where negative, domain dissociation), C3 (red) above zero (improving, especially Where). Reference line at y=0 (no change) highlights that only C0 shows classic forgetting (negative slopes both domains), while C1+C3 (47% combined) show improving memory. Error bars (±1 SD) overlap y=0 for most clusters, indicating within-cluster heterogeneity.*

---

## 5.3 Retrieval Paradigm Effects: Free Recall, Cued Recall, and Recognition

Episodic memory is not assessed via a single uniform test but through diverse retrieval paradigms that vary in the amount of environmental support provided during recall. Free recall requires self-initiated retrieval with minimal cues, placing maximal demands on strategic search and monitoring processes mediated by prefrontal cortex. Cued recall provides partial environmental support (e.g., category labels, contextual prompts) that constrain search space and facilitate retrieval. Recognition presents complete target information, requiring only a familiarity judgment or recollection-based matching process supported by perirhinal and hippocampal systems (Yonelinas, 2002). Transfer-appropriate processing theory (Morris et al., 1977) predicts that retrieval paradigms tap different memory processes, raising the possibility of paradigm-specific forgetting trajectories.

Understanding paradigm effects is critical for VR memory assessment development. If paradigms show equivalent forgetting rates (parallel trajectories), a single paradigm suffices for measuring episodic decay. If paradigms diverge—with recognition retaining robustness while free recall deteriorates—assessment batteries must balance sensitivity (detecting subtle deficits) against floor effects (avoiding chance performance). Moreover, paradigm interactions with consolidation windows or individual differences would reveal whether retrieval support modulates offline memory stabilization.

This section examines these questions using IRT-calibrated ability estimates for three item-level retrieval paradigms: Item Free Recall (IFR), Item Cued Recall (ICR), and Item Recognition (IRE). Task-level paradigms (e.g., room recall, temporal order) are excluded due to severe floor effects documented in RQ 5.2.1 (When domain: 5-19% accuracy, 77% item attrition).

---

### 5.3.1 Paradigm-Specific Forgetting Trajectories

**Research Question:** Do Free Recall, Cued Recall, and Recognition exhibit different forgetting rates over 6 days?

**Hypothesis:** Recognition will show the slowest forgetting (most robust) due to reliance on familiarity-based processes, while Free Recall will show the fastest forgetting due to demands on strategic retrieval. Cued Recall predicted to fall intermediate.

**Analysis:** (§4.2.1, §4.2.2, §4.3.1, §4.3.2)
Sample: N=100, 1,200 observations (100 participants × 3 paradigms × 4 test sessions). IRT: Three-dimensional GRM with correlated factors (Free Recall, Cued Recall, Recognition). Two-pass purification: 72 items → 45 items retained (62.5%; Free=12, Cued=19, Recognition=14). Pass 2 discrimination range a∈[0.35, 1.89], difficulty range b∈[-2.93, 3.34]. Extended model comparison (66 models) identified extreme functional form uncertainty. Best model: PowerLaw_01 (α=0.1, weight=6.7%), but Log models essentially tied (rank #2-4, ΔAIC=0.07). Model averaging across 14 competitive models (ΔAIC<2, cumulative weight=57.9%) yielded effective α=0.140 (shallow power-law/log hybrid). Formula: theta ~ log_Days × Paradigm + (log_Days | UID). Treatment coding: Free Recall=reference. Bonferroni correction: α=0.05/3=0.0167 for 3 pairwise baseline comparisons.

**Results:**

The hypothesis was rejected: Recognition showed the **fastest forgetting**, not the slowest. Baseline differences emerged as predicted—Recognition exhibited significantly higher initial ability (θ=0.7) than Free Recall (θ=0.5, β=+0.210, z=3.15, p_bonf=.006, surviving stringent Bonferroni correction for 3 comparisons). Cued Recall (θ=0.6) also exceeded Free Recall numerically but failed to reach significance (β=+0.023, p=.726 uncorrected, p=1.000 Bonferroni). Recognition also surpassed Cued Recall at baseline (β=+0.187, p_bonf=.015). This baseline ordering aligns with the retrieval support gradient: recognition judgments benefit from complete target presentation, yielding higher Day 0 performance than self-initiated retrieval.

However, forgetting rate interactions revealed a paradoxical pattern. Recognition showed a negative time interaction (β=-0.127, z=-2.47, p=.013 uncorrected), indicating steeper decline than Free Recall's reference slope (β=-0.470). This interaction narrowly failed Bonferroni correction (p=.013 > α=.0167), rendering the finding suggestive but not definitive. Cued Recall's interaction was near-zero and nonsignificant (β=-0.051, p=.326), indicating parallel forgetting to Free Recall. Effect sizes were uniformly negligible (f²<0.01 for all interactions), suggesting that while statistical trends exist, practical differences in forgetting rates are minimal.

Trajectory visualization confirmed the paradox: Recognition started highest (θ=0.7) but declined most steeply (total decline=1.4 SD over 250 hours), crossing below Cued Recall around 150 hours and converging with Free Recall by Day 6 (all paradigms: θ≈-0.6 to -0.7). On the probability scale (Decision D069), Recognition declined from 58% to 32% (26 percentage point drop, 45% relative decline), while Free Recall declined from 55% to 35% (20 points, 36% decline) and Cued Recall from 64% to 37% (27 points, 42% decline). All paradigms converged to 32-37% probability by 250 hours—near chance for three-option items (33%)—indicating universal floor effects regardless of retrieval support.

This paradoxical pattern—Recognition's baseline advantage eroding faster than Free Recall's—contradicts dual-process theory predictions (Yonelinas, 2002) that familiarity-based recognition should resist forgetting. Three mechanisms may explain the reversal: (1) **Ceiling compression at encoding**: Recognition's high Day 0 performance (58-64% probability, θ=0.7) reflects easier initial retrieval, but this advantage may stem from lenient item difficulty rather than superior memory quality—when recognition items approach ceiling, regression to mean predicts steeper subsequent decline. (2) **Retrieval practice asymmetry**: Free recall's four test sessions provided repeated effortful retrieval that may have strengthened traces (testing effect; Roediger & Karpicke, 2006), whereas recognition's four tests involved passive matching with minimal reactivation—participants who actively reconstructed free recall responses consolidated those memories better than participants who merely endorsed familiar recognition foils. (3) **Floor effect artifact**: Recognition's steeper slope (β=-0.127) may partly reflect its lower Day 6 endpoint (θ=-0.7 vs -0.5 for Cued)—with all paradigms approaching 30-35% probability floor, Recognition had "further to fall" from its elevated baseline, mechanically producing steeper decline even if underlying forgetting processes were equivalent.

Model averaging impact was assessed via extended functional form comparison (added 2025-12-08). The original single-model analysis reported "logarithmic forgetting decisively superior" (99.99% Akaike weight), but extended testing across 66 models revealed this as dramatic overconfidence: Log weight dropped to 6.7% (15-fold overestimation), with PowerLaw α=0.1 and Log models essentially tied (ΔAIC=0.07). The 14 competitive models (ΔAIC<2) exhibited effective model diversity H'=12.90, equivalent to 13 equally plausible models—among the highest uncertainties observed across all RQs. However, substantive conclusions remained unchanged: paradigm baseline differences (Recognition > Cued ≈ Free) and interaction terms (Recognition × Time negative) were consistent across all top models, differing only in magnitude by <5%. What changed was epistemic humility: the original claim of "proven logarithmic forgetting" was replaced with acknowledgment that power-law (α=0.1-0.2) and logarithmic forms fit equivalently well, with model-averaged predictions hedging between both (effective α=0.140).

These findings have methodological implications for VR assessment design. Recognition's baseline advantage but accelerated forgetting suggests a fundamental trade-off: recognition paradigms maximize Day 0 sensitivity (detecting encoding deficits via 64% vs 55% baseline separation) but sacrifice longitudinal discriminability (all paradigms converge to 30-35% by Day 6, eliminating between-person variance). Free recall shows the opposite pattern: lower baseline sensitivity but sustained individual differences across the retention interval. For clinical applications targeting encoding disorders, recognition paradigms provide optimal acute assessment; for research targeting consolidation processes, free recall paradigms provide superior longitudinal resolution before floor effects dominate.

**Cross-reference:** This paradigm-by-time interaction mirrors RQ 5.2.5's purification-trajectory paradox: static measurement advantages (Recognition's high baseline, Purified CTT's tight IRT convergence) can degrade dynamic measurement (Recognition's steep decline, Purified CTT's convergence failure). Both demonstrate that optimizing single-timepoint performance does not guarantee optimal trajectory inference—VR memory paradigms must balance baseline sensitivity against longitudinal robustness.

**Figure 5.3.1a:** [trajectory_theta.png](results/ch5/5.3.1/plots/trajectory_theta.png)
*Paradigm-specific forgetting on theta scale. Free Recall (blue dashed, reference), Cued Recall (green dashed), Recognition (orange dashed). All show logarithmic/power-law decline (rapid 0-50h, asymptotic thereafter). Baseline ordering: Recognition (θ=0.7) > Cued (θ=0.6) ≈ Free (θ=0.5). Recognition trajectory STEEPEST: starts highest but ends lowest (θ=-0.7), crossing below Cued around 150h. Free/Cued trajectories nearly parallel (β interaction=-0.051, p=.326 n.s.). Convergence at Day 6: all paradigms θ≈-0.6 to -0.7 (floor effect). Shaded 95% CIs widen over time (extrapolation uncertainty). Confirms Recognition×Time negative interaction (β=-0.127, p=.013 uncorrected, p>.0167 Bonferroni n.s.).*

**Figure 5.3.1b:** [trajectory_probability.png](results/ch5/5.3.1/plots/trajectory_probability.png)
*Paradigm-specific forgetting on probability scale. Practical declines: Free 55%→35% (20pp, 36% relative), Cued 64%→37% (27pp, 42% relative), Recognition 58%→32% (26pp, 45% relative, steepest absolute drop). Baseline ordering (probability): Cued HIGHEST (64%), Recognition intermediate (58%), Free lowest (55%)—differs from theta ordering due to non-linear transformation. Endpoint convergence: all paradigms 32-37% by 250h, near chance (33% for 3-option items, dotted line). Recognition's 26pp decline despite modest 58% baseline reflects baseline-to-floor distance compression. Dual-scale reporting (Decision D069) reveals Recognition's baseline advantage erodes completely by Day 6—no residual benefit of retrieval support at long delays.*

---

## 5.4 Encoding Factors and Schema Effects

[TBD: Section introduction 150-200 words]

---

[RQs will be added here as they are processed]

---

## 5.5 Consolidation and Sleep-Dependent Memory

[TBD: Section introduction 150-200 words]

---

[RQs will be added here as they are processed]

---

## 5.6 Chapter Summary

[TBD: 500-800 words synthesizing across all 35 RQs]

**Major Findings:**

[TBD: Bullet list of 10-12 key results]

**Convergent Evidence:**

[TBD: Where multiple RQs triangulate on same conclusion]

**Divergent Evidence:**

[TBD: Contradictions or unexpected null results]

**Theoretical Implications:**

[TBD: What do results mean for episodic memory theory?]

**Methodological Insights:**

[TBD: What did VR paradigm reveal?]

**Limitations:**

[TBD: Cross-cutting issues]

**Bridge to Discussion:**

[TBD: Preview Chapter 6 integration with literature]

---

**END CHAPTER 5 (Empirical Results)**
