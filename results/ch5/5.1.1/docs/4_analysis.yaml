# ============================================================================
# ANALYSIS RECIPE - COMPLETE SPECIFICATION
# ============================================================================
# Generated: 2025-11-25
# RQ: ch5/5.1.1
# Agent: rq_analysis v4.0.0
# Purpose: Self-contained recipe for g_code agent (reads ONLY this file)
# ============================================================================

metadata:
  rq_id: "ch5/5.1.1"
  total_steps: 7
  analysis_type: "IRT 2-pass purification -> 5-model LMM comparison -> AIC selection"
  generated_by: "rq_analysis v4.0.0"
  timestamp: "2025-11-25T00:00:00Z"

# ============================================================================
# ANALYSIS STEPS - COMPLETE SPECIFICATIONS
# ============================================================================

steps:
  # --------------------------------------------------------------------------
  # STEP 1: IRT CALIBRATION PASS 1 (All Items)
  # --------------------------------------------------------------------------
  - name: "step01_irt_calibration_pass1"
    step_number: "01"
    description: "Calibrate single-factor GRM on all items (baseline for purification)"

    analysis_call:
      type: "catalogued"
      module: "tools.analysis_irt"
      function: "calibrate_irt"
      signature: "calibrate_irt(df_long: DataFrame, groups: Dict[str, List[str]], config: dict) -> Tuple[DataFrame, DataFrame]"

      input_files:
        - path: "results/ch5/5.2.1/data/step00_irt_input.csv"
          source: "RQ 5.1 Step 0 (DERIVED data - VR item responses extracted from master.xlsx)"
          format: "CSV, wide format (composite_ID x item columns)"
          required_columns:
            - name: "composite_ID"
              type: "str"
              description: "UID_test format (e.g., P001_T1)"
          variable_name: "irt_data"
          expected_rows: 400
          notes: "All What/Where/When items from interactive paradigms"

      output_files:
        - path: "data/step01_theta_scores.csv"
          format: "CSV, one row per composite_ID"
          columns:
            - name: "composite_ID"
              type: "str"
              description: "UID_test format"
            - name: "Theta_All"
              type: "float64"
              description: "IRT ability estimate for omnibus 'All' factor"
              range: "[-4, 4] typical"
            - name: "SE_All"
              type: "float64"
              description: "Standard error of theta estimate"
              range: "[0.1, 1.5] typical"
          expected_rows: 400
          variable_name: "theta_scores"
          description: "Pass 1 theta estimates (all items, before purification)"

        - path: "logs/step01_item_parameters.csv"
          format: "CSV, one row per item"
          columns:
            - name: "item_name"
              type: "str"
              description: "Item identifier (VR-* format)"
            - name: "dimension"
              type: "str"
              description: "Factor assignment (value: 'All' for all items)"
            - name: "a"
              type: "float64"
              description: "Discrimination parameter"
              range: ">0.0, typically [0.2, 4.0]"
            - name: "b"
              type: "float64"
              description: "Difficulty parameter"
              range: "unrestricted (temporal items may have |b|>3.0)"
          expected_rows: 105
          variable_name: "item_params"
          description: "Pass 1 item parameters for purification decision"

        - path: "logs/step01_calibration.log"
          format: "Text log"
          description: "IRT convergence diagnostics"
          variable_name: "log_file"

      parameters:
        df_long: "irt_data"
        groups:
          All:
            - "VR-*"
        config:
          factors:
            - "All"
          correlated_factors: false
          device: "cpu"
          seed: 42
          model_fit:
            batch_size: 2048
            iw_samples: 100
            mc_samples: 1
          model_scores:
            scoring_batch_size: 2048
            mc_samples: 100
            iw_samples: 100

      returns:
        type: "Tuple[DataFrame, DataFrame]"
        unpacking: "theta_scores, item_params"

    validation_call:
      module: "tools.validation"
      function: "validate_irt_convergence"
      signature: "validate_irt_convergence(results: Dict[str, Any]) -> Dict[str, Any]"

      input_files:
        - path: "logs/step01_item_parameters.csv"
          source: "analysis call output (calibrate_irt return value[1])"
          variable_name: "item_params"
        - path: "data/step01_theta_scores.csv"
          source: "analysis call output (calibrate_irt return value[0])"
          variable_name: "theta_scores"

      parameters:
        results:
          item_params: "item_params"
          theta_scores: "theta_scores"
          log_file: "logs/step01_calibration.log"

      criteria:
        - "Model converged (loss function stabilized)"
        - "Theta estimates in [-4, 4] range"
        - "SE estimates in [0.1, 1.5] range"
        - "Item discrimination a > 0"
        - "All 400 composite_IDs present"
        - "No NaN values"

      on_failure:
        action: "raise ValueError"
        log_to: "logs/step01_calibration.log"
        invoke: "g_debug"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

    log_file: "logs/step01_calibration.log"

  # --------------------------------------------------------------------------
  # STEP 2: ITEM PURIFICATION (Decision D039)
  # --------------------------------------------------------------------------
  - name: "step02_purify_items"
    step_number: "02"
    description: "Apply Decision D039 thresholds (|b|<=3.0, a>=0.4) to identify high-quality items"

    analysis_call:
      type: "catalogued"
      module: "tools.analysis_irt"
      function: "filter_items_by_quality"
      signature: "filter_items_by_quality(df_items: DataFrame, a_threshold: float = 0.4, b_threshold: float = 3.0) -> Tuple[DataFrame, DataFrame]"

      input_files:
        - path: "logs/step01_item_parameters.csv"
          source: "Step 1 output"
          required_columns:
            - "item_name"
            - "dimension"
            - "a"
            - "b"
          variable_name: "pass1_params"

      output_files:
        - path: "data/step02_purified_items.csv"
          format: "CSV, one row per retained item"
          columns:
            - name: "item_name"
              type: "str"
            - name: "pass1_a"
              type: "float64"
              description: "Pass 1 discrimination"
              range: ">=0.4 (threshold enforced)"
            - name: "pass1_b"
              type: "float64"
              description: "Pass 1 difficulty"
              range: "[-3.0, 3.0] (threshold enforced)"
            - name: "dimension"
              type: "str"
              description: "value: 'All'"
          expected_rows: "40-60 (40-60% retention typical)"
          variable_name: "purified_items"

        - path: "logs/step02_purification_report.txt"
          format: "Text report"
          description: "Excluded items with reasons"
          variable_name: "removed_items"

      parameters:
        df_items: "pass1_params"
        a_threshold: 0.4
        b_threshold: 3.0

      returns:
        type: "Tuple[DataFrame, DataFrame]"
        unpacking: "purified_items, removed_items"

    validation_call:
      module: "tools.validation"
      function: "validate_irt_parameters"
      signature: "validate_irt_parameters(df_items: DataFrame, a_min: float = 0.4, b_max: float = 3.0, a_col: str = 'Discrimination', b_col: str = 'Difficulty') -> Dict[str, Any]"

      input_files:
        - path: "data/step02_purified_items.csv"
          source: "analysis call output"
          variable_name: "purified_items"

      parameters:
        df_items: "purified_items"
        a_min: 0.4
        b_max: 3.0
        a_col: "pass1_a"
        b_col: "pass1_b"

      criteria:
        - "All retained items have a >= 0.4"
        - "All retained items have |b| <= 3.0"
        - "Retention rate 30-70%"
        - "No NaN values"

      on_failure:
        action: "raise ValueError"
        log_to: "logs/step02_purification_report.txt"
        invoke: "g_debug"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

    log_file: "logs/step02_purification_report.txt"

  # --------------------------------------------------------------------------
  # STEP 3: IRT CALIBRATION PASS 2 (Purified Items)
  # --------------------------------------------------------------------------
  - name: "step03_irt_calibration_pass2"
    step_number: "03"
    description: "Re-calibrate GRM with purified items only (final theta estimates)"

    analysis_call:
      type: "catalogued"
      module: "tools.analysis_irt"
      function: "calibrate_irt"
      signature: "calibrate_irt(df_long: DataFrame, groups: Dict[str, List[str]], config: dict) -> Tuple[DataFrame, DataFrame]"

      input_files:
        - path: "results/ch5/5.2.1/data/step00_irt_input.csv"
          source: "RQ 5.1 Step 0 (same raw data as Step 1)"
          variable_name: "irt_data_raw"
        - path: "data/step02_purified_items.csv"
          source: "Step 2 output"
          variable_name: "purified_items"

      output_files:
        - path: "data/step03_theta_scores.csv"
          format: "CSV, one row per composite_ID"
          columns:
            - name: "composite_ID"
              type: "str"
            - name: "Theta_All"
              type: "float64"
              description: "Final IRT ability estimate"
              range: "[-4, 4]"
            - name: "SE_All"
              type: "float64"
              description: "Final standard error"
              range: "[0.1, 1.5]"
          expected_rows: 400
          variable_name: "theta_scores"
          description: "FINAL theta estimates for LMM (Pass 2, purified items)"

        - path: "logs/step03_item_parameters.csv"
          format: "CSV, one row per purified item"
          columns:
            - name: "item_name"
              type: "str"
            - name: "dimension"
              type: "str"
            - name: "a"
              type: "float64"
            - name: "b"
              type: "float64"
          expected_rows: "40-60 (matches purified item count)"
          variable_name: "item_params"

        - path: "logs/step03_calibration.log"
          format: "Text log"
          variable_name: "log_file"

      parameters:
        df_long: "irt_data_raw"
        groups:
          All: "purified_items['item_name'].tolist()"
        config:
          factors:
            - "All"
          correlated_factors: false
          device: "cpu"
          seed: 42
          model_fit:
            batch_size: 2048
            iw_samples: 100
            mc_samples: 1
          model_scores:
            scoring_batch_size: 2048
            mc_samples: 100
            iw_samples: 100

      returns:
        type: "Tuple[DataFrame, DataFrame]"
        unpacking: "theta_scores, item_params"

    validation_call:
      module: "tools.validation"
      function: "validate_irt_convergence"
      signature: "validate_irt_convergence(results: Dict[str, Any]) -> Dict[str, Any]"

      input_files:
        - path: "logs/step03_item_parameters.csv"
          variable_name: "item_params"
        - path: "data/step03_theta_scores.csv"
          variable_name: "theta_scores"

      parameters:
        results:
          item_params: "item_params"
          theta_scores: "theta_scores"
          log_file: "logs/step03_calibration.log"

      criteria:
        - "Model converged"
        - "Theta in [-4, 4]"
        - "SE in [0.1, 1.5]"
        - "SE_All <= SE_All from Pass 1 (purification improves precision)"
        - "All 400 composite_IDs present"
        - "Item count matches purified list"

      on_failure:
        action: "raise ValueError"
        log_to: "logs/step03_calibration.log"
        invoke: "g_debug"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

    log_file: "logs/step03_calibration.log"

  # --------------------------------------------------------------------------
  # STEP 4: PREPARE LMM INPUT DATA
  # --------------------------------------------------------------------------
  - name: "step04_prepare_lmm_input"
    step_number: "04"
    description: "Transform theta scores to LMM-ready format with time transformations"

    analysis_call:
      type: "stdlib"
      operations:
        - "Load data/step03_theta_scores.csv (theta scores from Pass 2)"
        - "Load results/ch5/5.2.1/data/step00_tsvr_mapping.csv (TSVR time variable)"
        - "Rename: Theta_All -> Theta, SE_All -> SE"
        - "Merge theta with TSVR on composite_ID (left join, all 400 must match)"
        - "Create time transformations: Days = TSVR_hours / 24.0, Days_squared = Days^2, log_Days_plus1 = log(Days + 1)"
        - "Parse composite_ID: Extract UID and test"
        - "Save to data/step04_lmm_input.csv"

      input_files:
        - path: "data/step03_theta_scores.csv"
          source: "Step 3 output"
          required_columns:
            - "composite_ID"
            - "Theta_All"
            - "SE_All"
          variable_name: "theta_data"

        - path: "results/ch5/5.2.1/data/step00_tsvr_mapping.csv"
          source: "RQ 5.1 Step 0 (DERIVED data - TSVR extraction)"
          required_columns:
            - "composite_ID"
            - "TSVR_hours"
          variable_name: "tsvr_data"

      output_files:
        - path: "data/step04_lmm_input.csv"
          format: "CSV, long format (one row per observation)"
          columns:
            - name: "composite_ID"
              type: "str"
            - name: "UID"
              type: "str"
            - name: "test"
              type: "str"
            - name: "Theta"
              type: "float64"
              range: "[-4, 4]"
            - name: "SE"
              type: "float64"
              range: "[0.1, 1.5]"
            - name: "TSVR_hours"
              type: "float64"
              range: "[0, 168]"
            - name: "Days"
              type: "float64"
              range: "[0, 7]"
            - name: "Days_squared"
              type: "float64"
              range: "[0, 49]"
            - name: "log_Days_plus1"
              type: "float64"
              range: "[0, 2.2]"
          expected_rows: 400
          expected_columns: 9
          variable_name: "lmm_input"

      parameters: {}

      returns:
        type: "DataFrame"
        variable_name: "lmm_input"

    validation_call:
      module: "tools.validation"
      function: "validate_irt_convergence"
      signature: "validate_irt_convergence(results: Dict[str, Any]) -> Dict[str, Any]"

      input_files:
        - path: "data/step04_lmm_input.csv"
          variable_name: "lmm_input"

      parameters:
        results:
          data: "lmm_input"
          expected_rows: 400
          expected_columns: 9

      criteria:
        - "All 400 rows present (no data loss during merge)"
        - "No NaN values in any column"
        - "TSVR merge 100% successful"
        - "Each UID appears exactly 4 times (T1-T4)"
        - "Time transformations valid (Days>=0, log_Days_plus1 defined)"

      on_failure:
        action: "raise ValueError"
        log_to: "logs/step04_prepare_lmm_input.log"
        invoke: "g_debug"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

    log_file: "logs/step04_prepare_lmm_input.log"

  # --------------------------------------------------------------------------
  # STEP 5: FIT 5 CANDIDATE LMM MODELS
  # --------------------------------------------------------------------------
  - name: "step05_fit_5_candidate_lmms"
    step_number: "05"
    description: "Fit 5 LMM models (Linear, Quadratic, Log, Lin+Log, Quad+Log) with REML=False"

    analysis_call:
      type: "catalogued"
      module: "tools.analysis_lmm"
      function: "compare_lmm_models_by_aic"
      signature: "compare_lmm_models_by_aic(data: DataFrame, n_factors: int, reference_group: str, groups: str, save_dir: Path) -> Dict"

      input_files:
        - path: "data/step04_lmm_input.csv"
          source: "Step 4 output"
          required_columns:
            - "composite_ID"
            - "UID"
            - "test"
            - "Theta"
            - "TSVR_hours"
            - "Days"
            - "Days_squared"
            - "log_Days_plus1"
          variable_name: "lmm_input"

      output_files:
        - path: "data/step05_model_fits.pkl"
          format: "Python pickle"
          description: "Dictionary of 5 fitted MixedLMResults objects"
          keys:
            - "Linear"
            - "Quadratic"
            - "Logarithmic"
            - "LinLog"
            - "QuadLog"
          variable_name: "model_fits"

        - path: "results/step05_model_comparison.csv"
          format: "CSV, one row per model"
          columns:
            - name: "model_name"
              type: "str"
            - name: "AIC"
              type: "float64"
            - name: "BIC"
              type: "float64"
            - name: "log_likelihood"
              type: "float64"
            - name: "n_params"
              type: "int64"
            - name: "converged"
              type: "bool"
          expected_rows: 5
          variable_name: "model_comparison"

        - path: "logs/step05_lmm_fitting.log"
          format: "Text log"
          variable_name: "log_file"

      parameters:
        data: "lmm_input"
        n_factors: 1
        reference_group: null
        groups: "UID"
        save_dir: "results/ch5/5.1.1/data"

      returns:
        type: "Dict"
        variable_name: "comparison_results"
        fields:
          - "models: Dict of fitted objects"
          - "aic_comparison: DataFrame"
          - "best_model: str"
          - "best_result: MixedLMResults"

    validation_call:
      module: "tools.validation"
      function: "validate_lmm_convergence"
      signature: "validate_lmm_convergence(lmm_result: MixedLMResults) -> Dict[str, Any]"

      input_files:
        - path: "results/step05_model_comparison.csv"
          variable_name: "model_comparison"

      parameters:
        lmm_result: "comparison_results['models']"

      criteria:
        - "All 5 models converged (converged=True)"
        - "AIC/BIC values finite (not NaN or Inf)"
        - "Log-likelihood reasonable (negative, not -Inf)"
        - "No singular covariance warnings"

      on_failure:
        action: "raise ValueError"
        log_to: "logs/step05_lmm_fitting.log"
        invoke: "g_debug"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

    log_file: "logs/step05_lmm_fitting.log"

  # --------------------------------------------------------------------------
  # STEP 6: AIC MODEL SELECTION
  # --------------------------------------------------------------------------
  - name: "step06_aic_model_selection"
    step_number: "06"
    description: "Compute delta AIC and Akaike weights, identify best model"

    analysis_call:
      type: "stdlib"
      operations:
        - "Load results/step05_model_comparison.csv"
        - "Compute delta_AIC = AIC_i - AIC_min"
        - "Compute Akaike weights: w_i = exp(-0.5 * delta_AIC_i) / sum(exp(-0.5 * delta_AIC_j))"
        - "Compute cumulative_weight (sorted by AIC)"
        - "Identify best model (delta_AIC = 0)"
        - "Categorize uncertainty (w_best > 0.90: very strong, 0.60-0.90: strong, 0.30-0.60: moderate, <0.30: high)"
        - "Save best model object separately"
        - "Generate best model summary text"

      input_files:
        - path: "results/step05_model_comparison.csv"
          source: "Step 5 output"
          variable_name: "model_comparison"
        - path: "data/step05_model_fits.pkl"
          source: "Step 5 output"
          variable_name: "model_fits"

      output_files:
        - path: "results/step06_aic_comparison.csv"
          format: "CSV, sorted by AIC ascending"
          columns:
            - name: "model_name"
              type: "str"
            - name: "AIC"
              type: "float64"
            - name: "delta_AIC"
              type: "float64"
              range: "[0, 20]"
            - name: "akaike_weight"
              type: "float64"
              range: "(0, 1)"
            - name: "cumulative_weight"
              type: "float64"
              range: "monotonic [first_weight, 1.0]"
          expected_rows: 5
          variable_name: "aic_comparison"

        - path: "data/step06_best_model.pkl"
          format: "Python pickle"
          description: "Best-fitting MixedLMResults object"
          variable_name: "best_model"

        - path: "results/step06_best_model_summary.txt"
          format: "Text summary"
          description: "Best model details (name, AIC, weight, uncertainty, coefficients)"
          variable_name: "summary_text"

      parameters: {}

      returns:
        type: "DataFrame"
        variable_name: "aic_comparison"

    validation_call:
      module: "tools.validation"
      function: "validate_irt_convergence"
      signature: "validate_irt_convergence(results: Dict[str, Any]) -> Dict[str, Any]"

      input_files:
        - path: "results/step06_aic_comparison.csv"
          variable_name: "aic_comparison"

      parameters:
        results:
          data: "aic_comparison"

      criteria:
        - "Akaike weights sum to 1.0 (within [0.999, 1.001])"
        - "All weights in (0, 1) exclusive"
        - "delta_AIC correct (best model = 0, others positive)"
        - "cumulative_weight monotonic increasing (ends at 1.0)"
        - "Best model identified (row 1 has delta_AIC = 0)"

      on_failure:
        action: "raise ValueError"
        log_to: "logs/step06_model_selection.log"
        invoke: "g_debug"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

    log_file: "logs/step06_model_selection.log"

  # --------------------------------------------------------------------------
  # STEP 7: PREPARE FUNCTIONAL FORM PLOT DATA
  # --------------------------------------------------------------------------
  - name: "step07_prepare_functional_form_plots"
    step_number: "07"
    description: "Create dual-scale plot data (theta + probability) with all 5 model predictions"

    analysis_call:
      type: "stdlib"
      operations:
        - "Load data/step04_lmm_input.csv (observed data)"
        - "Load data/step05_model_fits.pkl (all 5 models)"
        - "Load results/step06_aic_comparison.csv (best model identification)"
        - "Compute observed means per test with 95% CI"
        - "Generate prediction grid: Days in [0, 7] with 50 points"
        - "For each model: compute predictions on grid"
        - "Transform to probability scale: p = 1 / (1 + exp(-1.7 * theta))"
        - "Save theta-scale CSV (observed + 5 predictions)"
        - "Save probability-scale CSV (observed + 5 predictions)"

      input_files:
        - path: "data/step04_lmm_input.csv"
          source: "Step 4 output"
          variable_name: "lmm_input"
        - path: "data/step05_model_fits.pkl"
          source: "Step 5 output"
          variable_name: "model_fits"
        - path: "results/step06_aic_comparison.csv"
          source: "Step 6 output"
          variable_name: "aic_comparison"

      output_files:
        - path: "plots/step07_functional_form_theta_data.csv"
          format: "CSV for theta-scale plot"
          columns:
            - name: "Days"
              type: "float64"
              range: "[0, 7]"
            - name: "observed_theta"
              type: "float64"
              range: "[-3, 3]"
            - name: "CI_lower_theta"
              type: "float64"
            - name: "CI_upper_theta"
              type: "float64"
            - name: "pred_Linear"
              type: "float64"
            - name: "pred_Quadratic"
              type: "float64"
            - name: "pred_Logarithmic"
              type: "float64"
            - name: "pred_LinLog"
              type: "float64"
            - name: "pred_QuadLog"
              type: "float64"
            - name: "best_model"
              type: "str"
          expected_rows: 54
          variable_name: "theta_plot_data"

        - path: "plots/step07_functional_form_probability_data.csv"
          format: "CSV for probability-scale plot (Decision D069)"
          columns:
            - name: "Days"
              type: "float64"
            - name: "observed_prob"
              type: "float64"
              range: "[0, 1]"
            - name: "CI_lower_prob"
              type: "float64"
            - name: "CI_upper_prob"
              type: "float64"
            - name: "pred_Linear_prob"
              type: "float64"
            - name: "pred_Quadratic_prob"
              type: "float64"
            - name: "pred_Logarithmic_prob"
              type: "float64"
            - name: "pred_LinLog_prob"
              type: "float64"
            - name: "pred_QuadLog_prob"
              type: "float64"
            - name: "best_model"
              type: "str"
          expected_rows: 54
          variable_name: "prob_plot_data"

      parameters: {}

      returns:
        type: "Tuple[DataFrame, DataFrame]"
        unpacking: "theta_plot_data, prob_plot_data"

    validation_call:
      module: "tools.validation"
      function: "validate_irt_convergence"
      signature: "validate_irt_convergence(results: Dict[str, Any]) -> Dict[str, Any]"

      input_files:
        - path: "plots/step07_functional_form_theta_data.csv"
          variable_name: "theta_plot_data"
        - path: "plots/step07_functional_form_probability_data.csv"
          variable_name: "prob_plot_data"

      parameters:
        results:
          theta_data: "theta_plot_data"
          prob_data: "prob_plot_data"

      criteria:
        - "All probability values in [0, 1] bounds"
        - "CI bounds valid (CI_upper > CI_lower)"
        - "Monotonicity preserved (theta transform preserves ordering)"
        - "No NaN in Days column"
        - "Expected row count (54 rows per file)"

      on_failure:
        action: "raise ValueError"
        log_to: "logs/step07_prepare_plot_data.log"
        invoke: "g_debug"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

    log_file: "logs/step07_prepare_plot_data.log"

# ============================================================================
# END OF ANALYSIS RECIPE
# ============================================================================
