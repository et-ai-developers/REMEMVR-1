#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Plotting script for RQ 5.3: Paradigm-Specific Forgetting Trajectories (Free/Cued/Recognition)

GENERATED BY: rq_plots agent (v4.0.0)
DATE: 2025-11-24
PURPOSE: Create publication-ready plots from individual-level plot source CSVs

PLOT STYLE (matching legacy .archive/v1/plots.py):
- Faded scatter points in background (individual observations)
- Dashed fitted curves (LMM predictions)
- Shaded 95% CI bands (from LMM fixed effects covariance matrix)

PLOTS GENERATED:
1. trajectory_theta.png - Theta-scale trajectory (IRT latent variable)
2. trajectory_probability.png - Probability-scale trajectory (dual-scale)

DECISIONS APPLIED:
- Decision D069: BOTH theta + probability MANDATORY
- Decision D070: TSVR (actual hours) as time variable
"""

import sys
from pathlib import Path

# Add project root to path for imports
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import patsy
import statsmodels.formula.api as smf
from tools.plotting import set_plot_style_defaults, convert_theta_to_probability

# =============================================================================
# SETUP
# =============================================================================

RQ_ROOT = Path(__file__).resolve().parent.parent
PLOTS_DIR = RQ_ROOT / "plots"
DATA_DIR = RQ_ROOT / "data"

# Apply consistent plotting theme
set_plot_style_defaults()

print("=" * 70)
print("RQ 5.3: Paradigm-Specific Forgetting Trajectories - Plotting")
print("=" * 70)
print(f"RQ root: {RQ_ROOT}")
print(f"Plots directory: {PLOTS_DIR}")

# Plot style constants (matching legacy)
RESIDUAL_SCATTER_POINT_ALPHA = 0.15
MEAN_CI_ALPHA = 0.2
IRT_LINE_STYLE = 'dashed'

# Paradigm color scheme
COLORS = {
    "free_recall": "#3498DB",   # Blue
    "cued_recall": "#2ECC71",   # Green
    "recognition": "#E67E22",   # Orange
}

# Display labels for paradigms
LABELS = {
    "free_recall": "Free Recall",
    "cued_recall": "Cued Recall",
    "recognition": "Recognition",
}

# =============================================================================
# LOAD DATA AND FIT LMM
# =============================================================================

print("\n" + "-" * 70)
print("Loading data and fitting LMM for CI calculation...")
print("-" * 70)

# Load LMM input data
lmm_input_path = DATA_DIR / "step04_lmm_input.csv"
df_lmm = pd.read_csv(lmm_input_path)
print(f"  Loaded {len(df_lmm)} rows from step04_lmm_input.csv")

# Prepare for LMM - create log_Days
df_lmm['Days'] = df_lmm['TSVR_hours'] / 24.0
df_lmm['log_Days'] = np.log(df_lmm['Days'] + 1)

# Get UID from composite_ID if not present
if 'UID' not in df_lmm.columns:
    df_lmm['UID'] = df_lmm['composite_ID'].str.split('_').str[0]

# Create Factor column from paradigm (with proper case for matching model output)
df_lmm['Factor'] = df_lmm['paradigm'].replace({
    'free_recall': 'Free_Recall',
    'cued_recall': 'Cued_Recall',
    'recognition': 'Recognition'
})

# Fit Log model (best model from step05)
print("  Fitting LMM model (Log model - best by AIC)...")
log_model = smf.mixedlm(
    "theta ~ log_Days * C(Factor, Treatment('Free_Recall'))",
    data=df_lmm,
    groups=df_lmm['UID'],
    re_formula='~log_Days'
)
lmm_results = log_model.fit(method='powell', reml=False)
print(f"  Model fitted: AIC = {lmm_results.aic:.2f}")

# Load item parameters for probability conversion
item_params_path = DATA_DIR / "step03_item_parameters.csv"
df_items = pd.read_csv(item_params_path)

# Get paradigm-specific IRT parameters
# Check for column names
factor_col = next((c for c in ['domain', 'factor', 'paradigm'] if c in df_items.columns), None)
disc_col = next((c for c in ['Discrimination', 'a'] if c in df_items.columns), None)
diff_col = next((c for c in ['Difficulty_1', 'Difficulty', 'b'] if c in df_items.columns), None)

if factor_col is None:
    print("  Warning: No paradigm column found in item parameters, using overall mean")
    paradigm_params = {}
else:
    paradigm_params = df_items.groupby(factor_col).agg({
        disc_col: 'mean',
        diff_col: 'mean'
    }).to_dict('index')
    print(f"  Paradigm IRT parameters loaded from column '{factor_col}'")

# =============================================================================
# HELPER: Create prediction grid with CIs
# =============================================================================

def create_pred_grid_with_ci(lmm_results, df_long, time_range):
    """Create prediction grid with 95% CI from LMM covariance matrix."""

    paradigms = df_long['paradigm'].unique()

    pred_grid = pd.DataFrame([
        (t, p) for p in paradigms for t in time_range
    ], columns=['TSVR_hours', 'paradigm'])

    pred_grid['Days'] = pred_grid['TSVR_hours'] / 24.0
    pred_grid['log_Days'] = np.log(pred_grid['Days'] + 1)

    # Map to Factor for model prediction
    pred_grid['Factor'] = pred_grid['paradigm'].replace({
        'free_recall': 'Free_Recall',
        'cued_recall': 'Cued_Recall',
        'recognition': 'Recognition'
    })

    # Get formula RHS and create design matrix
    formula_rhs = lmm_results.model.formula.split('~')[1].strip()
    design_matrix = patsy.dmatrix(formula_rhs, pred_grid, return_type='dataframe')

    # Predict mean
    pred_grid['mean_theta'] = lmm_results.predict(pred_grid)

    # Calculate CI from fixed effects covariance
    fe_cov = lmm_results.cov_params().loc[lmm_results.fe_params.index, lmm_results.fe_params.index]
    design_matrix = design_matrix[fe_cov.columns]

    pred_var = np.sum((design_matrix @ fe_cov) * design_matrix, axis=1)
    pred_se = np.sqrt(pred_var)

    pred_grid['theta_ci_lower'] = pred_grid['mean_theta'] - 1.96 * pred_se
    pred_grid['theta_ci_upper'] = pred_grid['mean_theta'] + 1.96 * pred_se

    return pred_grid

# =============================================================================
# PLOT 1: TRAJECTORY (THETA-SCALE)
# =============================================================================

print("\n" + "-" * 70)
print("Generating Plot 1: Theta-scale trajectory (publication style)...")
print("-" * 70)

# Use individual-level data from LMM input for scatter
print(f"  Using {len(df_lmm)} individual observations for scatter")

# Create prediction grid with CI
time_range = np.linspace(df_lmm['TSVR_hours'].min(), df_lmm['TSVR_hours'].max(), 100)
pred_grid = create_pred_grid_with_ci(lmm_results, df_lmm, time_range)

# Create figure
fig, ax = plt.subplots(figsize=(10, 6))

paradigms = ['free_recall', 'cued_recall', 'recognition']

for paradigm in paradigms:
    color = COLORS.get(paradigm, '#333333')
    label = LABELS.get(paradigm, paradigm)

    # 1. Plot faded scatter points (individual observations)
    paradigm_data = df_lmm[df_lmm['paradigm'] == paradigm]
    ax.scatter(
        paradigm_data['TSVR_hours'],
        paradigm_data['theta'],
        c=color,
        alpha=RESIDUAL_SCATTER_POINT_ALPHA,
        s=15,
        edgecolors='none'
    )

    # 2. Get predictions for this paradigm
    paradigm_pred = pred_grid[pred_grid['paradigm'] == paradigm]

    # 3. Plot shaded CI band
    ax.fill_between(
        paradigm_pred['TSVR_hours'],
        paradigm_pred['theta_ci_lower'],
        paradigm_pred['theta_ci_upper'],
        color=color,
        alpha=MEAN_CI_ALPHA,
        edgecolor='none'
    )

    # 4. Plot dashed fitted curve
    ax.plot(
        paradigm_pred['TSVR_hours'],
        paradigm_pred['mean_theta'],
        color=color,
        linestyle=IRT_LINE_STYLE,
        linewidth=2.5,
        label=label
    )

# Formatting
ax.set_xlabel('Time since encoding (hours)', fontsize=12)
ax.set_ylabel('Memory Ability (Theta)', fontsize=12)
ax.set_title('RQ 5.3: Paradigm-Specific Forgetting Trajectories - Theta Scale', fontsize=14, fontweight='bold')
ax.legend(loc='upper right', framealpha=0.95, fontsize=10)
ax.grid(True, linestyle='--', alpha=0.6)
ax.set_xlim(-5, df_lmm['TSVR_hours'].max() + 5)

plt.tight_layout()
fig.savefig(PLOTS_DIR / "trajectory_theta.png", dpi=300, bbox_inches='tight', facecolor='white')
plt.close(fig)

print(f"  [PASS] Saved: {PLOTS_DIR / 'trajectory_theta.png'}")

# =============================================================================
# PLOT 2: TRAJECTORY (PROBABILITY-SCALE)
# =============================================================================

print("\n" + "-" * 70)
print("Generating Plot 2: Probability-scale trajectory (publication style)...")
print("-" * 70)

# For probability conversion, we need to convert theta to probability per paradigm
# Use overall mean discrimination if no paradigm-specific parameters

# Get overall mean parameters
mean_a = df_items[disc_col].mean()
mean_b = df_items[diff_col].mean() if diff_col else 0.0
print(f"  Overall mean discrimination: {mean_a:.3f}")

# Convert individual-level theta to probability
df_lmm['probability'] = convert_theta_to_probability(
    df_lmm['theta'].values, discrimination=mean_a, difficulty=mean_b
)
df_lmm['probability_pct'] = df_lmm['probability'] * 100

# Create figure
fig, ax = plt.subplots(figsize=(10, 6))

for paradigm in paradigms:
    color = COLORS.get(paradigm, '#333333')
    label = LABELS.get(paradigm, paradigm)

    # Get paradigm-specific IRT parameters if available
    paradigm_key_variants = [paradigm, paradigm.replace('_', ' '), paradigm.title()]
    paradigm_irt = None
    for key in paradigm_key_variants:
        if key in paradigm_params:
            paradigm_irt = paradigm_params[key]
            break

    if paradigm_irt:
        avg_a = paradigm_irt[disc_col]
        avg_b = paradigm_irt[diff_col]
    else:
        avg_a = mean_a
        avg_b = mean_b

    # 1. Plot faded scatter points (individual probabilities)
    paradigm_data = df_lmm[df_lmm['paradigm'] == paradigm]
    paradigm_prob = convert_theta_to_probability(
        paradigm_data['theta'].values, discrimination=avg_a, difficulty=avg_b
    ) * 100

    ax.scatter(
        paradigm_data['TSVR_hours'],
        paradigm_prob,
        c=color,
        alpha=RESIDUAL_SCATTER_POINT_ALPHA,
        s=15,
        edgecolors='none'
    )

    # 2. Get theta predictions and convert to probability
    paradigm_pred = pred_grid[pred_grid['paradigm'] == paradigm].copy()

    # Convert theta CI to probability
    paradigm_pred['prob_mean'] = convert_theta_to_probability(
        paradigm_pred['mean_theta'].values, discrimination=avg_a, difficulty=avg_b
    ) * 100
    paradigm_pred['prob_ci_lower'] = convert_theta_to_probability(
        paradigm_pred['theta_ci_lower'].values, discrimination=avg_a, difficulty=avg_b
    ) * 100
    paradigm_pred['prob_ci_upper'] = convert_theta_to_probability(
        paradigm_pred['theta_ci_upper'].values, discrimination=avg_a, difficulty=avg_b
    ) * 100

    # 3. Plot shaded CI band
    ax.fill_between(
        paradigm_pred['TSVR_hours'],
        paradigm_pred['prob_ci_lower'],
        paradigm_pred['prob_ci_upper'],
        color=color,
        alpha=MEAN_CI_ALPHA,
        edgecolor='none'
    )

    # 4. Plot dashed fitted curve
    ax.plot(
        paradigm_pred['TSVR_hours'],
        paradigm_pred['prob_mean'],
        color=color,
        linestyle=IRT_LINE_STYLE,
        linewidth=2.5,
        label=label
    )

# Formatting
ax.set_xlabel('Time since encoding (hours)', fontsize=12)
ax.set_ylabel('Probability Correct (%)', fontsize=12)
ax.set_title('RQ 5.3: Paradigm-Specific Forgetting Trajectories - Probability Scale', fontsize=14, fontweight='bold')
ax.legend(loc='upper right', framealpha=0.95, fontsize=10)
ax.grid(True, linestyle='--', alpha=0.6)
ax.set_xlim(-5, df_lmm['TSVR_hours'].max() + 5)
ax.set_ylim(0, 100)

plt.tight_layout()
fig.savefig(PLOTS_DIR / "trajectory_probability.png", dpi=300, bbox_inches='tight', facecolor='white')
plt.close(fig)

print(f"  [PASS] Saved: {PLOTS_DIR / 'trajectory_probability.png'}")

# =============================================================================
# SUMMARY
# =============================================================================

print("\n" + "=" * 70)
print("PLOTTING COMPLETE")
print("=" * 70)
print(f"Total plots generated: 2")
print(f"  - {PLOTS_DIR / 'trajectory_theta.png'}")
print(f"  - {PLOTS_DIR / 'trajectory_probability.png'}")
print("\nPlot style (matching legacy):")
print("  - Faded scatter points (individual observations)")
print("  - Dashed fitted curves (LMM predictions)")
print("  - Shaded 95% CI bands (from LMM covariance matrix)")
print("\nDecision D069 compliance: BOTH theta + probability scale plots generated")
print("All plots saved with 300 DPI publication quality.")
print("=" * 70)
