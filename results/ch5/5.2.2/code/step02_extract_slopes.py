#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step02
Step Name: Extract Segment-by-Domain Slopes
RQ: results/ch5/5.2.2
Generated: 2025-11-23

PURPOSE:
Extract 4 segment-domain specific forgetting slopes via linear combinations
from the fitted piecewise LMM model. Slopes represent forgetting rates
(theta change per day) for each combination of Segment (Early/Late) and
domain (what/where). When domain excluded due to floor effect in RQ 5.2.1.

EXPECTED INPUTS:
  - data/step01_piecewise_lmm_model.pkl
    Format: Pickled MixedLMResults object from statsmodels
    Contains: Fitted piecewise LMM with 3-way interaction (Days_within * Segment * domain)
    Fixed effects: 8 parameters (intercept + main effects + interactions for 2 domains)

EXPECTED OUTPUTS:
  - results/step02_fixed_effects.csv
    Columns: [Term, Coef, Std_Err, z, P_value, CI_lower, CI_upper]
    Format: Fixed effects table from LMM
    Expected rows: 8 (all fixed effect terms for 2 domains)

  - results/step02_segment_domain_slopes.csv
    Columns: [segment, domain, slope, se, CI_lower, CI_upper]
    Format: Computed slopes for each segment x domain combination
    Expected rows: 4 (2 segments x 2 domains - When excluded)

VALIDATION CRITERIA:
  - Fixed effects table has 5+ rows (intercept + interaction terms)
  - Slope table has exactly 4 rows (2 segments x 2 domains)
  - All segment-domain combinations present: Early/Late x what/where
  - Slopes have valid values: numeric, SE > 0, CI_lower < slope < CI_upper

g_code REASONING:
- Approach: Extract fixed effects from fitted LMM, then compute linear combinations
  to derive the 4 specific forgetting slopes (one per segment-domain combination)
- Why this approach: The piecewise LMM encodes slopes as interaction terms. The
  baseline slope (What in Early) is the Days_within coefficient. Other slopes
  require adding interaction terms (e.g., Where_Early = Days_within + Days_within:domain[T.where])
- Data flow: LMM model object -> extract_fixed_effects_from_lmm -> fixed effects table
             Fixed effects table -> linear combinations -> segment-domain slopes
- Expected performance: <5 seconds (no fitting, just extraction)

IMPLEMENTATION NOTES:
- Analysis tool: extract_fixed_effects_from_lmm from tools.analysis_lmm
- Slope computation done inline via linear combinations of fixed effects
- SE for combined slopes computed via delta method (variance propagation)
- 95% CI computed as slope +/- 1.96*SE

SLOPE COMPUTATION FORMULAS (When excluded - only What/Where):
  - What (Early): beta[Days_within]
  - Where (Early): beta[Days_within] + beta[Days_within:domain[T.where]]
  - What (Late): beta[Days_within] + beta[Days_within:Segment[T.Late]]
  - Where (Late): beta[Days_within] + beta[Days_within:Segment[T.Late]] +
                  beta[Days_within:domain[T.where]] + beta[Days_within:Segment[T.Late]:domain[T.where]]
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (5 levels deep from project root)
# parents[4] = REMEMVR/ (code -> rqY -> chX -> results -> REMEMVR)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_lmm import extract_fixed_effects_from_lmm
from statsmodels.regression.mixed_linear_model import MixedLMResults

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.2.2 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step02_extract_slopes.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_lmm_model_comparison.csv
#   CORRECT: data/step03_theta_scores.csv
#   WRONG:   results/lmm_model_comparison.csv  (wrong folder + no prefix)
#   WRONG:   data/theta_scores.csv             (missing step prefix)
#   WRONG:   logs/step02_removed_items.csv     (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Slope Computation Functions
# =============================================================================

def compute_segment_domain_slopes(
    lmm_model: MixedLMResults
) -> pd.DataFrame:
    """
    Compute the 4 segment-domain specific slopes via linear combinations.
    (When domain excluded due to floor effect in RQ 5.2.1)

    The piecewise LMM uses treatment coding:
    - Segment reference: 'Early'
    - domain reference: 'what'

    So the coefficient names follow the pattern:
    - Days_within: Base slope (What in Early segment)
    - Days_within:C(Segment...)[T.Late]: Change when in Late segment
    - Days_within:C(domain...)[T.where]: Change for where vs what
    - 3-way interactions: Combined changes

    Returns DataFrame with columns: segment, domain, slope, se, CI_lower, CI_upper
    """
    params = lmm_model.params
    cov_matrix = lmm_model.cov_params()

    # Identify coefficient names (they have verbose treatment coding names)
    coef_names = list(params.index)

    # Find the key coefficient names
    days_within = 'Days_within'
    days_segment_late = [n for n in coef_names if 'Days_within' in n and 'Segment' in n and 'Late' in n and 'domain' not in n]
    days_domain_where = [n for n in coef_names if 'Days_within' in n and 'domain' in n and 'where' in n and 'Segment' not in n]
    days_seg_dom_where = [n for n in coef_names if 'Days_within' in n and 'Segment' in n and 'Late' in n and 'where' in n]

    # Extract the single matching name from each list
    days_segment_late = days_segment_late[0] if days_segment_late else None
    days_domain_where = days_domain_where[0] if days_domain_where else None
    days_seg_dom_where = days_seg_dom_where[0] if days_seg_dom_where else None

    log(f"[DEBUG] days_within: {days_within}")
    log(f"[DEBUG] days_segment_late: {days_segment_late}")
    log(f"[DEBUG] days_domain_where: {days_domain_where}")
    log(f"[DEBUG] days_seg_dom_where: {days_seg_dom_where}")

    # Get coefficients
    b_days = params[days_within]
    b_late = params[days_segment_late] if days_segment_late else 0
    b_where = params[days_domain_where] if days_domain_where else 0
    b_late_where = params[days_seg_dom_where] if days_seg_dom_where else 0

    # Compute the 4 slopes (When excluded)
    slopes = []

    # 1. What (Early) = beta[Days_within]
    slope_what_early = b_days
    se_what_early = np.sqrt(cov_matrix.loc[days_within, days_within])
    slopes.append({
        'segment': 'Early',
        'domain': 'what',
        'slope': slope_what_early,
        'se': se_what_early
    })

    # 2. Where (Early) = beta[Days_within] + beta[Days_within:domain[T.where]]
    slope_where_early = b_days + b_where
    # SE via delta method: sqrt(var(b1) + var(b2) + 2*cov(b1,b2))
    if days_domain_where:
        var_days = cov_matrix.loc[days_within, days_within]
        var_where = cov_matrix.loc[days_domain_where, days_domain_where]
        cov_days_where = cov_matrix.loc[days_within, days_domain_where]
        se_where_early = np.sqrt(var_days + var_where + 2 * cov_days_where)
    else:
        se_where_early = se_what_early
    slopes.append({
        'segment': 'Early',
        'domain': 'where',
        'slope': slope_where_early,
        'se': se_where_early
    })

    # 3. What (Late) = beta[Days_within] + beta[Days_within:Segment[T.Late]]
    slope_what_late = b_days + b_late
    if days_segment_late:
        var_days = cov_matrix.loc[days_within, days_within]
        var_late = cov_matrix.loc[days_segment_late, days_segment_late]
        cov_days_late = cov_matrix.loc[days_within, days_segment_late]
        se_what_late = np.sqrt(var_days + var_late + 2 * cov_days_late)
    else:
        se_what_late = se_what_early
    slopes.append({
        'segment': 'Late',
        'domain': 'what',
        'slope': slope_what_late,
        'se': se_what_late
    })

    # 4. Where (Late) = beta[Days_within] + beta[Days_within:Segment[T.Late]] +
    #                   beta[Days_within:domain[T.where]] + beta[Days_within:Segment[T.Late]:domain[T.where]]
    slope_where_late = b_days + b_late + b_where + b_late_where
    # Full variance calculation for 4-term linear combination
    terms = [days_within]
    if days_segment_late:
        terms.append(days_segment_late)
    if days_domain_where:
        terms.append(days_domain_where)
    if days_seg_dom_where:
        terms.append(days_seg_dom_where)

    var_sum = 0
    for i, t1 in enumerate(terms):
        for j, t2 in enumerate(terms):
            var_sum += cov_matrix.loc[t1, t2]
    se_where_late = np.sqrt(var_sum)
    slopes.append({
        'segment': 'Late',
        'domain': 'where',
        'slope': slope_where_late,
        'se': se_where_late
    })

    # Convert to DataFrame
    df_slopes = pd.DataFrame(slopes)

    # Add 95% confidence intervals
    df_slopes['CI_lower'] = df_slopes['slope'] - 1.96 * df_slopes['se']
    df_slopes['CI_upper'] = df_slopes['slope'] + 1.96 * df_slopes['se']

    return df_slopes

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        # Ensure log directory exists
        LOG_FILE.parent.mkdir(parents=True, exist_ok=True)

        # Clear previous log
        with open(LOG_FILE, 'w', encoding='utf-8') as f:
            f.write("")

        log("[START] Step 02: Extract Segment-by-Domain Slopes")
        log("=" * 60)

        # =========================================================================
        # STEP 1: Load Input Data (LMM model from step01)
        # =========================================================================
        # Expected: Fitted piecewise LMM model object (MixedLMResults)
        # Purpose: Extract fixed effects and compute segment-domain slopes

        log("[LOAD] Loading piecewise LMM model from step01...")
        model_path = RQ_DIR / "data" / "step01_piecewise_lmm_model.pkl"

        if not model_path.exists():
            raise FileNotFoundError(f"Input file not found: {model_path}")

        lmm_model = MixedLMResults.load(str(model_path))
        log(f"[LOADED] Model loaded successfully")
        log(f"  Converged: {lmm_model.converged}")
        log(f"  Observations: {lmm_model.nobs}")
        log(f"  Fixed effects: {len([p for p in lmm_model.params.index if 'Group' not in p and 'Var' not in p])}")

        # =========================================================================
        # STEP 2: Run Analysis Tool - Extract Fixed Effects
        # =========================================================================
        # Tool: extract_fixed_effects_from_lmm
        # What it does: Extracts fixed effects table from fitted LMM
        # Expected output: DataFrame with Term, Coef, Std_Err, z, P_value, CI_lower, CI_upper

        log("\n[ANALYSIS] Extracting fixed effects from LMM...")
        df_fixed_effects = extract_fixed_effects_from_lmm(lmm_model)
        log(f"[DONE] Fixed effects extracted: {len(df_fixed_effects)} terms")

        # Log the fixed effects
        log("\nFixed Effects:")
        for _, row in df_fixed_effects.iterrows():
            sig = "*" if row['P_value'] < 0.05 else ""
            log(f"  {row['Term']}: {row['Coef']:.4f} (SE={row['Std_Err']:.4f}, p={row['P_value']:.4f}){sig}")

        # =========================================================================
        # STEP 3: Compute Segment-Domain Slopes
        # =========================================================================
        # What it does: Computes linear combinations of fixed effects to get slopes
        # Expected output: 4 slopes (2 segments x 2 domains - When excluded)

        log("\n[ANALYSIS] Computing segment-domain slopes via linear combinations...")
        df_slopes = compute_segment_domain_slopes(lmm_model)
        log(f"[DONE] Slopes computed: {len(df_slopes)} segment-domain combinations")

        # Log the slopes
        log("\nSegment-Domain Slopes (theta change per day):")
        for _, row in df_slopes.iterrows():
            log(f"  {row['segment']}-{row['domain']}: {row['slope']:.4f} (SE={row['se']:.4f}, 95% CI [{row['CI_lower']:.4f}, {row['CI_upper']:.4f}])")

        # =========================================================================
        # STEP 4: Save Analysis Outputs
        # =========================================================================
        # These outputs will be used by: step03 (contrasts), step04 (consolidation benefit)

        log("\n[SAVE] Saving fixed effects table...")
        fixed_effects_path = RQ_DIR / "results" / "step02_fixed_effects.csv"
        df_fixed_effects.to_csv(fixed_effects_path, index=False, encoding='utf-8')
        log(f"[SAVED] {fixed_effects_path} ({len(df_fixed_effects)} rows)")

        log("[SAVE] Saving segment-domain slopes...")
        slopes_path = RQ_DIR / "results" / "step02_segment_domain_slopes.csv"
        df_slopes.to_csv(slopes_path, index=False, encoding='utf-8')
        log(f"[SAVED] {slopes_path} ({len(df_slopes)} rows)")

        # =========================================================================
        # STEP 5: Run Inline Validation
        # =========================================================================
        # Validates: Fixed effects count, slope table completeness, valid values

        log("\n[VALIDATION] Running inline validation checks...")
        validation_errors = []

        # Validation 1: Fixed effects table complete (8 terms for 2 domains)
        if len(df_fixed_effects) < 5:
            validation_errors.append(f"Fixed effects table incomplete: expected >= 5 rows, got {len(df_fixed_effects)}")
        log(f"  [PASS] Fixed effects table has {len(df_fixed_effects)} rows (>= 5 required)")

        # Validation 2: Slope table complete (4 rows - When excluded)
        if len(df_slopes) != 4:
            validation_errors.append(f"Slope table incomplete: expected 4 rows, got {len(df_slopes)}")
        else:
            log(f"  [PASS] Slope table has {len(df_slopes)} rows (4 required - When excluded)")

        # Validation 3: All segment-domain combinations present (What/Where only)
        expected_segments = {'Early', 'Late'}
        expected_domains = {'what', 'where'}  # When excluded due to floor effect
        actual_segments = set(df_slopes['segment'].unique())
        actual_domains = set(df_slopes['domain'].unique())

        if actual_segments != expected_segments:
            validation_errors.append(f"Missing segments: expected {expected_segments}, got {actual_segments}")
        else:
            log(f"  [PASS] All segments present: {actual_segments}")

        if actual_domains != expected_domains:
            validation_errors.append(f"Missing domains: expected {expected_domains}, got {actual_domains}")
        else:
            log(f"  [PASS] All domains present (When excluded): {actual_domains}")

        # Validation 4: Slopes have valid values
        if df_slopes['se'].min() <= 0:
            validation_errors.append(f"Invalid SE: found SE <= 0")
        else:
            log(f"  [PASS] All SE values > 0 (min={df_slopes['se'].min():.4f})")

        # Check CI structure
        invalid_ci = df_slopes[~((df_slopes['CI_lower'] < df_slopes['slope']) &
                                  (df_slopes['slope'] < df_slopes['CI_upper']))]
        if len(invalid_ci) > 0:
            validation_errors.append(f"Invalid CI structure: {len(invalid_ci)} rows have CI_lower >= slope or slope >= CI_upper")
        else:
            log(f"  [PASS] CI structure valid (CI_lower < slope < CI_upper) for all rows")

        # Report validation result
        if validation_errors:
            log("\n[VALIDATION FAILED]")
            for err in validation_errors:
                log(f"  [FAIL] {err}")
            raise ValueError(f"Validation failed with {len(validation_errors)} error(s)")
        else:
            log("\n[VALIDATION PASSED] All checks passed")

        log("\n" + "=" * 60)
        log("[SUCCESS] Step 02 complete")
        log("=" * 60)
        sys.exit(0)

    except Exception as e:
        log(f"\n[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
