#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step02
Step Name: Purify Items by Quality Thresholds (Decision D039)
RQ: results/ch5/5.5.1
Generated: 2025-12-04

PURPOSE:
Filter items based on Decision D039 purification thresholds to retain only
high-quality items for Pass 2 calibration. This implements the 2-pass IRT
purification workflow: Pass 1 calibrates all items, Step 2 removes poor-quality
items (a < 0.4 or |b| > 3.0), and Pass 2 recalibrates with retained items only.

EXPECTED INPUTS:
  - data/step01_pass1_item_params.csv
    Columns: ['item_tag', 'factor', 'a', 'b']
    Format: IRT item parameters from Pass 1 calibration
    Expected rows: 36 (18 source + 18 destination items)

EXPECTED OUTPUTS:
  - data/step02_purified_items.csv
    Columns: ['item_tag', 'factor', 'a', 'b', 'retention_reason']
    Format: Items that passed purification thresholds
    Expected rows: ~32 (25-32 items, 4 items expected to be excluded)

  - data/step02_purification_report.txt
    Format: Text report with exclusion breakdown by reason and factor
    Contents: Total analyzed, retained count/percent, excluded count/percent,
             breakdown by exclusion reason, factor-specific retention counts,
             list of excluded items with reasons

VALIDATION CRITERIA:
  - All retained items have a >= 0.4 (Decision D039 discrimination threshold)
  - All retained items have |b| <= 3.0 (Decision D039 difficulty threshold)
  - Minimum 10 items per factor (source >= 10, destination >= 10)
  - No NaN values in output files
  - No duplicate items

g_code REASONING:
- Approach: Use tools.analysis_irt.filter_items_by_quality to apply Decision D039
  thresholds. This function handles both discrimination and difficulty criteria,
  returns retained items and excluded items with reasons.

- Why this approach: Decision D039 specifies 2-pass purification to remove
  psychometrically problematic items. Temporal items in REMEMVR are inherently
  difficult (expected 40-50% retention rate). Purification ensures only items
  with adequate discrimination (a >= 0.4) and reasonable difficulty (|b| <= 3.0)
  contribute to final theta estimates.

- Data flow: Pass 1 item parameters (36 items) -> filter_items_by_quality ->
  retained items (~32) + excluded items (~4). Expected exclusions from Pass 1
  results: TQ_IFR-D-i1 (a=0.353), TQ_IFR-D-i4 (a=0.234, b=3.16), TQ_IFR-U-i4
  (a=0.343), TQ_IRE-D-i4 (a=0.373). Final output has ~17 source items and
  ~15 destination items.

- Expected performance: ~1 second (simple filtering operation, no IRT calibration)

IMPLEMENTATION NOTES:
- Analysis tool: filter_items_by_quality from tools.analysis_irt
- Validation tool: validate_irt_parameters from tools.validation
- Parameters: a_threshold=0.4, b_threshold=3.0 (Decision D039), min_items_per_factor=10
- The tool accepts 'item_name' column but our data has 'item_tag' - will need to rename
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/ (5.5.1/)
#   parents[2] = chX/ (ch5/)
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_irt import filter_items_by_quality

# Import validation tool
from tools.validation import validate_irt_parameters

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.5.1 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step02_purify_items.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step02_purified_items.csv
#   CORRECT: data/step02_purification_report.txt
#   WRONG:   results/purified_items.csv  (wrong folder + no prefix)
#   WRONG:   data/purified_items.csv     (missing step prefix)
#   WRONG:   logs/step02_removed_items.csv (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 2: Purify Items by Quality Thresholds (Decision D039)")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: 36 items from Pass 1 calibration (18 source + 18 destination)
        # Purpose: Identify poor-quality items for exclusion before Pass 2

        log("[LOAD] Loading Pass 1 item parameters...")
        input_path = RQ_DIR / "data" / "step01_pass1_item_params.csv"

        if not input_path.exists():
            raise FileNotFoundError(f"Input file not found: {input_path}")

        pass1_params = pd.read_csv(input_path, encoding='utf-8')
        log(f"[LOADED] step01_pass1_item_params.csv ({len(pass1_params)} rows, {len(pass1_params.columns)} cols)")

        # Validate input columns
        required_cols = ['item_tag', 'factor', 'a', 'b']
        missing_cols = [col for col in required_cols if col not in pass1_params.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")

        # Show input summary
        log(f"[INPUT] Total items: {len(pass1_params)}")
        log(f"[INPUT] Items by factor:")
        for factor in pass1_params['factor'].unique():
            count = len(pass1_params[pass1_params['factor'] == factor])
            log(f"  - {factor}: {count} items")

        # =========================================================================
        # STEP 2: Run Analysis Tool (filter_items_by_quality)
        # =========================================================================
        # Tool: filter_items_by_quality from tools.analysis_irt
        # What it does: Applies Decision D039 thresholds (a >= 0.4, |b| <= 3.0)
        #               to identify items that should be retained vs excluded
        # Expected output: ~32 retained items, ~4 excluded items

        log("[ANALYSIS] Running filter_items_by_quality (Decision D039)...")
        log("[ANALYSIS] Thresholds: a >= 0.4, |b| <= 3.0")

        # CRITICAL: The tool expects 'item_name' column but our data has 'item_tag'
        # Rename temporarily for tool compatibility
        pass1_params_renamed = pass1_params.rename(columns={'item_tag': 'item_name'})

        # Run purification
        purified_items, excluded_items = filter_items_by_quality(
            df_items=pass1_params_renamed,
            a_threshold=0.4,    # Decision D039: minimum discrimination
            b_threshold=3.0     # Decision D039: maximum absolute difficulty
        )

        # Rename back to 'item_tag' for output consistency
        purified_items = purified_items.rename(columns={'item_name': 'item_tag'})
        excluded_items = excluded_items.rename(columns={'item_name': 'item_tag'})

        log("[DONE] Item purification complete")
        log(f"[RESULT] Retained: {len(purified_items)} items")
        log(f"[RESULT] Excluded: {len(excluded_items)} items")

        # =========================================================================
        # STEP 3: Save Analysis Outputs
        # =========================================================================
        # These outputs will be used by: Step 3 (Pass 2 calibration)

        # Output 1: Purified items CSV (retained items only)
        log("[SAVE] Saving purified items...")
        output_path_purified = RQ_DIR / "data" / "step02_purified_items.csv"

        # Add retention_reason column (all retained items passed thresholds)
        purified_items['retention_reason'] = 'PASS'

        # Ensure column order matches specification
        output_cols = ['item_tag', 'factor', 'a', 'b', 'retention_reason']
        purified_items_output = purified_items[output_cols]

        purified_items_output.to_csv(output_path_purified, index=False, encoding='utf-8')
        log(f"[SAVED] step02_purified_items.csv ({len(purified_items_output)} rows, {len(purified_items_output.columns)} cols)")

        # Show retention breakdown by factor
        log("[RESULT] Retained items by factor:")
        for factor in purified_items['factor'].unique():
            count = len(purified_items[purified_items['factor'] == factor])
            log(f"  - {factor}: {count} items")

        # Output 2: Purification report TXT (summary statistics)
        log("[SAVE] Generating purification report...")
        output_path_report = RQ_DIR / "data" / "step02_purification_report.txt"

        with open(output_path_report, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("ITEM PURIFICATION REPORT (Decision D039)\n")
            f.write("=" * 80 + "\n\n")

            # Summary statistics
            total_items = len(pass1_params)
            retained_count = len(purified_items)
            excluded_count = len(excluded_items)
            retained_pct = 100 * retained_count / total_items
            excluded_pct = 100 * excluded_count / total_items

            f.write(f"Total items analyzed: {total_items}\n")
            f.write(f"Items retained: {retained_count} ({retained_pct:.1f}%)\n")
            f.write(f"Items excluded: {excluded_count} ({excluded_pct:.1f}%)\n\n")

            # Breakdown by exclusion reason
            f.write("-" * 80 + "\n")
            f.write("EXCLUSION BREAKDOWN BY REASON\n")
            f.write("-" * 80 + "\n\n")

            if len(excluded_items) > 0:
                # Count exclusions by reason
                exclusion_reasons = excluded_items['exclusion_reason'].value_counts()
                for reason, count in exclusion_reasons.items():
                    f.write(f"  {reason}: {count} items\n")
            else:
                f.write("  No items excluded (all items passed thresholds)\n")

            f.write("\n")

            # Factor-specific retention counts
            f.write("-" * 80 + "\n")
            f.write("RETENTION BY FACTOR\n")
            f.write("-" * 80 + "\n\n")

            for factor in sorted(pass1_params['factor'].unique()):
                factor_total = len(pass1_params[pass1_params['factor'] == factor])
                factor_retained = len(purified_items[purified_items['factor'] == factor])
                factor_pct = 100 * factor_retained / factor_total
                f.write(f"  {factor}: {factor_retained}/{factor_total} ({factor_pct:.1f}%)\n")

            f.write("\n")

            # List of excluded items with reasons
            f.write("-" * 80 + "\n")
            f.write("EXCLUDED ITEMS (WITH REASONS)\n")
            f.write("-" * 80 + "\n\n")

            if len(excluded_items) > 0:
                for _, row in excluded_items.iterrows():
                    item = row['item_tag']
                    factor = row['factor']
                    a = row['a']
                    b = row['b']
                    reason = row['exclusion_reason']
                    f.write(f"  {item:20s} (factor={factor:12s}, a={a:.3f}, b={b:+.3f}): {reason}\n")
            else:
                f.write("  No items excluded\n")

            f.write("\n")
            f.write("=" * 80 + "\n")
            f.write("END OF REPORT\n")
            f.write("=" * 80 + "\n")

        log(f"[SAVED] step02_purification_report.txt")

        # =========================================================================
        # STEP 4: Run Validation Tool (validate_irt_parameters)
        # =========================================================================
        # Tool: validate_irt_parameters from tools.validation
        # Validates: All retained items meet purification criteria
        # Threshold: a >= 0.4, |b| <= 3.0, minimum 10 items per factor

        log("[VALIDATION] Running validate_irt_parameters...")

        # Prepare validation parameters (need to match tool signature)
        validation_result = validate_irt_parameters(
            df_items=purified_items.rename(columns={'item_tag': 'item_name', 'a': 'Discrimination', 'b': 'Difficulty'}),
            a_min=0.4,
            b_max=3.0,
            a_col='Discrimination',
            b_col='Difficulty'
        )

        # Report validation results
        if isinstance(validation_result, dict):
            for key, value in validation_result.items():
                log(f"[VALIDATION] {key}: {value}")
        else:
            log(f"[VALIDATION] {validation_result}")

        # Additional validation: minimum items per factor
        log("[VALIDATION] Checking minimum items per factor (threshold: 10)...")
        for factor in purified_items['factor'].unique():
            factor_count = len(purified_items[purified_items['factor'] == factor])
            if factor_count < 10:
                raise ValueError(f"Factor '{factor}' has only {factor_count} items (minimum 10 required)")
            log(f"[VALIDATION] Factor '{factor}': {factor_count} items [PASS]")

        # Check for NaN values
        log("[VALIDATION] Checking for NaN values...")
        nan_count = purified_items.isnull().sum().sum()
        if nan_count > 0:
            raise ValueError(f"Found {nan_count} NaN values in purified_items")
        log("[VALIDATION] No NaN values found [PASS]")

        # Check for duplicates
        log("[VALIDATION] Checking for duplicate items...")
        duplicate_count = purified_items['item_tag'].duplicated().sum()
        if duplicate_count > 0:
            duplicates = purified_items[purified_items['item_tag'].duplicated()]['item_tag'].tolist()
            raise ValueError(f"Found {duplicate_count} duplicate items: {duplicates}")
        log("[VALIDATION] No duplicate items found [PASS]")

        log("[SUCCESS] Step 2 complete - All validations passed")
        log(f"[SUMMARY] {retained_count} items retained, {excluded_count} items excluded")
        log(f"[SUMMARY] Ready for Pass 2 calibration (Step 3)")

        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
