#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step04
Step Name: compute_effect_size
RQ: results/ch5/rq9
Generated: 2025-11-28

PURPOSE:
Quantify age impact by comparing Day 6 memory for average vs older adults (Age + 1 SD).
Uses fitted LMM from step02 to predict theta scores for two age scenarios at Day 6 retention
interval. Computes decline in theta scores and percentage decline to quantify practical
significance of age effects on long-term memory retention.

EXPECTED INPUTS:
  - data/step02_lmm_model.pkl
    Description: Fitted LMM model object (statsmodels MixedLMResults)
    Expected: Model with Age_c, Time, Time_log predictors and interactions

  - data/step01_lmm_input_prepared.csv
    Columns: ['composite_ID', 'UID', 'TEST', 'TSVR_hours', 'theta', 'se_all', 'age', 'Age_c', 'Time', 'Time_log']
    Description: Prepared data with centered Age and time transformations
    Purpose: Extract SD_age for "Age + 1 SD" scenario and TSVR_day6 value (~144 hours)
    Expected rows: ~400 (100 participants x 4 tests)

EXPECTED OUTPUTS:
  - data/step04_effect_size.csv
    Columns: ['scenario', 'age_c', 'age_years', 'time_hours', 'theta_predicted']
    Description: Effect size scenarios (Average age vs Age + 1 SD at Day 6)
    Expected rows: 2 (one row per scenario)

  - results/step04_effect_size_summary.txt
    Description: Human-readable interpretation of effect size (decline in theta and percentage)
    Format: Text summary with predicted theta values, decline magnitude, and interpretation

VALIDATION CRITERIA:
  - theta_predicted in [-4, 4] (typical IRT theta range for memory ability)
  - age_c in [-30, 30] (centered age range for REMEMVR sample)
  - No NaN predictions (all scenarios produce valid theta estimates)

g_code REASONING:
- Approach: Use fitted LMM fixed effects to compute predicted theta for two age scenarios
  at Day 6 (~144 hours retention interval). Scenario 1: Average age (Age_c = 0).
  Scenario 2: Older adults (Age_c = +1 SD). Compare predictions to quantify age decline.

- Why this approach: LMM coefficients represent age effects on memory trajectory. By fixing
  time at Day 6 and varying age, we isolate age impact on long-term retention. Using +1 SD
  age difference provides interpretable effect size (comparing "typical" vs "older" adults).

- Data flow: Load fitted LMM → Extract SD(age) from prepared data → Define two scenarios
  (Age_c = 0 vs Age_c = SD_age, both at Day 6) → Compute predictions using fixed effects →
  Calculate decline (theta_older - theta_avg) and percentage → Save comparison table + summary

- Expected performance: <5 seconds (pure computation, no model fitting)

IMPLEMENTATION NOTES:
- Analysis tool: stdlib (pandas, numpy, pickle) for loading model and computing predictions
- Validation tool: tools.validation.validate_numeric_range (check theta and age_c ranges)
- Parameters: tsvr_day6 = 144 hours (Day 6 retention interval), scenarios = [Age_c=0, Age_c=SD_age]
- Prediction method: Manual computation using LMM fixed effects (theta = intercept + sum(coef_i * predictor_i))
- Time transformations: Time = TSVR_hours, Time_log = log(TSVR_hours + 1) as in LMM formula
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = chX/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import validation tool
from tools.validation import validate_numeric_range

# Import statsmodels for model loading
from statsmodels.regression.mixed_linear_model import MixedLMResults

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/chX/rqY (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step04_compute_effect_size.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html, .txt)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step04_effect_size.csv
#   CORRECT: results/step04_effect_size_summary.txt
#   WRONG:   results/effect_size.csv  (wrong folder + no prefix)
#   WRONG:   data/effect_size.csv     (missing step prefix)
#   WRONG:   logs/step04_effect_size.csv (CSV in logs folder)

# Effect size parameters
TSVR_DAY6 = 144.0  # Day 6 retention interval (~144 hours)
LOG_OFFSET = 1  # log(TSVR + 1) as in LMM formula

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 04: Compute Effect Size (Age Impact on Day 6 Memory)")

        # =========================================================================
        # STEP 1: Load Fitted LMM Model
        # =========================================================================
        # Expected: MixedLMResults object with formula theta ~ (Time + Time_log) * Age_c
        # Purpose: Extract fixed effects coefficients for prediction computation

        log("[LOAD] Loading fitted LMM model from step02...")
        model_path = RQ_DIR / "data" / "step02_lmm_model.pkl"

        # CRITICAL: Use MixedLMResults.load() method (NOT pickle.load())
        # Reason: statsmodels models require special loading to avoid patsy/eval errors
        lmm_result = MixedLMResults.load(str(model_path))

        log(f"[LOADED] LMM model from {model_path}")
        log(f"[INFO] Model formula: {lmm_result.model.formula}")
        log(f"[INFO] Converged: {lmm_result.converged}")

        # =========================================================================
        # STEP 2: Load Prepared Data (Extract SD_age and verify TSVR_day6)
        # =========================================================================
        # Expected: 400 rows (100 participants x 4 tests) with Age and TSVR columns
        # Purpose: Extract SD(age) for "Age + 1 SD" scenario definition

        log("[LOAD] Loading prepared data to extract SD(age)...")
        prepared_data_path = RQ_DIR / "data" / "step01_lmm_input_prepared.csv"
        df_prepared = pd.read_csv(prepared_data_path, encoding='utf-8')

        log(f"[LOADED] {prepared_data_path.name} ({len(df_prepared)} rows, {len(df_prepared.columns)} cols)")

        # Extract SD(age) for effect size scenarios
        sd_age = df_prepared['age'].std()
        mean_age = df_prepared['age'].mean()

        log(f"[INFO] Age statistics: Mean = {mean_age:.2f} years, SD = {sd_age:.2f} years")

        # Verify TSVR_day6 assumption (should be ~144 hours in actual data)
        tsvr_max = df_prepared['TSVR_hours'].max()
        log(f"[INFO] TSVR range in data: {df_prepared['TSVR_hours'].min():.1f} to {tsvr_max:.1f} hours")
        log(f"[INFO] Using TSVR_day6 = {TSVR_DAY6} hours for effect size computation")

        # =========================================================================
        # STEP 3: Define Effect Size Scenarios
        # =========================================================================
        # Scenario 1: Average age (Age_c = 0), Day 6 (Time = 144, Time_log = log(145))
        # Scenario 2: Age + 1 SD (Age_c = SD_age), Day 6 (Time = 144, Time_log = log(145))
        # Purpose: Compare predicted theta at Day 6 for typical vs older adults

        log("[COMPUTE] Defining effect size scenarios...")

        # Compute time transformations for Day 6
        time_day6 = TSVR_DAY6
        time_log_day6 = np.log(TSVR_DAY6 + LOG_OFFSET)

        log(f"[INFO] Day 6 time transformations: Time = {time_day6:.1f}, Time_log = {time_log_day6:.3f}")

        # Scenario definitions
        scenarios = [
            {
                'scenario': 'Average age',
                'age_c': 0.0,
                'age_years': mean_age,
                'time_hours': time_day6
            },
            {
                'scenario': 'Age + 1 SD',
                'age_c': sd_age,
                'age_years': mean_age + sd_age,
                'time_hours': time_day6
            }
        ]

        log(f"[INFO] Scenario 1: {scenarios[0]['scenario']} (Age_c = {scenarios[0]['age_c']:.2f}, Age = {scenarios[0]['age_years']:.1f} years)")
        log(f"[INFO] Scenario 2: {scenarios[1]['scenario']} (Age_c = {scenarios[1]['age_c']:.2f}, Age = {scenarios[1]['age_years']:.1f} years)")

        # =========================================================================
        # STEP 4: Compute Predicted Theta for Each Scenario
        # =========================================================================
        # Method: Use LMM fixed effects to compute theta = intercept + sum(coef_i * predictor_i)
        # Formula: theta ~ (Time + Time_log) * Age_c
        # Expanded: theta ~ 1 + Time + Time_log + Age_c + Time:Age_c + Time_log:Age_c
        # Purpose: Quantify age impact on Day 6 memory retention

        log("[COMPUTE] Computing predicted theta using LMM fixed effects...")

        # Extract fixed effects from LMM
        fixed_effects = lmm_result.fe_params

        log(f"[INFO] Fixed effects parameters:")
        for param_name, param_value in fixed_effects.items():
            log(f"  {param_name}: {param_value:.4f}")

        # Compute predictions for each scenario
        predictions = []

        for scenario in scenarios:
            age_c = scenario['age_c']
            time = time_day6
            time_log = time_log_day6

            # Manual prediction using fixed effects
            # theta = Intercept + Time*coef_Time + Time_log*coef_Time_log + Age_c*coef_Age_c
            #         + (Time*Age_c)*coef_Time:Age_c + (Time_log*Age_c)*coef_Time_log:Age_c

            theta_pred = (
                fixed_effects['Intercept'] +
                fixed_effects['Time'] * time +
                fixed_effects['Time_log'] * time_log +
                fixed_effects['Age_c'] * age_c +
                fixed_effects['Time:Age_c'] * (time * age_c) +
                fixed_effects['Time_log:Age_c'] * (time_log * age_c)
            )

            scenario['theta_predicted'] = theta_pred
            predictions.append(scenario)

            log(f"[PREDICTED] {scenario['scenario']}: theta = {theta_pred:.3f}")

        # Create DataFrame with predictions
        df_effect_size = pd.DataFrame(predictions)

        # =========================================================================
        # STEP 5: Compute Decline Metrics
        # =========================================================================
        # Decline = theta_older - theta_avg (expected negative)
        # Decline_percent = (Decline / theta_avg) * 100
        # Purpose: Quantify magnitude of age impact on Day 6 memory

        log("[COMPUTE] Computing age decline metrics...")

        theta_avg = df_effect_size.loc[df_effect_size['scenario'] == 'Average age', 'theta_predicted'].values[0]
        theta_older = df_effect_size.loc[df_effect_size['scenario'] == 'Age + 1 SD', 'theta_predicted'].values[0]

        decline_theta = theta_older - theta_avg
        decline_percent = (decline_theta / theta_avg) * 100 if theta_avg != 0 else np.nan

        log(f"[RESULT] Average age theta at Day 6: {theta_avg:.3f}")
        log(f"[RESULT] Age + 1 SD theta at Day 6: {theta_older:.3f}")
        log(f"[RESULT] Decline (theta): {decline_theta:.3f}")
        log(f"[RESULT] Decline (percent): {decline_percent:.1f}%")

        # =========================================================================
        # STEP 6: Save Effect Size Results
        # =========================================================================
        # Output 1: data/step04_effect_size.csv (comparison table)
        # Output 2: results/step04_effect_size_summary.txt (interpretation)

        log("[SAVE] Saving effect size results...")

        # Save comparison table
        output_csv = RQ_DIR / "data" / "step04_effect_size.csv"
        df_effect_size.to_csv(output_csv, index=False, encoding='utf-8')
        log(f"[SAVED] {output_csv.name} ({len(df_effect_size)} rows)")

        # Create summary text
        summary_text = f"""EFFECT SIZE SUMMARY - Age Impact on Day 6 Memory (RQ 5.9)
{'=' * 70}

SCENARIOS COMPARED:
  1. Average age: {scenarios[0]['age_years']:.1f} years (Age_c = {scenarios[0]['age_c']:.2f})
  2. Older adults: {scenarios[1]['age_years']:.1f} years (Age_c = {scenarios[1]['age_c']:.2f})

  Age difference: +1 SD = {sd_age:.2f} years

PREDICTED THETA SCORES AT DAY 6 (TSVR = {TSVR_DAY6:.0f} hours):
  Average age:  {theta_avg:.3f}
  Older adults: {theta_older:.3f}

AGE DECLINE AT DAY 6:
  Absolute decline: {decline_theta:.3f} theta units
  Percentage decline: {decline_percent:.1f}%

INTERPRETATION:
  Older adults (+ 1 SD age) show {'lower' if decline_theta < 0 else 'higher'} memory retention
  at Day 6 compared to average-age participants. A {abs(decline_theta):.3f} theta
  unit decline represents a {abs(decline_percent):.1f}% reduction in memory ability
  after ~6 days of retention.

NOTE:
  - Theta scores are on IRT scale (mean 0, SD 1 in calibration sample)
  - Negative decline indicates worse memory for older adults (expected)
  - Positive decline would indicate better memory for older adults (unexpected)
  - Effect size quantifies practical significance of age effects on forgetting

GENERATED: 2025-11-28
RQ: ch5/rq9 (Age effects on baseline memory and forgetting rate)
"""

        # Save summary text
        output_txt = RQ_DIR / "results" / "step04_effect_size_summary.txt"
        output_txt.parent.mkdir(parents=True, exist_ok=True)
        with open(output_txt, 'w', encoding='utf-8') as f:
            f.write(summary_text)
        log(f"[SAVED] {output_txt.name}")

        # =========================================================================
        # STEP 7: Validation - Check Predicted Theta Range
        # =========================================================================
        # Tool: tools.validation.validate_numeric_range
        # Criteria: theta_predicted in [-4, 4] (typical IRT range)
        # Purpose: Ensure predictions are plausible before reporting

        log("[VALIDATION] Validating predicted theta range...")

        validation_result = validate_numeric_range(
            data=df_effect_size['theta_predicted'].values,
            min_val=-4.0,
            max_val=4.0,
            column_name='theta_predicted'
        )

        if validation_result['valid']:
            log(f"[VALIDATION PASS] theta_predicted in [-4, 4]: {validation_result['message']}")
        else:
            log(f"[VALIDATION FAIL] theta_predicted out of range: {validation_result['message']}")
            raise ValueError(f"Validation failed: {validation_result['message']}")

        # Validate Age_c range
        log("[VALIDATION] Validating Age_c range...")

        validation_result_age = validate_numeric_range(
            data=df_effect_size['age_c'].values,
            min_val=-30.0,
            max_val=30.0,
            column_name='age_c'
        )

        if validation_result_age['valid']:
            log(f"[VALIDATION PASS] age_c in [-30, 30]: {validation_result_age['message']}")
        else:
            log(f"[VALIDATION FAIL] age_c out of range: {validation_result_age['message']}")
            raise ValueError(f"Validation failed: {validation_result_age['message']}")

        log("[SUCCESS] Step 04 complete - Effect size computed and validated")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
