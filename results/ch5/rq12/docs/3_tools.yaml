# 3_tools.yaml - Tool Catalog (Analysis + Validation Tools)
# Created by: rq_tools agent (Step 11)
# Consumed by: rq_analysis agent (Step 12)
# Architecture: Tool Catalog (Option A) - Each tool listed once, deduplication
# RQ: 5.12 - CTT-IRT Convergence via Item Purification
# Created: 2025-11-27

analysis_tools:
  compute_cronbachs_alpha:
    module: "tools.analysis_ctt"
    function: "compute_cronbachs_alpha"
    signature: "compute_cronbachs_alpha(data: DataFrame, n_bootstrap: int = 1000) -> Dict[str, Any]"
    validation_tool: "validate_numeric_range"

    input_files:
      - path: "data/step00_raw_ctt_data.csv"
        required_columns: ["composite_ID", "UID", "test", "TQ_ item columns"]
        expected_rows: "~400 (100 participants × 4 tests)"
        data_types:
          composite_ID: "string (format: {UID}_{test})"
          UID: "string (participant identifier)"
          test: "string (values: T1, T2, T3, T4)"
          TQ_items: "int (values: 0, 1, NaN)"

    output_files:
      - path: "results/step04_ctt_reliability.csv"
        columns: ["domain", "item_set", "alpha", "ci_lower", "ci_upper", "n_items"]
        description: "Cronbach's alpha with bootstrap 95% CIs for full and purified item sets"

    parameters:
      n_bootstrap: 1000

    description: "Compute Cronbach's alpha internal consistency reliability with bootstrap confidence intervals for full and purified CTT item sets"
    source_reference: "tools_inventory.md section 'Module: tools.analysis_ctt' - compute_cronbachs_alpha"

  compare_correlations_dependent:
    module: "tools.analysis_ctt"
    function: "compare_correlations_dependent"
    signature: "compare_correlations_dependent(r12: float, r13: float, r23: float, n: int) -> Dict[str, Any]"
    validation_tool: "validate_correlation_test_d068"

    input_files:
      - path: "data/step02_full_ctt_scores.csv"
        required_columns: ["composite_ID", "domain", "ctt_score_full"]
        expected_rows: "~1200 (400 composite_IDs × 3 domains)"
      - path: "data/step03_purified_ctt_scores.csv"
        required_columns: ["composite_ID", "domain", "ctt_score_purified"]
        expected_rows: "~1200"
      - path: "data/step00_theta_with_tsvr.csv"
        required_columns: ["composite_ID", "theta_common", "theta_congruent", "theta_incongruent"]
        expected_rows: "~400"

    output_files:
      - path: "results/step05_correlations.csv"
        columns: ["domain", "correlation_pair", "r", "n"]
        description: "Pairwise correlations between Full CTT, Purified CTT, and IRT theta"
      - path: "results/step05_steiger_tests.csv"
        columns: ["domain", "r_full_irt", "r_purified_irt", "delta_r", "z_statistic", "p_value", "interpretation"]
        description: "Steiger's z-test results comparing dependent correlations"

    parameters:
      test_type: "two_tailed"

    description: "Test whether purified CTT correlates more strongly with IRT theta than full CTT using Steiger's z-test for dependent correlations"
    source_reference: "tools_inventory.md section 'Module: tools.analysis_ctt' - compare_correlations_dependent"

  fit_lmm_trajectory_tsvr:
    module: "tools.analysis_lmm"
    function: "fit_lmm_trajectory_tsvr"
    signature: "fit_lmm_trajectory_tsvr(theta_scores: DataFrame, tsvr_data: DataFrame, formula: str, groups: str = 'UID', re_formula: str = '~Days', reml: bool = False) -> MixedLMResults"
    validation_tool: "validate_lmm_convergence"

    input_files:
      - path: "data/step06_standardized_scores.csv"
        required_columns: ["composite_ID", "UID", "test", "domain", "TSVR_hours", "z_full_ctt", "z_purified_ctt", "z_irt_theta"]
        expected_rows: "~1200 (400 composite_IDs × 3 domains)"
        data_types:
          composite_ID: "string"
          UID: "string"
          test: "string"
          domain: "string"
          TSVR_hours: "float (range: [0, 300])"
          z_scores: "float (range: [-4, 4])"

    output_files:
      - path: "results/step07_lmm_full_ctt_summary.txt"
        description: "Full CTT LMM model summary (fixed effects, random effects, AIC, BIC)"
      - path: "results/step07_lmm_purified_ctt_summary.txt"
        description: "Purified CTT LMM model summary"
      - path: "results/step07_lmm_irt_theta_summary.txt"
        description: "IRT theta LMM model summary (gold standard)"
      - path: "results/step07_lmm_comparison.csv"
        columns: ["measurement_approach", "AIC", "BIC", "delta_AIC_vs_IRT", "interpretation"]
        description: "AIC/BIC comparison across three measurement approaches"
      - path: "results/step07_interaction_coefficients.csv"
        columns: ["measurement_approach", "interaction_term", "coefficient", "SE", "p_value"]
        description: "Domain × Time interaction coefficients for all three approaches"

    parameters:
      formula: "z_Ability ~ (TSVR_hours + log(TSVR_hours+1)) * domain"
      groups: "UID"
      re_formula: "~TSVR_hours"
      reml: false

    description: "Fit parallel LMMs to all three standardized measurement approaches (Full CTT, Purified CTT, IRT theta) using TSVR as time variable per Decision D070"
    source_reference: "tools_inventory.md section 'Module: tools.analysis_lmm' - fit_lmm_trajectory_tsvr"

validation_tools:
  validate_numeric_range:
    module: "tools.validation"
    function: "validate_numeric_range"
    signature: "validate_numeric_range(data: np.ndarray or pd.Series, min_val: float, max_val: float, column_name: str) -> Dict[str, Any]"

    input_files:
      - path: "results/step04_ctt_reliability.csv"
        required_columns: ["alpha", "ci_lower", "ci_upper"]
        source: "analysis tool output (step04_assess_reliability)"

    parameters:
      checks:
        - column: "alpha"
          min_val: 0.5
          max_val: 0.95
          column_name: "Cronbach's alpha"
        - column: "ci_lower"
          min_val: 0.0
          max_val: 1.0
          column_name: "CI lower bound"
        - column: "ci_upper"
          min_val: 0.0
          max_val: 1.0
          column_name: "CI upper bound"

    criteria:
      - "All alpha values in range [0.5, 0.95] (episodic memory scales typically 0.7-0.9)"
      - "All CI bounds in valid range [0, 1]"
      - "ci_lower < alpha < ci_upper (CIs must bracket point estimate)"
      - "No NaN or infinite values"

    expected_output:
      format: "Dict[str, Any]"
      fields:
        valid: "bool (True if all criteria passed)"
        message: "str (human-readable explanation)"
        out_of_range_count: "int (number of violations)"
        violations: "list (first 10 violations for debugging)"

    behavior_on_failure:
      action: "raise ValueError"
      log_to: "logs/step04_assess_reliability.log"
      invoke: "g_debug (master invokes after error)"

    description: "Validate Cronbach's alpha values and confidence intervals are in acceptable ranges"
    source_reference: "tools_inventory.md section 'Module: tools.validation' - validate_numeric_range"

  validate_correlation_test_d068:
    module: "tools.validation"
    function: "validate_correlation_test_d068"
    signature: "validate_correlation_test_d068(correlation_df: DataFrame, required_cols: List[str] = None) -> Dict[str, Any]"

    input_files:
      - path: "results/step05_steiger_tests.csv"
        required_columns: ["z_statistic", "p_value"]
        source: "analysis tool output (step05_correlation_analysis)"

    parameters:
      required_cols: ["r_full_irt", "r_purified_irt", "z_statistic", "p_value"]

    criteria:
      - "Decision D068: Dual p-value reporting (uncorrected + correction method)"
      - "All correlation values r in [-1, 1]"
      - "All p-values in [0, 1]"
      - "No NaN values in correlation or p-value columns"

    expected_output:
      format: "Dict[str, Any]"
      fields:
        valid: "bool"
        d068_compliant: "bool (True if dual p-values present)"
        missing_cols: "List[str] (any missing required columns)"
        message: "str"

    behavior_on_failure:
      action: "raise ValueError"
      log_to: "logs/step05_correlation_analysis.log"
      invoke: "g_debug (master invokes)"

    description: "Validate correlation test results include Decision D068 dual p-value reporting"
    source_reference: "tools_inventory.md section 'Module: tools.validation' - validate_correlation_test_d068"

  validate_standardization:
    module: "tools.validation"
    function: "validate_standardization"
    signature: "validate_standardization(df: pd.DataFrame, column_names: List[str], tolerance: float = 0.01) -> Dict[str, Any]"

    input_files:
      - path: "data/step06_standardized_scores.csv"
        required_columns: ["z_full_ctt", "z_purified_ctt", "z_irt_theta"]
        source: "analysis tool output (step06_standardize_outcomes)"

    parameters:
      column_names: ["z_full_ctt", "z_purified_ctt", "z_irt_theta"]
      tolerance: 0.01

    criteria:
      - "All z-score means ≈ 0 (within ±0.01 tolerance)"
      - "All z-score SDs ≈ 1 (within [0.99, 1.01] tolerance)"
      - "All z-scores in range [-4, 4] (allow up to 4 SD for outliers)"
      - "No NaN values"

    expected_output:
      format: "Dict[str, Any]"
      fields:
        valid: "bool"
        message: "str"
        mean_values: "Dict[str, float] (actual means per column)"
        sd_values: "Dict[str, float] (actual SDs per column)"

    behavior_on_failure:
      action: "raise ValueError"
      log_to: "logs/step06_standardize_outcomes.log"
      invoke: "g_debug (master invokes)"

    description: "Validate z-score standardization (mean ≈ 0, SD ≈ 1) for valid AIC comparison across different measurement scales"
    source_reference: "tools_inventory.md section 'Module: tools.validation' - validate_standardization"

  validate_lmm_convergence:
    module: "tools.validation"
    function: "validate_lmm_convergence"
    signature: "validate_lmm_convergence(lmm_result: MixedLMResults) -> Dict[str, Any]"

    input_files:
      - path: "results/step07_lmm_full_ctt_summary.txt"
        source: "analysis tool output (step07_fit_parallel_lmms)"
      - path: "results/step07_lmm_purified_ctt_summary.txt"
        source: "analysis tool output (step07_fit_parallel_lmms)"
      - path: "results/step07_lmm_irt_theta_summary.txt"
        source: "analysis tool output (step07_fit_parallel_lmms)"

    parameters:
      check_singularity: true
      min_observations: 100

    criteria:
      - "Model converged (no convergence warnings)"
      - "No singular fit (random effects variance > 0)"
      - "Minimum 100 observations used"
      - "All fixed effects have finite estimates (no NaN/Inf)"

    expected_output:
      format: "Dict[str, Any]"
      fields:
        valid: "bool"
        message: "str"
        convergence_status: "str"
        warnings: "List[str]"

    behavior_on_failure:
      action: "raise ValueError"
      log_to: "logs/step07_fit_parallel_lmms.log"
      invoke: "g_debug (master invokes)"

    description: "Validate LMM converged successfully, no singular fit, all estimates finite"
    source_reference: "tools_inventory.md section 'Module: tools.validation' - validate_lmm_convergence"

  validate_lmm_assumptions_comprehensive:
    module: "tools.validation"
    function: "validate_lmm_assumptions_comprehensive"
    signature: "validate_lmm_assumptions_comprehensive(lmm_result: MixedLMResults, data: DataFrame, output_dir: Path, acf_lag1_threshold: float = 0.1, alpha: float = 0.05) -> Dict[str, Any]"

    input_files:
      - path: "results/step07_lmm_full_ctt_summary.txt"
        source: "analysis tool output (step07_fit_parallel_lmms)"
      - path: "data/step06_standardized_scores.csv"
        required_columns: ["composite_ID", "UID", "domain", "TSVR_hours", "z_full_ctt", "z_purified_ctt", "z_irt_theta"]
        source: "original data for residual diagnostics"

    parameters:
      output_dir: "logs/"
      acf_lag1_threshold: 0.1
      alpha: 0.05

    criteria:
      - "Residual normality (Shapiro-Wilk + Q-Q plot)"
      - "Homoscedasticity (Breusch-Pagan + residuals vs fitted)"
      - "Random effects normality (Shapiro-Wilk + Q-Q plots for intercepts/slopes)"
      - "Autocorrelation (ACF plot + Lag-1 test)"
      - "Linearity (partial residual CSVs for rq_plots)"
      - "Outliers (Cook's distance)"
      - "Convergence diagnostics"

    expected_output:
      format: "Dict[str, Any]"
      fields:
        valid: "bool (True only if ALL 7 diagnostics pass)"
        diagnostics: "Dict (results per diagnostic)"
        plot_paths: "List[Path] (6 diagnostic plots generated)"
        message: "str"

    behavior_on_failure:
      action: "raise ValueError"
      log_to: "logs/step07_fit_parallel_lmms.log"
      invoke: "g_debug (master invokes)"

    description: "Comprehensive LMM assumption validation with 7 diagnostics and remedial action recommendations"
    source_reference: "tools_inventory.md section 'Module: tools.validation' - validate_lmm_assumptions_comprehensive"

summary:
  analysis_tools_count: 3
  validation_tools_count: 5
  total_unique_tools: 8
  mandatory_decisions_embedded: ["D068", "D070"]
  notes: |
    RQ 5.12 uses hybrid CTT-IRT methodological comparison.
    Most analysis steps (Steps 0-3, 6, 8) use pandas stdlib operations (exempt from verification).
    Only 3 custom analysis tools required: compute_cronbachs_alpha, compare_correlations_dependent, fit_lmm_trajectory_tsvr.
    Validation tools include Decision D068 compliance checks (dual p-value reporting).
    All tools verified to exist in tools_inventory.md (CTT module created after initial FAIL).
