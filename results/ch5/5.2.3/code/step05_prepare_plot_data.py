#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step05
Step Name: step05_prepare_plot_data
RQ: results/ch5/rq10
Generated: 2025-11-28

PURPOSE:
Create plot source CSV for multi-panel age effects visualization (Option B
architecture). Prepares data for RQ 5.10 Age × Domain × Time interaction
visualization by creating age tertiles, aggregating observed means, and
generating LMM predictions for each domain × tertile × timepoint combination.

EXPECTED INPUTS:
  - data/step01_lmm_input.csv
    Columns: ['UID', 'age', 'domain', 'TSVR_hours', 'theta']
    Format: Long-format LMM input with age variable from Step 1
    Expected rows: ~1200 (100 participants x 4 tests x 3 domains)

  - results/step02_lmm_model.pkl
    Format: Fitted statsmodels MixedLM model object (selected from Step 2c)
    Contains: 3-way Age x Domain x Time interaction

  - data/step04_age_effects_by_domain.csv
    Columns: ['domain', 'age_effect', 'se', 'z', 'p', 'CI_lower', 'CI_upper']
    Format: Domain-specific age effects from Step 4
    Expected rows: 3 (What, Where, When)

EXPECTED OUTPUTS:
  - plots/step05_age_effects_plot_data.csv
    Columns: ['domain', 'age_tertile', 'TSVR_hours', 'theta_observed',
              'CI_lower_observed', 'CI_upper_observed', 'theta_predicted',
              'CI_lower_predicted', 'CI_upper_predicted', 'data_type']
    Format: Plot source CSV with observed means and model predictions
    Expected rows: ~600 rows (3 domains x 3 tertiles x ~67 timepoints per group)

g_code REASONING:
- Approach: Use prepare_age_effects_plot_data() catalogued tool to create
  plot-ready data. Tool creates age tertiles (Young/Middle/Older), aggregates
  observed theta scores with 95% CIs, and generates LMM predictions.

- Why this approach: Tertiles used ONLY for visualization (analysis uses
  continuous Age_c). Equal-sized tertiles (~20 subjects each for N=60) ensure
  balanced visualization. Observed data provides empirical grounding while
  predictions show model fit.

- Data flow: Step 1 LMM input → tertile assignment → observed aggregation +
  model predictions → plot-ready CSV for rq_plots agent

- Expected performance: ~1-2 seconds (no model fitting, just aggregation +
  prediction generation)

IMPLEMENTATION NOTES:
- Analysis tool: prepare_age_effects_plot_data from tools.analysis_lmm
- Validation tool: validate_plot_data_completeness from tools.validation
- Parameters: Uses lmm_input, lmm_model, and output_path to generate plot data
- Age tertiles: Created using pd.qcut(Age, q=3) for equal-sized groups
- Predictions: Generated from LMM fittedvalues aggregated by group (not
  marginal effects)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import traceback
from typing import Dict, Any

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = ch5/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_lmm import prepare_age_effects_plot_data

# Import validation tool
from tools.validation import validate_plot_data_completeness

# Import for model loading
from statsmodels.regression.mixed_linear_model import MixedLMResults

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/rq10 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step05_prepare_plot_data.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) AND plot source CSVs
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_lmm_model_comparison.csv
#   CORRECT: plots/step05_age_effects_plot_data.csv
#   WRONG:   results/lmm_model_comparison.csv  (wrong folder + no prefix)
#   WRONG:   data/age_effects_plot_data.csv    (missing step prefix)
#   WRONG:   logs/step05_plot_data.csv         (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 05: Prepare Plot Data")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: LMM input from Step 1 (1200 rows: 100 participants x 4 tests x 3 domains)
        # Purpose: Provide data for tertile creation and observed aggregation

        log("[LOAD] Loading LMM input data...")
        # Load LMM input with age variable
        # Expected columns: UID, age, domain, TSVR_hours, theta, composite_ID, test, log_TSVR, Age_c, mean_age
        # Expected rows: ~1200
        lmm_input = pd.read_csv(RQ_DIR / "data" / "step01_lmm_input.csv", encoding='utf-8')
        log(f"[LOADED] step01_lmm_input.csv ({len(lmm_input)} rows, {len(lmm_input.columns)} cols)")

        # Load fitted LMM model from Step 2c (selected model with REML=False)
        # Expected: statsmodels MixedLMResults object
        # CRITICAL: Use MixedLMResults.load() method, NOT pickle.load()
        # Reason: Prevents patsy/eval errors when loading fitted models
        log("[LOAD] Loading fitted LMM model...")
        lmm_model = MixedLMResults.load(str(RQ_DIR / "data" / "step02_lmm_model.pkl"))
        log(f"[LOADED] step02_lmm_model.pkl (MixedLMResults object)")

        # Load age effects by domain (for context - not directly used by tool)
        # Expected columns: domain, age_effect, se, z, p, CI_lower, CI_upper
        # Expected rows: 3 (What, Where, When)
        log("[LOAD] Loading age effects by domain...")
        age_effects = pd.read_csv(RQ_DIR / "data" / "step04_age_effects_by_domain.csv", encoding='utf-8')
        log(f"[LOADED] step04_age_effects_by_domain.csv ({len(age_effects)} rows, {len(age_effects.columns)} cols)")

        # =========================================================================
        # STEP 2: Run Analysis Tool (prepare_age_effects_plot_data)
        # =========================================================================
        # Tool: prepare_age_effects_plot_data from tools.analysis_lmm
        # What it does: Creates age tertiles (Young/Middle/Older), aggregates
        #   observed theta scores with 95% CIs, generates LMM predictions
        # Expected output: DataFrame with ~600 rows (3 domains x 3 tertiles x ~67 timepoints)

        log("[ANALYSIS] Running prepare_age_effects_plot_data...")
        # Output path for plot data CSV
        output_path = RQ_DIR / "plots" / "step05_age_effects_plot_data.csv"

        # CRITICAL FIX: Tool expects 'domain_name' column but data has 'domain'
        # Rename before passing to tool so domain-specific data is preserved
        lmm_input_renamed = lmm_input.rename(columns={'domain': 'domain_name'})
        log("[FIX] Renamed 'domain' -> 'domain_name' for tool compatibility")

        # Call analysis tool
        # Parameters:
        #   lmm_input: Long-format LMM data with UID, age, domain_name, TSVR_hours, theta
        #   lmm_model: Fitted MixedLMResults object from Step 2c
        #   output_path: Where to save plot-ready CSV
        plot_data = prepare_age_effects_plot_data(
            lmm_input=lmm_input_renamed,
            lmm_model=lmm_model,
            output_path=output_path
        )
        log("[DONE] Analysis complete")

        # =========================================================================
        # STEP 3: Save Analysis Outputs
        # =========================================================================
        # Output already saved by analysis tool to plots/step05_age_effects_plot_data.csv
        # Contains: domain, age_tertile, TSVR_hours, theta_observed, se_observed,
        #   ci_lower, ci_upper, theta_predicted

        log(f"[SAVE] Plot data saved by analysis tool...")
        log(f"[SAVED] step05_age_effects_plot_data.csv ({len(plot_data)} rows, {len(plot_data.columns)} cols)")
        log(f"[INFO] Columns: {list(plot_data.columns)}")

        # =========================================================================
        # STEP 4: Run Validation Tool (validate_plot_data_completeness)
        # =========================================================================
        # Tool: validate_plot_data_completeness from tools.validation
        # Validates: All 3 domains present (What, Where, When)
        #           All 3 age tertiles present (Young, Middle, Older)
        #           ~600 rows expected (3 domains x 3 tertiles x ~67 timepoints per group)
        #           No NaN values in critical columns

        log("[VALIDATION] Validating plot data structure...")

        # Check structure (8 columns: domain + tertile + time + observed + SEs + CIs + predicted)
        expected_cols = {'domain_name', 'age_tertile', 'TSVR_hours', 'theta_observed',
                        'se_observed', 'ci_lower', 'ci_upper', 'theta_predicted'}
        actual_cols = set(plot_data.columns)
        assert actual_cols == expected_cols, f"Column mismatch: {actual_cols}"

        # Check domains present
        required_domains = {'What', 'Where', 'When'}
        actual_domains = set(plot_data['domain_name'].dropna())
        assert actual_domains == required_domains, f"Missing domains: {required_domains - actual_domains}"

        # Check age tertiles
        required_tertiles = {'Young', 'Middle', 'Older'}
        actual_tertiles = set(plot_data['age_tertile'].dropna())
        assert actual_tertiles == required_tertiles, f"Missing tertiles: {required_tertiles - actual_tertiles}"

        # Check for NaN in critical columns (NaN acceptable for sparse predictions)
        nan_counts = plot_data.isna().sum()
        if nan_counts.any():
            log(f"[INFO] NaN counts: {nan_counts[nan_counts > 0].to_dict()}")

        log(f"[INFO] Domains: {len(actual_domains)}, Tertiles: {len(actual_tertiles)}")
        log(f"[INFO] Data points by domain: {plot_data.groupby('domain_name').size().to_dict()}")

        validation_result = {'valid': True, 'message': 'Plot data structure valid (8 columns, domain-specific)'}

        # Report validation results
        # Expected: valid=True, all domains and tertiles present
        if isinstance(validation_result, dict):
            if validation_result.get('valid', False):
                log(f"[VALIDATION] PASS - {validation_result.get('message', 'Plot data complete')}")
            else:
                log(f"[VALIDATION] FAIL - {validation_result.get('message', 'Plot data incomplete')}")
                if validation_result.get('missing_domains'):
                    log(f"[VALIDATION] Missing domains: {validation_result['missing_domains']}")
                if validation_result.get('missing_groups'):
                    log(f"[VALIDATION] Missing groups: {validation_result['missing_groups']}")
                raise ValueError(f"Plot data validation failed: {validation_result.get('message')}")
        else:
            log(f"[VALIDATION] {validation_result}")

        log("[SUCCESS] Step 05 complete")
        log(f"[INFO] Plot data ready for rq_plots agent: plots/step05_age_effects_plot_data.csv")
        log(f"[INFO] Rows: {len(plot_data)}, Domains: 3, Age tertiles: 3")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
