#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step02b
Step Name: Validate LMM Assumptions
RQ: ch5/5.2.3
Generated: 2025-11-28

PURPOSE:
Verify Linear Mixed Model assumptions before proceeding to inference. Runs
comprehensive 7-diagnostic assumption validation to ensure model validity:
(1) Residual normality, (2) Homoscedasticity, (3) Random effects normality,
(4) Independence (autocorrelation), (5) Linearity, (6) Outliers, (7) Convergence.

EXPECTED INPUTS:
  - results/step02_lmm_model.pkl
    Description: Fitted LMM from Step 2 (3-way Age x Domain x Time interaction)
    Format: statsmodels MixedLMResults pickle object
    Expected: Model with random intercepts/slopes structure

  - data/step01_lmm_input.csv
    Columns: ['UID', 'composite_ID', 'test', 'domain', 'theta', 'TSVR_hours',
              'log_TSVR', 'age', 'Age_c', 'mean_age']
    Format: Long-format LMM input with 1200 rows (100 participants x 4 tests x 3 domains)
    Expected rows: ~1200

EXPECTED OUTPUTS:
  - results/step02b_assumption_diagnostics.txt
    Description: Text summary of 7 assumption checks with overall assessment
    Format: Plain text report with Pass/Conditional/Fail per diagnostic
    Expected: Overall assessment (Pass / Conditional pass / Fail)

  - plots/step02b_diagnostic_plots.png
    Description: Multi-panel diagnostic plot (Q-Q, residuals vs fitted, ACF, Cook's D)
    Format: PNG image (multi-panel visualization)
    Expected: 6 diagnostic plots (qq_residuals, residuals_vs_fitted, qq_random_intercepts,
              qq_random_slopes, acf, cooks_distance)

VALIDATION CRITERIA:
  - All 7 diagnostics reported (residual normality, homoscedasticity, random effects
    normality, independence, linearity, outliers, convergence)
  - Overall assessment stated (Pass / Conditional pass / Fail)
  - Diagnostic plots generated successfully

g_code REASONING:
- Approach: Use validate_lmm_assumptions_comprehensive() from tools.validation which
  implements complete assumption checking framework per Schielzeth et al. 2020
- Why this approach: Comprehensive validation catches assumption violations BEFORE
  inference (prevents invalid conclusions from invalid models)
- Data flow: LMM model + input data → 7 diagnostic checks → text report + diagnostic plots
- Expected performance: ~10-30 seconds (depends on residual computations and plot generation)

IMPLEMENTATION NOTES:
- Analysis tool: validate_lmm_assumptions_comprehensive from tools.validation
- Validation tool: Same function (self-validating - checks its own outputs exist)
- Parameters: acf_lag1_threshold=0.1 (autocorrelation tolerance), alpha=0.05 (significance)
- Output: Dict with keys: valid (bool), diagnostics (Dict), plot_paths (List[Path]), message (str)
- Non-blocking: Assumption violations flagged but don't halt pipeline (conditional pass)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import pickle
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = chX/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.validation import validate_lmm_assumptions_comprehensive

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.2.3 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step02b_validate_assumptions.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html, .txt summaries)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step02b_diagnostics.csv
#   CORRECT: results/step02b_assumption_diagnostics.txt
#   WRONG:   data/diagnostics.csv             (missing step prefix)
#   WRONG:   logs/step02b_diagnostics.csv     (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 02b: Validate LMM Assumptions")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Fitted LMM model from Step 2 with 3-way Age x Domain x Time interaction
        # Purpose: Extract model object and original data for residual diagnostics

        log("[LOAD] Loading fitted LMM model from Step 2...")
        model_path = RQ_DIR / "data" / "step02_lmm_model.pkl"

        # Load statsmodels MixedLMResults object using statsmodels.load()
        # CRITICAL: Use MixedLMResults.load() method, NOT pickle.load()
        # Why: pickle.load() causes patsy/eval errors with statsmodels models
        from statsmodels.regression.mixed_linear_model import MixedLMResults
        lmm_model = MixedLMResults.load(str(model_path))
        log(f"[LOADED] LMM model from {model_path}")

        log("[LOAD] Loading LMM input data from Step 1...")
        lmm_input_path = RQ_DIR / "data" / "step01_lmm_input.csv"
        lmm_input = pd.read_csv(lmm_input_path, encoding='utf-8')
        log(f"[LOADED] LMM input data: {len(lmm_input)} rows, {len(lmm_input.columns)} columns")

        # Verify expected structure
        expected_cols = ['UID', 'composite_ID', 'test', 'domain', 'theta', 'TSVR_hours',
                        'log_TSVR', 'age', 'Age_c', 'mean_age']
        missing_cols = set(expected_cols) - set(lmm_input.columns)
        if missing_cols:
            raise ValueError(f"Missing expected columns in LMM input: {missing_cols}")
        log(f"[CHECK] All expected columns present in LMM input")

        # =========================================================================
        # STEP 2: Run Assumption Validation
        # =========================================================================
        # Tool: validate_lmm_assumptions_comprehensive
        # What it does: Comprehensive 7-diagnostic assumption checking framework
        #   (1) Residual normality: Shapiro-Wilk test + Q-Q plot
        #   (2) Homoscedasticity: Breusch-Pagan test + residuals vs fitted plot
        #   (3) Random effects normality: Shapiro-Wilk + Q-Q plots for intercepts/slopes
        #   (4) Independence: ACF plot + Lag-1 test (autocorrelation check)
        #   (5) Linearity: Partial residual CSVs for each predictor
        #   (6) Outliers: Cook's distance plot
        #   (7) Convergence: Model convergence status
        # Expected output: Dict with valid (bool), diagnostics (Dict), plot_paths (List), message (str)

        log("[VALIDATION] Running comprehensive LMM assumption checks...")
        log("[VALIDATION] This includes 7 diagnostics:")
        log("  (1) Residual normality (Shapiro-Wilk + Q-Q plot)")
        log("  (2) Homoscedasticity (Breusch-Pagan + residuals vs fitted)")
        log("  (3) Random effects normality (Shapiro-Wilk + Q-Q plots)")
        log("  (4) Independence (ACF plot + Lag-1 autocorrelation)")
        log("  (5) Linearity (partial residual plots)")
        log("  (6) Outliers (Cook's distance)")
        log("  (7) Convergence (model status)")

        # Create plots directory if it doesn't exist
        plots_dir = RQ_DIR / "plots"
        plots_dir.mkdir(parents=True, exist_ok=True)

        assumption_result = validate_lmm_assumptions_comprehensive(
            lmm_result=lmm_model,
            data=lmm_input,
            output_dir=plots_dir,
            acf_lag1_threshold=0.1,  # Autocorrelation tolerance (|ACF lag-1| < 0.1 acceptable)
            alpha=0.05  # Significance level for statistical tests
        )

        log("[DONE] Assumption validation complete")

        # =========================================================================
        # STEP 3: Save Assumption Diagnostics Report
        # =========================================================================
        # Output: results/step02b_assumption_diagnostics.txt
        # Contains: Text summary of all 7 diagnostics with overall assessment
        # Format: Plain text with Pass/Conditional/Fail per diagnostic

        log("[SAVE] Saving assumption diagnostics report...")
        diagnostics_path = RQ_DIR / "results" / "step02b_assumption_diagnostics.txt"

        with open(diagnostics_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("LMM ASSUMPTION VALIDATION REPORT\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"RQ: ch5/5.2.3 - Age x Domain x Time Interaction (3-way)\n")
            f.write(f"Step: 02b - Validate LMM Assumptions\n")
            f.write(f"Model: 3-way Age x Domain x Time interaction with random slopes\n\n")

            f.write("OVERALL ASSESSMENT\n")
            f.write("-" * 80 + "\n")
            if assumption_result['valid']:
                f.write("Status: PASS - All assumptions satisfied\n")
            else:
                f.write("Status: CONDITIONAL PASS / FAIL - See violations below\n")
            f.write(f"Message: {assumption_result['message']}\n\n")

            f.write("DIAGNOSTIC DETAILS\n")
            f.write("-" * 80 + "\n\n")

            # Write each diagnostic result
            diagnostics = assumption_result['diagnostics']
            for idx, (diag_name, diag_result) in enumerate(diagnostics.items(), 1):
                f.write(f"{idx}. {diag_name.upper()}\n")
                f.write(f"   Result: {diag_result}\n\n")

            f.write("\nDIAGNOSTIC PLOTS\n")
            f.write("-" * 80 + "\n")
            for plot_path in assumption_result.get('plot_paths', []):
                f.write(f"  - {plot_path.name}\n")

            f.write("\n" + "=" * 80 + "\n")
            f.write("END OF REPORT\n")
            f.write("=" * 80 + "\n")

        log(f"[SAVED] Assumption diagnostics report: {diagnostics_path}")

        # =========================================================================
        # STEP 4: Verify Diagnostic Plots Generated
        # =========================================================================
        # Expected: 6 diagnostic plots in plots/ directory
        # Purpose: Ensure all visual diagnostics available for inspection

        log("[VERIFY] Checking diagnostic plots...")
        plot_paths = assumption_result.get('plot_paths', [])
        if len(plot_paths) == 0:
            log("[WARNING] No diagnostic plots generated (unexpected)")
        else:
            log(f"[CHECK] {len(plot_paths)} diagnostic plots generated:")
            for plot_path in plot_paths:
                if plot_path.exists():
                    log(f"  [OK] {plot_path.name}")
                else:
                    log(f"  [MISSING] {plot_path.name}")

        # =========================================================================
        # STEP 5: Report Validation Summary
        # =========================================================================
        # Report overall status and any violations
        # Non-blocking: Assumption violations flagged but don't halt pipeline

        log("[VALIDATION SUMMARY]")
        log(f"  Overall valid: {assumption_result['valid']}")
        log(f"  Message: {assumption_result['message']}")

        # Report individual diagnostic statuses
        log("[DIAGNOSTIC STATUSES]")
        for diag_name, diag_result in assumption_result['diagnostics'].items():
            log(f"  {diag_name}: {diag_result}")

        # Determine exit status
        # NOTE: Assumption validation is NON-BLOCKING per 4_analysis.yaml
        # "on_failure: Flag violations in report, proceed with caution (not blocking)"
        if assumption_result['valid']:
            log("[SUCCESS] Step 02b complete - All assumptions satisfied")
            sys.exit(0)
        else:
            log("[CONDITIONAL SUCCESS] Step 02b complete - Some violations flagged")
            log("[NOTE] Assumption violations logged but not blocking (proceed with caution)")
            sys.exit(0)  # Exit 0 because non-blocking per specification

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
