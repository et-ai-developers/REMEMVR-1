#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code - manually fixed for WIDE->LONG reshape)
# =============================================================================
"""
Step ID: step00
Step Name: step00_get_data_from_rq51
RQ: results/ch5/rq10
Generated: 2025-11-28

PURPOSE:
Extract theta scores, TSVR mapping, and Age variable from RQ 5.1 outputs and
dfData.csv. CRITICAL FIX: RQ 5.1 outputs theta in WIDE format (theta_what,
theta_where, theta_when columns) but RQ 5.10 needs LONG format (domain + theta
columns). This script performs the WIDE->LONG reshape.

EXPECTED INPUTS:
  - results/ch5/rq1/data/step03_theta_scores.csv
    Columns: ['composite_ID', 'theta_what', 'theta_where', 'theta_when']
    Format: WIDE format (one row per composite_ID)
    Expected rows: ~400 (100 participants x 4 tests)

  - results/ch5/rq1/data/step00_tsvr_mapping.csv
    Columns: ['composite_ID', 'test', 'TSVR_hours']
    Format: Already correct
    Expected rows: 400 (100 participants x 4 tests)

  - data/cache/dfData.csv
    Columns: ['UID', 'age', ...]
    Format: One row per participant
    Expected rows: ~100

EXPECTED OUTPUTS:
  - data/step00_theta_from_rq51.csv
    Columns: ['composite_ID', 'domain', 'test', 'theta']
    Format: LONG format (1200 rows: 400 composite_IDs x 3 domains)

  - data/step00_tsvr_from_rq51.csv
    Columns: ['composite_ID', 'test', 'TSVR_hours']
    Format: Copy from RQ 5.1
    Expected rows: 400

  - data/step00_age_from_dfdata.csv
    Columns: ['UID', 'age']
    Format: Subset of dfData
    Expected rows: ~100

g_code REASONING:
- Format mismatch fix: RQ 5.1 uses WIDE format for efficiency (IRT calibration),
  but LMM analysis requires LONG format for domain comparisons. This script
  performs the reshape using pd.melt().

- Why manual fix needed: g_code agent correctly detected format mismatch and
  quit with FORMAT ERROR. This manual script implements the necessary reshape.

- Data flow: WIDE theta (400 rows) -> pd.melt() -> LONG theta (1200 rows)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = ch5/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/rq10
LOG_FILE = RQ_DIR / "logs" / "step00_get_data_from_rq51.log"

# Ensure output directories exist
(RQ_DIR / "data").mkdir(exist_ok=True, parents=True)
(RQ_DIR / "logs").mkdir(exist_ok=True, parents=True)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 00: Get Data from RQ 5.1")

        # =====================================================================
        # STEP 1: Load RQ 5.1 theta scores (WIDE format)
        # =====================================================================
        log("[LOAD] Loading theta scores from RQ 5.1 (WIDE format)...")
        rq1_theta_path = PROJECT_ROOT / "results" / "ch5" / "rq1" / "data" / "step03_theta_scores.csv"

        if not rq1_theta_path.exists():
            raise FileNotFoundError(f"RQ 5.1 dependency missing: {rq1_theta_path}")

        theta_wide = pd.read_csv(rq1_theta_path, encoding='utf-8')
        log(f"[LOADED] RQ 5.1 theta scores: {len(theta_wide)} rows (WIDE format)")
        log(f"[INFO] Columns: {list(theta_wide.columns)}")

        # Verify WIDE format columns
        expected_cols = ['composite_ID', 'theta_what', 'theta_where', 'theta_when']
        if not all(col in theta_wide.columns for col in expected_cols):
            raise ValueError(f"Expected WIDE format columns {expected_cols}, got {list(theta_wide.columns)}")

        # =====================================================================
        # STEP 2: Reshape WIDE -> LONG format
        # =====================================================================
        log("[TRANSFORM] Reshaping WIDE -> LONG format...")

        # Extract test number from composite_ID (format: UID_test)
        theta_wide['test'] = theta_wide['composite_ID'].str.split('_').str[1]

        # Melt from WIDE to LONG
        # Before: composite_ID, theta_what, theta_where, theta_when, test
        # After: composite_ID, test, domain, theta
        theta_long = pd.melt(
            theta_wide,
            id_vars=['composite_ID', 'test'],
            value_vars=['theta_what', 'theta_where', 'theta_when'],
            var_name='domain_raw',
            value_name='theta'
        )

        # Clean domain names: theta_what -> What, theta_where -> Where, theta_when -> When
        domain_mapping = {
            'theta_what': 'What',
            'theta_where': 'Where',
            'theta_when': 'When'
        }
        theta_long['domain'] = theta_long['domain_raw'].map(domain_mapping)
        theta_long = theta_long.drop(columns=['domain_raw'])

        # Reorder columns: composite_ID, domain, test, theta
        theta_long = theta_long[['composite_ID', 'domain', 'test', 'theta']]

        log(f"[TRANSFORMED] WIDE -> LONG: {len(theta_wide)} rows -> {len(theta_long)} rows")
        log(f"[INFO] Expected: {len(theta_wide)} x 3 domains = {len(theta_wide) * 3} rows")
        log(f"[INFO] Actual: {len(theta_long)} rows")

        # Validate reshape
        expected_rows = len(theta_wide) * 3
        if len(theta_long) != expected_rows:
            raise ValueError(f"Reshape failed: expected {expected_rows} rows, got {len(theta_long)}")

        # Validate all domains present
        domains = theta_long['domain'].unique()
        if set(domains) != {'What', 'Where', 'When'}:
            raise ValueError(f"Expected domains [What, Where, When], got {list(domains)}")

        log("[VALIDATION] PASS - All 3 domains present, row count correct")

        # =====================================================================
        # STEP 3: Load TSVR mapping (already correct format)
        # =====================================================================
        log("[LOAD] Loading TSVR mapping from RQ 5.1...")
        tsvr_path = PROJECT_ROOT / "results" / "ch5" / "rq1" / "data" / "step00_tsvr_mapping.csv"

        if not tsvr_path.exists():
            raise FileNotFoundError(f"RQ 5.1 dependency missing: {tsvr_path}")

        tsvr_data = pd.read_csv(tsvr_path, encoding='utf-8')
        log(f"[LOADED] TSVR mapping: {len(tsvr_data)} rows")
        log(f"[INFO] Columns: {list(tsvr_data.columns)}")

        # =====================================================================
        # STEP 4: Load Age from dfData.csv
        # =====================================================================
        log("[LOAD] Loading age variable from dfData.csv...")
        dfdata_path = PROJECT_ROOT / "data" / "cache" / "dfData.csv"

        if not dfdata_path.exists():
            raise FileNotFoundError(f"dfData.csv not found: {dfdata_path}")

        dfdata = pd.read_csv(dfdata_path, encoding='utf-8')

        # Subset to UID and age columns only
        if 'UID' not in dfdata.columns or 'age' not in dfdata.columns:
            raise ValueError(f"dfData.csv missing required columns [UID, age]. Columns: {list(dfdata.columns)}")

        age_data = dfdata[['UID', 'age']].copy()

        # Drop duplicates - dfData has multiple rows per participant (one per test)
        # Age is constant within participant, so drop_duplicates gives us one row per UID
        age_data = age_data.drop_duplicates(subset='UID')
        log(f"[LOADED] Age data: {len(age_data)} unique participants")

        # =====================================================================
        # STEP 5: Save outputs
        # =====================================================================

        # Save LONG format theta scores
        log("[SAVE] Saving data/step00_theta_from_rq51.csv (LONG format)...")
        theta_out_path = RQ_DIR / "data" / "step00_theta_from_rq51.csv"
        theta_long.to_csv(theta_out_path, index=False, encoding='utf-8')
        log(f"[SAVED] {theta_out_path.name} ({len(theta_long)} rows, {len(theta_long.columns)} cols)")

        # Save TSVR mapping (copy)
        log("[SAVE] Saving data/step00_tsvr_from_rq51.csv...")
        tsvr_out_path = RQ_DIR / "data" / "step00_tsvr_from_rq51.csv"
        tsvr_data.to_csv(tsvr_out_path, index=False, encoding='utf-8')
        log(f"[SAVED] {tsvr_out_path.name} ({len(tsvr_data)} rows, {len(tsvr_data.columns)} cols)")

        # Save age data (subset)
        log("[SAVE] Saving data/step00_age_from_dfdata.csv...")
        age_out_path = RQ_DIR / "data" / "step00_age_from_dfdata.csv"
        age_data.to_csv(age_out_path, index=False, encoding='utf-8')
        log(f"[SAVED] {age_out_path.name} ({len(age_data)} rows, {len(age_data.columns)} cols)")

        # =====================================================================
        # STEP 6: Final validation
        # =====================================================================
        log("[VALIDATION] Running final checks...")

        # Check theta LONG format
        if len(theta_long) != 1200:
            log(f"[WARNING] Expected 1200 rows (400 x 3 domains), got {len(theta_long)}")

        # Check no NaN values
        if theta_long['theta'].isna().any():
            raise ValueError("NaN values detected in theta column")

        if tsvr_data['TSVR_hours'].isna().any():
            raise ValueError("NaN values detected in TSVR_hours column")

        if age_data['age'].isna().any():
            raise ValueError("NaN values detected in age column")

        log("[VALIDATION] PASS - All files created successfully")
        log("[SUCCESS] Step 00 complete")
        log(f"[INFO] LONG format theta ready: {len(theta_long)} rows (3 domains)")

        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
