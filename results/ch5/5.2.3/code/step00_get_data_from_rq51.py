#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code - updated to use RQ 5.2.1 data)
# =============================================================================
"""
Step ID: step00
Step Name: step00_get_data_from_rq521
RQ: results/ch5/5.2.3
Generated: 2025-11-28
Updated: 2025-12-02 (Now sources from RQ 5.2.1, When domain excluded)

PURPOSE:
Extract theta scores and TSVR from RQ 5.2.1 step04_lmm_input.csv (already in LONG
format), filter out When domain, and extract Age from dfData.csv.

NOTE: When domain EXCLUDED due to floor effect discovered in RQ 5.2.1:
- Performance at 6-9% probability throughout study (near 0% floor)
- 20/26 When items (77%) excluded for low discrimination
- Only What and Where domains analyzed

EXPECTED INPUTS:
  - results/ch5/5.2.1/data/step04_lmm_input.csv
    Columns: ['composite_ID', 'UID', 'test', 'TSVR_hours', 'domain', 'theta']
    Format: LONG format (already has domain column)
    Expected rows: 1200 (100 participants x 4 tests x 3 domains)

  - data/cache/dfData.csv
    Columns: ['UID', 'age', ...]
    Format: One row per participant
    Expected rows: ~100

EXPECTED OUTPUTS:
  - data/step00_theta_from_rq51.csv
    Columns: ['composite_ID', 'domain', 'test', 'theta']
    Format: LONG format (800 rows: 400 composite_IDs x 2 domains - When excluded)

  - data/step00_tsvr_from_rq51.csv
    Columns: ['composite_ID', 'test', 'TSVR_hours', 'UID']
    Format: Extracted from RQ 5.2.1 lmm_input
    Expected rows: 400

  - data/step00_age_from_dfdata.csv
    Columns: ['UID', 'age']
    Format: Subset of dfData
    Expected rows: ~100

g_code REASONING:
- Data source change: RQ 5.2.1 step04_lmm_input.csv already has LONG format with
  domain-specific theta scores. Simply filter out When domain.
- Simpler approach: No reshape needed, just domain filtering + age merge
- Data flow: RQ 5.2.1 LONG theta (1200 rows) -> filter When -> 800 rows
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = ch5/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.2.3
LOG_FILE = RQ_DIR / "logs" / "step00_get_data_from_rq51.log"

# Ensure output directories exist
(RQ_DIR / "data").mkdir(exist_ok=True, parents=True)
(RQ_DIR / "logs").mkdir(exist_ok=True, parents=True)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 00: Get Data from RQ 5.2.1")

        # =====================================================================
        # STEP 1: Load RQ 5.2.1 lmm_input (LONG format with domain-specific theta)
        # =====================================================================
        log("[LOAD] Loading theta scores from RQ 5.2.1 (LONG format)...")
        rq521_path = PROJECT_ROOT / "results" / "ch5" / "5.2.1" / "data" / "step04_lmm_input.csv"

        if not rq521_path.exists():
            raise FileNotFoundError(f"RQ 5.2.1 dependency missing: {rq521_path}")

        lmm_input = pd.read_csv(rq521_path, encoding='utf-8')
        log(f"[LOADED] RQ 5.2.1 lmm_input: {len(lmm_input)} rows (LONG format)")
        log(f"[INFO] Columns: {list(lmm_input.columns)}")

        # Verify columns
        expected_cols = ['composite_ID', 'UID', 'test', 'TSVR_hours', 'domain', 'theta']
        if not all(col in lmm_input.columns for col in expected_cols):
            raise ValueError(f"Expected columns {expected_cols}, got {list(lmm_input.columns)}")

        # Check domains before filtering
        log(f"[INFO] Domains in input: {lmm_input['domain'].unique().tolist()}")
        log(f"[INFO] Rows per domain before filter: {lmm_input.groupby('domain').size().to_dict()}")

        # =====================================================================
        # STEP 2: Filter out When domain (floor effect)
        # =====================================================================
        log("[FILTER] Excluding When domain due to floor effect (RQ 5.2.1)...")

        # RQ 5.2.1 uses lowercase domain names
        theta_filtered = lmm_input[lmm_input['domain'].isin(['what', 'where'])].copy()

        log(f"[FILTERED] {len(lmm_input)} rows -> {len(theta_filtered)} rows (When excluded)")
        log(f"[INFO] Remaining domains: {theta_filtered['domain'].unique().tolist()}")

        # Standardize domain names: what -> What, where -> Where
        theta_filtered['domain'] = theta_filtered['domain'].map({'what': 'What', 'where': 'Where'})

        # Create theta output with required columns
        theta_long = theta_filtered[['composite_ID', 'domain', 'test', 'theta']].copy()

        # Validate (800 rows = 100 participants x 4 tests x 2 domains)
        expected_rows = 800
        if len(theta_long) != expected_rows:
            log(f"[WARNING] Expected {expected_rows} rows, got {len(theta_long)}")

        # Validate domains present
        domains = theta_long['domain'].unique()
        if set(domains) != {'What', 'Where'}:
            raise ValueError(f"Expected domains [What, Where], got {list(domains)}")

        log("[VALIDATION] PASS - When excluded, 2 domains present")

        # =====================================================================
        # STEP 3: Create TSVR mapping from lmm_input
        # =====================================================================
        log("[CREATE] Creating TSVR mapping...")

        # Get unique composite_ID rows for TSVR (one per test, not per domain)
        tsvr_data = theta_filtered[['composite_ID', 'test', 'TSVR_hours', 'UID']].drop_duplicates(
            subset=['composite_ID']
        )
        log(f"[CREATED] TSVR mapping: {len(tsvr_data)} rows")

        # Verify 400 rows (100 participants x 4 tests)
        if len(tsvr_data) != 400:
            log(f"[WARNING] Expected 400 TSVR rows, got {len(tsvr_data)}")

        # =====================================================================
        # STEP 4: Load Age from dfData.csv
        # =====================================================================
        log("[LOAD] Loading age variable from dfData.csv...")
        dfdata_path = PROJECT_ROOT / "data" / "cache" / "dfData.csv"

        if not dfdata_path.exists():
            raise FileNotFoundError(f"dfData.csv not found: {dfdata_path}")

        dfdata = pd.read_csv(dfdata_path, encoding='utf-8')

        # Subset to UID and age columns only
        if 'UID' not in dfdata.columns or 'age' not in dfdata.columns:
            raise ValueError(f"dfData.csv missing required columns [UID, age]. Columns: {list(dfdata.columns)}")

        age_data = dfdata[['UID', 'age']].copy()

        # Drop duplicates - dfData has multiple rows per participant (one per test)
        # Age is constant within participant, so drop_duplicates gives us one row per UID
        age_data = age_data.drop_duplicates(subset='UID')
        log(f"[LOADED] Age data: {len(age_data)} unique participants")

        # =====================================================================
        # STEP 5: Save outputs
        # =====================================================================

        # Save LONG format theta scores (When excluded)
        log("[SAVE] Saving data/step00_theta_from_rq51.csv (LONG format, When excluded)...")
        theta_out_path = RQ_DIR / "data" / "step00_theta_from_rq51.csv"
        theta_long.to_csv(theta_out_path, index=False, encoding='utf-8')
        log(f"[SAVED] {theta_out_path.name} ({len(theta_long)} rows, {len(theta_long.columns)} cols)")

        # Save TSVR mapping
        log("[SAVE] Saving data/step00_tsvr_from_rq51.csv...")
        tsvr_out_path = RQ_DIR / "data" / "step00_tsvr_from_rq51.csv"
        tsvr_data.to_csv(tsvr_out_path, index=False, encoding='utf-8')
        log(f"[SAVED] {tsvr_out_path.name} ({len(tsvr_data)} rows, {len(tsvr_data.columns)} cols)")

        # Save age data (subset)
        log("[SAVE] Saving data/step00_age_from_dfdata.csv...")
        age_out_path = RQ_DIR / "data" / "step00_age_from_dfdata.csv"
        age_data.to_csv(age_out_path, index=False, encoding='utf-8')
        log(f"[SAVED] {age_out_path.name} ({len(age_data)} rows, {len(age_data.columns)} cols)")

        # =====================================================================
        # STEP 6: Final validation
        # =====================================================================
        log("[VALIDATION] Running final checks...")

        # Check theta LONG format (800 rows due to When exclusion)
        if len(theta_long) != 800:
            log(f"[WARNING] Expected 800 rows (400 x 2 domains, When excluded), got {len(theta_long)}")

        # Check no NaN values
        if theta_long['theta'].isna().any():
            raise ValueError("NaN values detected in theta column")

        if tsvr_data['TSVR_hours'].isna().any():
            raise ValueError("NaN values detected in TSVR_hours column")

        if age_data['age'].isna().any():
            raise ValueError("NaN values detected in age column")

        log("[VALIDATION] PASS - All files created successfully")
        log("[SUCCESS] Step 00 complete")
        log(f"[INFO] Data sourced from RQ 5.2.1 (domain-specific theta)")
        log(f"[INFO] LONG format theta ready: {len(theta_long)} rows (2 domains - When excluded)")

        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
