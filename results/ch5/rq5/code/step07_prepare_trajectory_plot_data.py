#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step07
Step Name: Prepare Trajectory Plot Data (Decision D069)
RQ: results/ch5/rq5 (RQ 5.5: Schema Congruence Effects on Forgetting Trajectories)
Generated: 2025-11-24

PURPOSE:
Aggregate theta scores by congruence and time for dual-scale trajectory
visualization (D069). Creates both theta-scale and probability-scale plot data.

EXPECTED INPUTS:
  - data/step04_lmm_input.csv
    Columns: UID, composite_ID, test, congruence, theta, se, TSVR_hours, TSVR_sq, TSVR_log
    Format: Long-format LMM input
    Expected rows: 1200

EXPECTED OUTPUTS:
  - plots/step07_trajectory_theta_data.csv
    Columns: time, theta_mean, CI_lower, CI_upper, congruence
    Format: Theta-scale trajectory plot source data
    Expected rows: 12 (3 congruence x 4 tests)

  - plots/step07_trajectory_probability_data.csv
    Columns: time, prob_mean, CI_lower, CI_upper, congruence
    Format: Probability-scale trajectory plot source data
    Expected rows: 12 (3 congruence x 4 tests)

VALIDATION CRITERIA:
  - Both plot files created
  - 12 rows each (3 congruence x 4 tests)
  - All congruence categories present (4 rows each)
  - Theta range valid [-3, 3]
  - Probability range valid [0, 1]
  - CI bounds logical (lower < mean < upper)
  - No NaN values

g_code REASONING:
- Approach: Group by congruence and test, compute mean and 95% CI
- Why this approach: D069 requires both theta and probability scales for interpretability
- Data flow: LMM input -> group by -> aggregate -> IRT transform -> plot data
- Expected performance: ~seconds (aggregation)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]
LOG_FILE = RQ_DIR / "logs" / "step07_prepare_trajectory_plot_data.log"

# Input files
INPUT_LMM = RQ_DIR / "data" / "step04_lmm_input.csv"

# Output files
OUTPUT_THETA_PLOT = RQ_DIR / "plots" / "step07_trajectory_theta_data.csv"
OUTPUT_PROB_PLOT = RQ_DIR / "plots" / "step07_trajectory_probability_data.csv"

# IRT Transform Parameters (for probability scale)
# Using 2PL with a=1.0 (average discrimination) and b=0.0 (average difficulty)
IRT_A = 1.0
IRT_B = 0.0

# CI multiplier (1.96 for 95% CI)
CI_MULTIPLIER = 1.96

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# IRT Transform Functions
# =============================================================================

def theta_to_probability(theta, a=1.0, b=0.0):
    """
    Transform theta to probability using 2PL model.
    P(X=1|theta) = 1 / (1 + exp(-a * (theta - b)))
    """
    return 1 / (1 + np.exp(-a * (theta - b)))

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 07: Prepare Trajectory Plot Data")
        log(f"RQ Directory: {RQ_DIR}")

        # =========================================================================
        # STEP 1: Load LMM Input Data
        # =========================================================================
        log("\n[LOAD] Loading LMM input data...")

        df_lmm = pd.read_csv(INPUT_LMM)
        log(f"[LOADED] {INPUT_LMM.name} ({len(df_lmm)} rows, {len(df_lmm.columns)} cols)")

        # =========================================================================
        # STEP 2: Aggregate by Congruence and Test
        # =========================================================================
        log("\n[AGGREGATE] Computing group statistics...")

        # Group by congruence and test
        grouped = df_lmm.groupby(["congruence", "test"])

        # Compute aggregates
        agg_df = grouped.agg(
            theta_mean=("theta", "mean"),
            theta_std=("theta", "std"),
            theta_se=("theta", lambda x: x.std() / np.sqrt(len(x))),
            n=("theta", "count"),
            time=("TSVR_hours", "mean")  # Mean TSVR per test
        ).reset_index()

        log(f"[AGGREGATED] {len(agg_df)} groups")

        # =========================================================================
        # STEP 3: Compute 95% CI for Theta Scale
        # =========================================================================
        log("\n[CI] Computing 95% confidence intervals (theta scale)...")

        agg_df["CI_lower_theta"] = agg_df["theta_mean"] - CI_MULTIPLIER * agg_df["theta_se"]
        agg_df["CI_upper_theta"] = agg_df["theta_mean"] + CI_MULTIPLIER * agg_df["theta_se"]

        # Create theta-scale output
        df_theta_plot = agg_df[["time", "theta_mean", "CI_lower_theta", "CI_upper_theta", "congruence"]].copy()
        df_theta_plot = df_theta_plot.rename(columns={
            "CI_lower_theta": "CI_lower",
            "CI_upper_theta": "CI_upper"
        })

        log(f"  Theta mean range: [{df_theta_plot['theta_mean'].min():.3f}, {df_theta_plot['theta_mean'].max():.3f}]")

        # =========================================================================
        # STEP 4: Transform to Probability Scale
        # =========================================================================
        log("\n[TRANSFORM] Transforming to probability scale...")

        # Transform mean and CI bounds to probability
        agg_df["prob_mean"] = theta_to_probability(agg_df["theta_mean"], IRT_A, IRT_B)
        agg_df["CI_lower_prob"] = theta_to_probability(agg_df["CI_lower_theta"], IRT_A, IRT_B)
        agg_df["CI_upper_prob"] = theta_to_probability(agg_df["CI_upper_theta"], IRT_A, IRT_B)

        # Create probability-scale output
        df_prob_plot = agg_df[["time", "prob_mean", "CI_lower_prob", "CI_upper_prob", "congruence"]].copy()
        df_prob_plot = df_prob_plot.rename(columns={
            "CI_lower_prob": "CI_lower",
            "CI_upper_prob": "CI_upper"
        })

        log(f"  Probability mean range: [{df_prob_plot['prob_mean'].min():.3f}, {df_prob_plot['prob_mean'].max():.3f}]")

        # =========================================================================
        # STEP 5: Sort and Finalize
        # =========================================================================
        log("\n[FINALIZE] Sorting and finalizing output...")

        # Sort by congruence and time
        df_theta_plot = df_theta_plot.sort_values(["congruence", "time"]).reset_index(drop=True)
        df_prob_plot = df_prob_plot.sort_values(["congruence", "time"]).reset_index(drop=True)

        log(f"  Theta plot: {len(df_theta_plot)} rows")
        log(f"  Probability plot: {len(df_prob_plot)} rows")

        # =========================================================================
        # STEP 6: Save Outputs
        # =========================================================================
        log("\n[SAVE] Saving output files...")

        # Ensure plots directory exists
        (RQ_DIR / "plots").mkdir(parents=True, exist_ok=True)

        # Save theta-scale data
        df_theta_plot.to_csv(OUTPUT_THETA_PLOT, index=False, encoding='utf-8')
        log(f"[SAVED] {OUTPUT_THETA_PLOT.name} ({len(df_theta_plot)} rows)")

        # Save probability-scale data
        df_prob_plot.to_csv(OUTPUT_PROB_PLOT, index=False, encoding='utf-8')
        log(f"[SAVED] {OUTPUT_PROB_PLOT.name} ({len(df_prob_plot)} rows)")

        # =========================================================================
        # STEP 7: Validation
        # =========================================================================
        log("\n[VALIDATE] Validating results...")

        # Check both files created
        assert OUTPUT_THETA_PLOT.exists(), f"Theta plot file not created: {OUTPUT_THETA_PLOT}"
        assert OUTPUT_PROB_PLOT.exists(), f"Probability plot file not created: {OUTPUT_PROB_PLOT}"
        log("[PASS] Both plot files created")

        # Check row count
        expected_rows = 3 * 4  # 3 congruence x 4 tests
        if len(df_theta_plot) != expected_rows:
            log(f"[WARN] Theta plot has {len(df_theta_plot)} rows (expected {expected_rows})")
        else:
            log(f"[PASS] Row count: {len(df_theta_plot)} (3 congruence x 4 tests)")

        # Check all congruence categories present
        for cat in ["common", "congruent", "incongruent"]:
            n_cat = len(df_theta_plot[df_theta_plot["congruence"] == cat])
            if n_cat != 4:
                log(f"[WARN] {cat}: {n_cat} rows (expected 4)")
            else:
                log(f"[PASS] {cat}: {n_cat} rows")

        # Check theta range
        theta_min = df_theta_plot["theta_mean"].min()
        theta_max = df_theta_plot["theta_mean"].max()
        if theta_min < -3 or theta_max > 3:
            log(f"[WARN] Theta mean outside [-3, 3]: [{theta_min:.3f}, {theta_max:.3f}]")
        else:
            log(f"[PASS] Theta mean range: [{theta_min:.3f}, {theta_max:.3f}]")

        # Check probability range
        prob_min = df_prob_plot["prob_mean"].min()
        prob_max = df_prob_plot["prob_mean"].max()
        if prob_min < 0 or prob_max > 1:
            log(f"[WARN] Probability mean outside [0, 1]: [{prob_min:.3f}, {prob_max:.3f}]")
        else:
            log(f"[PASS] Probability mean range: [{prob_min:.3f}, {prob_max:.3f}]")

        # Check CI bounds logical
        ci_ok = all(df_theta_plot["CI_lower"] < df_theta_plot["theta_mean"]) and \
                all(df_theta_plot["theta_mean"] < df_theta_plot["CI_upper"])
        if ci_ok:
            log("[PASS] CI bounds logical (lower < mean < upper)")
        else:
            log("[WARN] CI bounds may be illogical")

        # Check no NaN
        nan_theta = df_theta_plot.isna().sum().sum()
        nan_prob = df_prob_plot.isna().sum().sum()
        if nan_theta > 0 or nan_prob > 0:
            log(f"[WARN] NaN values found: theta={nan_theta}, prob={nan_prob}")
        else:
            log("[PASS] No NaN values")

        # Print summary table
        log("\n  Trajectory Summary (Theta Scale):")
        log("  " + "-" * 60)
        for cat in ["common", "congruent", "incongruent"]:
            cat_data = df_theta_plot[df_theta_plot["congruence"] == cat]
            log(f"  {cat}:")
            for _, row in cat_data.iterrows():
                log(f"    time={row['time']:.1f}h: theta={row['theta_mean']:.3f} [{row['CI_lower']:.3f}, {row['CI_upper']:.3f}]")

        log("\n[SUCCESS] Step 07 complete (Trajectory Plot Data)")
        sys.exit(0)

    except Exception as e:
        log(f"\n[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
