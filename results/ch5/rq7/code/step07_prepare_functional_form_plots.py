#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step07
Step Name: Prepare Functional Form Plot Data
RQ: results/ch5/rq7
Generated: 2025-11-25

PURPOSE:
Create dual-scale plot data (theta scale + probability scale) for visualizing
forgetting curves across all 5 candidate models. Computes observed means per
test session with 95% CI, generates prediction grids for each model, transforms
to probability scale using logistic transform (Decision D069), and saves plot-ready
CSVs for visualization.

EXPECTED INPUTS:
  - data/step04_lmm_input.csv
    Columns: composite_ID, UID, test, Theta, SE, TSVR_hours, Days, Days_squared, log_Days_plus1
    Format: CSV with UTF-8 encoding
    Expected rows: 400
    Description: Observed theta scores for computing means/CIs

  - data/step05_model_fits.pkl
    Format: Python pickle dictionary
    Keys: 'Linear', 'Quadratic', 'Logarithmic', 'LinLog', 'QuadLog'
    Values: MixedLMResults objects
    Description: All 5 fitted models for generating predictions

  - results/step06_aic_comparison.csv
    Columns: model_name, AIC, delta_AIC, akaike_weight, cumulative_weight
    Format: CSV
    Expected rows: 5
    Description: Best model identification for plot annotation

EXPECTED OUTPUTS:
  - plots/step07_functional_form_theta_data.csv
    Columns: Days, observed_theta, CI_lower_theta, CI_upper_theta, pred_Linear,
             pred_Quadratic, pred_Logarithmic, pred_LinLog, pred_QuadLog, best_model
    Format: CSV for theta-scale plot
    Expected rows: 54 (4 observed + 50 prediction grid points)
    Description: Theta-scale forgetting curves for all 5 models

  - plots/step07_functional_form_probability_data.csv
    Columns: Days, observed_prob, CI_lower_prob, CI_upper_prob, pred_Linear_prob,
             pred_Quadratic_prob, pred_Logarithmic_prob, pred_LinLog_prob,
             pred_QuadLog_prob, best_model
    Format: CSV for probability-scale plot (Decision D069)
    Expected rows: 54
    Description: Probability-scale forgetting curves (easier interpretation)

VALIDATION CRITERIA:
  - All probability values in [0, 1] bounds
  - CI bounds valid (CI_upper > CI_lower)
  - Monotonicity preserved (theta transform preserves ordering)
  - No NaN in Days column
  - Expected row count (54 rows per file: 4 observed + 50 predictions)

g_code REASONING:
- Approach: Compute observed means/CIs per test session (4 time points), generate
  dense prediction grid (50 points from 0-7 days), extract predictions from all
  5 models, transform to probability scale (p = 1/(1 + exp(-1.7*theta))), combine
  observed + predictions, annotate best model.
- Why this approach: Dual-scale visualization aids interpretation. Theta scale
  shows IRT latent variable (standard for psychometrics), probability scale shows
  response probability (easier for non-psychometricians). Dense prediction grid
  shows smooth curves, observed points show data support.
- Data flow: Observed data -> group by test -> mean/CI -> prediction grid ->
  model predictions -> theta transform -> probability transform -> save both scales
- Expected performance: ~5-10 seconds (prediction grid generation for 5 models)

IMPLEMENTATION NOTES:
- Analysis type: stdlib (pandas, numpy, statsmodels predictions)
- Validation tool: tools.validation.validate_irt_convergence (generic validation)
- Theta-to-probability transform (Decision D069): p = 1 / (1 + exp(-1.7 * theta))
  where 1.7 is the scaling constant for 2PL IRT model
- Prediction grid: 50 evenly-spaced points from 0 to 7 days
- CI computation: Mean +/- 1.96 * SE / sqrt(n) (95% confidence intervals)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
import pickle
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (5 levels deep from project root)
# parents[4] = REMEMVR/ (code -> rq7 -> ch5 -> results -> REMEMVR)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import validation tool
from tools.validation import validate_irt_convergence

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/rq7
LOG_FILE = RQ_DIR / "logs" / "step07_prepare_plot_data.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_lmm_model_comparison.csv
#   CORRECT: data/step03_theta_scores.csv
#   WRONG:   results/lmm_model_comparison.csv  (wrong folder + no prefix)
#   WRONG:   data/theta_scores.csv             (missing step prefix)
#   WRONG:   logs/step02_removed_items.csv     (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Helper Function: Theta to Probability Transform
# =============================================================================

def theta_to_prob(theta: float) -> float:
    """
    Transform IRT theta (latent ability) to response probability.

    Decision D069: Use logistic transform with scaling constant 1.7
    Formula: p = 1 / (1 + exp(-1.7 * theta))

    Args:
        theta: IRT ability estimate (unbounded, typically [-4, 4])

    Returns:
        Probability of correct response [0, 1]
    """
    return 1.0 / (1.0 + np.exp(-1.7 * theta))

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 7: Prepare Functional Form Plot Data")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Observed theta scores, fitted models, best model identification
        # Purpose: Combine observed + predictions for dual-scale plotting

        log("[LOAD] Loading observed theta scores...")
        observed_path = RQ_DIR / "data" / "step04_lmm_input.csv"

        if not observed_path.exists():
            raise FileNotFoundError(f"LMM input data missing: {observed_path}\n"
                                     "Run step04_prepare_lmm_input.py first")

        lmm_input = pd.read_csv(observed_path, encoding='utf-8')
        log(f"[LOADED] {observed_path.name} ({len(lmm_input)} rows)")

        log("[LOAD] Loading best model identification...")
        aic_path = RQ_DIR / "results" / "step05_model_comparison.csv"

        if not aic_path.exists():
            raise FileNotFoundError(f"AIC comparison missing: {aic_path}\n"
                                     "Run step06_aic_model_selection.py first")

        aic_comparison = pd.read_csv(aic_path, encoding='utf-8')
        best_model_name = aic_comparison.iloc[0]['model_name']
        log(f"[LOADED] {aic_path.name}")
        log(f"  Best model: {best_model_name}")

        # Load all 5 model pickle files for predictions
        log("[LOAD] Loading all 5 fitted models for predictions...")
        model_fits = {}
        for model_name in ['Linear', 'Quadratic', 'Logarithmic', 'LinLog', 'QuadLog']:
            pickle_path = RQ_DIR / "data" / f"lmm_{model_name}.pkl"
            if pickle_path.exists():
                with open(pickle_path, 'rb') as f:
                    model_fits[model_name] = pickle.load(f)
                log(f"  Loaded {model_name}")
            else:
                log(f"  WARNING: {model_name} pickle not found")

        log(f"[LOADED] {len(model_fits)} model objects")

        # =========================================================================
        # STEP 2: Compute Observed Means per Test Session
        # =========================================================================
        # Purpose: 4 observed time points with 95% CI for plotting
        # Formula: Mean +/- 1.96 * SE / sqrt(n)

        log("[COMPUTE] Computing observed means per test session...")

        observed_summary = lmm_input.groupby('test').agg({
            'Days': 'mean',
            'Theta': ['mean', 'std', 'count']
        }).reset_index()

        # Flatten MultiIndex columns
        observed_summary.columns = ['test', 'Days', 'observed_theta', 'theta_std', 'n']

        # Compute 95% CI
        observed_summary['CI_lower_theta'] = (
            observed_summary['observed_theta'] -
            1.96 * observed_summary['theta_std'] / np.sqrt(observed_summary['n'])
        )
        observed_summary['CI_upper_theta'] = (
            observed_summary['observed_theta'] +
            1.96 * observed_summary['theta_std'] / np.sqrt(observed_summary['n'])
        )

        log(f"  Computed means for {len(observed_summary)} test sessions")
        log("")
        log("Observed Means (Theta Scale):")
        log(observed_summary[['test', 'Days', 'observed_theta', 'CI_lower_theta', 'CI_upper_theta']].to_string(index=False))
        log("")

        # =========================================================================
        # STEP 3: Generate Prediction Grid
        # =========================================================================
        # Purpose: Dense grid (50 points from 0-7 days) for smooth curves

        log("[COMPUTE] Generating prediction grid...")

        n_points = 50
        days_grid = np.linspace(0, 7, n_points)
        pred_grid = pd.DataFrame({
            'Days': days_grid,
            'Days_squared': days_grid ** 2,
            'log_Days_plus1': np.log(days_grid + 1)
        })

        log(f"  Grid: {n_points} points from {days_grid.min():.1f} to {days_grid.max():.1f} days")

        # =========================================================================
        # STEP 4: Generate Predictions for All 5 Models
        # =========================================================================
        # Purpose: Extract model predictions on grid for plotting

        log("[PREDICT] Generating predictions for all 5 models...")

        for model_name, model_result in model_fits.items():
            log(f"  Predicting {model_name}...")

            # Generate predictions using statsmodels predict method
            # Note: predict() returns predictions at population level (fixed effects only)
            predictions = model_result.predict(exog=pred_grid)

            pred_grid[f'pred_{model_name}'] = predictions

        log("[DONE] All predictions generated")

        # =========================================================================
        # STEP 5: Combine Observed + Predictions (Theta Scale)
        # =========================================================================
        # Purpose: Single DataFrame with observed points + prediction curves

        log("[COMBINE] Combining observed + predictions (theta scale)...")

        # Prepare observed data for merging
        observed_theta = observed_summary[['Days', 'observed_theta', 'CI_lower_theta', 'CI_upper_theta']].copy()

        # Prepare prediction data
        pred_theta = pred_grid[['Days', 'pred_Linear', 'pred_Quadratic', 'pred_Logarithmic', 'pred_LinLog', 'pred_QuadLog']].copy()

        # Merge (outer join to keep both observed and prediction points)
        theta_plot_data = pd.merge(
            observed_theta,
            pred_theta,
            on='Days',
            how='outer'
        ).sort_values('Days').reset_index(drop=True)

        # Add best model annotation
        theta_plot_data['best_model'] = best_model_name

        log(f"  Combined dataset: {len(theta_plot_data)} rows")
        log(f"    {observed_summary['observed_theta'].notna().sum()} observed points")
        log(f"    {len(pred_grid)} prediction points")

        # =========================================================================
        # STEP 6: Transform to Probability Scale (Decision D069)
        # =========================================================================
        # Purpose: Easier interpretation for non-psychometricians
        # Formula: p = 1 / (1 + exp(-1.7 * theta))

        log("[TRANSFORM] Converting to probability scale (Decision D069)...")

        prob_plot_data = theta_plot_data.copy()

        # Transform observed theta to probability
        prob_plot_data['observed_prob'] = theta_to_prob(prob_plot_data['observed_theta'])
        prob_plot_data['CI_lower_prob'] = theta_to_prob(prob_plot_data['CI_lower_theta'])
        prob_plot_data['CI_upper_prob'] = theta_to_prob(prob_plot_data['CI_upper_theta'])

        # Transform model predictions to probability
        for model_name in model_fits.keys():
            prob_plot_data[f'pred_{model_name}_prob'] = theta_to_prob(
                prob_plot_data[f'pred_{model_name}']
            )

        log("[DONE] Probability transformation complete")
        log(f"  Observed prob range: [{prob_plot_data['observed_prob'].min():.3f}, {prob_plot_data['observed_prob'].max():.3f}]")

        # =========================================================================
        # STEP 7: Save Plot Data (Both Scales)
        # =========================================================================
        # Output will be used by: rq_plots agent for visualization

        # Ensure plots/ directory exists
        plots_dir = RQ_DIR / "plots"
        plots_dir.mkdir(parents=True, exist_ok=True)

        # Save theta-scale plot data
        theta_output_path = plots_dir / "step07_functional_form_theta_data.csv"
        log(f"[SAVE] Saving theta-scale plot data to {theta_output_path.name}...")
        theta_plot_data.to_csv(theta_output_path, index=False, encoding='utf-8')
        log(f"[SAVED] {theta_output_path.name} ({len(theta_plot_data)} rows)")

        # Save probability-scale plot data
        prob_cols = ['Days', 'observed_prob', 'CI_lower_prob', 'CI_upper_prob',
                     'pred_Linear_prob', 'pred_Quadratic_prob', 'pred_Logarithmic_prob',
                     'pred_LinLog_prob', 'pred_QuadLog_prob', 'best_model']
        prob_output_path = plots_dir / "step07_functional_form_probability_data.csv"
        log(f"[SAVE] Saving probability-scale plot data to {prob_output_path.name}...")
        prob_plot_data[prob_cols].to_csv(prob_output_path, index=False, encoding='utf-8')
        log(f"[SAVED] {prob_output_path.name} ({len(prob_plot_data)} rows)")

        # =========================================================================
        # STEP 8: Validate Plot Data
        # =========================================================================
        # Tool: validate_irt_convergence (generic validation)
        # Validates: Probability bounds, CI validity, monotonicity, no NaN, row count

        log("[VALIDATION] Validating plot data...")

        # Check probability bounds [0, 1]
        prob_cols_to_check = ['observed_prob', 'CI_lower_prob', 'CI_upper_prob',
                               'pred_Linear_prob', 'pred_Quadratic_prob',
                               'pred_Logarithmic_prob', 'pred_LinLog_prob', 'pred_QuadLog_prob']

        for col in prob_cols_to_check:
            if (prob_plot_data[col].dropna() >= 0).all() and (prob_plot_data[col].dropna() <= 1).all():
                log(f"[PASS] {col} in [0, 1] bounds")
            else:
                raise ValueError(f"{col} contains values outside [0, 1] bounds")

        # Check CI bounds valid (CI_upper > CI_lower)
        valid_ci_theta = (
            (theta_plot_data['CI_upper_theta'] > theta_plot_data['CI_lower_theta']) |
            theta_plot_data['CI_upper_theta'].isna()
        ).all()

        if valid_ci_theta:
            log("[PASS] Theta CI bounds valid (CI_upper > CI_lower)")
        else:
            raise ValueError("Some theta CI bounds invalid (CI_upper <= CI_lower)")

        valid_ci_prob = (
            (prob_plot_data['CI_upper_prob'] > prob_plot_data['CI_lower_prob']) |
            prob_plot_data['CI_upper_prob'].isna()
        ).all()

        if valid_ci_prob:
            log("[PASS] Probability CI bounds valid (CI_upper > CI_lower)")
        else:
            raise ValueError("Some probability CI bounds invalid")

        # Check no NaN in Days column
        if theta_plot_data['Days'].notna().all():
            log("[PASS] No NaN in Days column")
        else:
            raise ValueError("Days column contains NaN values")

        # Check row count (4 observed + 50 predictions = 54)
        expected_rows = 54
        if len(theta_plot_data) == expected_rows:
            log(f"[PASS] Row count correct ({expected_rows} rows)")
        else:
            log(f"[WARNING] Row count differs from expected - got {len(theta_plot_data)}, expected ~{expected_rows}")

        # Invoke generic validation
        validation_result = validate_irt_convergence(
            results={
                "theta_data": theta_plot_data,
                "prob_data": prob_plot_data
            }
        )

        if isinstance(validation_result, dict):
            for key, value in validation_result.items():
                log(f"[VALIDATION] {key}: {value}")
        else:
            log(f"[VALIDATION] {validation_result}")

        log("[SUCCESS] Step 7 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
