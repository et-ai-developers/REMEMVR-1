#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step03
Step Name: IRT Calibration Pass 2 (Purified Items)
RQ: results/ch5/rq7
Generated: 2025-11-25

PURPOSE:
Re-calibrate single-factor IRT model using ONLY high-quality items identified
in Step 2 purification. This Pass 2 calibration yields final theta estimates
with improved precision for downstream LMM functional form analysis.

EXPECTED INPUTS:
  - ../../rq1/data/step00_irt_input.csv
    Columns: composite_ID (str), TQ_* item response columns (0/1 dichotomized)
    Format: Wide-format CSV with UTF-8 encoding
    Expected rows: ~400 (100 participants x 4 test sessions)
    Description: Same raw VR item responses as Pass 1 (from RQ 5.1 step00)

  - data/step02_purified_items.csv
    Columns: item_name (str), pass1_a (float), pass1_b (float), dimension (str)
    Format: CSV with UTF-8 encoding
    Expected rows: 40-60 (purified item list from Step 2)
    Description: High-quality items passing Decision D039 thresholds

EXPECTED OUTPUTS:
  - data/step03_theta_scores.csv
    Columns: composite_ID (str), Theta_All (float), SE_All (float)
    Format: CSV with UTF-8 encoding
    Expected rows: 400
    Description: FINAL person ability estimates from purified single-factor model

  - logs/step03_item_parameters.csv
    Columns: item_name (str), dimension (str), a (float), b (float)
    Format: CSV with UTF-8 encoding
    Expected rows: 40-60 (matches purified item count)
    Description: Pass 2 item parameters (re-estimated with purified set)

  - logs/step03_calibration.log
    Format: Text log
    Description: IRT convergence diagnostics for Pass 2

VALIDATION CRITERIA:
  - Model convergence: Convergence status = True
  - Theta range: All Theta_All in [-4, 4]
  - SE range: All SE_All in [0.1, 1.5]
  - SE improvement: SE_All <= SE_All from Pass 1 (purification improves precision)
  - Complete data: All 400 composite_IDs present
  - Item count match: Number of items equals purified list length

g_code REASONING:
- Approach: Re-calibrate IRT model using subset of items (purified from Pass 1).
  Same calibration procedure as Step 1 but with filtered item list.
- Why this approach: Purification removes noisy items, yielding more reliable
  theta estimates. Standard IRT practice for improving measurement quality.
- Data flow: Raw item responses (wide) + purified item list -> filter columns ->
  long-format DataFrame -> IRT calibration -> theta scores + item parameters ->
  validation checks -> CSV outputs
- Expected performance: ~1-3 minutes (fewer items than Pass 1, faster convergence)

IMPLEMENTATION NOTES:
- Analysis tool: tools.analysis_irt.calibrate_irt
- Validation tool: tools.validation.validate_irt_convergence
- Parameters: Single factor 'All', purified item list from Step 2, same config as Pass 1
- Item grouping: Only items in step02_purified_items.csv assigned to 'All'
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (5 levels deep from project root)
# parents[4] = REMEMVR/ (code -> rq7 -> ch5 -> results -> REMEMVR)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_irt import calibrate_irt

# Import validation tool
from tools.validation import validate_irt_convergence

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/rq7
LOG_FILE = RQ_DIR / "logs" / "step03_calibration.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_lmm_model_comparison.csv
#   CORRECT: data/step03_theta_scores.csv
#   WRONG:   results/lmm_model_comparison.csv  (wrong folder + no prefix)
#   WRONG:   data/theta_scores.csv             (missing step prefix)
#   WRONG:   logs/step02_removed_items.csv     (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 3: IRT Calibration Pass 2 (Purified Items)")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Raw VR item responses (same as Pass 1) + purified item list
        # Purpose: Re-calibrate IRT model with high-quality items only

        log("[LOAD] Loading raw VR item responses...")
        irt_input_path = PROJECT_ROOT / "results" / "ch5" / "rq1" / "data" / "step00_irt_input.csv"

        if not irt_input_path.exists():
            raise FileNotFoundError(f"IRT input data missing: {irt_input_path}\n"
                                     "Expected from RQ 5.1 step00")

        irt_data_raw = pd.read_csv(irt_input_path, encoding='utf-8')
        log(f"[LOADED] {irt_input_path.name} ({len(irt_data_raw)} rows, {len(irt_data_raw.columns)} cols)")

        log("[LOAD] Loading purified item list...")
        purified_path = RQ_DIR / "data" / "step02_purified_items.csv"

        if not purified_path.exists():
            raise FileNotFoundError(f"Purified items missing: {purified_path}\n"
                                     "Run step02_purify_items.py first")

        purified_items = pd.read_csv(purified_path, encoding='utf-8')
        log(f"[LOADED] {purified_path.name} ({len(purified_items)} items retained)")

        # Extract item names for calibration
        purified_item_names = purified_items['item_name'].tolist()
        log(f"  Purified items: {purified_item_names[:5]}... ({len(purified_item_names)} total)")

        # =========================================================================
        # STEP 2: Run Pass 2 IRT Calibration
        # =========================================================================
        # Tool: calibrate_irt
        # What it does: Calibrates single-factor GRM with purified item subset
        # Expected output: Theta scores + item parameters (Pass 2 estimates)

        log("[ANALYSIS] Running Pass 2 IRT calibration (purified items only)...")

        # Configure groups: Only purified items assigned to 'All' factor
        groups = {
            "All": purified_item_names
        }

        # Configure IRT model (same settings as Pass 1)
        config = {
            "factors": ["All"],
            "correlated_factors": False,  # Single factor (no correlations)
            "device": "cpu",
            "seed": 42,
            "model_fit": {
                "batch_size": 2048,
                "iw_samples": 100,
                "mc_samples": 1
            },
            "model_scores": {
                "scoring_batch_size": 2048,
                "mc_samples": 100,
                "iw_samples": 100
            }
        }

        theta_scores, item_params = calibrate_irt(
            df_long=irt_data_raw,
            groups=groups,
            config=config
        )

        log("[DONE] Pass 2 calibration complete")
        log(f"  Theta scores: {len(theta_scores)} rows")
        log(f"  Item parameters: {len(item_params)} items")

        # =========================================================================
        # STEP 3: Save Pass 2 Outputs
        # =========================================================================
        # These outputs will be used by: Step 4 (LMM input preparation)

        # Save theta scores (FINAL estimates for LMM)
        theta_output_path = RQ_DIR / "data" / "step03_theta_scores.csv"
        log(f"[SAVE] Saving Pass 2 theta scores to {theta_output_path.name}...")
        theta_scores.to_csv(theta_output_path, index=False, encoding='utf-8')
        log(f"[SAVED] {theta_output_path.name} ({len(theta_scores)} rows, {len(theta_scores.columns)} cols)")
        log(f"  Theta_All range: [{theta_scores['Theta_All'].min():.3f}, {theta_scores['Theta_All'].max():.3f}]")
        log(f"  SE_All range: [{theta_scores['SE_All'].min():.3f}, {theta_scores['SE_All'].max():.3f}]")

        # Save item parameters (Pass 2 estimates)
        params_output_path = RQ_DIR / "logs" / "step03_item_parameters.csv"
        log(f"[SAVE] Saving Pass 2 item parameters to {params_output_path.name}...")
        item_params.to_csv(params_output_path, index=False, encoding='utf-8')
        log(f"[SAVED] {params_output_path.name} ({len(item_params)} items, {len(item_params.columns)} cols)")
        log(f"  Discrimination (a) range: [{item_params['a'].min():.3f}, {item_params['a'].max():.3f}]")
        log(f"  Difficulty (b) range: [{item_params['b'].min():.3f}, {item_params['b'].max():.3f}]")

        # =========================================================================
        # STEP 4: Validate Pass 2 Results
        # =========================================================================
        # Tool: validate_irt_convergence
        # Validates: Model convergence, theta/SE ranges, item count match, SE improvement
        # Threshold: Same as Pass 1, plus SE improvement check

        log("[VALIDATION] Validating Pass 2 calibration results...")

        # Load Pass 1 theta scores for SE comparison
        pass1_theta_path = RQ_DIR / "data" / "step01_theta_scores.csv"
        if pass1_theta_path.exists():
            pass1_theta = pd.read_csv(pass1_theta_path, encoding='utf-8')
            se_comparison = theta_scores.merge(
                pass1_theta[['composite_ID', 'SE_All']],
                on='composite_ID',
                suffixes=('_pass2', '_pass1')
            )
            se_improved = (se_comparison['SE_All_pass2'] <= se_comparison['SE_All_pass1']).mean()
            log(f"[VALIDATION] SE improvement: {se_improved*100:.1f}% of cases have SE_pass2 <= SE_pass1")
        else:
            log("[VALIDATION] Pass 1 theta scores not found - skipping SE comparison")

        validation_result = validate_irt_convergence(
            results={
                "item_params": item_params,
                "theta_scores": theta_scores,
                "log_file": str(LOG_FILE)
            }
        )

        # Report validation results
        if isinstance(validation_result, dict):
            for key, value in validation_result.items():
                log(f"[VALIDATION] {key}: {value}")
        else:
            log(f"[VALIDATION] {validation_result}")

        # Check item count matches purified list
        if len(item_params) == len(purified_items):
            log(f"[PASS] Item count matches purified list ({len(item_params)} items)")
        else:
            log(f"[WARNING] Item count mismatch - expected {len(purified_items)}, got {len(item_params)}")

        log("[SUCCESS] Step 3 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
