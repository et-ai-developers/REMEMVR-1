#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step05
Step Name: Fit 5 Candidate LMM Models
RQ: results/ch5/rq7
Generated: 2025-11-25

PURPOSE:
Fit 5 candidate LMM models with different functional forms for forgetting curves:
(1) Linear: Days
(2) Quadratic: Days + Days_squared
(3) Logarithmic: log_Days_plus1
(4) Linear + Log: Days + log_Days_plus1
(5) Quadratic + Log: Days + Days_squared + log_Days_plus1

All models fitted with REML=False for AIC-based model comparison in Step 6.

EXPECTED INPUTS:
  - data/step04_lmm_input.csv
    Columns: composite_ID, UID, test, Theta, SE, TSVR_hours, Days, Days_squared, log_Days_plus1
    Format: CSV with UTF-8 encoding
    Expected rows: 400
    Description: LMM-ready dataset with theta outcome and time transformations

EXPECTED OUTPUTS:
  - data/step05_model_fits.pkl
    Format: Python pickle dictionary
    Keys: 'Linear', 'Quadratic', 'Logarithmic', 'LinLog', 'QuadLog'
    Values: MixedLMResults objects (statsmodels fitted models)
    Description: All 5 fitted LMM models for downstream comparison

  - results/step05_model_comparison.csv
    Columns: model_name, AIC, BIC, log_likelihood, n_params, converged
    Format: CSV with UTF-8 encoding
    Expected rows: 5
    Description: Model fit statistics for AIC comparison

  - logs/step05_lmm_fitting.log
    Format: Text log
    Description: Fitting diagnostics and convergence status for each model

VALIDATION CRITERIA:
  - All 5 models converged (converged=True)
  - AIC/BIC values finite (not NaN or Inf)
  - Log-likelihood reasonable (negative, not -Inf)
  - No singular covariance warnings (indicates identification issues)

g_code REASONING:
- Approach: Use tools.analysis_lmm.compare_lmm_models_by_aic to fit all 5 models
  simultaneously. Random intercepts by UID, no reference group (continuous outcome),
  REML=False for AIC comparison.
- Why this approach: Functional form comparison requires fitting multiple models
  with different time predictors. AIC-based selection identifies which forgetting
  curve best describes longitudinal theta trajectories.
- Data flow: LMM input -> 5 model formulas (different time terms) -> fit with
  REML=False -> extract AIC/BIC/LL -> save fitted models + comparison table
- Expected performance: ~1-2 minutes (5 models, 400 observations, simple random effects)

IMPLEMENTATION NOTES:
- Analysis tool: tools.analysis_lmm.compare_lmm_models_by_aic
- Validation tool: tools.validation.validate_lmm_convergence
- Parameters: n_factors=1 (single outcome Theta), groups='UID' (random intercepts),
              save_dir for pickle output
- Model formulas (defined in compare_lmm_models_by_aic):
    Linear: Theta ~ Days + (1 | UID)
    Quadratic: Theta ~ Days + Days_squared + (1 | UID)
    Logarithmic: Theta ~ log_Days_plus1 + (1 | UID)
    LinLog: Theta ~ Days + log_Days_plus1 + (1 | UID)
    QuadLog: Theta ~ Days + Days_squared + log_Days_plus1 + (1 | UID)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (5 levels deep from project root)
# parents[4] = REMEMVR/ (code -> rq7 -> ch5 -> results -> REMEMVR)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_lmm import compare_lmm_models_by_aic

# Import validation tool
from tools.validation import validate_lmm_convergence

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/rq7
LOG_FILE = RQ_DIR / "logs" / "step05_lmm_fitting.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_lmm_model_comparison.csv
#   CORRECT: data/step03_theta_scores.csv
#   WRONG:   results/lmm_model_comparison.csv  (wrong folder + no prefix)
#   WRONG:   data/theta_scores.csv             (missing step prefix)
#   WRONG:   logs/step02_removed_items.csv     (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 5: Fit 5 Candidate LMM Models")

        # =========================================================================
        # STEP 1: Load LMM Input Data
        # =========================================================================
        # Expected: LMM-ready dataset with theta outcome + time transformations
        # Purpose: Fit 5 functional form models for forgetting curve comparison

        log("[LOAD] Loading LMM input data...")
        input_path = RQ_DIR / "data" / "step04_lmm_input.csv"

        if not input_path.exists():
            raise FileNotFoundError(f"LMM input data missing: {input_path}\n"
                                     "Run step04_prepare_lmm_input.py first")

        lmm_input = pd.read_csv(input_path, encoding='utf-8')
        log(f"[LOADED] {input_path.name} ({len(lmm_input)} rows, {len(lmm_input.columns)} cols)")
        log(f"  Columns: {lmm_input.columns.tolist()}")
        log(f"  Theta range: [{lmm_input['Theta'].min():.3f}, {lmm_input['Theta'].max():.3f}]")
        log(f"  Days range: [{lmm_input['Days'].min():.2f}, {lmm_input['Days'].max():.2f}]")

        # =========================================================================
        # STEP 1.5: Transform Column Names for Tool Compatibility
        # =========================================================================
        # The compare_lmm_models_by_aic tool expects specific column names:
        # - 'Ability' as outcome variable (instead of 'Theta')
        # - 'Days_sq' for quadratic term (instead of 'Days_squared')
        # - 'log_Days' for logarithmic term (instead of 'log_Days_plus1')

        log("[TRANSFORM] Renaming columns for tool compatibility...")
        lmm_input = lmm_input.rename(columns={
            'Theta': 'Ability',
            'Days_squared': 'Days_sq',
            'log_Days_plus1': 'log_Days'
        })
        log("  Renamed: Theta -> Ability, Days_squared -> Days_sq, log_Days_plus1 -> log_Days")

        # =========================================================================
        # STEP 2: Fit 5 Candidate Models
        # =========================================================================
        # Tool: compare_lmm_models_by_aic
        # What it does: Fits 5 LMM models with different time predictors, returns
        #               fitted models + AIC comparison table + best model selection
        # Expected output: Dictionary with models, aic_comparison, best_model, best_result

        log("[ANALYSIS] Fitting 5 candidate LMM models...")
        log("  Models:")
        log("    (1) Linear: Theta ~ Days")
        log("    (2) Quadratic: Theta ~ Days + Days_squared")
        log("    (3) Logarithmic: Theta ~ log_Days_plus1")
        log("    (4) LinLog: Theta ~ Days + log_Days_plus1")
        log("    (5) QuadLog: Theta ~ Days + Days_squared + log_Days_plus1")
        log("  Random effects: (1 | UID)")
        log("  REML: False (for AIC comparison)")

        # Create save directory for pickle output
        save_dir = RQ_DIR / "data"
        save_dir.mkdir(parents=True, exist_ok=True)

        comparison_results = compare_lmm_models_by_aic(
            data=lmm_input,
            n_factors=1,              # Single outcome variable (Theta)
            reference_group=None,     # No reference group (continuous outcome)
            groups='UID',             # Random intercepts by participant UID
            save_dir=save_dir         # Directory for pickle output
        )

        log("[DONE] All 5 models fitted")
        log(f"  Best model: {comparison_results['best_model']}")

        # =========================================================================
        # STEP 3: Save Model Comparison Results
        # =========================================================================
        # Output will be used by: Step 6 (AIC model selection)

        # Save AIC comparison table
        comparison_output_path = RQ_DIR / "results" / "step05_model_comparison.csv"
        log(f"[SAVE] Saving model comparison table to {comparison_output_path.name}...")
        comparison_results['aic_comparison'].to_csv(
            comparison_output_path,
            index=False,
            encoding='utf-8'
        )
        log(f"[SAVED] {comparison_output_path.name}")
        log("")
        log("AIC Comparison:")
        log(comparison_results['aic_comparison'].to_string(index=False))
        log("")

        # Pickle file saved by compare_lmm_models_by_aic
        pickle_path = RQ_DIR / "data" / "step05_model_fits.pkl"
        if pickle_path.exists():
            log(f"[SAVED] Model fits pickle: {pickle_path.name}")
        else:
            log(f"[WARNING] Expected pickle file not found: {pickle_path.name}")

        # =========================================================================
        # STEP 4: Validate Model Convergence
        # =========================================================================
        # Tool: validate_lmm_convergence
        # Validates: All models converged, AIC/BIC finite, no singular covariance

        log("[VALIDATION] Validating LMM convergence...")

        # Check convergence for each model
        all_converged = True
        for model_name, model_result in comparison_results['models'].items():
            try:
                validation_result = validate_lmm_convergence(lmm_result=model_result)

                if isinstance(validation_result, dict):
                    converged = validation_result.get('converged', False)
                    if converged:
                        log(f"[PASS] {model_name}: Converged")
                    else:
                        log(f"[FAIL] {model_name}: Did not converge")
                        all_converged = False
                else:
                    log(f"[VALIDATION] {model_name}: {validation_result}")

            except Exception as e:
                log(f"[ERROR] {model_name}: Validation failed - {str(e)}")
                all_converged = False

        # Check AIC/BIC finite
        aic_comparison = comparison_results['aic_comparison']
        if aic_comparison[['AIC', 'BIC', 'log_likelihood']].isna().any().any():
            log("[FAIL] Some models have NaN AIC/BIC/log_likelihood")
            all_converged = False
        else:
            log("[PASS] All AIC/BIC/log_likelihood values finite")

        if np.isinf(aic_comparison[['AIC', 'BIC', 'log_likelihood']]).any().any():
            log("[FAIL] Some models have Inf AIC/BIC/log_likelihood")
            all_converged = False
        else:
            log("[PASS] All AIC/BIC/log_likelihood values finite (not Inf)")

        # Overall validation summary
        if all_converged:
            log("[SUCCESS] All 5 models converged successfully")
        else:
            log("[WARNING] Some models did not converge - check fitting diagnostics")

        log("[SUCCESS] Step 5 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
