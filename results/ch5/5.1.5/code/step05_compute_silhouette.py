#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: 05
Step Name: compute_silhouette
RQ: results/ch5/5.1.5
Generated: 2025-12-02

PURPOSE:
Compute silhouette coefficient to assess cluster quality using Rousseeuw 1987
methodology. Silhouette measures how similar each participant is to their own
cluster compared to other clusters. Higher values indicate better-defined clusters.

EXPECTED INPUTS:
  - data/step01_standardized_features.csv
    Columns: ['UID', 'Intercept_z', 'Slope_z']
    Format: Z-scored random effects (mean=0, SD=1)
    Expected rows: ~100 participants

  - data/step03_cluster_assignments.csv
    Columns: ['UID', 'cluster']
    Format: Cluster assignments from optimal K-means model
    Expected rows: ~100 participants

EXPECTED OUTPUTS:
  - data/step05_silhouette_score.txt
    Format: Silhouette coefficient + interpretation
    Contains: Single float in [-1, 1] + interpretation text
    Expected: Typically 0.25-0.70 for real behavioral clustering

VALIDATION CRITERIA:
  - Silhouette coefficient in [-1, 1]
  - Silhouette finite (not NaN, not inf)

g_code REASONING:
- Approach: Use sklearn.metrics.silhouette_score on standardized features
- Why this approach: Silhouette coefficient quantifies cluster separation and cohesion
  simultaneously, providing single interpretable metric for cluster quality
- Data flow: Load z-scored features + cluster assignments -> Compute silhouette ->
  Interpret (>= 0.50 Strong, 0.25-0.49 Reasonable, < 0.25 Weak) -> Save score + text
- Expected performance: ~1 second (N=100, K=2-3 clusters typical)

IMPLEMENTATION NOTES:
- Analysis tool: silhouette_score from sklearn.metrics
- Validation tool: validate_numeric_range from tools.validation
- Parameters: Euclidean metric (standard for continuous features), standardized input
- Interpretation thresholds from Rousseeuw (1987) and Kaufman & Rousseeuw (1990):
  - >= 0.70: Strong structure found
  - 0.50-0.69: Reasonable structure found
  - 0.25-0.49: Weak structure (artificial clustering possible)
  - < 0.25: No substantial structure found
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/ (5.1.5)
#   parents[2] = chX/ (ch5)
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from sklearn.metrics import silhouette_score

# Import validation tool
from tools.validation import validate_numeric_range

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.1.5 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step05_compute_silhouette.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_silhouette_score.txt
#   CORRECT: data/step03_cluster_assignments.csv
#   WRONG:   results/silhouette_score.txt       (wrong folder + no prefix)
#   WRONG:   data/silhouette.txt                (missing step prefix)
#   WRONG:   logs/step05_silhouette.csv         (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 05: Compute Silhouette Coefficient")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Standardized features (z-scored random effects) from Step 1
        #           and cluster assignments from Step 3 (after K-means fitting)
        # Purpose: Compute silhouette coefficient to assess cluster separation/cohesion

        log("[LOAD] Loading standardized features from Step 1...")
        # Standardized features: UID, Intercept_z, Slope_z (100 participants, mean=0, SD=1)
        features_df = pd.read_csv(RQ_DIR / "data/step01_standardized_features.csv", encoding='utf-8')
        log(f"[LOADED] step01_standardized_features.csv ({len(features_df)} rows, {len(features_df.columns)} cols)")
        log(f"[INFO] Columns: {features_df.columns.tolist()}")

        log("[LOAD] Loading cluster assignments from Step 3...")
        # Cluster assignments: UID, cluster (100 participants, cluster IDs 0 to K-1)
        assignments_df = pd.read_csv(RQ_DIR / "data/step03_cluster_assignments.csv", encoding='utf-8')
        log(f"[LOADED] step03_cluster_assignments.csv ({len(assignments_df)} rows, {len(assignments_df.columns)} cols)")
        log(f"[INFO] Columns: {assignments_df.columns.tolist()}")

        # =========================================================================
        # STEP 2: Prepare Data for Silhouette Computation
        # =========================================================================
        # Need: (1) Feature matrix X (100 x 2: Intercept_z, Slope_z)
        #       (2) Cluster labels (100 x 1: cluster IDs)
        # Both must be aligned by participant UID

        log("[PREPARE] Merging features with cluster assignments on UID...")
        # Inner merge ensures alignment (all 100 participants present in both files)
        merged_df = features_df.merge(assignments_df, on='UID', how='inner')
        log(f"[MERGED] {len(merged_df)} participants with features + cluster assignments")

        if len(merged_df) != len(features_df):
            raise ValueError(f"UID mismatch: features has {len(features_df)} rows, merged has {len(merged_df)} rows")

        # Extract feature matrix X (N x 2 numpy array)
        X = merged_df[['Intercept_z', 'Slope_z']].values
        log(f"[PREPARED] Feature matrix X: shape {X.shape} (100 participants x 2 features)")

        # Extract cluster labels (N x 1 numpy array)
        labels = merged_df['cluster'].values
        n_clusters = len(np.unique(labels))
        log(f"[PREPARED] Cluster labels: {len(labels)} participants, {n_clusters} unique clusters")
        log(f"[INFO] Cluster sizes: {pd.Series(labels).value_counts().sort_index().to_dict()}")

        # =========================================================================
        # STEP 3: Compute Silhouette Coefficient
        # =========================================================================
        # Tool: sklearn.metrics.silhouette_score
        # What it does: Computes mean silhouette coefficient across all participants
        #   - For each participant i:
        #     a(i) = mean distance to other participants in same cluster (cohesion)
        #     b(i) = mean distance to participants in nearest other cluster (separation)
        #     s(i) = (b(i) - a(i)) / max(a(i), b(i))  (silhouette coefficient)
        #   - Overall silhouette = mean of s(i) across all participants
        # Expected output: Single float in [-1, 1]
        #   - 1 = perfect clustering (each point close to own cluster, far from others)
        #   - 0 = overlapping clusters (point on decision boundary)
        #   - -1 = wrong cluster assignment (point closer to other cluster)

        log("[ANALYSIS] Computing silhouette coefficient using Euclidean metric...")
        silhouette_coef = silhouette_score(X=X, labels=labels, metric='euclidean')
        log(f"[COMPUTED] Silhouette coefficient: {silhouette_coef:.4f}")

        # =========================================================================
        # STEP 4: Interpret Silhouette Score
        # =========================================================================
        # Interpretation thresholds from Rousseeuw (1987) and Kaufman & Rousseeuw (1990)
        # Used in cluster validation literature for K-means and hierarchical clustering

        if silhouette_coef >= 0.70:
            interpretation = "Strong cluster structure found"
            detail = "Clusters are well-separated and cohesive (silhouette >= 0.70)"
        elif silhouette_coef >= 0.50:
            interpretation = "Reasonable cluster structure found"
            detail = "Clusters have moderate separation and cohesion (0.50 <= silhouette < 0.70)"
        elif silhouette_coef >= 0.25:
            interpretation = "Weak cluster structure"
            detail = "Clusters have poor separation, may be artificial (0.25 <= silhouette < 0.50)"
        else:
            interpretation = "No substantial cluster structure"
            detail = "Clustering may be arbitrary, consider K=1 (silhouette < 0.25)"

        log(f"[INTERPRETATION] {interpretation}")
        log(f"[DETAIL] {detail}")

        # =========================================================================
        # STEP 5: Save Silhouette Score and Interpretation
        # =========================================================================
        # Output: Single text file with silhouette score + interpretation
        # Format: Silhouette: 0.XXXX\nInterpretation: [text]
        # Used by: Step 7 for plot metadata annotation

        output_path = RQ_DIR / "data/step05_silhouette_score.txt"
        log(f"[SAVE] Saving silhouette score and interpretation to {output_path.name}...")

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(f"Silhouette Coefficient: {silhouette_coef:.4f}\n")
            f.write(f"Interpretation: {interpretation}\n")
            f.write(f"Detail: {detail}\n")
            f.write(f"Number of Clusters: {n_clusters}\n")
            f.write(f"Number of Participants: {len(labels)}\n")

        log(f"[SAVED] {output_path.name}")

        # =========================================================================
        # STEP 6: Run Validation Tool
        # =========================================================================
        # Tool: validate_numeric_range from tools.validation
        # Validates: Silhouette coefficient in [-1, 1], finite (not NaN/inf)
        # Why needed: Silhouette computation can fail with degenerate clusters
        #   (e.g., single-participant clusters, identical feature values)

        log("[VALIDATION] Running validate_numeric_range on silhouette coefficient...")

        # Convert single float to numpy array for validation function
        # (validate_numeric_range expects ndarray or Series)
        silhouette_array = np.array([silhouette_coef])

        validation_result = validate_numeric_range(
            data=silhouette_array,
            min_val=-1.0,  # Theoretical minimum (point in wrong cluster)
            max_val=1.0,   # Theoretical maximum (perfect clustering)
            column_name='silhouette'  # For error messages
        )

        # Report validation results
        if validation_result['valid']:
            log(f"[VALIDATION] PASS: Silhouette coefficient in valid range [-1, 1]")
            log(f"[VALIDATION] Message: {validation_result['message']}")
        else:
            # Validation failed - silhouette out of bounds or NaN/inf
            log(f"[VALIDATION] FAIL: {validation_result['message']}")
            raise ValueError(f"Silhouette validation failed: {validation_result['message']}")

        log("[SUCCESS] Step 05 complete - Silhouette coefficient computed and validated")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
