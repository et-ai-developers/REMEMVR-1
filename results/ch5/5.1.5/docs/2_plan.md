# Analysis Plan for RQ 5.1.5: Individual Clustering

**Created by:** rq_planner agent
**Date:** 2025-12-02
**Status:** Ready for rq_tools (Step 11 workflow)

---

## Overview

This RQ examines whether participants can be grouped into latent classes based on their forgetting trajectories (intercepts and slopes extracted from RQ 5.1.4). The analysis uses K-means clustering on 2 standardized variables (Total_Intercept, Total_Slope) to identify distinct forgetting profiles across N=100 participants.

**Analysis Type:** K-means clustering on DERIVED data (no IRT calibration, no LMM fitting required)

**Pipeline:** Load random effects -> Standardize features -> Test K=1-6 clusters -> Select optimal K via BIC -> Fit final model -> Validate stability (bootstrap) -> Compute quality metrics (silhouette) -> Characterize clusters -> Visualize

**Total Steps:** 8 (Step 0: data loading, Steps 1-7: clustering pipeline)

**Estimated Runtime:** Low (clustering analysis on 100 x 2 matrix, <5 minutes total)

**Key Decisions Applied:**
- Bootstrap stability validation required (Hennig 2007 methodology - N=100 small sample requires resampling validation)
- Silhouette coefficient quality assessment (Rousseeuw 1987)
- Undersized cluster remediation (reduce K if any cluster <10% of sample)
- Reproducibility via random_state=42, n_init=50

**Cross-RQ Dependencies:**
- RQ 5.1.4 Step 4 output (random effects extraction MANDATORY)
- RQ 5.1.1 outputs (optional - for trajectory visualization if needed)

---

## Analysis Plan

### Step 0: Load Random Effects from RQ 5.1.4

**Dependencies:** None (first step, but requires RQ 5.1.4 completion)

**Complexity:** Low (<1 minute data loading with dependency validation)

**Purpose:** Load individual random effects (Total_Intercept, Total_Slope) from RQ 5.1.4 best-fitting LMM model.

**Input:**

**File 1:** results/ch5/5.1.4/data/step04_random_effects.csv
**Source:** Generated by RQ 5.1.4 Step 4 (extract individual random effects from best LMM)
**Format:** CSV with columns:
  - `UID` (string, format: P### with leading zeros, e.g., P001, P042, P100)
  - `Total_Intercept` (float, random intercept for each participant, unrestricted range)
  - `Total_Slope` (float, random slope for each participant, expected negative values = forgetting)
**Expected Rows:** 100 participants (all participants from RQ 5.1.1)
**Expected Columns:** 3 (UID, Total_Intercept, Total_Slope)

**Circuit Breaker:** If results/ch5/5.1.4/data/step04_random_effects.csv does not exist, QUIT with:
```
EXPECTATIONS ERROR: RQ 5.1.4 Step 4 must complete before RQ 5.1.5

Missing file: results/ch5/5.1.4/data/step04_random_effects.csv

Action: Run RQ 5.1.4 through Step 4 (extract random effects) before running RQ 5.1.5

Dependency chain: RQ 5.1.1 (Steps 1-6) -> RQ 5.1.4 (Steps 1-4) -> RQ 5.1.5
```

**Processing:**
1. Check file existence (circuit breaker if missing)
2. Load CSV with pandas.read_csv()
3. Validate structure: exactly 100 rows, exactly 3 columns (UID, Total_Intercept, Total_Slope)
4. Check for missing values (no NaN tolerated in clustering variables)
5. Save to data/step00_random_effects_from_rq514.csv (local copy for lineage tracking)

**Output:**

**File 1:** data/step00_random_effects_from_rq514.csv
**Format:** CSV (copy of RQ 5.1.4 output with local lineage)
**Columns:**
  - `UID` (string)
  - `Total_Intercept` (float)
  - `Total_Slope` (float)
**Expected Rows:** 100 participants
**Expected Columns:** 3

**Validation Requirement:**
Validation tools MUST be used after data loading. Specific validation tools will be determined by rq_tools based on data format requirements. The rq_analysis agent will embed validation tool calls after the data loading tool call for this step.

**Substance Validation Criteria (for rq_inspect post-execution validation):**

*Output Files:*
- data/step00_random_effects_from_rq514.csv exists (exact path)
- Expected rows: 100 (all participants present, no data loss)
- Expected columns: 3 (UID, Total_Intercept, Total_Slope)
- Data types: UID (object/string), Total_Intercept (float64), Total_Slope (float64)

*Value Ranges:*
- Total_Intercept: typically in [-2, 2] (IRT theta scale, random effects centered near 0)
- Total_Slope: typically in [-1, 1] (slope magnitude, negative = forgetting)
- No extreme outliers (|intercept| > 5 or |slope| > 3 suggests extraction error)

*Data Quality:*
- No NaN values tolerated (clustering requires complete data)
- All 100 participants present (no missing UIDs)
- No duplicate UIDs
- UID format correct (P### pattern with leading zeros)

*Log Validation:*
- Required pattern: "Loaded 100 participants from RQ 5.1.4"
- Required pattern: "No missing values detected"
- Forbidden patterns: "ERROR", "NaN detected", "Missing file"
- Acceptable warnings: None expected for data loading step

**Expected Behavior on Validation Failure:**
- Raise error with specific failure message (e.g., "Expected 100 rows, found 87")
- Log failure to logs/step00_load_random_effects.log
- Quit script immediately (do NOT proceed to Step 1)
- If dependency file missing: circuit breaker activates, user must run RQ 5.1.4 first

---

### Step 1: Standardize Clustering Features

**Dependencies:** Step 0 (requires loaded random effects)

**Complexity:** Low (<1 minute z-score transformation)

**Purpose:** Standardize Total_Intercept and Total_Slope to z-scores (mean=0, SD=1) to ensure equal weighting in K-means distance calculations.

**Input:**

**File 1:** data/step00_random_effects_from_rq514.csv
**Source:** Step 0 output
**Format:** CSV with 100 rows, 3 columns (UID, Total_Intercept, Total_Slope)

**Processing:**
1. Load random effects
2. Compute z-scores: z = (x - mean(x)) / sd(x) for Total_Intercept and Total_Slope separately
3. Verify standardization: mean ~ 0 (tolerance: |mean| < 0.01 due to floating point), SD ~ 1 (tolerance: 0.95 < SD < 1.05)
4. Create standardized DataFrame with columns: UID, Intercept_z, Slope_z
5. Save to data/step01_standardized_features.csv

**Rationale for Standardization:**
K-means uses Euclidean distance. Without standardization, variables with larger variance dominate distance calculations. Intercepts and slopes may have different scales, so z-scoring ensures equal contribution to cluster formation.

**Output:**

**File 1:** data/step01_standardized_features.csv
**Format:** CSV
**Columns:**
  - `UID` (string, participant identifier)
  - `Intercept_z` (float64, z-scored Total_Intercept, mean ~ 0, SD ~ 1)
  - `Slope_z` (float64, z-scored Total_Slope, mean ~ 0, SD ~ 1)
**Expected Rows:** 100 participants
**Expected Columns:** 3

**Validation Requirement:**
Validation tools MUST be used after standardization tool execution. Specific validation tools will be determined by rq_tools (likely validate_standardization function from tools_catalog.md). The rq_analysis agent will embed validation tool calls after the standardization tool call for this step.

**Substance Validation Criteria (for rq_inspect post-execution validation):**

*Output Files:*
- data/step01_standardized_features.csv exists
- Expected rows: 100
- Expected columns: 3 (UID, Intercept_z, Slope_z)
- Data types: UID (object), Intercept_z (float64), Slope_z (float64)

*Value Ranges:*
- Intercept_z: typically in [-3, 3] (z-scores, extreme outliers > |3| rare but possible)
- Slope_z: typically in [-3, 3]
- Mean of Intercept_z: ~ 0 (tolerance: |mean| < 0.01)
- Mean of Slope_z: ~ 0 (tolerance: |mean| < 0.01)
- SD of Intercept_z: ~ 1 (tolerance: 0.95 < SD < 1.05)
- SD of Slope_z: ~ 1 (tolerance: 0.95 < SD < 1.05)

*Data Quality:*
- No NaN values (standardization should not introduce NaN)
- All 100 participants present
- No duplicate UIDs

*Log Validation:*
- Required pattern: "Standardization complete: Intercept_z mean={value}, SD={value}"
- Required pattern: "Standardization complete: Slope_z mean={value}, SD={value}"
- Required pattern: "VALIDATION - PASS: Standardization criteria met"
- Forbidden patterns: "ERROR", "NaN introduced", "VALIDATION - FAIL"
- Acceptable warnings: "Mean slightly off zero (within tolerance)" if |mean| < 0.01

**Expected Behavior on Validation Failure:**
- Raise error if standardization failed (mean not ~ 0 or SD not ~ 1)
- Log failure to logs/step01_standardize_features.log
- Quit script immediately
- Common causes: constant variable (SD=0), incorrect formula, floating point precision issues

---

### Step 2: Test K=1 to K=6 Clusters and Select Optimal K via BIC

**Dependencies:** Step 1 (requires standardized features)

**Complexity:** Medium (K-means fitting 6 times, ~2-3 minutes with n_init=50 per model)

**Purpose:** Fit K-means for K=1 to K=6 clusters, compute inertia (within-cluster sum of squares) and BIC (Bayesian Information Criterion) for each K, select optimal K as BIC minimum.

**Input:**

**File 1:** data/step01_standardized_features.csv
**Source:** Step 1 output
**Format:** CSV with 100 rows, 3 columns (UID, Intercept_z, Slope_z)

**Processing:**
1. Load standardized features (100 x 2 matrix: Intercept_z, Slope_z)
2. For K in {1, 2, 3, 4, 5, 6}:
   a. Fit K-means with K clusters (random_state=42, n_init=50 for stability)
   b. Extract inertia (within-cluster sum of squared distances to cluster centers)
   c. Compute BIC = N * log(inertia/N) + K * log(N) where N=100
   d. Record K, inertia, BIC in results table
3. Select K_optimal as argmin(BIC) (K with lowest BIC value)
4. Save cluster selection results to data/step02_cluster_selection.csv
5. Save K_optimal to data/step02_optimal_k.txt

**BIC Formula:**
BIC = N * log(inertia / N) + K * log(N)
- Lower BIC = better model (penalizes complexity)
- BIC balances fit (inertia) vs parsimony (fewer clusters)

**Expected Pattern:**
- K=1: High inertia, low BIC (no clustering)
- K=2-3: Inertia decreases, BIC reaches minimum (optimal K expected here)
- K=4-6: Inertia continues to decrease but BIC increases (overfitting penalty)

**Output:**

**File 1:** data/step02_cluster_selection.csv
**Format:** CSV
**Columns:**
  - `K` (int, number of clusters tested: 1, 2, 3, 4, 5, 6)
  - `inertia` (float64, within-cluster sum of squares, always positive, decreases with K)
  - `BIC` (float64, Bayesian Information Criterion, can be negative, optimal K has minimum BIC)
**Expected Rows:** 6 (one row per K value)
**Expected Columns:** 3

**File 2:** data/step02_optimal_k.txt
**Format:** Plain text file
**Content:** Single integer (optimal K selected by BIC minimum, expected: 2 or 3)
**Example:** "3" (if K=3 has lowest BIC)

**Validation Requirement:**
Validation tools MUST be used after cluster selection tool execution. Specific validation tools will be determined by rq_tools. The rq_analysis agent will embed validation tool calls after the cluster selection tool call for this step.

**Substance Validation Criteria (for rq_inspect post-execution validation):**

*Output Files:*
- data/step02_cluster_selection.csv exists
- Expected rows: 6 (K=1 to K=6)
- Expected columns: 3 (K, inertia, BIC)
- Data types: K (int64), inertia (float64), BIC (float64)
- data/step02_optimal_k.txt exists
- Content: Single integer in range [1, 6]

*Value Ranges:*
- K: exactly {1, 2, 3, 4, 5, 6}
- inertia: positive values, monotonically decreasing with K (inertia_K1 > inertia_K6)
- BIC: finite values (not NaN, not inf)
- optimal_k: integer in [1, 6], typically 2 or 3 for this RQ

*Data Quality:*
- No NaN values in cluster_selection.csv
- All 6 K values present (no missing rows)
- No duplicate K values
- Inertia decreases monotonically: inertia[K] >= inertia[K+1]
- BIC has clear minimum (optimal K unambiguous, not a tie)

*Log Validation:*
- Required pattern: "K-means tested for K=1 to K=6"
- Required pattern: "BIC minimum at K={value}"
- Required pattern: "Optimal K selected: {value}"
- Forbidden patterns: "ERROR", "NaN in BIC", "Inertia increased with K"
- Acceptable warnings: "BIC tie between K={a} and K={b}" (if difference < 1.0)

**Expected Behavior on Validation Failure:**
- Raise error if inertia not monotonically decreasing (K-means convergence issue)
- Raise error if BIC contains NaN/inf (computation error)
- Log failure to logs/step02_test_k_clusters.log
- Quit script immediately
- Common causes: K-means failed to converge, numerical instability in BIC computation

---

### Step 3: Fit Final K-means Model with Optimal K

**Dependencies:** Step 2 (requires optimal K selection)

**Complexity:** Low (<1 minute single K-means fit)

**Purpose:** Fit final K-means model using optimal K (from Step 2), extract cluster assignments for 100 participants and cluster centers (mean Intercept_z and Slope_z per cluster).

**Input:**

**File 1:** data/step01_standardized_features.csv
**Source:** Step 1 output
**Format:** CSV with 100 rows, 3 columns (UID, Intercept_z, Slope_z)

**File 2:** data/step02_optimal_k.txt
**Source:** Step 2 output
**Format:** Plain text file with single integer (optimal K)

**Processing:**
1. Load standardized features (100 x 2 matrix)
2. Read optimal K from step02_optimal_k.txt
3. Fit K-means with K clusters (random_state=42, n_init=50 for reproducibility)
4. Extract cluster assignments (which cluster each participant belongs to: 0, 1, ..., K-1)
5. Check cluster sizes: if any cluster < 10% of sample (N < 10), reduce K by 1 and refit (remedial action for undersized clusters per concept.md)
6. Record K_initial (from BIC) and K_final (after size constraint) if remedial action taken
7. Extract cluster centers (mean Intercept_z and Slope_z per cluster)
8. Save cluster assignments to data/step03_cluster_assignments.csv
9. Save cluster centers to data/step03_cluster_centers.csv
10. If K_final != K_initial, save remedial action report to data/step03_remedial_action.txt

**Remedial Action Logic:**
- If min(cluster_sizes) < 10: K_final = K_initial - 1, refit K-means
- Repeat until all clusters >= 10 participants OR K_final = 1
- Document K_initial vs K_final in remedial action report

**Output:**

**File 1:** data/step03_cluster_assignments.csv
**Format:** CSV
**Columns:**
  - `UID` (string, participant identifier)
  - `cluster` (int, cluster assignment: 0, 1, ..., K_final-1)
**Expected Rows:** 100 participants
**Expected Columns:** 2

**File 2:** data/step03_cluster_centers.csv
**Format:** CSV
**Columns:**
  - `cluster` (int, cluster ID: 0, 1, ..., K_final-1)
  - `Intercept_z_center` (float64, mean Intercept_z for cluster, should be distinct across clusters)
  - `Slope_z_center` (float64, mean Slope_z for cluster, should be distinct across clusters)
**Expected Rows:** K_final (typically 2-3)
**Expected Columns:** 3

**File 3 (conditional):** data/step03_remedial_action.txt
**Format:** Plain text (only created if K_final != K_initial)
**Content:** "K_initial from BIC: {K_initial}\nK_final after size constraint: {K_final}\nReason: Cluster {id} had {N} participants (<10% threshold)"

**Validation Requirement:**
Validation tools MUST be used after K-means fitting tool execution. Specific validation tools will be determined by rq_tools (likely validate_cluster_assignment from tools_catalog.md). The rq_analysis agent will embed validation tool calls after the K-means fitting tool call for this step.

**Substance Validation Criteria (for rq_inspect post-execution validation):**

*Output Files:*
- data/step03_cluster_assignments.csv exists
- Expected rows: 100
- Expected columns: 2 (UID, cluster)
- Data types: UID (object), cluster (int64)
- data/step03_cluster_centers.csv exists
- Expected rows: K_final (2 or 3 typically)
- Expected columns: 3 (cluster, Intercept_z_center, Slope_z_center)
- Data types: cluster (int64), centers (float64)

*Value Ranges:*
- cluster assignments: consecutive integers starting from 0 (0, 1, ..., K_final-1)
- Intercept_z_center: typically in [-2, 2] (cluster means, wider than individual z-scores)
- Slope_z_center: typically in [-2, 2]
- No cluster ID > K_final - 1 (0-indexed)

*Data Quality:*
- No NaN in cluster assignments (all participants assigned)
- All 100 participants present in assignments
- No duplicate UIDs
- Cluster sizes balanced: each cluster >= 10 participants (10% threshold enforced)
- Cluster IDs consecutive: if K_final=3, must have clusters {0, 1, 2}, not {0, 2, 5}
- Cluster centers distinct: no two clusters with identical centers

*Log Validation:*
- Required pattern: "K-means fitted with K={K_final} clusters"
- Required pattern: "Cluster sizes: {N0}, {N1}, ... (all >= 10)"
- Required pattern: "All clusters meet 10% size threshold"
- Forbidden patterns: "ERROR", "Cluster size < 10", "CONVERGENCE FAILED"
- Acceptable warnings: "Remedial action: reduced K from {K_initial} to {K_final}"

**Expected Behavior on Validation Failure:**
- Raise error if cluster sizes < 10 and K cannot be reduced further (K_final=1)
- Raise error if K-means failed to converge
- Log failure to logs/step03_fit_final_kmeans.log
- Quit script immediately
- Common causes: K too large for N=100, poor initialization, data structure not conducive to clustering

---

### Step 4: Bootstrap Stability Validation

**Dependencies:** Step 3 (requires final K-means model and cluster assignments)

**Complexity:** Medium (B=100 bootstrap iterations, ~2-3 minutes)

**Purpose:** Validate cluster stability via bootstrap resampling (B=100 iterations). For each bootstrap sample, refit K-means with K_final and compute Jaccard coefficient comparing bootstrap cluster assignments to original assignments. Stability thresholds: Jaccard >= 0.75 = stable, 0.60-0.74 = questionable, <0.60 = unstable.

**Input:**

**File 1:** data/step01_standardized_features.csv
**Source:** Step 1 output
**Format:** CSV with 100 rows, 3 columns (UID, Intercept_z, Slope_z)

**File 2:** data/step03_cluster_assignments.csv
**Source:** Step 3 output
**Format:** CSV with 100 rows, 2 columns (UID, cluster)

**File 3:** data/step02_optimal_k.txt OR data/step03_remedial_action.txt
**Source:** Step 2 or Step 3 (to get K_final)

**Processing:**
1. Load standardized features and original cluster assignments
2. Read K_final (from optimal_k.txt or remedial_action.txt)
3. For b in 1 to B=100:
   a. Create bootstrap sample (resample 100 participants with replacement)
   b. Fit K-means on bootstrap sample with K_final clusters (random_state=42+b for reproducibility)
   c. Map bootstrap cluster IDs to original cluster IDs (best match via Jaccard maximization)
   d. Compute Jaccard coefficient: J = (number of agreement pairs) / (number of total pairs)
   e. Record Jaccard for iteration b
4. Compute summary statistics: mean Jaccard, 95% CI (2.5th and 97.5th percentiles)
5. Classify stability:
   - Jaccard >= 0.75: "Stable (proceed with confidence)"
   - 0.60 <= Jaccard < 0.75: "Questionable (report with caution)"
   - Jaccard < 0.60: "Unstable (consider reducing K)"
6. Save bootstrap Jaccard coefficients to data/step04_bootstrap_jaccard.csv
7. Save stability summary to data/step04_stability_summary.txt

**Jaccard Coefficient:**
Measures pairwise agreement between two clusterings:
- J = (number of pairs in same cluster in both) / (number of pairs in same cluster in at least one)
- Range: [0, 1], where 1 = perfect agreement, 0 = no agreement

**Bootstrap Rationale:**
N=100 is relatively small for clustering. Bootstrap resampling tests whether cluster structure is robust to sampling variation (Hennig 2007). Low Jaccard indicates clusters are sampling artifacts, not true population structure.

**Output:**

**File 1:** data/step04_bootstrap_jaccard.csv
**Format:** CSV
**Columns:**
  - `iteration` (int, bootstrap iteration: 1 to 100)
  - `jaccard` (float64, Jaccard coefficient for iteration, range [0, 1])
**Expected Rows:** 100 (B=100 bootstrap iterations)
**Expected Columns:** 2

**File 2:** data/step04_stability_summary.txt
**Format:** Plain text
**Content:**
```
Bootstrap Stability Validation (B=100 iterations)
Mean Jaccard: {mean_value}
95% CI: [{lower}, {upper}]
Stability Classification: {Stable/Questionable/Unstable}
Recommendation: {proceed/report with caution/reduce K}
```

**Validation Requirement:**
Validation tools MUST be used after bootstrap validation tool execution. Specific validation tools will be determined by rq_tools (likely validate_bootstrap_stability from tools_catalog.md). The rq_analysis agent will embed validation tool calls after the bootstrap tool call for this step.

**Substance Validation Criteria (for rq_inspect post-execution validation):**

*Output Files:*
- data/step04_bootstrap_jaccard.csv exists
- Expected rows: 100 (B bootstrap iterations)
- Expected columns: 2 (iteration, jaccard)
- Data types: iteration (int64), jaccard (float64)
- data/step04_stability_summary.txt exists
- Contains: mean Jaccard, 95% CI, stability classification

*Value Ranges:*
- iteration: exactly {1, 2, ..., 100}
- jaccard: in [0, 1] (Jaccard coefficient bounded)
- mean_jaccard: in [0, 1]
- 95% CI lower bound: in [0, mean_jaccard]
- 95% CI upper bound: in [mean_jaccard, 1]

*Data Quality:*
- No NaN in jaccard values (bootstrap should always produce valid coefficient)
- All 100 iterations present
- No duplicate iterations
- Jaccard distribution reasonable (not all 0 or all 1)
- 95% CI width reasonable (not too wide = unstable, not zero = suspicious)

*Log Validation:*
- Required pattern: "Bootstrap validation: 100 iterations complete"
- Required pattern: "Mean Jaccard: {value}"
- Required pattern: "Stability classification: {Stable/Questionable/Unstable}"
- Forbidden patterns: "ERROR", "NaN in Jaccard", "Bootstrap failed"
- Acceptable warnings: "Stability questionable (Jaccard < 0.75)" if 0.60 <= Jaccard < 0.75

**Expected Behavior on Validation Failure:**
- Raise error if Jaccard values outside [0, 1] (computation error)
- Raise error if bootstrap iterations failed to complete
- Log failure to logs/step04_bootstrap_stability.log
- Quit script immediately if Jaccard < 0.60 AND user requested strict validation
- Report with caution if 0.60 <= Jaccard < 0.75 (do not quit, but flag concern)
- Common causes: K too large for N=100, cluster structure weak, high sampling variation

---

### Step 5: Compute Silhouette Coefficient

**Dependencies:** Step 3 (requires cluster assignments and standardized features)

**Complexity:** Low (<1 minute silhouette computation)

**Purpose:** Compute silhouette coefficient to assess cluster quality. Silhouette measures how similar each point is to its own cluster compared to other clusters. Interpretation thresholds: silhouette >= 0.50 = strong structure, 0.25-0.49 = reasonable structure, <0.25 = weak/artificial structure (Rousseeuw 1987).

**Input:**

**File 1:** data/step01_standardized_features.csv
**Source:** Step 1 output
**Format:** CSV with 100 rows, 3 columns (UID, Intercept_z, Slope_z)

**File 2:** data/step03_cluster_assignments.csv
**Source:** Step 3 output
**Format:** CSV with 100 rows, 2 columns (UID, cluster)

**Processing:**
1. Load standardized features (100 x 2 matrix: Intercept_z, Slope_z)
2. Load cluster assignments (100 participants with cluster IDs)
3. Compute silhouette coefficient using sklearn.metrics.silhouette_score
4. Interpret silhouette:
   - >= 0.50: "Strong cluster structure (well-separated clusters)"
   - 0.25-0.49: "Reasonable cluster structure (moderate separation)"
   - < 0.25: "Weak/artificial cluster structure (poor separation)"
5. Save silhouette score and interpretation to data/step05_silhouette_score.txt

**Silhouette Coefficient:**
Silhouette = (b - a) / max(a, b) where:
- a = mean intra-cluster distance (distance to points in same cluster)
- b = mean nearest-cluster distance (distance to points in nearest other cluster)
- Range: [-1, 1], where 1 = perfect separation, 0 = overlapping clusters, -1 = misclassified

**Output:**

**File 1:** data/step05_silhouette_score.txt
**Format:** Plain text
**Content:**
```
Silhouette Coefficient: {value}
Interpretation: {Strong/Reasonable/Weak} cluster structure
Threshold: >= 0.50 strong, 0.25-0.49 reasonable, < 0.25 weak
Recommendation: {proceed/report with caution/reconsider clustering}
```

**Validation Requirement:**
Validation tools MUST be used after silhouette computation tool execution. Specific validation tools will be determined by rq_tools. The rq_analysis agent will embed validation tool calls after the silhouette tool call for this step.

**Substance Validation Criteria (for rq_inspect post-execution validation):**

*Output Files:*
- data/step05_silhouette_score.txt exists
- Contains: silhouette coefficient (numeric), interpretation (string), recommendation

*Value Ranges:*
- silhouette coefficient: in [-1, 1] (theoretical range)
- Expected range for valid clustering: [0, 1] (negative silhouette suggests misclassification)

*Data Quality:*
- Silhouette not NaN (computation should succeed)
- Silhouette finite (not inf)
- Interpretation matches value (e.g., if silhouette=0.45, interpretation="Reasonable")

*Log Validation:*
- Required pattern: "Silhouette coefficient: {value}"
- Required pattern: "Cluster quality: {Strong/Reasonable/Weak}"
- Forbidden patterns: "ERROR", "NaN silhouette", "Computation failed"
- Acceptable warnings: "Weak cluster structure (silhouette < 0.25)" if structure poor

**Expected Behavior on Validation Failure:**
- Raise error if silhouette NaN or inf (computation error)
- Raise error if silhouette < -1 or > 1 (impossible value)
- Log failure to logs/step05_compute_silhouette.log
- Report with caution if silhouette < 0.25 (weak structure, do not quit but flag)
- Common causes: K=1 (no clustering, silhouette undefined), overlapping clusters, poor K selection

---

### Step 6: Characterize Clusters

**Dependencies:** Step 3 (requires cluster assignments and centers)

**Complexity:** Low (<1 minute descriptive statistics and label assignment)

**Purpose:** Characterize clusters by computing mean intercept and slope per cluster (raw scale, not z-scored), assign interpretive labels based on profile patterns (e.g., "High baseline, slow forgetting" vs "Low baseline, fast forgetting"), examine cluster composition by age band (post-hoc demographic analysis if age data available).

**Input:**

**File 1:** data/step00_random_effects_from_rq514.csv
**Source:** Step 0 output (raw-scale intercepts and slopes)
**Format:** CSV with 100 rows, 3 columns (UID, Total_Intercept, Total_Slope)

**File 2:** data/step03_cluster_assignments.csv
**Source:** Step 3 output
**Format:** CSV with 100 rows, 2 columns (UID, cluster)

**Optional File (if demographic analysis):** data/cache/dfData.csv
**Purpose:** Age variable for post-hoc composition analysis

**Processing:**
1. Load raw-scale random effects and cluster assignments
2. Merge on UID (100 participants with cluster + raw intercept/slope)
3. For each cluster k:
   a. Compute mean Total_Intercept (raw scale, interpretable baseline)
   b. Compute mean Total_Slope (raw scale, interpretable forgetting rate)
   c. Compute SD for both (variability within cluster)
   d. Count N participants per cluster
4. Assign interpretive labels based on profile patterns:
   - High baseline, slow forgetting: Intercept > 0, Slope > median (less negative)
   - Average baseline, average forgetting: Intercept ~ 0, Slope ~ median
   - Low baseline, fast forgetting: Intercept < 0, Slope < median (more negative)
5. (Optional) If age data available: compute age distribution per cluster (mean, SD, range)
6. Save cluster characterization to data/step06_cluster_characterization.csv
7. Save interpretive labels and descriptions to data/step06_cluster_labels.txt

**Output:**

**File 1:** data/step06_cluster_characterization.csv
**Format:** CSV
**Columns:**
  - `cluster` (int, cluster ID: 0, 1, ..., K_final-1)
  - `N` (int, number of participants in cluster)
  - `mean_intercept` (float64, mean Total_Intercept in raw scale)
  - `sd_intercept` (float64, SD of Total_Intercept within cluster)
  - `mean_slope` (float64, mean Total_Slope in raw scale, negative = forgetting)
  - `sd_slope` (float64, SD of Total_Slope within cluster)
  - `label` (string, interpretive label: "High baseline slow forgetting", etc.)
**Expected Rows:** K_final (typically 2-3)
**Expected Columns:** 7

**File 2:** data/step06_cluster_labels.txt
**Format:** Plain text
**Content:**
```
Cluster 0: {label}
  Description: {interpretive description based on mean intercept/slope}
  N participants: {N}
  Mean baseline (intercept): {value}
  Mean forgetting rate (slope): {value}

Cluster 1: {label}
  ...
```

**Validation Requirement:**
Validation tools MUST be used after cluster characterization tool execution. Specific validation tools will be determined by rq_tools (likely validate_cluster_summary_stats from tools_catalog.md). The rq_analysis agent will embed validation tool calls after the characterization tool call for this step.

**Substance Validation Criteria (for rq_inspect post-execution validation):**

*Output Files:*
- data/step06_cluster_characterization.csv exists
- Expected rows: K_final (2 or 3 typically)
- Expected columns: 7 (cluster, N, mean_intercept, sd_intercept, mean_slope, sd_slope, label)
- Data types: cluster (int64), N (int64), means/SDs (float64), label (object/string)
- data/step06_cluster_labels.txt exists

*Value Ranges:*
- N: sum across clusters = 100 (all participants assigned)
- mean_intercept: typically in [-1, 1] (random effects scale)
- mean_slope: typically in [-0.5, 0.5] (forgetting rates, negative expected)
- sd_intercept: >= 0 (SD non-negative)
- sd_slope: >= 0
- Labels non-empty strings

*Data Quality:*
- No NaN in means or SDs
- All clusters characterized (K_final rows present)
- Sum of N = 100 (all participants accounted for)
- SD > 0 for all clusters (some within-cluster variability expected)
- Labels distinct (no duplicate labels unless profiles identical)
- Cluster means show separation: at least one dimension differs significantly across clusters

*Log Validation:*
- Required pattern: "Cluster characterization complete: {K_final} clusters"
- Required pattern: "All {K_final} clusters labeled"
- Forbidden patterns: "ERROR", "NaN in means", "Sum of N != 100"
- Acceptable warnings: "Cluster {k} has low within-cluster variability (SD < 0.1)"

**Expected Behavior on Validation Failure:**
- Raise error if sum of N != 100 (assignment error)
- Raise error if SD < 0 (computation error)
- Log failure to logs/step06_characterize_clusters.log
- Quit script immediately
- Common causes: Merge failure, missing cluster in assignments, incorrect groupby

---

### Step 7: Create Cluster Scatter Plot Data

**Dependencies:** Step 1 (standardized features), Step 3 (cluster assignments), Step 5 (silhouette score)

**Complexity:** Low (<1 minute plot data aggregation)

**Purpose:** Prepare plot source CSV for scatter plot visualization (Option B architecture). Plot will show participants colored by cluster membership, with cluster centers marked and reference lines (mean intercept=0, mean slope=0 due to z-score standardization). Silhouette score annotated on plot.

**Input:**

**File 1:** data/step01_standardized_features.csv
**Source:** Step 1 output
**Format:** CSV with 100 rows, 3 columns (UID, Intercept_z, Slope_z)

**File 2:** data/step03_cluster_assignments.csv
**Source:** Step 3 output
**Format:** CSV with 100 rows, 2 columns (UID, cluster)

**File 3:** data/step03_cluster_centers.csv
**Source:** Step 3 output
**Format:** CSV with K_final rows, 3 columns (cluster, Intercept_z_center, Slope_z_center)

**File 4:** data/step05_silhouette_score.txt
**Source:** Step 5 output
**Purpose:** Extract silhouette coefficient for plot annotation

**Processing:**
1. Load standardized features, cluster assignments, cluster centers, silhouette score
2. Merge features with assignments on UID (100 participants with Intercept_z, Slope_z, cluster)
3. Create scatter plot data CSV with columns: Intercept_z, Slope_z, cluster (for coloring points)
4. Create cluster centers data CSV with columns: Intercept_z_center, Slope_z_center, cluster (for marking centers)
5. Create plot metadata YAML with:
   - silhouette_score (for annotation)
   - K_final (number of clusters)
   - reference_lines: {intercept: 0, slope: 0} (mean lines due to z-scoring)
6. Save to data/step07_scatter_plot_data.csv and data/step07_scatter_plot_metadata.yaml

**Plot Description:**
Scatter plot with participants as points (x = Intercept_z, y = Slope_z), colored by cluster. Cluster centers marked with larger symbols (e.g., stars). Reference lines at x=0 and y=0 (means due to z-score standardization). Silhouette score annotated in corner.

**Output:**

**File 1:** data/step07_scatter_plot_data.csv
**Format:** CSV (plot source data for participant points)
**Columns:**
  - `Intercept_z` (float64, x-axis value)
  - `Slope_z` (float64, y-axis value)
  - `cluster` (int, cluster assignment for coloring)
**Expected Rows:** 100 participants
**Expected Columns:** 3

**File 2:** data/step07_scatter_plot_centers.csv
**Format:** CSV (plot source data for cluster centers)
**Columns:**
  - `Intercept_z_center` (float64, x-coordinate of cluster center)
  - `Slope_z_center` (float64, y-coordinate of cluster center)
  - `cluster` (int, cluster ID)
**Expected Rows:** K_final (typically 2-3)
**Expected Columns:** 3

**File 3:** data/step07_scatter_plot_metadata.yaml
**Format:** YAML
**Content:**
```yaml
silhouette_score: {value}
K_final: {value}
reference_lines:
  intercept: 0
  slope: 0
xlabel: "Standardized Intercept (z-score)"
ylabel: "Standardized Slope (z-score)"
title: "Cluster Assignments (K={K_final}, Silhouette={silhouette_score})"
```

**Validation Requirement:**
Validation tools MUST be used after plot data preparation tool execution. Specific validation tools will be determined by rq_tools (likely validate_plot_data_completeness from tools_catalog.md). The rq_analysis agent will embed validation tool calls after the plot data preparation tool call for this step.

**Substance Validation Criteria (for rq_inspect post-execution validation):**

*Output Files:*
- data/step07_scatter_plot_data.csv exists
- Expected rows: 100
- Expected columns: 3 (Intercept_z, Slope_z, cluster)
- data/step07_scatter_plot_centers.csv exists
- Expected rows: K_final
- Expected columns: 3
- data/step07_scatter_plot_metadata.yaml exists

*Value Ranges:*
- Intercept_z: typically in [-3, 3] (z-scores)
- Slope_z: typically in [-3, 3]
- cluster: in {0, 1, ..., K_final-1}
- Intercept_z_center: typically in [-2, 2] (cluster means)
- Slope_z_center: typically in [-2, 2]
- silhouette_score: in [0, 1] (expected positive for valid clustering)

*Data Quality:*
- No NaN values in plot data (all participants have valid z-scores and cluster assignments)
- All 100 participants present
- All K_final clusters represented in centers
- Cluster IDs match between data and centers (0, 1, ..., K_final-1)

*Log Validation:*
- Required pattern: "Plot data preparation complete: 100 participants, {K_final} clusters"
- Required pattern: "Silhouette score: {value}"
- Forbidden patterns: "ERROR", "NaN in plot data", "Missing cluster"
- Acceptable warnings: None expected for plot data preparation

**Expected Behavior on Validation Failure:**
- Raise error if row counts incorrect (not 100 participants or not K_final centers)
- Raise error if cluster IDs mismatch between data and centers
- Log failure to logs/step07_prepare_scatter_plot_data.log
- Quit script immediately (do NOT proceed to rq_plots)
- Common causes: Merge failure, missing clusters, incorrect filtering

---

## Expected Data Formats

### Cross-Step Data Transformations

**Step 0 -> Step 1: Raw scale to z-scores**
- Input: Total_Intercept, Total_Slope (raw random effects scale)
- Transformation: z = (x - mean(x)) / sd(x)
- Output: Intercept_z, Slope_z (mean=0, SD=1)
- Rationale: Equal weighting in K-means distance calculations

**Step 1 -> Step 2-3: Z-scores to cluster assignments**
- Input: 100 x 2 matrix (Intercept_z, Slope_z)
- Transformation: K-means algorithm assigns each point to nearest cluster center
- Output: 100 cluster assignments (0, 1, ..., K_final-1)

**Step 3 -> Step 6: Z-scores back to raw scale for interpretation**
- Input: Cluster assignments + z-scored features
- Transformation: Merge with raw-scale intercepts/slopes from Step 0
- Output: Raw-scale cluster means (interpretable baseline and forgetting rate)
- Rationale: Z-scores aid clustering, but raw scale aids interpretation

### Column Naming Conventions

Per names.md (populated during RQ 5.1):
- `UID`: Participant identifier (P### format, no underscore)
- `cluster`: Cluster assignment (int, 0-indexed)
- `Intercept_z`: Standardized Total_Intercept (z-score)
- `Slope_z`: Standardized Total_Slope (z-score)
- `Total_Intercept`: Raw random intercept from LMM (IRT theta scale)
- `Total_Slope`: Raw random slope from LMM (theta change per unit time)

**New conventions for RQ 5.1.5:**
- `jaccard`: Jaccard coefficient for bootstrap stability (float in [0, 1])
- `silhouette`: Silhouette coefficient for cluster quality (float in [-1, 1])
- `K_final`: Final number of clusters after remedial action (int)

---

## Cross-RQ Dependencies

**Dependency Type:** DERIVED Data from RQ 5.1.4 (mandatory)

**This RQ requires outputs from:**

**RQ 5.1.4 (Variance Decomposition):**
- File: results/ch5/5.1.4/data/step04_random_effects.csv
- Used in: Step 0 (load random effects for clustering)
- Rationale: RQ 5.1.4 extracts individual random effects (Total_Intercept, Total_Slope) from the best-fitting LMM in RQ 5.1.1. This RQ clusters participants based on those random effects to identify latent profiles of forgetting trajectories.

**RQ 5.1.1 (Functional Form Comparison) - indirect dependency:**
- RQ 5.1.4 uses RQ 5.1.1 best model as input
- Therefore RQ 5.1.5 indirectly depends on RQ 5.1.1 completing Steps 1-6
- No direct file access from RQ 5.1.1 required

**Execution Order Constraint:**
1. RQ 5.1.1 must complete Steps 1-6 (IRT calibration, LMM model selection)
2. RQ 5.1.4 must complete Steps 1-4 (load RQ 5.1.1 model, extract random effects)
3. This RQ executes third (clusters participants using RQ 5.1.4 random effects)

**Dependency Chain:**
```
RQ 5.1.1 (Steps 1-6) -> RQ 5.1.4 (Steps 1-4) -> RQ 5.1.5 (Steps 0-7)
```

**Data Source Boundaries:**
- **RAW data:** None (this RQ uses no master.xlsx data directly)
- **DERIVED data:** results/ch5/5.1.4/data/step04_random_effects.csv (MANDATORY)
- **Scope:** This RQ does NOT re-fit LMMs or re-calibrate IRT models (uses extracted random effects as-is)

**Validation:**
- Step 0: Check results/ch5/5.1.4/data/step04_random_effects.csv exists (circuit breaker: EXPECTATIONS ERROR if absent)
- If file missing: quit with error, user must execute RQ 5.1.4 Step 4 first
- If RQ 5.1.4 incomplete: quit with error, dependency chain must complete sequentially

**Circuit Breaker (from Step 0):**
```
EXPECTATIONS ERROR: RQ 5.1.4 Step 4 must complete before RQ 5.1.5

Missing file: results/ch5/5.1.4/data/step04_random_effects.csv

Action: Run RQ 5.1.4 through Step 4 (extract random effects) before running RQ 5.1.5

Dependency chain: RQ 5.1.1 (Steps 1-6) -> RQ 5.1.4 (Steps 1-4) -> RQ 5.1.5
```

---

## Validation Requirements

**CRITICAL MANDATE:**

Every analysis step in this plan MUST use validation tools after analysis tool execution.

This is not optional. This is the core architectural principle preventing cascading failures observed in v3.0 (where analysis errors propagated undetected through 5+ downstream steps before discovery).

**Exact Specification Requirement:**

> "Validation tools MUST be used after analysis tool execution"

**Implementation:**
- rq_tools (Step 11 workflow) will read tool_inventory.md validation tools section
- rq_tools will specify BOTH analysis tool + validation tool per step in 3_tools.yaml
- rq_analysis (Step 12 workflow) will embed validation tool call AFTER analysis tool call in 4_analysis.yaml
- g_code (Step 14 workflow) will generate stepN_name.py scripts with validation function calls
- bash execution (Step 14 workflow) will run analysis -> validation -> error on validation failure

**Downstream Agent Requirements:**
- **rq_tools:** MUST specify validation tool for EVERY analysis step (no exceptions)
- **rq_analysis:** MUST embed validation tool call for EVERY analysis step (no exceptions)
- **g_code:** MUST generate code with validation function calls (no exceptions)
- **rq_inspect:** MUST verify validation ran successfully (checks logs/stepN_name.log for validation output)

### Validation Requirements By Step

**Step 0: Load Random Effects from RQ 5.1.4**
- Analysis Tool: (determined by rq_tools - likely pandas.read_csv with custom validation wrapper)
- Validation Tool: (determined by rq_tools - likely validate_dataframe_structure from tools_catalog.md)
- Criteria: File exists, 100 rows, 3 columns, no NaN in clustering variables, UID format correct
- On Failure: Circuit breaker if file missing, quit if data quality issues

**Step 1: Standardize Clustering Features**
- Analysis Tool: (determined by rq_tools - likely custom z-score standardization)
- Validation Tool: (determined by rq_tools - likely validate_standardization from tools_catalog.md)
- Criteria: Mean ~ 0 (|mean| < 0.01), SD ~ 1 (0.95 < SD < 1.05), no NaN introduced
- On Failure: Quit if standardization failed (mean/SD criteria not met)

**Step 2: Test K=1 to K=6 Clusters and Select Optimal K**
- Analysis Tool: (determined by rq_tools - likely sklearn KMeans in loop with BIC computation)
- Validation Tool: (determined by rq_tools - likely custom BIC validation checking monotonicity and finite values)
- Criteria: 6 K values tested, inertia monotonically decreasing, BIC finite, optimal K selected
- On Failure: Quit if inertia not monotonic (convergence issue) or BIC NaN/inf

**Step 3: Fit Final K-means Model**
- Analysis Tool: (determined by rq_tools - likely sklearn KMeans with remedial action logic)
- Validation Tool: (determined by rq_tools - likely validate_cluster_assignment from tools_catalog.md)
- Criteria: All participants assigned, cluster sizes >= 10, cluster IDs consecutive
- On Failure: Quit if cluster sizes < 10 and K cannot be reduced further

**Step 4: Bootstrap Stability Validation**
- Analysis Tool: (determined by rq_tools - likely custom bootstrap resampling with Jaccard computation)
- Validation Tool: (determined by rq_tools - likely validate_bootstrap_stability from tools_catalog.md)
- Criteria: 100 iterations complete, Jaccard in [0, 1], mean Jaccard computed
- On Failure: Report with caution if Jaccard < 0.75 (do not quit, flag concern)

**Step 5: Compute Silhouette Coefficient**
- Analysis Tool: (determined by rq_tools - likely sklearn.metrics.silhouette_score)
- Validation Tool: (determined by rq_tools - likely custom silhouette validation checking range)
- Criteria: Silhouette in [-1, 1], finite value
- On Failure: Report with caution if silhouette < 0.25 (weak structure, flag concern)

**Step 6: Characterize Clusters**
- Analysis Tool: (determined by rq_tools - likely pandas groupby with descriptive stats)
- Validation Tool: (determined by rq_tools - likely validate_cluster_summary_stats from tools_catalog.md)
- Criteria: Sum of N = 100, SD >= 0, cluster means distinct
- On Failure: Quit if sum of N != 100 (assignment error)

**Step 7: Create Cluster Scatter Plot Data**
- Analysis Tool: (determined by rq_tools - likely custom plot data aggregation)
- Validation Tool: (determined by rq_tools - likely validate_plot_data_completeness from tools_catalog.md)
- Criteria: 100 participant rows, K_final center rows, cluster IDs match, no NaN
- On Failure: Quit if row counts incorrect or cluster IDs mismatch

---

## Summary

**Total Steps:** 8 (Step 0: data loading, Steps 1-7: clustering pipeline)

**Estimated Runtime:** Low-Medium (~5-10 minutes total)
- Step 0: <1 min (data loading)
- Step 1: <1 min (z-score transformation)
- Step 2: ~2-3 min (K-means tested 6 times with n_init=50)
- Step 3: <1 min (single K-means fit)
- Step 4: ~2-3 min (100 bootstrap iterations)
- Step 5: <1 min (silhouette computation)
- Step 6: <1 min (descriptive stats)
- Step 7: <1 min (plot data aggregation)

**Cross-RQ Dependencies:** RQ 5.1.4 Step 4 (MANDATORY - random effects extraction)

**Primary Outputs:**
- Cluster assignments (100 participants with cluster IDs)
- Cluster centers (K_final clusters with mean intercept/slope)
- Bootstrap stability metrics (Jaccard coefficient, stability classification)
- Silhouette quality metric (cluster separation assessment)
- Cluster characterization (interpretive labels, raw-scale means)
- Scatter plot data (visualization-ready CSV for rq_plots)

**Validation Coverage:** 100% (all 8 steps have validation requirements with 4-layer substance criteria)

**Success Criteria:**
- Random effects loaded successfully (100 participants, no missing values)
- Standardization correct (mean ~ 0, SD ~ 1)
- BIC minimum clearly identified (optimal K = 2 or 3 expected)
- Cluster sizes balanced (all clusters >= 10 participants)
- Bootstrap stability achieved (mean Jaccard >= 0.75 for "Stable" classification)
- Silhouette coefficient >= 0.25 (reasonable cluster structure)
- Cluster centers interpretable (distinct patterns in intercept/slope space)
- Plot data complete (100 participants + K_final centers, ready for rq_plots)

---

**Next Steps (Workflow):**
1. User reviews and approves this plan (Step 7 user gate)
2. Workflow continues to Step 11: rq_tools reads this plan -> creates 3_tools.yaml
3. Workflow continues to Step 12: rq_analysis reads this plan + 3_tools.yaml -> creates 4_analysis.yaml
4. Workflow continues to Step 14: g_code reads 4_analysis.yaml -> generates stepN_name.py scripts

---

**Version History:**
- v1.0 (2025-12-02): Initial plan created by rq_planner agent for RQ 5.1.5
