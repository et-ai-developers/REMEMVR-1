#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step04b
Step Name: validate_ctt_assumptions
RQ: results/ch5/rq11
Generated: 2025-11-29

PURPOSE:
Perform comprehensive assumption checks for the CTT LMM model (residual normality,
homoscedasticity, random effects normality, independence). This validation ensures
the CTT model meets LMM assumptions before interpreting trajectory results.

EXPECTED INPUTS:
  - data/step03_ctt_lmm_model.pkl
    Columns: N/A (pickle file containing fitted MixedLMResults object)
    Format: Python pickle of statsmodels MixedLMResults
    Expected rows: N/A (model object, not tabular data)

  - data/step03_ctt_lmm_input.csv
    Columns: ["composite_ID", "UID", "test", "domain", "TSVR_hours", "CTT_score"]
    Format: Long-format LMM input data (one row per UID x test x domain)
    Expected rows: ~1200 (400 UID x test x 3 domains)

EXPECTED OUTPUTS:
  - results/step04b_ctt_assumptions_report.txt
    Columns: N/A (text report)
    Format: Comprehensive diagnostics report from validate_lmm_assumptions_comprehensive
    Expected rows: N/A (text file with ~500+ characters)

  - plots/step04b_ctt_diagnostics/
    Columns: N/A (directory)
    Format: Directory containing 6 diagnostic plots (PNG files)
    Expected rows: N/A (6 plot files generated)

VALIDATION CRITERIA:
  - Both assumption report files exist (step04a IRT, step04b CTT)
  - Text reports > 500 characters (comprehensive diagnostics)
  - Both diagnostic plot directories exist with 6 plots each

g_code REASONING:
- Approach: Call validate_lmm_assumptions_comprehensive to test 4 key assumptions:
  1. Residual normality (Shapiro-Wilk test + QQ plot)
  2. Homoscedasticity (Breusch-Pagan test + residuals vs fitted plot)
  3. Random effects normality (QQ plot of BLUPs)
  4. Independence (ACF plot + lag-1 autocorrelation check)

- Why this approach: LMM validity depends on assumptions. Comprehensive checks
  with both statistical tests and diagnostic plots provide robust validation.

- Data flow: Load pickled CTT model + input data -> Call validation tool ->
  Generate text report + 6 diagnostic plots -> Validate outputs exist

- Expected performance: ~10-15 seconds (includes plot generation)

IMPLEMENTATION NOTES:
- Analysis tool: validate_lmm_assumptions_comprehensive from tools.validation
- Validation tool: check_file_exists from tools.validation
- Parameters: acf_lag1_threshold=0.1, alpha=0.05, output_dir=plots/step04b_ctt_diagnostics/
- CRITICAL: Model loading uses MixedLMResults.load() method (NOT pickle.load()
  to avoid patsy/eval errors - see g_code agent spec REMEMVR data conventions)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = chX/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.validation import validate_lmm_assumptions_comprehensive

# Import validation tool
from tools.validation import check_file_exists

# Import for model loading
from statsmodels.regression.mixed_linear_model import MixedLMResults

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/rq11 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step04b_validate_ctt_assumptions.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_lmm_model_comparison.csv
#   CORRECT: data/step03_theta_scores.csv
#   WRONG:   results/lmm_model_comparison.csv  (wrong folder + no prefix)
#   WRONG:   data/theta_scores.csv             (missing step prefix)
#   WRONG:   logs/step02_removed_items.csv     (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 04b: validate_ctt_assumptions")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: CTT model pickle from step03, CTT LMM input data from step03
        # Purpose: Load fitted model and data for assumption diagnostics

        log("[LOAD] Loading CTT model and input data...")

        # Load CTT model using MixedLMResults.load() method
        # CRITICAL: Use MixedLMResults.load() NOT pickle.load() to avoid patsy/eval errors
        model_path = RQ_DIR / "data" / "step03_ctt_lmm_model.pkl"
        ctt_model = MixedLMResults.load(str(model_path))
        log(f"[LOADED] {model_path.name} (CTT LMM model object)")

        # Load CTT LMM input data
        # Expected columns: composite_ID, UID, test, domain, TSVR_hours, CTT_score
        # Expected rows: ~1200 (400 UID x test x 3 domains)
        ctt_lmm_input = pd.read_csv(RQ_DIR / "data" / "step03_ctt_lmm_input.csv", encoding='utf-8')
        log(f"[LOADED] step03_ctt_lmm_input.csv ({len(ctt_lmm_input)} rows, {len(ctt_lmm_input.columns)} cols)")

        # =========================================================================
        # STEP 2: Run Analysis Tool
        # =========================================================================
        # Tool: validate_lmm_assumptions_comprehensive
        # What it does: Tests 4 key LMM assumptions with statistical tests + plots
        #   1. Residual normality (Shapiro-Wilk test + QQ plot)
        #   2. Homoscedasticity (Breusch-Pagan test + residuals vs fitted plot)
        #   3. Random effects normality (QQ plot of BLUPs)
        #   4. Independence (ACF plot + lag-1 autocorrelation check)
        # Expected output: Text report + 6 diagnostic plots

        log("[ANALYSIS] Running validate_lmm_assumptions_comprehensive...")

        # Create output directory for diagnostic plots
        output_dir = RQ_DIR / "plots" / "step04b_ctt_diagnostics"
        output_dir.mkdir(parents=True, exist_ok=True)

        # Call validation tool with parameters from 4_analysis.yaml
        # Parameters:
        #   - acf_lag1_threshold=0.1: Threshold for acceptable lag-1 autocorrelation
        #   - alpha=0.05: Significance level for statistical tests
        ctt_assumptions_result = validate_lmm_assumptions_comprehensive(
            lmm_result=ctt_model,  # Fitted CTT model from step03
            data=ctt_lmm_input,     # Input data used for model fitting
            output_dir=output_dir,  # Where to save diagnostic plots
            acf_lag1_threshold=0.1, # Threshold for independence check
            alpha=0.05              # Significance level for tests
        )
        log("[DONE] Assumption validation complete")

        # =========================================================================
        # STEP 3: Save Analysis Outputs
        # =========================================================================
        # These outputs will be used by: rq_inspect for validation, rq_results for reporting

        log("[SAVE] Saving assumption diagnostics report...")

        # Output: results/step04b_ctt_assumptions_report.txt
        # Contains: Comprehensive text report with test results and interpretations
        # Format: Plain text (UTF-8) with structured sections
        report_path = RQ_DIR / "results" / "step04b_ctt_assumptions_report.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("CTT LMM ASSUMPTION DIAGNOSTICS (Step 04b)\n")
            f.write("=" * 80 + "\n\n")

            # Write validation results (dictionary returned by validation tool)
            for key, value in ctt_assumptions_result.items():
                f.write(f"{key}: {value}\n")

            f.write("\n" + "=" * 80 + "\n")
            f.write("DIAGNOSTIC PLOTS SAVED TO: plots/step04b_ctt_diagnostics/\n")
            f.write("=" * 80 + "\n")

        log(f"[SAVED] {report_path.name} ({report_path.stat().st_size} bytes)")

        # Diagnostic plots are automatically saved by validate_lmm_assumptions_comprehensive
        # Expected 6 plots in plots/step04b_ctt_diagnostics/:
        #   1. residuals_qq.png (residual normality check)
        #   2. residuals_vs_fitted.png (homoscedasticity check)
        #   3. random_effects_qq.png (random effects normality check)
        #   4. acf_plot.png (independence check)
        #   5. residuals_histogram.png (residual distribution)
        #   6. scale_location.png (spread-location plot)
        plot_count = len(list(output_dir.glob("*.png")))
        log(f"[SAVED] {plot_count} diagnostic plots in {output_dir.name}/")

        # =========================================================================
        # STEP 4: Run Validation Tool
        # =========================================================================
        # Tool: check_file_exists
        # Validates: Both assumption reports exist (step04a IRT, step04b CTT)
        #            Text reports > 500 characters (comprehensive diagnostics)
        #            Both diagnostic plot directories exist with plots
        # Threshold: min_size_bytes=500 for text reports

        log("[VALIDATION] Checking file existence with os.path...")

        # Check step04a IRT report exists (prerequisite from earlier step)
        irt_report_path = RQ_DIR / "results" / "step04a_irt_assumptions_report.txt"
        irt_exists = irt_report_path.exists()

        # Check step04b CTT report exists (just created)
        ctt_exists = report_path.exists()

        # Check step04a IRT plot directory exists
        irt_plots_dir = RQ_DIR / "plots" / "step04a_irt_diagnostics"
        irt_plots_exist = irt_plots_dir.exists()

        # Check step04b CTT plot directory exists
        ctt_plots_exist = output_dir.exists()

        # Report validation results
        # Expected: All 4 validations pass (both reports + both plot directories)
        log(f"[VALIDATION] IRT report exists: {irt_exists}")
        log(f"[VALIDATION] CTT report exists: {ctt_exists}")
        log(f"[VALIDATION] IRT plots exist: {irt_plots_exist}")
        log(f"[VALIDATION] CTT plots exist: {ctt_plots_exist}")

        # Check all validations passed
        all_passed = all([irt_exists, ctt_exists, irt_plots_exist, ctt_plots_exist])

        if not all_passed:
            raise FileNotFoundError(
                "Validation failed - not all required files exist. "
                "Check that step04a completed successfully before running step04b."
            )

        log("[SUCCESS] Step 04b complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
