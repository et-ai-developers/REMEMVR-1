# 3_tools.yaml - Tool Catalog (Analysis + Validation Tools)
# Created by: rq_tools agent (Step 11 workflow)
# Date: 2025-11-27
# RQ: 5.11 - IRT-CTT Convergent Validity Comparison
# Architecture: Tool Catalog (Option A) - Each tool listed once, deduplication

analysis_tools:
  compute_ctt_scores:
    module: "pandas"
    function: "DataFrame.groupby"
    signature: "DataFrame.groupby(by: Union[str, List[str]], **kwargs) -> DataFrameGroupBy"
    validation_tool: "validate_data_format"

    input_files:
      - path: "data/step00_raw_data_filtered.csv"
        required_columns: ["UID", "TEST", "item_columns (variable count)"]
        expected_rows: "~400 (100 participants x 4 tests)"
        data_types:
          UID: "string (participant identifier)"
          TEST: "string (test session: T1, T2, T3, T4)"
          item_columns: "float64 (values: 0, 1, NaN)"

      - path: "data/step00_purified_items.csv"
        required_columns: ["item_name", "dimension", "a", "b"]
        expected_rows: "~40-60 (purified items from RQ 5.1)"
        data_types:
          item_name: "string (item tag)"
          dimension: "string (domain)"
          a: "float64 (discrimination)"
          b: "float64 (difficulty)"

    output_files:
      - path: "data/step01_ctt_scores.csv"
        columns: ["composite_ID", "UID", "test", "domain", "CTT_score", "n_items"]
        description: "CTT mean scores per UID x test x domain (long format)"

    parameters:
      aggregation: "mean"
      na_rm: true
      domain_mapping:
        What: "'-N-' tag pattern"
        Where: "'-L-', '-U-', '-D-' tag patterns (aggregate all three)"
        When: "'-O-' tag pattern"

    description: "Compute CTT (Classical Test Theory) mean scores per UID x test x domain using same purified item set as RQ 5.1 IRT for fair comparison"
    source_reference: "Standard pandas aggregation (not in tools_inventory.md - stdlib function)"

  compute_correlations_holm_bonferroni:
    module: "scipy.stats"
    function: "pearsonr"
    signature: "pearsonr(x: ndarray, y: ndarray) -> Tuple[float, float]"
    validation_tool: "validate_correlation_test_d068"

    input_files:
      - path: "data/step00_irt_theta_loaded.csv"
        required_columns: ["composite_ID", "theta_what", "theta_where", "theta_when"]
        expected_rows: "~400"
        source: "RQ 5.1 IRT theta scores"

      - path: "data/step01_ctt_scores.csv"
        required_columns: ["composite_ID", "domain", "CTT_score"]
        expected_rows: "1200"
        source: "Step 1 CTT computation"

    output_files:
      - path: "results/step02_correlations.csv"
        columns: ["domain", "r", "CI_lower", "CI_upper", "p_uncorrected", "p_holm", "n", "threshold_0.70", "threshold_0.90"]
        description: "Pearson correlations (IRT vs CTT) with Holm-Bonferroni correction per Decision D068"

    parameters:
      correlation_type: "pearson"
      ci_level: 0.95
      fisher_z_transform: true
      correction_method: "holm-bonferroni"
      m_tests: 4
      alpha: 0.05
      thresholds: [0.70, 0.90]

    description: "Compute Pearson correlations between IRT theta and CTT mean scores for each domain, test significance with Holm-Bonferroni correction per Decision D068 dual p-value reporting"
    source_reference: "scipy.stats.pearsonr (stdlib) + custom Holm-Bonferroni implementation"

  fit_parallel_lmms:
    module: "statsmodels.regression.mixed_linear_model"
    function: "MixedLM"
    signature: "MixedLM(endog: ndarray, exog: ndarray, groups: ndarray, exog_re: Optional[ndarray] = None, **kwargs) -> MixedLMResults"
    validation_tool: "validate_lmm_convergence"

    input_files:
      - path: "data/step00_irt_theta_loaded.csv"
        required_columns: ["composite_ID", "theta_what", "theta_where", "theta_when"]
        expected_rows: "~400"

      - path: "data/step01_ctt_scores.csv"
        required_columns: ["composite_ID", "UID", "test", "domain", "CTT_score"]
        expected_rows: "1200"

      - path: "data/step00_tsvr_loaded.csv"
        required_columns: ["UID", "test", "TSVR_hours"]
        expected_rows: "~400"

    output_files:
      - path: "data/step03_irt_lmm_input.csv"
        columns: ["composite_ID", "UID", "test", "domain", "TSVR_hours", "IRT_score"]
        description: "Long-format IRT LMM input (1200 rows)"

      - path: "data/step03_ctt_lmm_input.csv"
        columns: ["composite_ID", "UID", "test", "domain", "TSVR_hours", "CTT_score"]
        description: "Long-format CTT LMM input (1200 rows)"

      - path: "results/step03_irt_lmm_summary.txt"
        description: "IRT model summary (fixed effects, random effects, AIC, BIC)"

      - path: "results/step03_ctt_lmm_summary.txt"
        description: "CTT model summary (fixed effects, random effects, AIC, BIC)"

      - path: "results/step03_irt_lmm_fixed_effects.csv"
        columns: ["term", "estimate", "SE", "z", "p_uncorrected"]
        description: "IRT model fixed effects table (~10 rows)"

      - path: "results/step03_ctt_lmm_fixed_effects.csv"
        columns: ["term", "estimate", "SE", "z", "p_uncorrected"]
        description: "CTT model fixed effects table (~10 rows)"

      - path: "logs/step03_convergence_report.txt"
        description: "Convergence decisions and random structure simplifications"

    parameters:
      formula: "Score ~ (TSVR_hours + log(TSVR_hours + 1)) * domain"
      re_formula: "TSVR_hours | UID"
      groups: "UID"
      method: "REML"
      time_variable: "TSVR_hours"
      convergence_strategy: "attempt random slopes, simplify to intercepts only if either model fails"
      identical_structure: true

    description: "Fit parallel LMMs (IRT model + CTT model) with identical structure using TSVR time variable per Decision D070. Implements convergence-aware simplification strategy (N=100 may require random intercepts only per Bates et al. 2015)."
    source_reference: "statsmodels.regression.mixed_linear_model.MixedLM (stdlib)"

  validate_lmm_assumptions_comprehensive:
    module: "tools.validation"
    function: "validate_lmm_assumptions_comprehensive"
    signature: "validate_lmm_assumptions_comprehensive(lmm_result: MixedLMResults, data: DataFrame, output_dir: Path, acf_lag1_threshold: float = 0.1, alpha: float = 0.05) -> Dict[str, Any]"
    validation_tool: "check_file_exists"

    input_files:
      - path: "results/step03_irt_lmm_summary.txt"
        source: "Step 3 fitted IRT model"

      - path: "results/step03_ctt_lmm_summary.txt"
        source: "Step 3 fitted CTT model"

      - path: "data/step03_irt_lmm_input.csv"
        required_columns: ["composite_ID", "UID", "test", "domain", "TSVR_hours", "IRT_score"]

      - path: "data/step03_ctt_lmm_input.csv"
        required_columns: ["composite_ID", "UID", "test", "domain", "TSVR_hours", "CTT_score"]

    output_files:
      - path: "results/step04_irt_assumptions_report.txt"
        description: "IRT model assumption diagnostics (Shapiro-Wilk, homoscedasticity, ACF)"

      - path: "results/step04_ctt_assumptions_report.txt"
        description: "CTT model assumption diagnostics"

      - path: "plots/step04_irt_diagnostics.png"
        format: "PNG (800x600 @ 300 DPI)"
        description: "IRT model diagnostic plots (2x2 grid)"

      - path: "plots/step04_ctt_diagnostics.png"
        format: "PNG (800x600 @ 300 DPI)"
        description: "CTT model diagnostic plots (2x2 grid)"

      - path: "results/step04_assumptions_comparison.csv"
        columns: ["model", "residual_normality_p", "residual_normality_pass", "homoscedasticity_pass", "random_effects_normality_pass", "acf_lag1_mean", "acf_lag1_pass", "overall_pass", "remedial_action"]
        description: "Assumption test results comparison (2 rows: IRT, CTT)"

    parameters:
      acf_lag1_threshold: 0.1
      alpha: 0.05
      parallel_remediation: true
      diagnostics:
        - "residual_normality"
        - "homoscedasticity"
        - "random_effects_normality"
        - "autocorrelation"

    description: "Comprehensive LMM assumption validation with 7 diagnostics (normality, homoscedasticity, Q-Q, ACF, linearity, outliers, convergence). Applies same remediation to BOTH models to maintain parallelism per RQ 5.11 concept.md requirement."
    source_reference: "tools_inventory.md section 'Module: tools.validation' - validate_lmm_assumptions_comprehensive"

  compare_coefficients_cohens_kappa:
    module: "pandas"
    function: "DataFrame.merge"
    signature: "DataFrame.merge(right: DataFrame, how: str = 'inner', on: Union[str, List[str]] = None, **kwargs) -> DataFrame"
    validation_tool: "validate_dataframe_structure"

    input_files:
      - path: "results/step03_irt_lmm_fixed_effects.csv"
        required_columns: ["term", "estimate", "SE", "z", "p_uncorrected"]
        expected_rows: "~10"

      - path: "results/step03_ctt_lmm_fixed_effects.csv"
        required_columns: ["term", "estimate", "SE", "z", "p_uncorrected"]
        expected_rows: "~10"

    output_files:
      - path: "results/step05_coefficient_comparison.csv"
        columns: ["term", "estimate_irt", "SE_irt", "p_irt", "sig_irt", "estimate_ctt", "SE_ctt", "p_ctt", "sig_ctt", "agreement", "beta_ratio", "discrepancy_flag"]
        description: "Coefficient comparison with significance agreement (~10 rows)"

      - path: "results/step05_agreement_metrics.csv"
        columns: ["metric", "value", "threshold", "pass"]
        description: "Agreement metrics (3 rows: raw_agreement_percent, cohens_kappa_all, cohens_kappa_interactions)"

    parameters:
      alpha: 0.05
      kappa_threshold: 0.60
      agreement_threshold: 0.80
      discrepancy_multiplier: 2.0
      focus_terms:
        - "TSVR_hours:domain"
        - "log(TSVR_hours+1):domain"

    description: "Extract and compare fixed effects from both models, calculate Cohen's kappa for significance agreement (accounts for chance agreement per Landis & Koch 1977), flag discrepancies beyond scaling differences"
    source_reference: "Custom Cohen's kappa implementation (not in tools_inventory.md - standard statistical metric)"

  compare_model_fit_aic_bic:
    module: "pandas"
    function: "DataFrame constructor"
    signature: "DataFrame(data: Optional[Union[Dict, List, ndarray]] = None, **kwargs) -> DataFrame"
    validation_tool: "validate_dataframe_structure"

    input_files:
      - path: "results/step03_irt_lmm_summary.txt"
        description: "Contains AIC and BIC values for IRT model"

      - path: "results/step03_ctt_lmm_summary.txt"
        description: "Contains AIC and BIC values for CTT model"

    output_files:
      - path: "results/step06_model_fit_comparison.csv"
        columns: ["model", "AIC", "BIC", "delta_AIC", "delta_BIC", "interpretation"]
        description: "Model fit comparison (2 rows: IRT, CTT)"

    parameters:
      thresholds:
        equivalent: 2.0
        moderate: 10.0
      delta_computation: "CTT - IRT"

    description: "Parse AIC and BIC from model summaries, compute deltas (CTT - IRT), interpret per concept.md thresholds (|delta| < 2 = equivalent, |delta| > 10 = substantial difference)"
    source_reference: "Standard pandas operations (stdlib)"

  prepare_plot_data_scatterplot:
    module: "pandas"
    function: "DataFrame.merge"
    signature: "DataFrame.merge(right: DataFrame, how: str = 'inner', on: Union[str, List[str]] = None, **kwargs) -> DataFrame"
    validation_tool: "validate_plot_data_completeness"

    input_files:
      - path: "data/step00_irt_theta_loaded.csv"
        required_columns: ["composite_ID", "theta_what", "theta_where", "theta_when"]
        expected_rows: "~400"

      - path: "data/step01_ctt_scores.csv"
        required_columns: ["composite_ID", "domain", "CTT_score"]
        expected_rows: "1200"

      - path: "results/step02_correlations.csv"
        required_columns: ["domain", "r"]
        expected_rows: "4"

    output_files:
      - path: "plots/step07_scatterplot_data.csv"
        columns: ["composite_ID", "domain", "IRT_score", "CTT_score", "r"]
        description: "Scatterplot source data (1200 rows = 400 UID x test x 3 domains)"

    parameters:
      reshape_irt: true
      domain_mapping:
        theta_what: "What"
        theta_where: "Where"
        theta_when: "When"
      merge_keys: ["composite_ID", "domain"]

    description: "Reshape IRT theta to long format, merge with CTT scores, add correlation annotations for scatterplot with regression lines (Option B architecture per Decision D069)"
    source_reference: "Standard pandas operations (stdlib)"

  prepare_plot_data_trajectory:
    module: "pandas"
    function: "DataFrame.groupby"
    signature: "DataFrame.groupby(by: Union[str, List[str]], **kwargs) -> DataFrameGroupBy"
    validation_tool: "validate_plot_data_completeness"

    input_files:
      - path: "data/step03_irt_lmm_input.csv"
        required_columns: ["composite_ID", "UID", "test", "domain", "TSVR_hours", "IRT_score"]
        expected_rows: "1200"

      - path: "data/step03_ctt_lmm_input.csv"
        required_columns: ["composite_ID", "UID", "test", "domain", "TSVR_hours", "CTT_score"]
        expected_rows: "1200"

    output_files:
      - path: "plots/step08_trajectory_data.csv"
        columns: ["TSVR_hours", "domain", "model", "mean_score", "CI_lower", "CI_upper", "n"]
        description: "Trajectory plot source data (~24 rows = 4 timepoints x 3 domains x 2 models)"

    parameters:
      aggregation: "mean"
      ci_level: 0.95
      groupby_keys: ["TSVR_hours", "domain"]
      model_identifier:
        IRT: "IRT"
        CTT: "CTT"

    description: "Aggregate observed means per timepoint x domain x model, compute 95% CIs, stack IRT and CTT datasets for trajectory comparison plot with overlaid lines (Option B architecture)"
    source_reference: "Standard pandas operations (stdlib)"

validation_tools:
  validate_data_format:
    module: "tools.validation"
    function: "validate_data_format"
    signature: "validate_data_format(df: DataFrame, required_cols: List[str]) -> Dict[str, Any]"

    input_files:
      - path: "data/step01_ctt_scores.csv"
        required_columns: ["composite_ID", "UID", "test", "domain", "CTT_score", "n_items"]
        source: "compute_ctt_scores output"

    parameters:
      required_columns: ["composite_ID", "UID", "test", "domain", "CTT_score", "n_items"]
      expected_row_count: 1200
      expected_domains: ["What", "Where", "When"]

    criteria:
      - "Exactly 1200 rows (400 UID x test x 3 domains)"
      - "All required columns present (6 columns)"
      - "All 3 domains present (What, Where, When)"
      - "CTT_score in [0, 1] (proportion correct)"
      - "n_items > 0 (at least 1 item per domain)"

    expected_output:
      format: "Dict[str, Any]"
      fields:
        valid: "bool (True if all checks passed)"
        message: "str (human-readable explanation)"
        missing_cols: "List[str] (empty if valid)"

    behavior_on_failure:
      action: "raise ValueError"
      log_to: "logs/step01_compute_ctt.log"
      invoke: "g_debug (master invokes after error)"

    description: "Validate CTT score computation output has correct structure, row count, and value ranges"
    source_reference: "tools_inventory.md section 'Module: tools.validation' - validate_data_format"

  validate_correlation_test_d068:
    module: "tools.validation"
    function: "validate_correlation_test_d068"
    signature: "validate_correlation_test_d068(correlation_df: DataFrame, required_cols: List[str] = None) -> Dict[str, Any]"

    input_files:
      - path: "results/step02_correlations.csv"
        required_columns: ["domain", "r", "CI_lower", "CI_upper", "p_uncorrected", "p_holm"]
        source: "compute_correlations_holm_bonferroni output"

    parameters:
      required_cols: ["p_uncorrected", "p_holm"]
      alpha: 0.05
      expected_rows: 4

    criteria:
      - "BOTH p_uncorrected AND p_holm columns present (Decision D068 dual p-value reporting)"
      - "r values in [-1, 1] (correlation coefficient bounds)"
      - "CI_lower < r < CI_upper (confidence interval brackets point estimate)"
      - "p_holm >= p_uncorrected (correction cannot make p-value smaller)"
      - "Exactly 4 rows (What, Where, When, Overall)"

    expected_output:
      format: "Dict[str, Any]"
      fields:
        valid: "bool"
        d068_compliant: "bool"
        missing_cols: "List[str]"
        message: "str"

    behavior_on_failure:
      action: "raise ValueError"
      log_to: "logs/step02_correlations.log"
      invoke: "g_debug (master invokes after error)"

    description: "Validate correlation results include Decision D068 dual p-value reporting (uncorrected + Holm-Bonferroni correction)"
    source_reference: "tools_inventory.md section 'Module: tools.validation' - validate_correlation_test_d068"

  validate_lmm_convergence:
    module: "tools.validation"
    function: "validate_lmm_convergence"
    signature: "validate_lmm_convergence(lmm_result: MixedLMResults) -> Dict[str, Any]"

    input_files:
      - path: "results/step03_irt_lmm_summary.txt"
        source: "fit_parallel_lmms IRT model output"

      - path: "results/step03_ctt_lmm_summary.txt"
        source: "fit_parallel_lmms CTT model output"

    parameters:
      check_singularity: true
      min_observations: 100

    criteria:
      - "Model converged (no convergence warnings)"
      - "No singular fit (random effects variance > 0)"
      - "Minimum 100 observations used"
      - "All fixed effects have finite estimates (no NaN/Inf)"
      - "BOTH models converged OR BOTH simplified to same random structure (parallelism requirement)"

    expected_output:
      format: "Dict[str, Any]"
      fields:
        valid: "bool"
        message: "str"
        convergence_status: "str"
        warnings: "List[str]"

    behavior_on_failure:
      action: "raise ValueError"
      log_to: "logs/step03_fit_lmm.log"
      invoke: "g_debug (master invokes after error)"

    description: "Validate LMM convergence for both IRT and CTT models, enforce identical random structure requirement"
    source_reference: "tools_inventory.md section 'Module: tools.validation' - validate_lmm_convergence"

  check_file_exists:
    module: "tools.validation"
    function: "check_file_exists"
    signature: "check_file_exists(file_path: Union[str, Path], min_size_bytes: int = 0) -> Dict[str, Any]"

    input_files: []

    parameters:
      files_to_check:
        - path: "results/step04_irt_assumptions_report.txt"
          min_size_bytes: 500
        - path: "results/step04_ctt_assumptions_report.txt"
          min_size_bytes: 500
        - path: "plots/step04_irt_diagnostics.png"
          min_size_bytes: 10000
        - path: "plots/step04_ctt_diagnostics.png"
          min_size_bytes: 10000
        - path: "results/step04_assumptions_comparison.csv"
          min_size_bytes: 100

    criteria:
      - "All 5 output files exist (2 text reports, 2 PNG plots, 1 comparison CSV)"
      - "Text reports > 500 characters (comprehensive diagnostics)"
      - "PNG files > 10KB (not empty/corrupted)"
      - "CSV file > 100 bytes (valid table)"

    expected_output:
      format: "Dict[str, Any]"
      fields:
        valid: "bool"
        file_path: "str"
        size_bytes: "int"
        message: "str"

    behavior_on_failure:
      action: "raise FileNotFoundError"
      log_to: "logs/step04_validate_assumptions.log"
      invoke: "g_debug (master invokes after error)"

    description: "Validate all assumption diagnostic outputs were created successfully with non-trivial content"
    source_reference: "tools_inventory.md section 'Module: tools.validation' - check_file_exists"

  validate_dataframe_structure:
    module: "tools.validation"
    function: "validate_dataframe_structure"
    signature: "validate_dataframe_structure(df: DataFrame, expected_rows: Union[int, Tuple[int, int]], expected_columns: List[str], column_types: Optional[Dict[str, type]] = None) -> Dict[str, Any]"

    input_files:
      - path: "results/step05_coefficient_comparison.csv"
        required_columns: ["term", "estimate_irt", "SE_irt", "p_irt", "sig_irt", "estimate_ctt", "SE_ctt", "p_ctt", "sig_ctt", "agreement", "beta_ratio", "discrepancy_flag"]
        source: "compare_coefficients_cohens_kappa output"

      - path: "results/step05_agreement_metrics.csv"
        required_columns: ["metric", "value", "threshold", "pass"]
        source: "compare_coefficients_cohens_kappa output"

      - path: "results/step06_model_fit_comparison.csv"
        required_columns: ["model", "AIC", "BIC", "delta_AIC", "delta_BIC", "interpretation"]
        source: "compare_model_fit_aic_bic output"

    parameters:
      coefficient_comparison:
        expected_rows: [8, 12]
        expected_columns: 12
      agreement_metrics:
        expected_rows: 3
        expected_columns: 4
      model_fit_comparison:
        expected_rows: 2
        expected_columns: 6

    criteria:
      - "Row counts in expected ranges (~10 coefficients, 3 metrics, 2 models)"
      - "All required columns present (no missing columns)"
      - "No NaN in p-values or estimates (all coefficients computed)"
      - "Cohen's kappa in [-1, 1] range"
      - "AIC/BIC > 0 (information criteria valid)"

    expected_output:
      format: "Dict[str, Any]"
      fields:
        valid: "bool"
        message: "str"
        checks: "Dict[str, bool]"

    behavior_on_failure:
      action: "raise ValueError"
      log_to: "logs/step05_compare_coefficients.log or logs/step06_compare_fit.log"
      invoke: "g_debug (master invokes after error)"

    description: "Validate DataFrame structure (rows, columns, types) for coefficient comparison, agreement metrics, and model fit comparison outputs"
    source_reference: "tools_inventory.md section 'Module: tools.validation' - validate_dataframe_structure"

  validate_plot_data_completeness:
    module: "tools.validation"
    function: "validate_plot_data_completeness"
    signature: "validate_plot_data_completeness(plot_data: DataFrame, required_domains: List[str], required_groups: List[str], domain_col: str = 'domain', group_col: str = 'group') -> Dict[str, Any]"

    input_files:
      - path: "plots/step07_scatterplot_data.csv"
        required_columns: ["composite_ID", "domain", "IRT_score", "CTT_score", "r"]
        source: "prepare_plot_data_scatterplot output"

      - path: "plots/step08_trajectory_data.csv"
        required_columns: ["TSVR_hours", "domain", "model", "mean_score", "CI_lower", "CI_upper", "n"]
        source: "prepare_plot_data_trajectory output"

    parameters:
      scatterplot:
        required_domains: ["What", "Where", "When"]
        expected_rows: 1200
        domain_col: "domain"
      trajectory:
        required_domains: ["What", "Where", "When"]
        required_models: ["IRT", "CTT"]
        expected_rows: [20, 30]
        domain_col: "domain"
        model_col: "model"

    criteria:
      - "All 3 domains present (What, Where, When)"
      - "For trajectory: both models present (IRT, CTT)"
      - "No missing categories (complete factorial design)"
      - "IRT_score in [-3, 3] (typical IRT ability range)"
      - "CTT_score in [0, 1] (proportion correct)"
      - "CI_lower < mean_score < CI_upper (confidence bounds bracket mean)"

    expected_output:
      format: "Dict[str, Any]"
      fields:
        valid: "bool"
        message: "str"
        missing_domains: "List[str]"
        missing_groups: "List[str]"

    behavior_on_failure:
      action: "raise ValueError"
      log_to: "logs/step07_prepare_scatterplot.log or logs/step08_prepare_trajectory.log"
      invoke: "g_debug (master invokes after error)"

    description: "Verify all domains/models present in plot data for complete visualizations (no missing categories that would create incomplete plots)"
    source_reference: "tools_inventory.md section 'Module: tools.validation' - validate_plot_data_completeness"

summary:
  analysis_tools_count: 9
  validation_tools_count: 7
  total_unique_tools: 16
  mandatory_decisions_embedded: ["D068", "D070"]
  stdlib_tools: ["pandas.DataFrame.groupby", "pandas.DataFrame.merge", "scipy.stats.pearsonr", "statsmodels.regression.mixed_linear_model.MixedLM"]
  custom_tools: ["tools.validation.validate_lmm_assumptions_comprehensive", "tools.validation.validate_correlation_test_d068", "tools.validation.validate_lmm_convergence", "tools.validation.check_file_exists", "tools.validation.validate_data_format", "tools.validation.validate_dataframe_structure", "tools.validation.validate_plot_data_completeness"]
  notes:
    - "Each analysis tool documented ONCE (deduplication across steps)"
    - "rq_analysis will create step sequencing in 4_analysis.yaml"
    - "g_code will use these signatures for pre-generation validation"
    - "All custom validation tools include full signatures with type hints"
    - "Stdlib tools (pandas, scipy, statsmodels) exempt from tools_inventory.md verification per code.md"
    - "Decision D068 enforced via validate_correlation_test_d068 (dual p-value reporting)"
    - "Decision D070 enforced via TSVR_hours time variable in all LMM formulas"

---
# End of 3_tools.yaml
