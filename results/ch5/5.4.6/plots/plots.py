#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Plotting script for RQ 5.4.6 - Schema-Specific Variance Decomposition

GENERATED BY: rq_plots agent (v4.0.0)
DATE: 2025-12-09
PURPOSE: Create publication-ready plots for MODEL-AVERAGED variance decomposition

CRITICAL CONTEXT: MODEL-AVERAGED RANDOM EFFECTS
This RQ was rerun with model averaging after discovering that single Log model
UNDERESTIMATED slope variance by 85-95%. The original analysis showed ICC_slope H 0.000
(spike at zero, suggesting no meaningful variance). Model averaging across 6 competitive
models revealed NON-ZERO slope variance:
  - Common: ICC_slope = 0.148 (LOW-MODERATE trait stability)
  - Congruent: ICC_slope = 0.078 (LOW but meaningful)
  - Incongruent: ICC_slope = 0.036 (VERY LOW)

These plots visualize the model-averaged random effects from:
  - step02_averaged_random_effects.csv (300 rows: 100 UIDs × 3 congruence levels)
  - step02_averaged_iccs.csv (9 ICC estimates)
  - competitive_models.csv (6 models with weights)

PLOTS GENERATED:
1. random_slopes_histogram_common.png - Histogram of model-averaged slopes (Common items)
2. random_slopes_histogram_congruent.png - Histogram of model-averaged slopes (Congruent items)
3. random_slopes_histogram_incongruent.png - Histogram of model-averaged slopes (Incongruent items)
4. random_slopes_qqplot_common.png - Q-Q plot for normality check (Common)
5. random_slopes_qqplot_congruent.png - Q-Q plot for normality check (Congruent)
6. random_slopes_qqplot_incongruent.png - Q-Q plot for normality check (Incongruent)
7. icc_comparison_barplot.png - ICC estimates across congruence levels (intercept + slopes)
8. model_weights_barplot.png - Model weights from model averaging (6 competitive models)
"""

from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from tools.plotting import (
    set_plot_style_defaults,
    plot_histogram_by_group,
    plot_comparison_bars
)

# =============================================================================
# SETUP
# =============================================================================

# Get absolute path to RQ root (plots.py is in results/ch5/5.4.6/plots/)
RQ_ROOT = Path(__file__).parent.parent

# Apply consistent plotting theme from config/plotting.yaml
set_plot_style_defaults()

print("="*70)
print("PLOTTING FOR RQ 5.4.6 - MODEL-AVERAGED VARIANCE DECOMPOSITION")
print("="*70)
print(f"RQ root: {RQ_ROOT}")
print("\nIMPORTANT: These plots use MODEL-AVERAGED random effects from 6 competitive models")
print("            Original Log-only analysis showed ICC_slope H 0.000 (underestimated by 85-95%)")
print("            Model averaging reveals NON-ZERO slope variance (LOW-MODERATE trait stability)")
print()

# =============================================================================
# LOAD DATA
# =============================================================================

print("Loading model-averaged data files...")

# Random effects (model-averaged)
df_random = pd.read_csv(RQ_ROOT / "data" / "step02_averaged_random_effects.csv")
print(f"  Loaded {len(df_random)} rows from step02_averaged_random_effects.csv")
print(f"  Columns: {list(df_random.columns)}")

# ICC estimates (model-averaged)
df_iccs = pd.read_csv(RQ_ROOT / "data" / "step02_averaged_iccs.csv")
print(f"  Loaded {len(df_iccs)} rows from step02_averaged_iccs.csv")
print(f"  Columns: {list(df_iccs.columns)}")

# Competitive models (model comparison table)
df_models = pd.read_csv(RQ_ROOT / "data" / "competitive_models.csv")
print(f"  Loaded {len(df_models)} rows from competitive_models.csv")
print(f"  Columns: {list(df_models.columns)}")

# Rename columns for compatibility with plotting functions
df_random = df_random.rename(columns={
    'intercept_avg': 'Total_Intercept',
    'slope_avg': 'Total_Slope'
})

print("\nData loaded successfully. Beginning plot generation...\n")

# =============================================================================
# PLOT 1-3: RANDOM SLOPES HISTOGRAMS (BY CONGRUENCE)
# =============================================================================

print("="*70)
print("GENERATING PLOTS 1-3: Random Slopes Histograms (By Congruence)")
print("="*70)

congruence_colors = {
    'common': '#2E86AB',      # Blue
    'congruent': '#A23B72',   # Purple
    'incongruent': '#F18F01'  # Orange
}

for cong in ['common', 'congruent', 'incongruent']:
    print(f"\nPlot: random_slopes_histogram_{cong}.png")

    # Subset data
    df_cong = df_random[df_random['congruence'] == cong].copy()
    n = len(df_cong)

    # Get ICC_slope for this congruence level
    icc_slope = df_iccs[df_iccs['congruence'] == cong]['ICC_slope_simple'].values[0]

    # Descriptive stats
    mean_slope = df_cong['Total_Slope'].mean()
    sd_slope = df_cong['Total_Slope'].std()

    print(f"  Congruence: {cong}")
    print(f"  N participants: {n}")
    print(f"  ICC_slope_simple: {icc_slope:.4f}")
    print(f"  Mean slope: {mean_slope:.4f}")
    print(f"  SD slope: {sd_slope:.4f}")

    # Create figure
    fig, ax = plt.subplots(figsize=(10, 6))

    # Histogram
    ax.hist(df_cong['Total_Slope'], bins=20, alpha=0.7,
            color=congruence_colors[cong], edgecolor='black', linewidth=1.2)

    # Overlay normal distribution curve
    x = np.linspace(df_cong['Total_Slope'].min(), df_cong['Total_Slope'].max(), 100)
    normal_curve = stats.norm.pdf(x, mean_slope, sd_slope)
    # Scale to histogram height
    ax_right = ax.twinx()
    ax_right.plot(x, normal_curve, 'k--', linewidth=2, label='Normal distribution')
    ax_right.set_ylabel('Probability Density', fontweight='bold')
    ax_right.legend(loc='upper right')

    # Vertical line at mean
    ax.axvline(x=mean_slope, color='red', linestyle='--', linewidth=2,
               label=f'Mean = {mean_slope:.3f}')

    # Vertical line at zero
    ax.axvline(x=0, color='black', linestyle='-', linewidth=1, alpha=0.5)

    # Formatting
    ax.set_xlabel('Random Slope (Model-Averaged)', fontweight='bold')
    ax.set_ylabel('Frequency', fontweight='bold')
    ax.set_title(f'Random Slopes Distribution - {cong.capitalize()}\n'
                 f'ICC_slope = {icc_slope:.3f}, N = {n}',
                 fontweight='bold', pad=15)
    ax.legend(loc='upper left')
    ax.grid(True, alpha=0.3)

    plt.tight_layout()

    # Save
    output_path = RQ_ROOT / "plots" / f"random_slopes_histogram_{cong}.png"
    fig.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"   Saved: plots/random_slopes_histogram_{cong}.png")

    plt.close(fig)

# =============================================================================
# PLOT 4-6: RANDOM SLOPES Q-Q PLOTS (BY CONGRUENCE)
# =============================================================================

print("\n" + "="*70)
print("GENERATING PLOTS 4-6: Random Slopes Q-Q Plots (By Congruence)")
print("="*70)

for cong in ['common', 'congruent', 'incongruent']:
    print(f"\nPlot: random_slopes_qqplot_{cong}.png")

    # Subset data
    df_cong = df_random[df_random['congruence'] == cong].copy()

    # Create figure
    fig, ax = plt.subplots(figsize=(8, 8))

    # Q-Q plot
    stats.probplot(df_cong['Total_Slope'], dist="norm", plot=ax)

    # Formatting
    ax.set_title(f'Q-Q Plot: Random Slopes - {cong.capitalize()}',
                 fontweight='bold', pad=15)
    ax.set_xlabel('Theoretical Quantiles (Normal)', fontweight='bold')
    ax.set_ylabel('Sample Quantiles (Random Slopes)', fontweight='bold')
    ax.grid(True, alpha=0.3)

    # Add text with Shapiro-Wilk test
    shapiro_stat, shapiro_p = stats.shapiro(df_cong['Total_Slope'])
    textstr = f'Shapiro-Wilk Test:\nW = {shapiro_stat:.4f}\np = {shapiro_p:.4f}'
    ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,
            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout()

    # Save
    output_path = RQ_ROOT / "plots" / f"random_slopes_qqplot_{cong}.png"
    fig.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"   Saved: plots/random_slopes_qqplot_{cong}.png")
    print(f"  Shapiro-Wilk: W={shapiro_stat:.4f}, p={shapiro_p:.4f}")

    plt.close(fig)

# =============================================================================
# PLOT 7: ICC COMPARISON BARPLOT (ACROSS CONGRUENCE LEVELS)
# =============================================================================

print("\n" + "="*70)
print("GENERATING PLOT 7: ICC Comparison Barplot")
print("="*70)

# Reshape ICC data to long format for plotting
df_iccs_long = df_iccs.melt(id_vars='congruence',
                              value_vars=['ICC_intercept', 'ICC_slope_simple', 'ICC_slope_conditional'],
                              var_name='ICC_type', value_name='ICC_value')

# Clean up ICC type names for legend
df_iccs_long['ICC_type'] = df_iccs_long['ICC_type'].replace({
    'ICC_intercept': 'Intercept',
    'ICC_slope_simple': 'Slope (Simple)',
    'ICC_slope_conditional': 'Slope (Conditional)'
})

# Create figure
fig, ax = plt.subplots(figsize=(12, 7))

# Grouped bar plot
congruence_levels = ['common', 'congruent', 'incongruent']
icc_types = ['Intercept', 'Slope (Simple)', 'Slope (Conditional)']
x = np.arange(len(congruence_levels))
width = 0.25

for i, icc_type in enumerate(icc_types):
    df_subset = df_iccs_long[df_iccs_long['ICC_type'] == icc_type]
    values = [df_subset[df_subset['congruence'] == c]['ICC_value'].values[0]
              for c in congruence_levels]

    offset = (i - 1) * width
    ax.bar(x + offset, values, width, label=icc_type, alpha=0.8)

# Horizontal reference lines
ax.axhline(y=0.20, color='gray', linestyle='--', linewidth=1, alpha=0.5)
ax.text(len(congruence_levels) - 0.5, 0.21, 'Moderate threshold (0.20)',
        fontsize=9, style='italic', ha='right')

ax.axhline(y=0.40, color='gray', linestyle='--', linewidth=1, alpha=0.5)
ax.text(len(congruence_levels) - 0.5, 0.41, 'Substantial threshold (0.40)',
        fontsize=9, style='italic', ha='right')

# Formatting
ax.set_xlabel('Congruence Level', fontweight='bold')
ax.set_ylabel('ICC Value', fontweight='bold')
ax.set_title('ICC Estimates by Congruence Level (Model-Averaged)\n'
             'Reveals NON-ZERO Slope Variance (vs Log-only spike at zero)',
             fontweight='bold', pad=15)
ax.set_xticks(x)
ax.set_xticklabels([c.capitalize() for c in congruence_levels])
ax.set_ylim(0, 1.0)
ax.legend(loc='upper right', framealpha=0.9)
ax.grid(True, alpha=0.3, axis='y')

plt.tight_layout()

# Save
output_path = RQ_ROOT / "plots" / "icc_comparison_barplot.png"
fig.savefig(output_path, dpi=300, bbox_inches='tight')
print(f"\n Saved: plots/icc_comparison_barplot.png")
print("\nICC Summary:")
for cong in congruence_levels:
    row = df_iccs[df_iccs['congruence'] == cong].iloc[0]
    print(f"  {cong.capitalize()}:")
    print(f"    ICC_intercept:          {row['ICC_intercept']:.4f}")
    print(f"    ICC_slope_simple:       {row['ICC_slope_simple']:.4f}")
    print(f"    ICC_slope_conditional:  {row['ICC_slope_conditional']:.4f}")

plt.close(fig)

# =============================================================================
# PLOT 8: MODEL WEIGHTS BARPLOT (MODEL AVERAGING TRANSPARENCY)
# =============================================================================

print("\n" + "="*70)
print("GENERATING PLOT 8: Model Weights Barplot")
print("="*70)

# Create figure
fig, ax = plt.subplots(figsize=(10, 6))

# Sort by weight descending
df_models_sorted = df_models.sort_values('weight_renorm', ascending=False)

# Bar plot
colors = plt.cm.viridis(np.linspace(0, 1, len(df_models_sorted)))
bars = ax.bar(range(len(df_models_sorted)), df_models_sorted['weight_renorm'],
              color=colors, edgecolor='black', linewidth=1.2)

# Formatting
ax.set_xlabel('Model', fontweight='bold')
ax.set_ylabel('Model Weight (Renormalized)', fontweight='bold')
ax.set_title('Model Weights from Model Averaging (6 Competitive Models)\n'
             'PowerLaw_01 = 18.7%, Log/Log10/Log2 = 17.9% each, PowerLaw_02 = 15.5%, SquareRoot = 12.2%',
             fontweight='bold', pad=15)
ax.set_xticks(range(len(df_models_sorted)))
ax.set_xticklabels(df_models_sorted['model_name'], rotation=45, ha='right')
ax.set_ylim(0, max(df_models_sorted['weight_renorm']) * 1.1)
ax.grid(True, alpha=0.3, axis='y')

# Add value labels on bars
for i, (idx, row) in enumerate(df_models_sorted.iterrows()):
    height = row['weight_renorm']
    ax.text(i, height + 0.005, f'{height:.3f}',
            ha='center', va='bottom', fontsize=9)

plt.tight_layout()

# Save
output_path = RQ_ROOT / "plots" / "model_weights_barplot.png"
fig.savefig(output_path, dpi=300, bbox_inches='tight')
print(f"\n Saved: plots/model_weights_barplot.png")
print("\nModel Weights:")
for idx, row in df_models_sorted.iterrows():
    print(f"  {row['model_name']}: {row['weight_renorm']:.4f} ({row['weight_renorm']*100:.1f}%)")

plt.close(fig)

# =============================================================================
# SUMMARY
# =============================================================================

print("\n" + "="*70)
print("PLOTTING COMPLETE")
print("="*70)
print(f"Total plots generated: 8")
print(f"  - 3 random slopes histograms (by congruence)")
print(f"  - 3 random slopes Q-Q plots (by congruence)")
print(f"  - 1 ICC comparison barplot (3 congruence × 3 ICC types)")
print(f"  - 1 model weights barplot (6 competitive models)")
print()
print("KEY FINDING VISUALIZED:")
print("  Model averaging reveals NON-ZERO slope variance (ICC_slope = 0.036-0.148)")
print("  This contrasts with Log-only analysis showing ICC_slope H 0.000 (spike at zero)")
print("  Log model UNDERESTIMATED slope variance by 85-95%")
print()
print("All plots saved with 300 DPI publication quality.")
print("="*70)
