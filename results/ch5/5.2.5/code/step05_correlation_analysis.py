#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step05
Step Name: Correlation Analysis with Steiger's z-test
RQ: ch5/5.2.5
Generated: 2025-11-30

PURPOSE:
Test primary hypothesis that purified CTT correlates more strongly with IRT
theta than full CTT using Steiger's z-test for dependent correlations. This
addresses whether IRT purification improves CTT-IRT convergence by removing
poor-quality items.

EXPECTED INPUTS:
- data/step00_theta_scores.csv
  Columns: ['composite_ID', 'theta_what', 'theta_where', 'theta_when']
  Format: IRT theta scores from RQ 5.1 Step 3 (Pass 2 calibration)
  Expected rows: ~400 (100 participants x 4 tests)

- data/step02_ctt_full_scores.csv
  Columns: ['composite_ID', 'UID', 'TEST', 'CTT_full_what', 'CTT_full_where', 'CTT_full_when']
  Format: Full CTT scores (all items) from Step 2
  Expected rows: ~400

- data/step03_ctt_purified_scores.csv
  Columns: ['composite_ID', 'UID', 'TEST', 'CTT_purified_what', 'CTT_purified_where', 'CTT_purified_when']
  Format: Purified CTT scores (retained items only) from Step 3
  Expected rows: ~400

EXPECTED OUTPUTS:
- data/step05_correlation_analysis.csv
  Columns: ['domain', 'r_full_irt', 'r_purified_irt', 'r_full_purified', 'delta_r', 'steiger_z', 'p_uncorrected', 'p_bonferroni', 'interpretation']
  Format: Steiger's z-test results comparing Full CTT-IRT vs Purified CTT-IRT correlations
  Expected rows: 3 (one per domain: what, where, when)

VALIDATION CRITERIA:
- Decision D068 dual p-value reporting: BOTH p_uncorrected and p_bonferroni present
- All p-values in [0, 1] range
- All correlations in [-1, 1] range
- Bonferroni correction factor = 3 (3 domains tested)

g_code REASONING:
- Approach: Compute 3 pairwise correlations per domain (Full CTT-IRT, Purified CTT-IRT,
  Full CTT-Purified CTT), then apply Steiger's (1980) z-test to test if r(Purified,IRT)
  differs significantly from r(Full,IRT). These are DEPENDENT correlations because all
  three variables (Full CTT, Purified CTT, IRT theta) come from the same participants.

- Why this approach: Steiger's z-test is the correct statistical method for comparing
  two correlations that share a common variable (IRT theta). Standard independent
  correlations test (Fisher's z) would be incorrect here because it assumes the two
  correlations come from different samples.

- Data flow: Merge theta, full CTT, and purified CTT on composite_ID -> Loop through
  3 domains (what, where, when) -> For each domain: compute 3 correlations -> Apply
  Steiger's test -> Apply Bonferroni correction -> Interpret results -> Save table.

- Expected performance: ~5 seconds (correlation computation + Steiger's test x 3 domains)

IMPLEMENTATION NOTES:
- Analysis tool: compare_correlations_dependent from tools.analysis_ctt
- Validation tool: validate_correlation_test_d068 from tools.validation
- Parameters: r12 = r(Full,IRT), r13 = r(Full,Purified), r23 = r(Purified,IRT), n = 400
- Steiger's test uses Fisher's z-transformation and asymptotic covariance formula
- Bonferroni correction: multiply p-value by 3 (number of domains), cap at 1.0
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = chX/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_ctt import compare_correlations_dependent

# Import validation tool
from tools.validation import validate_correlation_test_d068

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.2.5 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step05_correlation_analysis.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_correlation_analysis.csv
#   CORRECT: logs/step05_correlation_analysis.log
#   WRONG:   results/correlation_analysis.csv  (wrong folder + no prefix)
#   WRONG:   data/correlation_analysis.csv     (missing step prefix)
#   WRONG:   logs/step05_correlation_results.csv  (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 5: Correlation Analysis with Steiger's z-test")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: 3 DataFrames with ~400 rows each (100 participants x 4 tests)
        # Purpose: Merge all measurement approaches to compute pairwise correlations

        log("[LOAD] Loading input data...")

        # Load IRT theta scores from RQ 5.1
        df_theta = pd.read_csv(RQ_DIR / "data" / "step00_theta_scores.csv")
        log(f"[LOADED] step00_theta_scores.csv ({len(df_theta)} rows, {len(df_theta.columns)} cols)")

        # Load Full CTT scores from Step 2
        df_ctt_full = pd.read_csv(RQ_DIR / "data" / "step02_ctt_full_scores.csv")
        log(f"[LOADED] step02_ctt_full_scores.csv ({len(df_ctt_full)} rows, {len(df_ctt_full.columns)} cols)")

        # Load Purified CTT scores from Step 3
        df_ctt_purified = pd.read_csv(RQ_DIR / "data" / "step03_ctt_purified_scores.csv")
        log(f"[LOADED] step03_ctt_purified_scores.csv ({len(df_ctt_purified)} rows, {len(df_ctt_purified.columns)} cols)")

        # =========================================================================
        # STEP 2: Merge Data Sources on composite_ID
        # =========================================================================
        # Merge all three measurement approaches into single DataFrame
        # Expected: ~400 rows with columns for IRT theta, full CTT, and purified CTT per domain

        log("[MERGE] Merging theta, full CTT, and purified CTT on composite_ID...")

        # Merge theta + full CTT
        df_merged = df_theta.merge(
            df_ctt_full[['composite_ID', 'CTT_full_what', 'CTT_full_where', 'CTT_full_when']],
            on='composite_ID',
            how='inner'
        )

        # Merge + purified CTT
        df_merged = df_merged.merge(
            df_ctt_purified[['composite_ID', 'CTT_purified_what', 'CTT_purified_where', 'CTT_purified_when']],
            on='composite_ID',
            how='inner'
        )

        log(f"[MERGED] Combined dataset: {len(df_merged)} rows, {len(df_merged.columns)} cols")

        # Check for missing data
        n_missing = df_merged.isnull().sum().sum()
        if n_missing > 0:
            log(f"[WARNING] {n_missing} missing values detected in merged data")
            log("[INFO] Missing data by column:")
            for col in df_merged.columns:
                n_col_missing = df_merged[col].isnull().sum()
                if n_col_missing > 0:
                    log(f"  {col}: {n_col_missing} missing")

        # =========================================================================
        # STEP 3: Run Correlation Analysis with Steiger's z-test
        # =========================================================================
        # Tool: compare_correlations_dependent
        # What it does: Tests if two dependent correlations differ significantly
        # Expected output: Steiger's z-statistic with p_uncorrected and p_bonferroni

        log("[ANALYSIS] Running Steiger's z-test for each domain...")

        # Define domains to analyze
        domains = ['what', 'where', 'when']

        # Initialize results list
        results = []

        # Sample size for correlation tests
        n = len(df_merged)
        log(f"[INFO] Sample size for correlations: n = {n}")

        # Loop through domains
        for domain in domains:
            log(f"[DOMAIN] Processing domain: {domain}")

            # Extract domain-specific columns
            # Variable 1: Full CTT
            full_ctt = df_merged[f'CTT_full_{domain}'].values

            # Variable 2: IRT theta
            irt_theta = df_merged[f'theta_{domain}'].values

            # Variable 3: Purified CTT
            purified_ctt = df_merged[f'CTT_purified_{domain}'].values

            # Remove rows with any NaN in this domain's trio
            mask = ~(np.isnan(full_ctt) | np.isnan(irt_theta) | np.isnan(purified_ctt))
            full_ctt_clean = full_ctt[mask]
            irt_theta_clean = irt_theta[mask]
            purified_ctt_clean = purified_ctt[mask]

            n_valid = len(full_ctt_clean)
            log(f"  Valid observations after removing NaN: {n_valid}")

            # Compute 3 pairwise correlations
            # r12: Full CTT <-> IRT theta
            r12 = np.corrcoef(full_ctt_clean, irt_theta_clean)[0, 1]

            # r13: Full CTT <-> Purified CTT
            r13 = np.corrcoef(full_ctt_clean, purified_ctt_clean)[0, 1]

            # r23: Purified CTT <-> IRT theta
            r23 = np.corrcoef(purified_ctt_clean, irt_theta_clean)[0, 1]

            log(f"  Correlations:")
            log(f"    r(Full CTT, IRT) = {r12:.3f}")
            log(f"    r(Full CTT, Purified CTT) = {r13:.3f}")
            log(f"    r(Purified CTT, IRT) = {r23:.3f}")

            # Apply Steiger's z-test
            # Tests H0: r12 = r23 (Full CTT-IRT vs Purified CTT-IRT)
            steiger_result = compare_correlations_dependent(
                r12=r12,  # Full CTT <-> IRT theta
                r13=r13,  # Full CTT <-> Purified CTT
                r23=r23,  # Purified CTT <-> IRT theta
                n=n_valid
            )

            log(f"  Steiger's z = {steiger_result['z_statistic']:.3f}")
            log(f"  p (uncorrected) = {steiger_result['p_value']:.4f}")

            # Compute delta_r = r23 - r12 (improvement from purification)
            delta_r = r23 - r12
            log(f"  Delta r (Purified - Full) = {delta_r:.3f}")

            # Bonferroni correction (3 domains tested)
            p_bonferroni = min(steiger_result['p_value'] * 3, 1.0)
            log(f"  p (Bonferroni) = {p_bonferroni:.4f}")

            # Interpretation
            if p_bonferroni < 0.05:
                if delta_r > 0:
                    interpretation = "Purified CTT significantly higher correlation with IRT (Bonferroni p < 0.05)"
                else:
                    interpretation = "Full CTT significantly higher correlation with IRT (Bonferroni p < 0.05)"
            else:
                interpretation = "No significant difference between Full and Purified CTT correlations with IRT"

            log(f"  Interpretation: {interpretation}")

            # Append result
            results.append({
                'domain': domain,
                'r_full_irt': r12,
                'r_purified_irt': r23,
                'r_full_purified': r13,
                'delta_r': delta_r,
                'steiger_z': steiger_result['z_statistic'],
                'p_uncorrected': steiger_result['p_value'],
                'p_bonferroni': p_bonferroni,
                'interpretation': interpretation
            })

        log("[DONE] Steiger's z-test complete for all domains")

        # =========================================================================
        # STEP 4: Save Analysis Outputs
        # =========================================================================
        # Output: CSV with Steiger's z-test results per domain
        # Contains: Correlations, z-statistic, dual p-values, interpretation

        log("[SAVE] Saving correlation analysis results...")

        # Create DataFrame from results
        df_correlations = pd.DataFrame(results)

        # Save to CSV
        output_path = RQ_DIR / "data" / "step05_correlation_analysis.csv"
        df_correlations.to_csv(output_path, index=False, encoding='utf-8')
        log(f"[SAVED] step05_correlation_analysis.csv ({len(df_correlations)} rows, {len(df_correlations.columns)} cols)")

        # Log summary statistics
        log("[SUMMARY] Correlation analysis results:")
        log(f"  Domains analyzed: {len(df_correlations)}")
        log(f"  Mean r(Full CTT, IRT): {df_correlations['r_full_irt'].mean():.3f}")
        log(f"  Mean r(Purified CTT, IRT): {df_correlations['r_purified_irt'].mean():.3f}")
        log(f"  Mean delta_r: {df_correlations['delta_r'].mean():.3f}")
        log(f"  Significant differences (Bonferroni p < 0.05): {(df_correlations['p_bonferroni'] < 0.05).sum()}")

        # =========================================================================
        # STEP 5: Run Validation Tool
        # =========================================================================
        # Tool: validate_correlation_test_d068
        # Validates: Decision D068 dual p-value reporting (uncorrected + Bonferroni)
        # Checks: Required columns present, p-values in [0,1], correlations in [-1,1]

        log("[VALIDATION] Running validate_correlation_test_d068...")

        # Required columns per Decision D068
        required_cols = [
            'domain',
            'r_full_irt',
            'r_purified_irt',
            'steiger_z',
            'p_uncorrected',
            'p_bonferroni'
        ]

        validation_result = validate_correlation_test_d068(
            correlation_df=df_correlations,
            required_cols=required_cols
        )

        # Report validation results
        if validation_result['valid']:
            log(f"[VALIDATION] PASSED - {validation_result['message']}")
        else:
            log(f"[VALIDATION] FAILED - {validation_result['message']}")
            if validation_result.get('missing_cols'):
                log(f"  Missing columns: {validation_result['missing_cols']}")
            raise ValueError(f"Validation failed: {validation_result['message']}")

        # Additional range checks
        log("[VALIDATION] Checking value ranges...")

        # Check correlations in [-1, 1]
        for col in ['r_full_irt', 'r_purified_irt', 'r_full_purified']:
            if not df_correlations[col].between(-1, 1).all():
                raise ValueError(f"Column {col} has values outside [-1, 1] range")
        log("  [PASS] All correlations in [-1, 1] range")

        # Check p-values in [0, 1]
        for col in ['p_uncorrected', 'p_bonferroni']:
            if not df_correlations[col].between(0, 1).all():
                raise ValueError(f"Column {col} has values outside [0, 1] range")
        log("  [PASS] All p-values in [0, 1] range")

        # Check D068 compliance
        if validation_result.get('d068_compliant'):
            log("  [PASS] Decision D068 compliant (dual p-value reporting)")
        else:
            raise ValueError("Decision D068 violation - missing dual p-values")

        log("[SUCCESS] Step 5 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
