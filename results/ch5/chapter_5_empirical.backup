# Chapter 5: Empirical Results

## 5.0 Introduction

[TBD: 300-500 words]

---

## 5.1 Functional Form and Individual Differences in Forgetting Trajectories

Understanding the mathematical form of forgetting trajectories is fundamental to memory theory because different functional forms imply different underlying mechanisms. Ebbinghaus (1885) proposed logarithmic forgetting—rapid initial decline followed by a gradually slowing rate—suggesting that forgetting is proportional to the logarithm of time elapsed. In contrast, Wixted and Ebbesen (1991) argued for power-law forgetting, where forgetting rate decreases proportionally with elapsed time, consistent with temporal distinctiveness and scale-invariant memory processes. Alternative forms such as linear decay (simple trace degradation) or quadratic functions (two-phase consolidation) have also been proposed.

Beyond characterizing the average trajectory, it is equally important to understand individual differences. Do all participants forget at the same rate, or do forgetting trajectories vary systematically with factors like age, cognitive ability, or memory quality? Random slope analyses quantify this heterogeneity by testing whether forgetting rates vary across individuals.

This section examines these questions using model comparison methods (§4.3.2) and variance decomposition via random effects (§4.3.1). The overarching goal is to establish the functional form of VR episodic forgetting and determine the extent of individual variability in forgetting trajectories.

---

### 5.1.1 Functional Form of Forgetting Trajectories

**Research Question:** Which functional form best describes episodic forgetting trajectories across a 6-day retention interval?

**Hypothesis:** Logarithmic model, consistent with Ebbinghaus (1885).

**Analysis:** (§4.2.1, §4.2.2, §4.3.1, §4.3.2)
Sample: N=100 participants, 400 observations (4 test sessions per participant)
IRT: Two-pass GRM with omnibus factor "All". Pass 1 calibrated 105 items; item purification excluded 37 items (discrimination a < 0.4 or difficulty |b| > 3.0), retaining 68 items (64.8%) for Pass 2 calibration. Theta range: [-2.52, 2.73].
LMM: Extended model comparison of 66 candidate models using continuous time variable (TSVR_hours, range 1-246 hours) with random intercepts by participant. Models compared via AIC (REML=False). Best model weight < 0.30 triggered model averaging across 16 competitive models (ΔAIC < 2).

**Results:**

Observed memory decline followed a characteristic forgetting pattern with rapid early loss. Theta scores dropped 1.18 SD over 6 days: from θ = 0.67 (Day 0) to θ = -0.51 (Day 6), with the steepest decline occurring in the first 24 hours (Δθ = -0.55 SD). On the probability scale (Decision D069), performance fell from 76% correct initially to 30% correct by Day 6—a 46 percentage point decline approaching near-chance performance for three-option items.

Extended model comparison (66 models) revealed extreme model selection uncertainty. The single best-fitting model, PowerLaw_04 (α = 0.4, AIC = 866.61), captured only 5.6% of the Akaike weight, indicating a 94% probability that some other model in the candidate set was superior. Power-law models dominated the top rankings: the five highest-ranked models were all power-law variants (α = 0.2 to 0.7), collectively accounting for 24% of model support. Notably, the logarithmic model—originally hypothesized as best—ranked 33rd with AIC = 869.71 (ΔAIC = +3.10, weight = 1.2%). This represents an evidence ratio of 4.7:1 against the logarithmic form in favor of the best power-law model.

Given this high model selection uncertainty, model averaging was applied across the 16 competitive models (ΔAIC < 2), which collectively accounted for 57.1% of the model weight. The effective model diversity was Shannon H' = 2.71, equivalent to 15 equally plausible models. Model-averaged predictions yielded an effective power-law exponent of α_eff = 0.410, with prediction standard errors ranging from 0.001 to 0.046 (between-model variance).

These findings contradict the original hypothesis. Rather than logarithmic forgetting (Ebbinghaus, 1885), VR episodic memories followed power-law decay (Wixted & Ebbesen, 1991). The effective exponent α_eff = 0.410 is intermediate within the typical range reported for laboratory memory tasks (α = 0.2-0.8), suggesting that immersive VR episodes occupy a middle ground between highly distinctive autobiographical events (shallow decay, α ≈ 0.2) and impoverished word lists (steep decay, α ≈ 0.6-0.8). The power-law form implies that forgetting rate decreases proportionally with elapsed time—consistent with temporal distinctiveness theory (Brown, Neath, & Chater, 2007), where recent events are compressed in memory and thus less discriminable than remote events.

The paradigm shift from logarithmic to power-law forgetting occurred for three methodological reasons. First, the original analysis used a discrete Days variable (4 unique values) that could not stably estimate fractional exponents; the extended analysis used continuous TSVR_hours (295 unique values), providing sufficient resolution for power-law estimation. Second, the original analysis tested only 5 models and omitted power-law variants entirely despite citing Wixted and Ebbesen (1991) in the hypothesis; the extended analysis tested 66 models including 12 power-law specifications. Third, the original analysis selected a single best model (logarithmic, 48% weight), ignoring 52% probability that another model was better; the extended analysis applied model averaging, acknowledging extreme uncertainty and providing robust predictions weighted across competitive alternatives.

**Figure 5.1.1a:** [functional_form_theta.png](results/ch5/5.1.1/plots/functional_form_theta.png)
*Forgetting trajectory on theta scale. Gray points show observed means at four test sessions (T1-T4). Model-averaged predictions (line) follow power-law decay with effective exponent α = 0.410. Shaded region represents ±1.96 SE (between-model uncertainty). Rapid decline in first 24 hours, followed by gradual asymptotic approach. [NOTE: Current plot shows original logarithmic model; regeneration with model-averaged predictions pending.]*

**Figure 5.1.1b:** [functional_form_probability.png](results/ch5/5.1.1/plots/functional_form_probability.png)
*Forgetting trajectory on probability scale (Decision D069). Performance declined from 76% correct (Day 0) to 30% correct (Day 6), approaching chance (33% for three-option items). Non-linear pattern consistent with power-law decay on latent theta scale. [NOTE: Regeneration with model-averaged predictions pending.]*

---

### 5.1.2 Two-Phase Forgetting: Consolidation Window Hypothesis

**Research Question:** Do episodic memory data support a two-phase model with rapid initial decline (Day 0-1) followed by slower decay (Day 1-6)?

**Hypothesis:** Piecewise model with inflection at 48 hours (one night's sleep + consolidation window) will outperform continuous models, consistent with two-phase consolidation theory (Hardt et al., 2013).

**Analysis:** (§4.2.1, §4.3.1, §4.3.2, §4.3.3, §4.5.1)
Sample: N=100, 400 observations (inherited theta scores from RQ 5.1.1).
LMM: Three-test triangulation strategy: (1) Quadratic model testing Time² significance; (2) Piecewise model (inflection 48h) vs continuous model AIC comparison; (3) Early (0-48h) vs Late (48-240h) slope ratio extraction. Bonferroni correction: α = 0.05/15 = 0.003 (correcting for 15 Chapter 5 RQs). Random intercepts by participant; random slopes attempted but failed convergence (N=100 insufficient per Bates et al., 2015). Comprehensive assumption validation (§4.3.3) performed.

**Results:**

Three independent tests triangulated evidence for two-phase forgetting. Test 1 (quadratic term significance) yielded a positive and highly significant Time² coefficient (β = 0.000054, SE = 0.00001, z = 5.415, p < 0.001, well below Bonferroni α = 0.003). This positive coefficient indicates significant deceleration in forgetting rate—memory declines rapidly initially, then slows over time, producing concave-up curvature. The effect survived stringent multiple testing correction, suggesting robust evidence for non-linear trajectory form.

Test 2 (model comparison) compared piecewise and continuous models via AIC. The piecewise model (inflection at 48 hours) yielded AIC = 873.31, while the best continuous model from RQ 5.1.1 (logarithmic) yielded AIC = 873.71 (ΔAIC = -0.40). By conventional interpretation (Burnham & Anderson, 2002), |ΔAIC| < 2 indicates equivalent models—neither piecewise nor continuous provides meaningfully superior fit. This result is theoretically ambiguous: deceleration exists (Test 1 confirmed), but data cannot distinguish whether the transition is abrupt (sharp inflection at 48h) or gradual (smooth curve).

Test 3 (slope ratio) provided the strongest evidence for two-phase structure. The piecewise model estimated Early slope (0-48h) as β = -0.432 theta units/day (SE = 0.071, 95% CI [-0.572, -0.292]) and Late slope (48-240h) as β = -0.070 theta units/day (SE = 0.026, 95% CI [-0.121, -0.018]). The slope ratio was 0.161 (95% CI [0.032, 0.291])—Late forgetting proceeded at only 16.1% the rate of Early forgetting, a 6.2-fold difference. The Segment × Time interaction was highly significant (p < 0.000002), far exceeding the Bonferroni threshold and indicating dramatically different forgetting rates across phases. Using a conservative criterion (ratio < 0.5 = Late forgetting less than half Early rate), this result provides strong quantitative support for two-phase forgetting.

A supplementary practice-effects decomposition analysis (Step 7, added 2025-12-09) revealed an important ambiguity in interpreting the two-phase pattern. The practice decomposition model segmented trajectories into Practice phase (T1→T2, first retest) and Forgetting phase (T2→T4, subsequent tests), yielding AIC = 869.86 (ΔAIC = -3.45 relative to original piecewise model, indicating superior fit). Practice phase decline was β = -0.0033 theta units/day (SE = 0.0010, p = 0.001), whereas Forgetting phase decline was β = -0.0190 theta units/day (SE = 0.0031, p < 0.001). The Phase × Time interaction was highly significant (p < 0.000002), with Forgetting phase decline 5.7 times faster than Practice phase decline. This finding suggests that the apparent deceleration in forgetting may partially reflect retrieval practice effects: initial testing (T1→T2) provides retrieval practice that masks genuine forgetting, and the practice benefit saturates after the first retest, allowing "true" forgetting rate to emerge in T2→T4 interval. Current data cannot definitively separate consolidation (biological memory stabilization) from practice saturation (methodological artifact of repeated testing), leaving the mechanism of two-phase forgetting unresolved.

Assumption validation (§4.3.3) revealed marginal violations. Both quadratic and piecewise models passed residual normality (Shapiro-Wilk p = 0.099, 0.111), random effects normality (p = 0.057, 0.056), and outlier detection (<0.5% outliers). However, both models failed homoscedasticity (Breusch-Pagan p = 0.031, 0.049, marginally below 0.05 threshold) and temporal independence (Lag-1 ACF = -0.22, exceeding |0.1| threshold). These violations can inflate Type I error rates; however, primary effects were highly significant (p < 0.001), suggesting conclusions are robust despite assumption violations.

In summary, two-phase forgetting received strong empirical support from two of three triangulation tests (Tests 1 and 3), while Test 2 was inconclusive. The 6.2-fold difference in forgetting rates (0-48h vs 48-240h) is dramatic and highly significant. However, the mechanism remains ambiguous: deceleration may reflect biological consolidation (Hardt et al., 2013), retrieval practice saturation (Roediger & Karpicke, 2006), or both processes operating in tandem. The equivalence of piecewise and continuous models (Test 2, ΔAIC = -0.40) suggests that while two distinct rates exist, the transition between phases may be gradual rather than abrupt, challenging strict interpretations of discrete consolidation windows.

**Figure 5.1.2:** [piecewise_comparison.png](results/ch5/5.1.2/plots/piecewise_comparison.png)
*Model comparison: Continuous quadratic (left panel) vs piecewise inflection at 48h (right panel). Observed means (black points with error bars) fit both models. Left: Smooth concave-up curve (red line) shows gradual deceleration. Right: Two-phase structure (blue = Early 0-48h, green = Late 48-240h) shows steep initial slope followed by shallow late slope, with visible "kink" at 48h inflection (gray dashed line). Confidence bands (shaded regions) overlap substantially despite significant interaction (p < 0.000002), reflecting equivalent AIC (ΔAIC = -0.40). Visual supports Test 1 (deceleration visible) and Test 3 (dramatically different slopes), but explains Test 2 ambiguity (no obvious inflection in raw data).*

---

### 5.1.3 Age Effects on Baseline Memory and Forgetting Rate

**Research Question:** Does age predict episodic memory baseline ability and/or forgetting rate in immersive VR environments?

**Hypothesis:** Dual-deficit hypothesis predicts: (1) older adults have lower baseline memory (negative Age effect on intercept), and (2) older adults forget faster (negative Age × Time interaction).

**Analysis:** (§4.2.1, §4.3.1, §4.3.2, §4.5.1)
Sample: N=100, age range 20-70 years (M=44.6, SD=14.5), 400 observations. IRT theta scores inherited from RQ 5.1.1. Original analysis: Single Lin+Log model with Age × Time interactions, random slopes for time by participant, Bonferroni correction (α=0.017 for 3 tests). Extended analysis: 66 functional forms tested with Age interactions, 40 converged (61%), model averaging across 17 competitive models (ΔAIC < 2), best model SquareRoot+Lin (AIC=876.02, weight=9.9%). Practice decomposition analysis: Tested Age × Phase interaction (Practice T1→T2 vs Forgetting T2→T4) to rule out practice-effect confound.

**Results:**

The dual-deficit hypothesis received no empirical support. Model-averaged estimates (40 converged models) yielded Age_c β = -0.011 (SE = 0.016, p = 0.48, 95% CI [-0.042, 0.020]) for baseline memory. This coefficient indicates that a 1 SD increase in age (~14.5 years) predicts only 0.011 lower theta units at encoding—a Cohen's d-equivalent effect size of 0.01 (trivial by conventional standards). The effect was not statistically significant and the 95% CI spanned zero symmetrically, suggesting true effect near-zero rather than underpowered detection.

Age effects on forgetting rate were similarly null. For linear time slopes, Age × Time_c β = 0.000022 (SE = 0.00044, p = 0.96, based on 11 models). For logarithmic time slopes (early rapid forgetting), Age × Time_log_c β = 0.0013 (SE = 0.0090, p = 0.89, based on 10 models). Both coefficients were near-zero with extremely wide confidence intervals, indicating no systematic relationship between age and forgetting rate. Notably, in the original single-model analysis (Lin+Log), age × time coefficients were positive (β = +0.000015, +0.001), opposite the hypothesized direction—though model averaging revealed this as a functional-form artifact with true effects centered near zero.

Random effects decomposition revealed 74.9% of total variance resided between participants (random intercept ICC = 0.749), indicating substantial individual differences in baseline memory ability. However, only 0.004% of variance resided in random slopes (ICC = 0.00004), indicating negligible individual differences in forgetting rates—all participants followed essentially parallel trajectories despite differing baselines. This pattern is inconsistent with the dual-deficit hypothesis, which predicts heterogeneous forgetting rates correlated with age.

A supplementary practice-effects decomposition ruled out methodological confounds. If younger adults benefited disproportionately from retrieval practice at T1→T2, this could spuriously flatten age-related forgetting curves. However, the Age × Phase interaction was not significant (β = -0.0045, SE = 0.0055, p = 0.41). Both young and older adults showed equivalent practice benefits (Practice phase slope β_young = +0.0014, β_old = +0.0059, p > 0.05 for both), indicating that null age effects reflect genuine age-invariance in VR episodic forgetting rather than offsetting practice artifacts.

Extreme model selection uncertainty necessitated model averaging. The best single model (SquareRoot+Lin) captured only 9.9% of Akaike weight, with 17 competitive models (ΔAIC < 2) collectively accounting for 95% of support. Effective model diversity was H' = 2.71 (equivalent to 15.0 equally plausible models). Model-averaged estimates provide robust conclusions: age effects on both baseline memory and forgetting rate are trivial in magnitude (Cohen's d < 0.01) and statistically indistinguishable from zero across all competitive functional forms.

These findings converge with the growing literature on context-supported memory (Craik & Rose, 2012). Immersive VR environments provide rich multimodal spatial and temporal cues that scaffold memory encoding and retrieval. Such environmental support may compensate for age-related declines in strategic encoding and hippocampal pattern separation, yielding age-invariant memory trajectories. Alternatively, the present sample's age range (20-70) may not capture the steepest declines, which typically emerge after age 75 (Park & Festini, 2017). Floor effects may also constrain age differences: by Day 6, all age groups approached 30% correct (near-chance for three-option items), limiting discriminability.

**Cross-reference:** These null age effects contrast sharply with cognitive battery results (RQ 5.3.X, pending), where traditional verbal and visuospatial memory tasks show robust age-related declines. This dissociation supports the hypothesis that immersive VR provides unique cognitive scaffolding absent from standard neuropsychological assessments.

**Figure 5.1.3:** [age_tertile_trajectory.png](results/ch5/5.1.3/plots/age_tertile_trajectory.png)
*Forgetting trajectories by age tertile. Individual observations (solid circles) and LMM predictions (dashed lines) for Young (green, 20-38 yrs, N=33), Middle (orange, 38-55 yrs, N=34), and Older (red, 55-70 yrs, N=33) tertiles. Substantial scatter within tertiles and overlapping distributions across all timepoints visually confirm null age effects. High between-subject variability (random intercept ICC = 74.9%) evident in 4-unit theta range at each timepoint. All tertiles show general downward trend (forgetting) but no systematic age-graded ordering. Minimal separation at Day 6 (theta ≈ -0.5 for all ages) consistent with model-averaged Age_c β = -0.011 (p = 0.48, d ≈ 0.01).*

---

### 5.1.4 Individual Differences in Forgetting Rate: A Stable Cognitive Trait?

**Research Question:** What proportion of variance in forgetting rate (slopes) is between-person (stable individual differences) vs within-person (measurement error)?

**Hypothesis:** Substantial between-person variance exists in forgetting rate (ICC > 40%), indicating forgetting rate is a stable, trait-like individual difference.

**Analysis:** (§4.3.1, §4.3.2)
Sample: N=100, 400 observations (inherited from RQ 5.1.1). Extended model comparison: 65 functional forms tested with random slopes (~1 + Time | UID), 10 competitive models (ΔAIC < 2), all power-law or fractional exponent variants. Model averaging mandatory (best weight = 5.7%, effective N models = 17.6). Variance components extracted from covariance matrices: var_intercept, var_slope, cov_int_slope, var_residual. ICCs computed: ICC_intercept = var_intercept / (var_intercept + var_residual), ICC_slope = var_slope / (var_slope + var_residual).

**Results:**

Model averaging revealed a dramatic paradigm shift in interpreting individual differences in forgetting rate. The original single-model analysis (Lin+Log, AIC rank #24, ΔAIC = 3.81, weight = 0.8%) estimated random slope variance as var_slope = 0.000157, yielding ICC_slope = 0.05%—essentially zero between-person variability. This result suggested forgetting rate was entirely noise-dominated, with no trait-like stability. However, model averaging across 10 competitive power-law models (cumulative weight = 44.9%) revealed var_slope = 0.098, a 623-fold increase. The corresponding ICC_slope = 21.61% represents a 432-fold increase from the single-model estimate, elevating forgetting rate from "pure noise" (0.05%) to "moderate trait" (21.61%) classification by conventional ICC thresholds (20-40% = moderate clustering).

The functional form sensitivity of random slope variance is striking. All 10 competitive models were power-law or fractional exponent variants (α = 0.2 to 0.7, cube root, fourth root, log-log), collectively dominating the top AIC rankings. The Lin+Log model, which formed the basis of the original single-model conclusion, ranked 24th and was not competitive (ΔAIC = 3.81). Power-law models' superior fit stems from their ability to capture scale-invariant decay: participants differ not in linear rate per hour, but in proportional decay per time interval—a fundamentally different parameterization that distributes variance differently across intercepts and slopes.

Model-averaged variance components were: var_intercept = 0.422 (SD = 0.650 theta units), var_slope = 0.098 (SD = 0.313 theta units), var_residual = 0.319 (SD = 0.565 theta units), and cov_int_slope = -0.065 (r = -0.643). The intercept-slope correlation of r = -0.643 indicates a moderate-strong compensatory mechanism: participants with high baseline memory (large positive intercepts) tended to forget more slowly (negative slopes closer to zero), explaining 41.3% of slope variance. This correlation was substantially weaker than the Lin+Log estimate (r = -0.973), which approached collinearity and was biologically implausible. The model-averaged estimate (r = -0.643) falls within typical literature ranges and allows 58.7% of slope variance to remain independent of baseline ability—consistent with consolidation processes operating partially independently of encoding quality.

The ICC_intercept = 56.95% (baseline memory ability) was 2.6 times larger than ICC_slope = 21.61% (forgetting rate), indicating that individual differences in initial encoding are more stable than differences in consolidation/forgetting. However, both ICCs exceeded 20%, qualifying both as meaningful traits. The slope SD of 0.313 theta units is not negligible: this represents a range of ±0.63 theta units (±2 SD) in forgetting rate, equivalent to a difference between fastest and slowest forgetters of 1.26 theta units over the retention interval—comparable to the total population mean decline of 1.18 theta units (Day 0 to Day 6). Thus, forgetting rate heterogeneity spans nearly the full range of population-level forgetting, indicating substantial practical significance despite "moderate" ICC classification.

The hypothesis (ICC > 40%) was not strictly supported (ICC = 21.61%), but the conclusion shifts qualitatively: forgetting rate is NOT noise-dominated (as single-model analysis suggested), but rather a stable cognitive trait of moderate strength. This finding has implications for memory intervention research: if forgetting rates are trait-like, targeting consolidation processes (e.g., sleep optimization, spaced retrieval practice) may yield individualized benefits contingent on baseline forgetting rate. Conversely, if forgetting rates were pure noise (ICC ≈ 0%), such interventions would show uniform effects across individuals.

The 432-fold discrepancy between single-model and model-averaged ICC estimates underscores the critical importance of model averaging when functional form is uncertain. Variance decomposition is extraordinarily sensitive to trajectory shape: linear models allocate variance to intercepts and residuals (treating curvature as noise), whereas power-law models allocate variance to slopes (treating curvature as individual differences in decay rate). Model averaging hedges against this sensitivity by weighting across plausible functional forms, providing robust estimates that do not hinge on arbitrary single-model selection.

**Cross-reference:** The moderate ICC_slope (21.61%) contrasts with near-zero ICC_slope in RQ 5.1.3 age models (0.004%), where age did not explain slope variance. This suggests forgetting rate heterogeneity exists but is not captured by age—consistent with multifactorial influences (genetics, sleep quality, stress, prior expertise) operating independently of chronological age.

**Figure 5.1.4:** [variance_comparison.png](results/ch5/5.1.4/plots/variance_comparison.png)
*Variance component comparison: Lin+Log single model vs model-averaged (10 competitive models). Bar chart shows 623-fold increase in var_slope (0.000157 → 0.098), 11% decrease in var_intercept (0.476 → 0.422), and 3% increase in var_residual (0.310 → 0.319). Dramatic reallocation of variance from residuals/intercepts to slopes under power-law functional forms. Lin+Log model severely underestimated between-person heterogeneity in forgetting rate by treating power-law curvature as noise rather than individual differences in decay exponent.*

---

### 5.1.5 Latent Trajectory Profiles: Clustering on Random Effects

**Research Question:** Do distinct latent subgroups exist with qualitatively different forgetting trajectory patterns?

**Hypothesis:** K=2 or K=3 clusters will emerge, reflecting "high maintainers" (high baseline, slow forgetting) vs "rapid forgetters" (average/low baseline, fast forgetting).

**Analysis:** (§4.3.1, §4.6)
Sample: N=100 (model-averaged random effects from RQ 5.1.4). Clustering variables: random intercepts (baseline ability) and random slopes (forgetting rate) extracted from 5-model average (Log, PowerLaw α=0.3/0.5, CubeRoot, SquareRoot weighted by Akaike weights). K-means algorithm tested K=1 to K=10, optimal K selection via elbow method (largest second derivative of BIC curve). Cluster quality assessed via silhouette coefficient (s > 0.50 strong, 0.25-0.50 reasonable, <0.25 poor) and bootstrap stability (100 iterations, Jaccard ≥0.75 stable, <0.60 unstable). Variables z-scored prior to clustering.

**Results:**

Extended K selection (K=1 to K=10) identified K=3 via elbow method (second derivative = 38.52, strongest curvature), remedying BIC boundary overfitting at K=10. The three-cluster solution partitioned participants into: Cluster 0 (N=25, 25%, "Low Stable"), Cluster 1 (N=44, 44%, "High Maintainers"), and Cluster 2 (N=31, 31%, "Fast Learners"). All clusters exceeded 10% size threshold, ensuring adequate representation. However, cluster quality metrics revealed substantial limitations. The silhouette coefficient (s = 0.408) indicated weak structure (range 0.25-0.50), with average participants only 41% closer to their own cluster centroid than to the nearest alternative cluster. Bootstrap stability was poor (Jaccard = 0.293, 95% CI [0.00, 0.98]), far below the 0.75 threshold for stable clustering. This instability is expected when clustering on model-averaged random effects: incorporating functional form uncertainty (5 competing models) introduces appropriate variance that destabilizes cluster boundaries—a feature rather than flaw of robust uncertainty quantification.

Cluster centers (standardized scale) revealed interpretable profiles. Cluster 0 ("Low Stable") exhibited intercept_z = -1.40 (1.4 SD below mean baseline) and slope_z = -0.29 (slightly below-average decline rate). On raw theta scale, mean intercept = -0.78 and mean slope = -0.014 (near-zero, indicating stable low performance with minimal forgetting). Cluster 1 ("High Maintainers") showed intercept_z = +0.67 (above-average baseline) and slope_z = -0.62 (well-below-average decline rate), translating to raw intercept = 0.37 and slope = -0.030 (gradual decline from high baseline). Cluster 2 ("Fast Learners") had intercept_z = +0.17 (average baseline) and slope_z = +1.10 (well-above-average rate), corresponding to raw intercept = 0.10 and slope = +0.054—notably POSITIVE, indicating improvement over time rather than forgetting.

The emergence of Cluster 2 with positive slopes challenges the universal forgetting assumption. Thirty-one percent of participants showed upward trajectories (mean slope +0.054 theta units, range +0.017 to +0.116), consistent with retrieval practice effects, delayed consolidation, or test familiarization. This bidirectional heterogeneity (Clusters 0-1 declining/stable vs Cluster 2 improving) was invisible in single-model analyses, which averaged over improvement trajectories and diluted slope variance (RQ 5.1.4 ICC_slope = 0.05% for Lin+Log vs 21.6% for model-averaged). Model averaging preserved this heterogeneity by weighting across functional forms that differ in how they allocate variance between intercepts and slopes—power-law models (which dominated the competitive set) parameterize decay as proportional rate, making individual differences in exponent appear as slope variance.

The intercept-slope pattern across clusters supports a compensatory mechanism. Cluster 1 (high baseline) exhibited the slowest decline (slope = -0.030), while Cluster 0 (low baseline) showed near-zero slope (-0.014), and Cluster 2 (average baseline) actually improved (slope = +0.054). This negative correlation (r = -0.64 from RQ 5.1.4) suggests encoding quality influences consolidation dynamics: strong initial encoding may facilitate subsequent maintenance, whereas weak encoding offers little to consolidate. However, Cluster 2's improvement trajectory indicates practice effects can override initial encoding quality—participants with average baseline theta nonetheless showed largest positive gains, possibly reflecting greater room for learning or differential engagement with repeated testing.

Clustering instability (Jaccard = 0.293) limits generalizability. Wide 95% CI [0.00, 0.98] indicates some bootstrap samples recovered original clusters perfectly while others failed completely. This extreme variability reflects model averaging's incorporation of between-model uncertainty: different functional forms (Log vs PowerLaw α=0.3 vs PowerLaw α=0.5) yield different random slope estimates, and weighting across these models propagates this uncertainty into cluster assignments. The original single-model analysis (Log-only) achieved high stability (Jaccard = 0.929) but ignored model selection uncertainty (ΔAIC = 3.81 for Log vs best power-law model). The trade-off is clear: single-model clustering yields stable but potentially misspecified profiles, whereas model-averaged clustering yields unstable but appropriately uncertain profiles.

Given weak silhouette (0.408) and poor bootstrap stability (0.293), these clusters should be interpreted as provisional latent patterns rather than robust subgroups. The three-profile structure (low/stable, high/maintain, average/improve) is theoretically plausible and aligns with cognitive reserve theory (Cluster 1) and practice effects literature (Cluster 2), but replication in independent samples is necessary. Future work could apply mixture modeling with model selection uncertainty (e.g., Bayesian finite mixture models averaging over functional forms), which formalizes the integration of clustering and trajectory shape uncertainty within a unified probabilistic framework.

**Cross-reference:** These latent profiles do not align with age (RQ 5.1.3 showed null age effects), suggesting forgetting heterogeneity arises from factors orthogonal to chronological age—possibly encoding strategies, sleep quality, stress, or genetic variation in consolidation efficiency.

**Figure 5.1.5:** [cluster_scatter.png](results/ch5/5.1.5/plots/cluster_scatter.png)
*Three-cluster solution on model-averaged random effects. Scatter plot shows participants (colored points) in 2D space of standardized random intercepts (x-axis) and slopes (y-axis). Cluster 0 (red, N=25): Low baseline (-1.4 SD), stable slope (-0.3 SD). Cluster 1 (blue, N=44): High baseline (+0.7 SD), slow decline (-0.6 SD). Cluster 2 (green, N=31): Average baseline (+0.2 SD), improvement (+1.1 SD). Black stars mark cluster centers. Moderate overlap visible (silhouette = 0.408), with clearest separation on slope dimension (Cluster 2 vertically separated from others). Weak structure and bootstrap instability (Jaccard = 0.293) indicate provisional profiles, not robust subgroups. Positive slopes in Cluster 2 reveal bidirectional heterogeneity missed by single-model analyses.*

---

## 5.2 Domain-Specific Forgetting Patterns

Episodic memory comprises distinct components corresponding to what happened, where it occurred, and when it took place (Tulving, 1983). These "What/Where/When" domains may rely on dissociable neural systems—object recognition (ventral stream), spatial navigation (hippocampal place cells, parietal cortex), and temporal sequencing (prefrontal cortex, hippocampal time cells)—raising the possibility of domain-specific forgetting trajectories. Prior research suggests temporal information decays faster than spatial or semantic content (Friedman, 1993), potentially reflecting weaker encoding or greater interference susceptibility. Conversely, environmental support theory predicts spatial information (Where) benefits from rich contextual cues in immersive VR, yielding superior retention relative to abstract temporal order (When).

This section examines domain-specific forgetting using IRT-derived ability estimates for What, Where, and When components calibrated separately. If domains rely on distinct consolidation mechanisms or differ in encoding strength, forgetting trajectories should diverge: steeper slopes for vulnerable domains, shallower slopes for resilient domains. Null domain × time interactions would instead suggest a common forgetting mechanism operating uniformly across content types, with apparent domain differences reflecting only baseline encoding quality rather than differential decay rates.

---

### 5.2.1 Domain-Specific Forgetting Trajectories (What/Where/When)

**Research Question:** Are there domain-specific differences in the rate and pattern of episodic forgetting over 6 days?

**Hypothesis:** When (temporal order) will show faster forgetting than Where (spatial location) and What (object identity), consistent with prior literature suggesting temporal information is more fragile.

**Analysis:** (§4.2.1, §4.2.2, §4.3.1, §4.3.2)
Sample: N=100, 1,200 domain-specific observations (100 participants × 4 sessions × 3 domains in long format). IRT: Three-dimensional GRM with correlated factors (What/Where/When). Two-pass calibration: Pass 1 = 105 items (29 What, 50 Where, 26 When); purification excluded 35 items (a<0.4 or |b|>3.0); Pass 2 = 70 items (19 What, 45 Where, 6 When). Domain-specific theta scores estimated. LMM: Extended model comparison (66 functional forms), model averaging across 10 competitive models (ΔAIC<2, cumulative weight=54.8%). Best single model: Recip+Log (AIC=2532.42, weight=8.9%). Original Log model demoted to rank #43 (ΔAIC=+8.91, 89:1 evidence ratio against). Random intercepts and slopes by participant.

**Results:**

Extended model comparison revealed the original logarithmic model (RQ 5.1.1 functional form) was severely misspecified for domain-specific data. The Log model ranked 43rd of 66 models tested (AIC=2541.34), with an evidence ratio of 89:1 against it in favor of the best model (Recip+Log, AIC=2532.42). The best single model captured only 8.9% of Akaike weight, with 10 competitive models (ΔAIC<2) collectively accounting for 54.8% of support. This extreme model uncertainty (effective N models = 9.45) necessitated model averaging. The dominant functional form, Recip+Log, represents a two-process forgetting mechanism: rapid initial decay via the reciprocal term [1/(t+1)] operating over 0-24 hours (consolidation failure), followed by slow asymptotic decay via the logarithmic term [log(t+1)] operating beyond 24 hours (systems consolidation). This contrasts sharply with single-process Ebbinghaus-style logarithmic forgetting, aligning instead with Rubin and Wenzel's (1996) retention function combining multiple time scales.

Model-averaged trajectories on the theta scale showed near-identical patterns across What, Where, and When domains: all declined approximately 0.86 SD from Day 0 (θ≈0.52) to Day 6 (θ≈-0.34), with prediction SE increasing from 0.004 (early) to 0.069 (late) due to functional form extrapolation uncertainty. This theta-scale equivalence suggests domains share a common forgetting mechanism when measured on the latent ability scale, contradicting the hypothesis of domain-specific decay rates. However, transformation to probability scale via domain-specific IRT parameters revealed dramatic separation: What declined from 87% to 72% (15 percentage points), Where from 59% to 41% (18 points), and When from 19% to 5% (14 points). Critically, these differences reflect baseline encoding disparities (87% vs 59% vs 19% at Day 0) rather than differential forgetting rates—all domains showed parallel theta declines, but started at vastly different levels.

The When domain results constitute a measurement failure rather than a cognitive finding. Item purification excluded 20 of 26 When items (77%) for low discrimination (a<0.4), retaining only 6 items (23.1% vs 65.5% for What, 90.0% for Where). Performance was near floor throughout (5-19% probability), precluding meaningful inference about temporal forgetting trajectories. This floor effect likely reflects task difficulty: participants encoded temporal sequences during a single 10-minute VR session but were tested days later, with no retrieval practice for temporal order (unlike repeated exposure to What/Where via environmental exploration). The When domain's failure to discriminate across ability levels renders its trajectory uninterpretable—apparent "resilience" (shallow probability decline from 19% to 5%) is an artifact of floor compression, not preserved temporal memory.

Domain-specific forgetting rates (slopes) showed minimal differentiation after model averaging, despite individual models within the competitive set exhibiting weak Domain × Time interactions. Post-hoc contrasts from the original 5-model analysis (pre-averaging) indicated When vs What differences (p<0.001, Bonferroni-corrected α=0.0011), but these effects were small (f²<0.02) and likely unstable across functional forms. The inability to robustly detect domain × time interactions despite testing 66 models suggests either (1) true effect sizes are trivially small (below detection threshold for N=100), or (2) measurement error in When domain (6-item scale) attenuates power to detect interactions. The former interpretation is consistent with common-mechanism forgetting; the latter highlights the necessity of adequate item coverage for interaction detection.

Dual-scale reporting (Decision D069) prevented misinterpretation. Theta-scale results correctly identify parallel forgetting across domains (common mechanism), while probability-scale results reveal why domains appear different in raw performance (baseline encoding disparities, not differential decay). Future VR memory paradigms should redesign When tasks to achieve floor-to-ceiling range (e.g., coarser temporal bins, explicit temporal cues during encoding, retrieval practice for sequencing) before conclusions about temporal forgetting can be drawn.

**Cross-reference:** The two-process Recip+Log functional form (RQ 5.2.1) differs from the single-process power-law form (RQ 5.1.1, omnibus "All" factor). This discrepancy may reflect: (1) domain-specific data revealing finer temporal structure (1,200 obs vs 400 obs), (2) correlated-factors IRT introducing dependencies absent in omnibus calibration, or (3) functional form being data-structure dependent (long-format domain × time interactions favor composite models). Reconciling these competing forms requires direct model comparison using identical data structure (RQ 5.2.X pending).

**Figure 5.2.1a:** [trajectory_theta.png](results/ch5/5.2.1/plots/trajectory_theta.png)
*Domain-specific forgetting on theta scale (model-averaged, 10 models). What (blue), Where (green), When (orange) show near-identical trajectories: all decline ~0.86 SD from θ≈0.52 (Day 0) to θ≈-0.34 (Day 6). Shaded bands = ±1.96 SE from model averaging, widening over time (early SE=0.004, late SE=0.069) due to functional form extrapolation uncertainty. Scatter points = individual observations (N=1,200). Pattern supports common forgetting mechanism on latent ability scale.*

**Figure 5.2.1b:** [trajectory_probability.png](results/ch5/5.2.1/plots/trajectory_probability.png)
*Domain-specific forgetting on probability scale. What (blue): 87%→72% (high retention, clinically meaningful). Where (green): 59%→41% (moderate retention, approaching chance). When (orange): 19%→5% (FLOOR EFFECT, measurement failure). Clear domain separation reflects baseline encoding disparities (87% vs 59% vs 19% at Day 0), NOT differential forgetting rates. When domain's 77% item exclusion (6/26 retained) and floor compression (5-19% throughout) render trajectory uninterpretable. Dual-scale reporting (Decision D069) prevents misattribution of baseline differences to forgetting mechanisms.*

---

### 5.2.2 Domain-Specific Consolidation: Sleep-Dependent Spatial Memory Advantage?

**Research Question:** Do memory domains (What/Where) show different rates of forgetting during the early consolidation window (Day 0-1) versus later decay (Day 1-6)?

**Hypothesis:** Spatial memory (Where) should show greater consolidation benefit than object identity (What) due to hippocampal-dependent replay during sleep (Wilson & McNaughton, 1994; Rasch & Born, 2013).

**Analysis:** (§4.2.1, §4.3.1, §4.5.1)
Sample: N=100, 800 observations (100 participants × 4 tests × 2 domains). Theta scores inherited from RQ 5.2.1 domain-specific calibration. When domain excluded due to floor effect (RQ 5.2.1: 77% item exclusion, 5-19% probability). LMM piecewise model: theta ~ Days_within × Segment × Domain, with Early segment (Days 0-1) vs Late segment (Days 1-6). Random intercepts and slopes by participant. Bonferroni correction: α = 0.05/3 = 0.0167 (3 planned contrasts). Treatment coding: What = reference domain, Early = reference segment.

**Results:**

The two-phase forgetting pattern observed in omnibus analyses (RQ 5.1.2) replicated robustly within both domains. What domain showed Early slope β = -0.456 theta units/day (SE = 0.059, 95% CI [-0.573, -0.340]) declining to Late slope β = -0.071 (SE = 0.025, 95% CI [-0.121, -0.021]), an 84.4% reduction in forgetting rate. Where domain exhibited nearly identical dynamics: Early slope β = -0.433 (SE = 0.059, 95% CI [-0.549, -0.317]) declining to Late slope β = -0.085 (SE = 0.025, 95% CI [-0.134, -0.035]), an 80.4% reduction. The Segment × Time interaction was highly significant for both domains (p < 0.001), confirming that consolidation benefits are substantial and domain-general.

The critical three-way interaction (Days_within × Segment × Domain) tested whether spatial memory received preferential consolidation relative to object memory. This interaction was not significant (β = -0.037, SE = 0.087, z = -0.43, p = 0.671), failing to survive even liberal significance thresholds, let alone Bonferroni correction (α = 0.0167). Planned contrasts quantified domain differences within each segment: Where vs What in Early segment yielded β = 0.023 (SE = 0.084, p = 0.782, d = 0.029, 95% CI [-0.165, 0.223]), and in Late segment β = -0.014 (SE = 0.036, p = 0.699, d = -0.054, 95% CI [-0.248, 0.140]). All effect sizes were negligible (|d| < 0.06), with confidence intervals spanning zero symmetrically.

Consolidation benefit indices—defined as the magnitude of forgetting rate reduction from Early to Late segments—revealed a numerically opposite pattern to the hypothesis. What domain showed consolidation benefit of 0.385 theta units (95% CI [0.259, 0.512]), while Where showed 0.348 theta units (95% CI [0.222, 0.474]). Although this 0.037 difference was not significant (CIs overlap substantially), the direction contradicts hippocampal replay theory, which predicts spatial memories should benefit disproportionately from sleep consolidation. The observed pattern suggests either (1) hippocampal replay operates equivalently across What/Where domains in immersive VR (domain-general consolidation), or (2) VR's integrated object-location encoding weakens domain dissociability relative to unimodal laboratory tasks.

On the probability scale (Decision D069), domain trajectories were nearly superimposed. What declined from 65% correct (Day 0) to 48% (Day 6), a 17 percentage point drop. Where declined from 67% to 49%, an 18 point drop. The 1 percentage point separation at Day 6 is clinically and practically negligible—far below the threshold for differential assessment utility. Both domains remained well above chance (33% for three-option items) throughout the retention interval, indicating adequate measurement range despite substantial forgetting.

These findings converge with RQ 5.2.1's domain-general forgetting rates on the theta scale, now extended to test sleep-dependent consolidation mechanisms. The null three-way interaction (p = 0.671) and negligible effect sizes (|d| < 0.06) provide strong evidence against domain-specific consolidation in VR episodic memory. This contrasts with rodent studies showing preferential hippocampal replay of spatial trajectories during slow-wave sleep (Wilson & McNaughton, 1994). The discrepancy may reflect species differences, task complexity (integrated multi-domain episodes vs isolated spatial navigation), or VR-specific encoding that binds object identity and location into unified representations resistant to selective consolidation.

**Cross-reference:** RQ 5.1.2 identified two-phase forgetting with 6.2-fold rate reduction but left mechanism ambiguous (consolidation vs practice saturation). RQ 5.2.2 confirms the consolidation interpretation operates uniformly across What/Where domains, ruling out spatially selective replay as the dominant mechanism in immersive VR contexts.

**Figure 5.2.2a:** [piecewise_trajectory_theta.png](results/ch5/5.2.2/plots/piecewise_trajectory_theta.png)
*Piecewise domain-specific forgetting on theta scale. What (blue) and Where (green) show nearly parallel trajectories with clear two-phase structure: steep Early slopes (What β=-0.456, Where β=-0.433) transition to shallow Late slopes (What β=-0.071, Where β=-0.085) around 24 hours. Three-way interaction nonsignificant (p=0.671), indicating domain-general consolidation. Minimal vertical separation reflects baseline encoding equivalence after excluding When domain floor effect (RQ 5.2.1). [NOTE: Current plot outdated with 3 domains; regeneration with 2 domains pending (Step 16).]*

**Figure 5.2.2b:** [piecewise_trajectory_probability.png](results/ch5/5.2.2/plots/piecewise_trajectory_probability.png)
*Piecewise domain-specific forgetting on probability scale. What (blue): 65%→48% (17 point decline). Where (green): 67%→49% (18 point decline). Trajectories nearly superimposed (1 percentage point separation at Day 6), confirming negligible domain-specific consolidation effects. Both domains remain well above chance (33%, dotted line) throughout retention interval. Dual-scale reporting (Decision D069) shows equivalent consolidation benefits across domains despite theoretical predictions of spatial advantage. [NOTE: Plot regeneration pending.]*

---

### 5.2.3 Domain-Specific Age Effects: Hippocampal Aging Hypothesis

**Research Question:** Does the effect of age on forgetting rate vary by memory domain (What vs Where)?

**Hypothesis:** Hippocampal aging hypothesis (Raz et al., 2005) predicts greater age-related vulnerability in spatial memory (Where, hippocampal-dependent) compared to object identity (What, perirhinal-dependent).

**Analysis:** (§4.2.1, §4.3.1, §4.3.2, §4.5.1)
Sample: N=100, age range 20-70 years (M=44.6, SD=14.5), 800 observations (100 × 4 tests × 2 domains). Theta scores inherited from RQ 5.2.1. When domain excluded (floor effect). LMM with Age × Domain × Time three-way interactions, random intercepts by participant. Two time transformations tested: (1) Original Log-only model (TSVR_hours + log_TSVR, AIC=1549.27), (2) ROOT-updated Recip+Log model (recip_TSVR + log_TSVR, AIC=1466.20, ΔAIC=-83.07, converged with random slopes). Age continuous, grand-mean centered. Treatment coding: What=reference domain. Bonferroni correction: α=0.05/2=0.025 for two omnibus three-way interaction tests.

**Results:**

The hippocampal aging hypothesis received no empirical support across two functional forms differing dramatically in model fit. In the original Log-only model, both three-way Age × Domain × Time interactions were nonsignificant: TSVR_hours × Age_c × Where yielded β = -0.00006 (SE = 0.00009, z = -0.683, p = 0.495), and log_TSVR × Age_c × Where yielded β = 0.00246 (SE = 0.00317, z = 0.776, p = 0.438). Neither approached the Bonferroni threshold (α = 0.025), with p-values exceeding 0.4. The ROOT-updated Recip+Log model—which improved fit by ΔAIC = -83.07 and converged successfully with random slopes—replicated these null findings: recip_TSVR × Age_c × Where β = -0.0263 (SE = 0.0336, p = 0.432), and log_TSVR × Age_c × Where β = -0.0026 (SE = 0.0042, p = 0.545). Functional form sensitivity, which profoundly affected variance components (RQ 5.1.4: 623-fold increase) and best-fitting trajectory shape (RQ 5.1.1: power-law vs logarithmic), had no impact on the age × domain interaction conclusion—both models converged on robust null effects.

Domain-specific age slopes, evaluated at Day 3 (TSVR = 72 hours), were trivially small and statistically indistinguishable from zero. What domain showed age slope β = -0.000014 (SE = 0.000041, z = -0.336, p = 0.737, 95% CI [-0.000094, 0.000066]), while Where domain showed β = 0.000014 (SE = 0.000041, z = 0.336, p = 0.737, 95% CI [-0.000066, 0.000094]). The slopes were identical in magnitude (0.000014 theta units per year) but opposite in sign—likely reflecting numerical noise rather than true opposing trends. Over a 50-year age span (20 to 70 years), these slopes predict a cumulative decline of 0.035 SD (0.000014 × 50 years ÷ 0.80 residual SD), functionally negligible compared to the 1.18 SD population-level forgetting observed over 6 days (RQ 5.1.1).

These findings converge with RQ 5.1.3's omnibus null age effects (Age_c β = -0.011, p = 0.48, d = 0.01) to triangulate strong evidence against age-related memory decline in immersive VR contexts. RQ 5.1.3 tested age effects aggregated across all domains; RQ 5.2.3 tested whether age effects differ between What and Where domains specifically. Both analyses yielded null results with nearly identical effect sizes (|d| < 0.02), suggesting that VR episodic memory is not only age-invariant overall but also exhibits domain-general age-invariance—no differential vulnerability emerges for spatial vs object memory. This contradicts dual-process theory (Yonelinas, 2002), which predicts recollection (hippocampal, spatial) should decline faster with age than familiarity (perirhinal, object).

The discrepancy with neuroanatomical aging literature (Raz et al., 2005: 5% hippocampal volume decline per decade) may reflect: (1) functional compensation via entorhinal cortex or parahippocampal regions, (2) VR's rich multimodal encoding reducing reliance on isolated hippocampal processes, or (3) floor effects constraining age differences at Day 6 (performance approached 33% chance level for all ages in RQ 5.1.3). Alternatively, the present age range (20-70) may precede the steepest cognitive declines, which typically emerge after age 75 (Park & Festini, 2017). However, the near-zero slopes (β ≈ 0.00001) with symmetrical confidence intervals spanning zero suggest true null effects rather than underpowered detection—power analyses for RQ 5.1.3 (N=100, 400 obs) indicated adequate sensitivity for medium effects (d ≥ 0.50).

The robustness of null findings across Log-only (AIC=1549.27) and Recip+Log (AIC=1466.20) functional forms provides strong evidence against domain-specific age effects. Model comparison (ΔAIC = -83.07) decisively favors Recip+Log, yet both models reached identical substantive conclusions (p > 0.4 for three-way interactions). This functional form insensitivity contrasts sharply with variance decomposition (RQ 5.1.4: 432-fold ICC change) and trajectory interpretation (RQ 5.1.1: logarithmic vs power-law), where functional form was determinative. The pattern suggests age effects—when present—should replicate across plausible functional forms, whereas their absence indicates true null effects robust to model misspecification.

**Cross-reference:** These domain-general age effects align with RQ 5.2.2's domain-general consolidation (three-way p=0.671) and RQ 5.2.1's domain-general forgetting rates (parallel theta declines), forming a convergent pattern: immersive VR episodic memory exhibits domain-general mechanisms for forgetting, consolidation, and aging—contrary to predictions from domain-specific neural substrates.

**Figure 5.2.3:** [age_effects_by_domain.png](results/ch5/5.2.3/plots/age_effects_by_domain.png)
*Age effects on forgetting by domain. Two panels: What (left) and Where (right). Each panel shows forgetting trajectories for age tertiles: Young (green, 20-38 yrs), Middle (orange, 38-55 yrs), Older (red, 55-70 yrs). All tertiles exhibit declining trajectories over 0-250 hours, but lines overlap extensively within each domain (visualizing null three-way Age×Domain×Time interactions, p>0.4). Age slopes nearly zero (What β=-0.000014, Where β=+0.000014, p=0.737) with identical magnitude across domains. Substantial individual variability (scatter) evident at all ages. Pattern supports domain-general age-invariance in VR episodic memory. [NOTE: Current plot includes 3 domains (outdated); regeneration with 2 domains pending.]*

---

### 5.2.4 Convergent Validity: IRT Theta vs CTT Mean Scores

**Research Question:** Do IRT theta scores and CTT mean scores yield the same conclusions about domain-specific forgetting trajectories?

**Hypothesis:** IRT and CTT should converge at static measurement (r > 0.90 for within-domain correlations) but diverge in detecting individual differences in forgetting rates (IRT superior).

**Analysis:** (§4.2.1, §4.3.1, §4.3.2)
Sample: N=100, 800 observations (100 × 4 tests × 2 domains). IRT theta scores from RQ 5.2.1 (64 purified items: 17 What, 47 Where). CTT scores: unweighted mean of same 64 dichotomized items. Two LMM specifications tested: (1) Original Log-only model (score ~ log_TSVR × domain + (log_TSVR | UID)), (2) ROOT-updated Recip+Log model (score ~ recip_TSVR + log_TSVR + interactions + (recip_TSVR | UID)). Pearson correlations computed separately for What, Where, and Overall, with Holm-Bonferroni correction for multiple testing (3 comparisons).

**Results:**

Static convergence between IRT and CTT was exceptional. What domain yielded r = 0.906 (95% CI [0.887, 0.922], p < 0.001), exceeding the stringent 0.90 threshold for near-perfect correspondence. Where domain showed even tighter convergence (r = 0.970, 95% CI [0.963, 0.975], p < 0.001), the highest observed across all analyses. Overall correlation aggregating both domains reached r = 0.792 (95% CI [0.765, 0.817], p < 0.001), exceeding the liberal 0.70 threshold but falling below 0.90 due to between-domain baseline differences (What baseline θ ≈ 0.6 vs Where θ ≈ 0.6 on IRT scale, but What CTT ≈ 0.75 vs Where CTT ≈ 0.60). These correlations survived Holm-Bonferroni correction, indicating robust static convergence—IRT theta and CTT mean scores measure the same latent construct at individual timepoints, differing primarily in scaling (IRT unbounded ±2 SD vs CTT bounded 0-1 proportion).

Dynamic convergence—testing whether methods detect individual differences in forgetting rates—revealed critical functional form sensitivity. In the original Log-only model (AIC_IRT = 1546.92), IRT detected modest individual differences in forgetting rates (random slope variance = 0.021, SD = 0.145 theta units per log-hour), while CTT detected none (variance = 0.000, boundary estimate, indicating convergence failure). This suggested IRT's superiority for trajectory-level inference. However, ROOT model comparison (RQ 5.2.1: Recip+Log outperformed Log-only by ΔAIC = -8.91) prompted re-analysis. The Recip+Log model improved fit for both methods (IRT ΔAIC = -86.60, CTT ΔAIC = -56.21) and dramatically increased detected individual differences: IRT variance increased 71.8-fold (0.021 → 1.507, SD = 1.228), while CTT variance moved off boundary (0.000 → 0.022, SD = 0.148). CTT now detected individual variation—previously masked by Log-only misspecification—but IRT remained 68× more sensitive (variance ratio 1.507/0.022 = 68.5).

This functional form sensitivity parallels RQ 5.1.4's 623-fold ICC increase when shifting from linear to power-law models. Log-only specifications systematically underestimate individual differences by treating two-process forgetting (rapid consolidation failure via reciprocal term, slow systems consolidation via logarithmic term) as single-process decay. The Recip+Log form aligns with Rubin and Wenzel's (1996) retention function combining multiple time scales, capturing both early steep decline (0-24h, β_recip dominant) and late asymptotic decay (24-240h, β_log dominant). IRT's greater sensitivity (68× larger variance) likely reflects its ability to weight items by discrimination (a parameters), down-weighting noisy items that inflate CTT measurement error. CTT weights all items equally, conflating encoding quality with forgetting dynamics.

Coefficient agreement analysis revealed 75% raw agreement (3 of 4 fixed effects) but only moderate Cohen's κ = 0.500, below the 0.60 threshold for substantial agreement. The critical disagreement concerned domain main effects: IRT estimated Where vs What baseline difference as β = 0.069 (SE = 0.077, p = 0.369, nonsignificant), while CTT estimated β = -0.171 (SE = 0.017, p < 0.001, highly significant, indicating Where performed 17 percentage points lower than What). This discrepancy reflects scaling: IRT places What and Where on commensurate theta scales via correlated-factors calibration (RQ 5.2.1), whereas CTT's proportion-correct metric is sensitive to item difficulty distributions—Where items may be inherently harder (more discrimination variance, lower mean difficulty), producing spurious domain differences absent from IRT's difficulty-adjusted scale.

These findings support hybrid recommendations for VR memory assessment: IRT theta scores provide superior person-specific trajectory inference (68× greater sensitivity to forgetting rate heterogeneity) and valid cross-domain comparisons (difficulty-adjusted scaling), making them optimal for research applications testing individual differences or domain-specific mechanisms. CTT mean scores provide adequate static measurement (r > 0.90 within-domain convergence) and computational simplicity, making them suitable for clinical screening where single-timepoint assessment suffices. However, CTT's boundary estimate in Log-only models (variance = 0.000) illustrates a critical pitfall: methodological conclusions about "what CTT can detect" depend crucially on functional form specification. Proper two-process forgetting models (Recip+Log) allow CTT to detect individual differences—albeit less sensitively than IRT—challenging prior claims that CTT cannot capture dynamics.

**Cross-reference:** RQ 5.1.4 demonstrated 432-fold ICC increase when model averaging across power-law variants vs single linear model. RQ 5.2.4 extends this lesson to measurement theory: functional form misspecification (Log-only) masked individual differences for BOTH IRT and CTT, with CTT hitting boundary (complete masking) and IRT showing 71.8× underestimation. Proper functional form is prerequisite for valid inference about individual differences, regardless of measurement framework.

**Figure 5.2.4a:** [scatterplot_irt_ctt.png](results/ch5/5.2.4/plots/scatterplot_irt_ctt.png)
*IRT-CTT static convergence by domain. Left panel: What domain (r=0.906, near-perfect). Right panel: Where domain (r=0.970, highest observed). Scatterplots show IRT theta (x-axis, -2.5 to +2.5 SD) vs CTT proportion correct (y-axis, 0.0 to 1.0). Strong positive linear relationships with tight scatter around regression lines confirm exceptional static convergence (both r > 0.90). Where domain's tighter fit (smaller residual variance) explains higher correlation. Ceiling effects at CTT=1.0 visible (perfect accuracy compression). Pattern validates using IRT or CTT for single-timepoint assessment but highlights need for IRT in trajectory analyses.*

**Figure 5.2.4b:** [trajectory_comparison.png](results/ch5/5.2.4/plots/trajectory_comparison.png)
*IRT vs CTT forgetting trajectories over 0-160 hours. Two panels (What, Where), each showing IRT (circles, theta scale) and CTT (squares, proportion scale). Both methods capture qualitative pattern: consolidation boost (T1→T2 increase) followed by forgetting (T2→T4 decline). IRT trajectories show wider 95% CIs reflecting individual differences (Log-only: Var=0.021; Recip+Log: Var=1.507). CTT trajectories show narrower CIs (Log-only: Var=0.000 boundary; Recip+Log: Var=0.022). Scaling differences evident: IRT unbounded (±2 SD range) vs CTT bounded (0-1 range). Domain similarity: IRT shows parallel What/Where trajectories; CTT shows more separation (domain main effect disagreement, p<0.001 for CTT vs p=0.369 for IRT).*

---

### 5.2.5 Purification Effects: Does Item Quality Improve CTT-IRT Convergence?

**Research Question:** Does IRT purification (excluding poor-quality items) improve convergence between CTT mean scores and IRT theta scores?

**Hypothesis:** Purified CTT scores should show stronger correlations with IRT theta than Full CTT scores, because purification removes low-discrimination items that add noise to CTT sums.

**Analysis:** (§4.2.1, §4.2.2, §4.3.1, §4.3.2)
Sample: N=100, 400 observations (inherited from RQ 5.2.1). IRT purification: 105 items → 69 items (65.7% retention overall; What 65.5%, Where 90.0%, When 19.2%). Full CTT scores: unweighted mean of all 105 dichotomized items. Purified CTT scores: unweighted mean of 69 purified items. Convergence assessed via Pearson correlations computed separately per domain, tested with Steiger's z-test for dependent correlations (Bonferroni correction: α=0.05/3=0.0167). Parallel LMMs: All three measurement types (Full CTT, Purified CTT, IRT theta) fit with identical formulas to test trajectory fit. Two functional forms tested: (1) Original Log-only model with random slopes, (2) ROOT-updated Recip+Log model with random intercepts only.

**Results:**

The hypothesis received partial support contingent on domain-specific item pool quality. What domain showed purification benefit: correlation with IRT increased from r = 0.879 (Full CTT) to r = 0.906 (Purified CTT), a significant improvement (Δr = +0.027, Steiger's z = 10.06, p < .001, surviving Bonferroni correction). Where domain exhibited similar improvement: r = 0.940 → r = 0.955 (Δr = +0.015, z = 14.22, p < .001 Bonferroni-corrected), achieving the highest correlation observed across all convergence analyses (r = 0.955 represents near-perfect static measurement agreement). Both What and Where purification effects were statistically robust and theoretically meaningful—removing low-discrimination items reduced measurement error, tightening CTT-IRT correspondence.

The When domain exhibited a dramatically different pattern. Full CTT-IRT correlation was catastrophically low (r = 0.451), reflecting severe measurement failure in the 26-item temporal order pool. Purification appeared to rescue convergence (r = 0.838, Δr = +0.388, z = 2.09), representing an 86% increase in shared variance. However, this improvement failed to survive Bonferroni correction (p = .037 uncorrected, p = .111 corrected), and the apparent benefit is illusory: purification excluded 21 of 26 When items (81%), retaining only 5 items—an item pool far too sparse for reliable measurement (Cronbach's α = 0.616, 95% CI [0.551, 0.674]). The Δr = +0.388 reflects Full CTT's catastrophic failure rather than Purified CTT's success. When domain requires item redesign (coarser temporal bins, explicit sequencing cues during encoding), not just threshold adjustment.

Reliability assessment via Cronbach's alpha confirmed purification did not degrade internal consistency. What domain alpha remained stable (0.712 → 0.702, Δα = -0.010, 95% CIs overlap), as did Where domain (0.821 → 0.829, Δα = +0.007). When domain showed apparent improvement (0.575 → 0.616, Δα = +0.041), but this is an artifact of the 5-item pool—alpha estimates are unstable and unreliable with fewer than 10 items (Cortina, 1993). The critical finding is that What and Where purification preserved reliability while improving IRT convergence, indicating successful noise reduction without information loss.

Parallel LMM trajectory analysis revealed a purification-trajectory paradox. In the original Log-only model, purified CTT showed paradoxically worse trajectory fit than Full CTT: AIC rankings were IRT theta (1655.06, best) < Full CTT (1780.06, ΔAIC = +125.0) < Purified CTT (1812.26, ΔAIC = +157.2, worst). This counterintuitive ordering—better static correlations (r increased) but worse dynamic fit (AIC increased)—suggests that purification, by reducing item coverage, sacrifices the breadth of measurement needed for trajectory modeling. Full CTT's 105 items provide redundancy that buffers against idiosyncratic item-time interactions; Purified CTT's 69 items are more psychometrically pure but less robust to missing the nuances of forgetting dynamics.

The ROOT-updated Recip+Log model analysis (added 2025-12-10) dramatically amplified this paradox. While Full CTT and IRT theta both converged successfully (AIC: Full CTT 1789.15, IRT 1683.32), Purified CTT FAILED to converge—yielding a singular covariance matrix, indicating insufficient data to estimate random effects parameters. This convergence failure occurs because the Recip+Log model represents two-process forgetting (rapid consolidation failure via reciprocal term 0-24h, slow systems consolidation via logarithmic term 24-240h), requiring sufficient item-level variance to discriminate between early and late phases. Purified CTT's sparse item pools—especially When domain's 5 items—lack this variance, causing the optimizer to encounter a boundary solution where random slope variance collapses to zero. The pattern is clear: static measurement improves with purification (correlations increase), but dynamic measurement degrades (convergence fails), demonstrating a fundamental trade-off between item quality and item quantity for trajectory inference.

The IRT theta model showed robust superiority across both functional forms. In Log-only models, IRT outperformed both CTT variants by ΔAIC = 125-157, representing evidence ratios exceeding 10^27:1 in favor of IRT (Burnham & Anderson, 2002). In Recip+Log models, the IRT advantage increased: ΔAIC = +106 for Full CTT, while Purified CTT could not be evaluated due to convergence failure. This pattern confirms RQ 5.2.4's conclusion that IRT's discrimination-weighted scoring provides superior trajectory-level inference—a finding that holds regardless of functional form or purification status.

These findings carry methodological implications for VR memory assessment. Item purification improves CTT for single-timepoint cross-sectional measurement (r > 0.90 convergence with IRT for What/Where), making Purified CTT suitable for clinical screening where simplicity and interpretability matter. However, purification WORSENS CTT for longitudinal trajectory analysis, where model convergence failures expose item pool sparsity. IRT purification thus serves a dual purpose: (1) it identifies and removes low-quality items that should be redesigned (When domain's 77% exclusion rate signals fundamental task difficulty issues), and (2) it provides theta scores that support both static and dynamic inference without the purification-trajectory trade-off that afflicts CTT. The lesson is that CTT cannot salvage catastrophically poor item pools (<25% retention)—such scenarios require item redesign, not threshold adjustment.

**Cross-reference:** RQ 5.2.4 demonstrated 68× greater IRT sensitivity to individual differences in forgetting rates (random slope variance ratio 1.507/0.022). RQ 5.2.5 extends this by showing purification creates a static-dynamic dissociation for CTT: better correlations (static) but worse/non-convergent trajectory fit (dynamic). This dissociation does not occur for IRT, which maintains superior performance across both static and dynamic domains after purification.

**Figure 5.2.5a:** [correlation_comparison.png](results/ch5/5.2.5/plots/correlation_comparison.png)
*CTT-IRT correlation comparison by domain. Grouped bar chart: Blue = Full CTT, Orange = Purified CTT. What domain: Both >0.70, purified higher (r=0.906 vs 0.879, Δr=+0.027, p<.001 Bonferroni). Where domain: Both >0.90 (excellent), minimal visual gap (r=0.955 vs 0.940, Δr=+0.015, p<.001 Bonferroni). When domain: Large gap—Full CTT r=0.451 (catastrophic), Purified CTT r=0.838 (improvement not significant after correction, p=.111). Reference lines at r=0.70 (adequate) and r=0.90 (excellent). Asterisks mark Bonferroni-significant improvements (What, Where only). Pattern demonstrates domain-general purification benefit for What/Where, but When domain's improvement reflects Full CTT failure rather than Purified CTT success.*

**Figure 5.2.5b:** [aic_comparison.png](results/ch5/5.2.5/plots/aic_comparison.png)
*AIC comparison for parallel LMMs (Log-only model). Bar chart of ΔAIC relative to IRT theta baseline (0.0). Full CTT: ΔAIC = +125 (worse fit than IRT by 125 AIC units). Purified CTT: ΔAIC = +157 (worst fit, 32 AIC units worse than Full CTT). IRT theta: ΔAIC = 0.0 (reference, best fit). Reference lines: Black at ΔAIC=0.0 (IRT), orange dashed at ±2 (weak evidence), red dashed at ±10 (strong evidence). Paradoxical ordering: Purified CTT has better static correlations (Fig 5.2.5a) but worse dynamic trajectory fit, demonstrating purification-trajectory trade-off. IRT theta avoids this trade-off—superior fit for both static and dynamic inference.*

---

### 5.2.6 Domain-Specific Variance Decomposition: Trait-Like Forgetting?

**Research Question:** What proportion of variance in forgetting rate is between-person versus within-person for each memory domain (What, Where)?

**Hypothesis:** Forgetting rate is a stable trait-like individual difference (ICC_slope ≥ 0.40) in both domains, with Where domain showing higher ICC than What domain due to hippocampal-dependent recollection processes.

**Analysis:** (§4.2.1, §4.3.1, §4.4.2)
Sample: N=100, 800 observations (100 × 4 tests × 2 domains). Theta scores inherited from RQ 5.2.1. When domain excluded (floor effect). Domain-stratified LMMs: separate models per domain with formula theta ~ TSVR_hours + (TSVR_hours | UID). Random intercepts and slopes by participant. Bonferroni correction: α=0.01/2=0.005 for intercept-slope correlations (2 domains). ICC computed three ways: ICC_intercept (baseline variance proportion), ICC_slope_simple (slope variance ignoring covariance), ICC_slope_conditional (Day 6 variance accounting for intercept-slope correlation).

**Results:**

The hypothesis received strong support: both What and Where domains exhibited substantial between-person variance in forgetting outcomes. ICC_slope_conditional at Day 6 (144 hours post-encoding) reached 0.518 for What domain and 0.531 for Where domain, both exceeding the 0.40 threshold for "substantial" clustering by conventional ICC interpretation (Cicchetti, 1994). This indicates that approximately 52% of theta variance at the end of the retention interval reflects stable individual differences in memory consolidation, with the remaining 48% attributable to within-person fluctuation (measurement error, state-dependent factors, stochastic encoding variation). Forgetting rate is not noise-dominated but rather a meaningful cognitive trait with moderate-to-strong stability across the 6-day window.

The domain-specific ICC estimates revealed minimal practical differences. Where domain's ICC_slope_conditional (0.531) exceeded What domain (0.518) by only 1.3 percentage points—a difference so small as to suggest domain-general mechanisms for individual differences in forgetting. This null domain differentiation contrasts with theoretical predictions that hippocampal-dependent spatial memory (Where) should show greater individual variability due to reliance on pattern separation and consolidation processes known to exhibit high between-person variance (Stark et al., 2019). The pattern instead supports a general memory ability factor (g-factor) operating equivalently across What and Where domains in immersive VR contexts.

The ICC paradox—ICC_slope_simple < 0.02 versus ICC_slope_conditional > 0.50—requires careful interpretation. Simple slope ICC (0.008 for What, 0.011 for Where) computes the proportion of slope variance in isolation, ignoring intercept-slope correlations. With only 4 timepoints, slope estimation is unreliable when treated independently; nearly all variance appears residual. However, conditional ICC accounts for the joint distribution of intercepts and slopes at a specific timepoint (Day 6), incorporating the intercept-slope covariance. This reveals that high baseline performers (large positive intercepts) tend to maintain that advantage over time, even if their absolute forgetting rates (slopes) are similar to low performers. The conditional ICC thus captures the cumulative individual differences manifest at Day 6, whereas simple slope ICC artificially isolates a component with poor reliability in sparse longitudinal data.

Intercept-slope correlations tested the Fan Effect hypothesis: do high baseline performers show slower forgetting (negative correlation) or faster forgetting (positive correlation, regression to mean)? Where domain exhibited a significant negative correlation (r = -0.316, p_uncorrected = 0.001, p_bonferroni = 0.003), surviving stringent Bonferroni correction (α = 0.005). This indicates that participants with high spatial memory at Day 0 maintained their advantage more effectively than low performers—a pattern consistent with encoding quality facilitating subsequent consolidation. In contrast, What domain showed a positive trend (r = +0.272, p_uncorrected = 0.006) that failed Bonferroni correction (p_bonferroni = 0.012), suggesting no reliable relationship between object memory baseline and forgetting rate. This domain dissociation may reflect differential reliance on hippocampal consolidation: Where memory benefits from sleep-dependent spatial replay (Wilson & McNaughton, 1994), which preferentially strengthens already-strong spatial traces (Fan Effect), whereas What memory relies more on perirhinal familiarity processes less sensitive to encoding quality (Yonelinas, 2002).

Variance component decomposition quantified the sources of individual differences. What domain allocated 50.9% of total variance to random intercepts (baseline ability), 0.8% to random slopes (forgetting rate per se), and 48.3% to residuals (within-person noise). Where domain showed a similar partition: 56.7% intercepts, 1.1% slopes, 43.2% residuals. The dominance of intercept variance (50-57%) over slope variance (0.8-1.1%) indicates that stable individual differences primarily reflect encoding quality rather than consolidation efficiency. However, the ICC_slope_conditional metric (52-53%) reveals that by Day 6, intercept and slope contributions combine to produce substantial trait-like stability—individual differences in "who remembers well" at Day 6 are highly predictable from baseline ability, even if forgetting rates themselves vary minimally.

Cross-domain correlations among random effects (extracted for RQ 5.2.7 clustering) revealed extreme intercept correlation (r = 0.961) and strong slope correlation (r = 0.773) between What and Where domains. This near-unity intercept correlation suggests a powerful general episodic memory factor (g_episodic) dominating domain-specific variance: participants good at remembering object identity are almost perfectly predictive of spatial memory ability. The lower but still substantial slope correlation (r = 0.773) indicates moderate domain-general forgetting—individuals who forget objects quickly also tend to forget locations quickly, though with more domain-specific deviation than at baseline. This pattern aligns with hierarchical memory models where a superordinate g-factor explains 90%+ variance in baseline ability, with domain-specific factors contributing residual variance for forgetting dynamics.

These findings extend RQ 5.1.4's omnibus analysis (ICC_slope = 21.6% aggregated across all domains) by showing domain-stratified ICCs are 2.4-fold higher (52-53%). This amplification likely reflects reduced measurement error when domains are calibrated separately (RQ 5.2.1 domain-specific IRT) versus aggregated into an omnibus "All" factor (RQ 5.1.1). Domain-specific theta scores isolate What and Where variance more cleanly, reducing within-domain heterogeneity that inflates residual variance in omnibus models. The lesson: ICC estimates are sensitive to measurement granularity—domain-specific calibration reveals individual differences masked by omnibus aggregation.

**Cross-reference:** RQ 5.1.4 reported ICC_slope = 21.6% for omnibus "All" factor, contrasting with RQ 5.2.6's domain-specific ICCs of 52-53%. This discrepancy reflects measurement precision: domain-stratified IRT (RQ 5.2.1) reduces noise, revealing stronger trait-like variance. Both analyses converge on forgetting as a meaningful individual difference, differing only in magnitude. The Where domain's Fan Effect (r = -0.316) aligns with RQ 5.2.2's null consolidation advantage—spatial memory does not consolidate faster overall, but high spatial performers maintain advantages via quality-dependent replay.

**Figure 5.2.6:** [domain_icc_barplot.png](results/ch5/5.2.6/plots/domain_icc_barplot.png)
*Domain-specific ICC_slope_conditional at Day 6. Bar chart: What domain ICC = 0.518 (green bar), Where domain ICC = 0.531 (green bar), both exceeding dashed threshold line at ICC = 0.40 (substantial clustering). Y-axis spans 0.0-1.0, with threshold clearly marked. Minimal separation (1.3 percentage points) indicates domain-general trait-like forgetting. When domain absent (noted with annotation: "excluded due to floor effect"). Both ICCs above 0.50 indicate that majority of Day 6 variance is between-person (stable individual differences) rather than within-person (noise). Pattern supports forgetting as meaningful cognitive trait with moderate-to-strong stability, operant equivalently across object and spatial memory domains in immersive VR contexts.*

---

### 5.2.7 Latent Trajectory Profiles: Domain-Based Clustering

**Research Question:** Do distinct latent subgroups exist with qualitatively different forgetting trajectory patterns across What and Where domains?

**Hypothesis:** K=3-4 clusters will emerge, reflecting prototypical profiles: "High Maintainers" (high baseline, slow forgetting), "Average Decliners" (average baseline, typical forgetting), and "Rapid Forgetters" (low baseline, fast forgetting).

**Analysis:** (§4.3.1, §4.6)
Sample: N=100 participants. Clustering variables: 4 random effects per participant (What intercept, What slope, Where intercept, Where slope) extracted from RQ 5.2.6 model-averaged estimates (17-model ensemble weighted by Akaike weights). When domain excluded (floor effect, RQ 5.2.1). K-means algorithm tested K=1 to K=6, optimal K selected via BIC with parsimony rule (when ΔBIC < 2.0 between adjacent K, select smaller K). Variables z-scored prior to clustering. Cluster quality assessed via silhouette coefficient (cohesion), Davies-Bouldin index (separation), and bootstrap Jaccard stability (100 iterations, 80% subsampling).

**Results:**

The hypothesis received partial support: K=4 clusters emerged, identifying four prototypical trajectory profiles. BIC comparison revealed K=4 (BIC=91.86) and K=5 (BIC=91.86) as equivalent models (ΔBIC=0.001), triggering the parsimony rule that selected K=4 (fewer clusters preferred when fit equivalent). This differs from the original Log-only analysis (RQ 5.1.5, which selected K=5 with clear BIC minimum), suggesting that model averaging—by smoothing random effects across 17 competing functional forms—reduces spurious sub-clustering driven by single-model noise. All four clusters exceeded the 10% minimum size threshold (Cluster 0: N=36, 36%; Cluster 1: N=28, 28%; Cluster 2: N=17, 17%; Cluster 3: N=19, 19%), ensuring adequate representation without degenerate singleton clusters.

Cluster quality metrics revealed a stable-but-fuzzy structure. Bootstrap Jaccard stability was high (0.871, 95% CI [0.756, 1.000]), exceeding the 0.75 threshold for stable clustering—participants were reliably assigned to the same clusters across 100 resampling iterations, demonstrating robustness despite model averaging uncertainty. Davies-Bouldin index was 0.952 (threshold: <1.0 = good separation), indicating that cluster centroids were well-separated in the 4-dimensional What/Where intercept-slope space—the four prototypical profiles occupy distinct regions. However, silhouette coefficient was only 0.352 (threshold: >0.50 = strong, >0.40 = acceptable), indicating weak cohesion—the average participant was only 35% closer to their own cluster centroid than to the nearest neighboring cluster. This apparent contradiction (high stability, good centroid separation, but poor cohesion) reflects the nature of individual differences: prototypical profiles are distinct and replicable, but individual participants occupy a continuous distribution with substantial overlap between clusters. The clusters should thus be interpreted as "fuzzy prototypes" rather than discrete categories—useful for characterizing典型 trajectory patterns but not reflecting hard boundaries in the population.

The four cluster profiles revealed theoretically meaningful heterogeneity in baseline ability and trajectory dynamics. **Cluster 0 ("Average Decliners," 36%, largest group)** exhibited average baseline memory (What θ=0.284, Where θ=0.256, both near grand mean) with declining trajectories in both domains (What slope=-0.036 theta/day, Where slope=-0.028/day). This profile represents classic Ebbinghaus forgetting: reasonable encoding quality followed by gradual decay over 6 days, capturing the modal population pattern. **Cluster 1 ("Below-Average Improvers," 28%, second largest)** showed below-average baseline (What θ=-0.207, Where θ=-0.202) but surprising improvement trajectories (What slope=+0.037/day, Where slope=+0.039/day, both positive). This profile—representing 28% of the sample—challenges the universal forgetting assumption: nearly one-third of participants showed upward memory trajectories, consistent with retrieval practice effects (testing effect; Roediger & Karpicke, 2006) or sleep-dependent consolidation preferentially benefiting initially weak traces.

**Cluster 2 ("Low-Baseline Dissociators," 17%, smallest group)** revealed the most theoretically striking pattern: severely impaired baseline memory in both domains (What θ=-0.815, Where θ=-0.850, approximately 0.8 SD below population mean) combined with domain-dissociated trajectories—What memory was stable or improving (slope=+0.011/day, near-zero decline), while Where memory declined substantially (slope=-0.039/day, steepest decline of any cluster). This domain-selective consolidation pattern suggests differential plasticity across memory systems: perirhinal-dependent object recognition (What) retained consolidation capacity despite severe encoding deficits, whereas hippocampal-dependent spatial memory (Where) showed progressive decay. This dissociation occurred exclusively in the low-baseline group—high-ability individuals (Cluster 3) showed no such domain-specific vulnerability—indicating that consolidation failures may emerge selectively in spatial memory when encoding resources are limited. The finding has clinical relevance: low-memory individuals may benefit disproportionately from spatial rehearsal interventions targeting hippocampal consolidation.

**Cluster 3 ("High Maintainers," 19%)** exhibited superior baseline memory (What θ=0.497, Where θ=0.573, approximately 0.5 SD above population mean) with stable or improving trajectories (What slope=+0.004/day, near-zero; Where slope=+0.030/day, improving). This profile represents the "cognitive reserve" phenotype: strong initial encoding combined with preserved or enhanced consolidation, consistent with high cognitive capacity protecting against forgetting. Notably, Where memory improved more than What memory in this cluster (slope difference=+0.026/day), suggesting that high-baseline spatial encoding may facilitate sleep-dependent hippocampal replay—participants who encoded spatial layouts robustly at Day 0 showed continued strengthening across subsequent days, possibly reflecting offline consolidation during intervening sleep periods.

Cross-domain patterns revealed strong What-Where coupling with selective dissociation. The near-unity intercept correlation (r≈0.85, visually estimated from scatter matrix, quantified in RQ 5.2.6 as r=0.961) manifested as parallel baseline profiles across all four clusters—no cluster showed domain-selective baseline impairment (What≈Where for all clusters). This aligns with RQ 5.2.6's finding of a dominant general episodic memory factor (g_episodic) explaining 92% shared baseline variance. However, slope patterns revealed moderate What-Where correlation (r≈0.75), with Cluster 2's domain dissociation (What improving, Where declining) as the critical exception. This suggests that while baseline memory ability is highly domain-general (shared encoding quality), forgetting dynamics allow for domain-specific consolidation failures—particularly in individuals with limited cognitive resources (Cluster 2's low baseline).

An unexpected finding was the prevalence of improving memory trajectories. Aggregating across clusters, 47% of participants showed positive slopes in at least one domain: Cluster 1 (28%) improved in both domains, Cluster 3 (19%) showed stable What and improving Where. This is substantially higher than anticipated under traditional forgetting models (Ebbinghaus predicts universal decay). Three mechanisms may contribute: (1) **Retrieval practice effects**—four test sessions over 6 days provided repeated retrieval opportunities, known to strengthen memories (testing effect); (2) **Sleep consolidation**—participants slept three nights during the retention interval, allowing hippocampal replay to stabilize or enhance initially encoded traces (Wamsley, 2019); (3) **Model averaging artifact**—the 17-model ensemble was dominated by power-law models (ranks #1-5, cumulative weight 60%), which parameterize decay as proportional rate and may produce shallower or positive slopes compared to the logarithmic model (rank #10, 3.4% weight). The true proportion of "improvers" thus remains uncertain—falling between the lower bound of 28% (Cluster 1 only, robust across models) and upper bound of 47% (Clusters 1+3 combined, may include model averaging optimism).

These findings extend RQ 5.2.6's variance decomposition by identifying four prototypical patterns underlying the observed ICC_slope_conditional of 52-53%. RQ 5.2.6 demonstrated that forgetting rates are trait-like (substantial between-person variance); RQ 5.2.7 characterizes the qualitative structure of that variance: declining (Cluster 0, 36%), improving (Clusters 1+3, 47%), and domain-dissociated (Cluster 2, 17%). The fuzzy cluster boundaries (silhouette=0.352) combined with high stability (Jaccard=0.871) suggest these profiles represent peaks in a continuous distribution rather than discrete subpopulations—consistent with recent proposals that individual differences in cognition are better conceptualized as continuous dimensions with prototypical "attractors" rather than categorical types (Hedge et al., 2018).

**Cross-reference:** RQ 5.1.5 clustered omnibus "All" factor random effects (2 variables: intercept, slope) and identified K=3 profiles with 45% improvers. RQ 5.2.7 clustered domain-specific random effects (4 variables: What/Where intercepts and slopes) and identified K=4 profiles with 47% improvers. The additional cluster (K=4 vs K=3) captures Cluster 2's domain dissociation, which was invisible in omnibus analysis. Improver prevalence is similar (45% vs 47%), suggesting domain aggregation does not obscure improvement trajectories—consistent with high What-Where slope correlation (r=0.773, RQ 5.2.6).

**Figure 5.2.7a:** [bic_elbow.png](results/ch5/5.2.7/plots/bic_elbow.png)
*K-means model selection via BIC. Left panel: Elbow curve showing inertia (within-cluster sum of squares) declining monotonically from 396.0 (K=1) to 84.9 (K=6), with no clear inflection point. Right panel: BIC values showing minimum at K=4 (BIC=91.86) and K=5 (BIC=91.86, ΔBIC=0.001), followed by increase at K=6 (BIC=94.14). Red dashed line marks selected K=4. Black annotation highlights parsimony rule: when ΔBIC<2.0, smaller K preferred. Pattern demonstrates model averaging impact—original Log-only analysis selected K=5 with clear BIC minimum, whereas model-averaged random effects yield equivalent fit at K=4, triggering parsimony rule.*

**Figure 5.2.7b:** [cluster_scatter_matrix.png](results/ch5/5.2.7/plots/cluster_scatter_matrix.png)
*4×4 scatter matrix showing all pairwise relationships among clustering variables (What/Where intercepts and slopes). Points (N=100) colored by cluster: Blue (C0, Average Decliners, N=36), Orange (C1, Below-Average Improvers, N=28), Green (C2, Low-Baseline Dissociators, N=17), Red (C3, High Maintainers, N=19). Large black X markers show cluster centroids (N=4). Top-left quadrant (intercept vs intercept): Strong positive correlation (r≈0.85), with C2 (green) bottom-left (low baseline both domains), C3 (red) top-right (high baseline both domains), C0+C1 centered. Bottom-right quadrant (slope vs slope): Bimodal distribution visible—declining mode (C0 left, negative slopes) vs improving mode (C1+C3 right, positive slopes). Diagonal histograms reveal bimodal slope distributions (two peaks: negative and positive). Cluster separation: Centroids well-separated (explains Davies-Bouldin=0.952), but substantial member overlap visible (explains Silhouette=0.352). Green line (C2) crosses y=0 in slope panels, visualizing domain dissociation (What improving, Where declining).*

**Figure 5.2.7c:** [cluster_profiles.png](results/ch5/5.2.7/plots/cluster_profiles.png)
*Cluster profiles via parallel coordinates. Left panel (Baseline): Four horizontal lines show What/Where intercepts per cluster—C2 (green) lowest (-0.82 theta, severely impaired), C1 (orange) below-average (-0.20 theta), C0 (blue) average (0.27 theta), C3 (red) highest (0.54 theta, superior). All lines parallel (no crossing), confirming domain-general baseline ability. Right panel (Trajectories): Slope profiles reveal heterogeneity—C0 (blue) below zero (declining both domains), C1 (orange) above zero (improving both), C2 (green) CROSSES y=0 (What positive, Where negative, domain dissociation), C3 (red) above zero (improving, especially Where). Reference line at y=0 (no change) highlights that only C0 shows classic forgetting (negative slopes both domains), while C1+C3 (47% combined) show improving memory. Error bars (±1 SD) overlap y=0 for most clusters, indicating within-cluster heterogeneity.*

---

## 5.3 Retrieval Paradigm Effects: Free Recall, Cued Recall, and Recognition

Episodic memory is not assessed via a single uniform test but through diverse retrieval paradigms that vary in the amount of environmental support provided during recall. Free recall requires self-initiated retrieval with minimal cues, placing maximal demands on strategic search and monitoring processes mediated by prefrontal cortex. Cued recall provides partial environmental support (e.g., category labels, contextual prompts) that constrain search space and facilitate retrieval. Recognition presents complete target information, requiring only a familiarity judgment or recollection-based matching process supported by perirhinal and hippocampal systems (Yonelinas, 2002). Transfer-appropriate processing theory (Morris et al., 1977) predicts that retrieval paradigms tap different memory processes, raising the possibility of paradigm-specific forgetting trajectories.

Understanding paradigm effects is critical for VR memory assessment development. If paradigms show equivalent forgetting rates (parallel trajectories), a single paradigm suffices for measuring episodic decay. If paradigms diverge—with recognition retaining robustness while free recall deteriorates—assessment batteries must balance sensitivity (detecting subtle deficits) against floor effects (avoiding chance performance). Moreover, paradigm interactions with consolidation windows or individual differences would reveal whether retrieval support modulates offline memory stabilization.

This section examines these questions using IRT-calibrated ability estimates for three item-level retrieval paradigms: Item Free Recall (IFR), Item Cued Recall (ICR), and Item Recognition (IRE). Task-level paradigms (e.g., room recall, temporal order) are excluded due to severe floor effects documented in RQ 5.2.1 (When domain: 5-19% accuracy, 77% item attrition).

---

### 5.3.1 Paradigm-Specific Forgetting Trajectories

**Research Question:** Do Free Recall, Cued Recall, and Recognition exhibit different forgetting rates over 6 days?

**Hypothesis:** Recognition will show the slowest forgetting (most robust) due to reliance on familiarity-based processes, while Free Recall will show the fastest forgetting due to demands on strategic retrieval. Cued Recall predicted to fall intermediate.

**Analysis:** (§4.2.1, §4.2.2, §4.3.1, §4.3.2)
Sample: N=100, 1,200 observations (100 participants × 3 paradigms × 4 test sessions). IRT: Three-dimensional GRM with correlated factors (Free Recall, Cued Recall, Recognition). Two-pass purification: 72 items → 45 items retained (62.5%; Free=12, Cued=19, Recognition=14). Pass 2 discrimination range a∈[0.35, 1.89], difficulty range b∈[-2.93, 3.34]. Extended model comparison (66 models) identified extreme functional form uncertainty. Best model: PowerLaw_01 (α=0.1, weight=6.7%), but Log models essentially tied (rank #2-4, ΔAIC=0.07). Model averaging across 14 competitive models (ΔAIC<2, cumulative weight=57.9%) yielded effective α=0.140 (shallow power-law/log hybrid). Formula: theta ~ log_Days × Paradigm + (log_Days | UID). Treatment coding: Free Recall=reference. Bonferroni correction: α=0.05/3=0.0167 for 3 pairwise baseline comparisons.

**Results:**

The hypothesis was rejected: Recognition showed the **fastest forgetting**, not the slowest. Baseline differences emerged as predicted—Recognition exhibited significantly higher initial ability (θ=0.7) than Free Recall (θ=0.5, β=+0.210, z=3.15, p_bonf=.006, surviving stringent Bonferroni correction for 3 comparisons). Cued Recall (θ=0.6) also exceeded Free Recall numerically but failed to reach significance (β=+0.023, p=.726 uncorrected, p=1.000 Bonferroni). Recognition also surpassed Cued Recall at baseline (β=+0.187, p_bonf=.015). This baseline ordering aligns with the retrieval support gradient: recognition judgments benefit from complete target presentation, yielding higher Day 0 performance than self-initiated retrieval.

However, forgetting rate interactions revealed a paradoxical pattern. Recognition showed a negative time interaction (β=-0.127, z=-2.47, p=.013 uncorrected), indicating steeper decline than Free Recall's reference slope (β=-0.470). This interaction narrowly failed Bonferroni correction (p=.013 > α=.0167), rendering the finding suggestive but not definitive. Cued Recall's interaction was near-zero and nonsignificant (β=-0.051, p=.326), indicating parallel forgetting to Free Recall. Effect sizes were uniformly negligible (f²<0.01 for all interactions), suggesting that while statistical trends exist, practical differences in forgetting rates are minimal.

Trajectory visualization confirmed the paradox: Recognition started highest (θ=0.7) but declined most steeply (total decline=1.4 SD over 250 hours), crossing below Cued Recall around 150 hours and converging with Free Recall by Day 6 (all paradigms: θ≈-0.6 to -0.7). On the probability scale (Decision D069), Recognition declined from 58% to 32% (26 percentage point drop, 45% relative decline), while Free Recall declined from 55% to 35% (20 points, 36% decline) and Cued Recall from 64% to 37% (27 points, 42% decline). All paradigms converged to 32-37% probability by 250 hours—near chance for three-option items (33%)—indicating universal floor effects regardless of retrieval support.

This paradoxical pattern—Recognition's baseline advantage eroding faster than Free Recall's—contradicts dual-process theory predictions (Yonelinas, 2002) that familiarity-based recognition should resist forgetting. Three mechanisms may explain the reversal: (1) **Ceiling compression at encoding**: Recognition's high Day 0 performance (58-64% probability, θ=0.7) reflects easier initial retrieval, but this advantage may stem from lenient item difficulty rather than superior memory quality—when recognition items approach ceiling, regression to mean predicts steeper subsequent decline. (2) **Retrieval practice asymmetry**: Free recall's four test sessions provided repeated effortful retrieval that may have strengthened traces (testing effect; Roediger & Karpicke, 2006), whereas recognition's four tests involved passive matching with minimal reactivation—participants who actively reconstructed free recall responses consolidated those memories better than participants who merely endorsed familiar recognition foils. (3) **Floor effect artifact**: Recognition's steeper slope (β=-0.127) may partly reflect its lower Day 6 endpoint (θ=-0.7 vs -0.5 for Cued)—with all paradigms approaching 30-35% probability floor, Recognition had "further to fall" from its elevated baseline, mechanically producing steeper decline even if underlying forgetting processes were equivalent.

Model averaging impact was assessed via extended functional form comparison (added 2025-12-08). The original single-model analysis reported "logarithmic forgetting decisively superior" (99.99% Akaike weight), but extended testing across 66 models revealed this as dramatic overconfidence: Log weight dropped to 6.7% (15-fold overestimation), with PowerLaw α=0.1 and Log models essentially tied (ΔAIC=0.07). The 14 competitive models (ΔAIC<2) exhibited effective model diversity H'=12.90, equivalent to 13 equally plausible models—among the highest uncertainties observed across all RQs. However, substantive conclusions remained unchanged: paradigm baseline differences (Recognition > Cued ≈ Free) and interaction terms (Recognition × Time negative) were consistent across all top models, differing only in magnitude by <5%. What changed was epistemic humility: the original claim of "proven logarithmic forgetting" was replaced with acknowledgment that power-law (α=0.1-0.2) and logarithmic forms fit equivalently well, with model-averaged predictions hedging between both (effective α=0.140).

These findings have methodological implications for VR assessment design. Recognition's baseline advantage but accelerated forgetting suggests a fundamental trade-off: recognition paradigms maximize Day 0 sensitivity (detecting encoding deficits via 64% vs 55% baseline separation) but sacrifice longitudinal discriminability (all paradigms converge to 30-35% by Day 6, eliminating between-person variance). Free recall shows the opposite pattern: lower baseline sensitivity but sustained individual differences across the retention interval. For clinical applications targeting encoding disorders, recognition paradigms provide optimal acute assessment; for research targeting consolidation processes, free recall paradigms provide superior longitudinal resolution before floor effects dominate.

**Cross-reference:** This paradigm-by-time interaction mirrors RQ 5.2.5's purification-trajectory paradox: static measurement advantages (Recognition's high baseline, Purified CTT's tight IRT convergence) can degrade dynamic measurement (Recognition's steep decline, Purified CTT's convergence failure). Both demonstrate that optimizing single-timepoint performance does not guarantee optimal trajectory inference—VR memory paradigms must balance baseline sensitivity against longitudinal robustness.

**Figure 5.3.1a:** [trajectory_theta.png](results/ch5/5.3.1/plots/trajectory_theta.png)
*Paradigm-specific forgetting on theta scale. Free Recall (blue dashed, reference), Cued Recall (green dashed), Recognition (orange dashed). All show logarithmic/power-law decline (rapid 0-50h, asymptotic thereafter). Baseline ordering: Recognition (θ=0.7) > Cued (θ=0.6) ≈ Free (θ=0.5). Recognition trajectory STEEPEST: starts highest but ends lowest (θ=-0.7), crossing below Cued around 150h. Free/Cued trajectories nearly parallel (β interaction=-0.051, p=.326 n.s.). Convergence at Day 6: all paradigms θ≈-0.6 to -0.7 (floor effect). Shaded 95% CIs widen over time (extrapolation uncertainty). Confirms Recognition×Time negative interaction (β=-0.127, p=.013 uncorrected, p>.0167 Bonferroni n.s.).*

**Figure 5.3.1b:** [trajectory_probability.png](results/ch5/5.3.1/plots/trajectory_probability.png)
*Paradigm-specific forgetting on probability scale. Practical declines: Free 55%→35% (20pp, 36% relative), Cued 64%→37% (27pp, 42% relative), Recognition 58%→32% (26pp, 45% relative, steepest absolute drop). Baseline ordering (probability): Cued HIGHEST (64%), Recognition intermediate (58%), Free lowest (55%)—differs from theta ordering due to non-linear transformation. Endpoint convergence: all paradigms 32-37% by 250h, near chance (33% for 3-option items, dotted line). Recognition's 26pp decline despite modest 58% baseline reflects baseline-to-floor distance compression. Dual-scale reporting (Decision D069) reveals Recognition's baseline advantage erodes completely by Day 6—no residual benefit of retrieval support at long delays.*

---

### 5.3.2 Linear Trend in Forgetting Rate Across Retrieval Paradigms

**Research Question:** Does forgetting rate decrease monotonically from Free Recall → Cued Recall → Recognition, consistent with an ordered retrieval support gradient?

**Hypothesis:** Forgetting rate (slope magnitude) follows a linear trend: Free Recall (fastest forgetting) > Cued Recall (intermediate) > Recognition (slowest), reflecting the retrieval support continuum from self-initiated retrieval to cue-supported recognition.

**Analysis:** (§4.3.1, §4.5.1)
Sample: N=100, 1,200 observations (same dataset as RQ 5.3.1). Linear trend contrast testing within the best-fitting Log model from RQ 5.3.1 (AIC=2346.60). Contrast weights: Free Recall=-1, Cued Recall=0, Recognition=+1 (tests ordered hypothesis that forgetting decreases linearly across paradigms). Marginal means evaluated at Day 3 midpoint (72 hours post-encoding) to avoid extrapolation artifacts. Bonferroni correction: α=0.05/15≈0.0033 (conservative family-wise correction across ~15 tests in Chapter 5).

**Results:**

The hypothesis was **rejected**: the linear trend was in the **opposite direction** to predictions. Rather than forgetting rates decreasing from Free Recall to Recognition, they **increased**. Recognition exhibited the **steepest** forgetting slope (β=-0.597, fastest decline), Cued Recall was intermediate (β=-0.520), and Free Recall showed the **shallowest** forgetting (β=-0.470, slowest decline). The formal linear trend contrast was statistically significant when uncorrected (Contrast estimate=-0.127, SE=0.052, z=-2.47, p=.013), but failed to survive Bonferroni correction for multiple comparisons (p_bonf=.200 > α_adj=.0033). The negative contrast estimate (-0.127 theta units per paradigm step) indicates that each step along the retrieval support gradient (Free → Cued → Recognition) was associated with 0.127 theta/step **faster** decline, contradicting the hypothesis that increased retrieval support should slow forgetting.

Marginal means at Day 3 revealed Recognition maintained the **highest** absolute ability (θ=0.083, 95% CI [-0.045, 0.211]) despite having the fastest forgetting rate, while Cued Recall fell lowest (θ=-0.019, 95% CI [-0.148, 0.109]) and Free Recall was intermediate (θ=0.013, 95% CI [-0.115, 0.141]). All confidence intervals overlapped substantially, indicating no pairwise differences at this single timepoint. This pattern—Recognition highest at Day 3 yet declining fastest—reconciles the paradox from RQ 5.3.1: Recognition's elevated Day 0 baseline (θ=0.7) provided sufficient cushion that even after the steepest decline over 72 hours, it remained numerically superior to other paradigms at the midpoint. However, by Day 6 (250 hours), all paradigms converged to θ≈-0.6 to -0.7 (floor effect), eliminating Recognition's residual advantage.

The reversed linear trend contradicts **retrieval support gradient theory** (Morris et al., 1977), which predicts that increasing environmental support (Free < Cued < Recognition) should slow forgetting by reducing reliance on self-initiated strategic retrieval processes vulnerable to decay. Three mechanisms may explain the reversal: (1) **Encoding-retrieval trade-off**: Participants anticipating recognition tests during VR encoding may have adopted shallow processing strategies (e.g., visual familiarity) rather than deep elaborative encoding, producing higher Day 0 performance but fragile memory traces vulnerable to rapid decay. Free recall expectancy, conversely, encourages deep organizational encoding that yields lower initial performance but more durable representations. (2) **Ceiling regression artifact**: Recognition's Day 0 baseline (θ=0.7, 58% probability) approached the upper range of measurement, leaving maximal "room to fall" toward the population mean. Regression to the mean predicts steeper subsequent decline for high-baseline groups even if underlying forgetting processes are equivalent. (3) **Item difficulty confound**: Recognition items may have been inherently easier (lower discrimination, broader difficulty thresholds) than Free Recall items, producing artificially elevated baselines that collapsed once the novelty of exact target-foil matching wore off after 24-72 hours.

The failure to survive Bonferroni correction (p=.013 uncorrected vs α_adj=.0033) introduces interpretive ambiguity. On one hand, the uncorrected p=.013 provides moderate evidence against the null hypothesis of zero linear trend. On the other, Bonferroni correction—while conservative—guards against inflated Type I error when testing ~15 hypotheses across §5.3 paradigm RQs. The marginal significance (p=.013, just below α=.05 but far above α_adj=.0033) suggests this finding is **suggestive but not definitive**. Replication with independent samples or pre-registered analyses would clarify whether the reversed trend reflects a genuine paradigm effect or sampling variability.

**Cross-reference:** This reversed trend aligns with RQ 5.3.1's recognition-forgetting paradox (Recognition steepest decline, β=-0.127 time interaction) and extends it by demonstrating the pattern is **linear and monotonic** across the full retrieval support gradient. Together, RQs 5.3.1 and 5.3.2 establish that retrieval support advantages at encoding do not predict forgetting resistance—in fact, the opposite pattern emerged, with Free Recall (minimal support) showing the most stable trajectories. This challenges simple dual-process models (Yonelinas, 2002) and suggests VR episodic memory assessment must trade off baseline sensitivity (favoring Recognition) against longitudinal stability (favoring Free Recall).

**Figure 5.3.2:** [paradigm_forgetting_rates.png](results/ch5/5.3.2/plots/paradigm_forgetting_rates.png)
*Paradigm-specific marginal means at Day 3 (72 hours post-encoding) with linear trend overlay. Bar heights show predicted theta: Free Recall (red, θ=0.013), Cued Recall (blue, θ=-0.019, lowest), Recognition (green, θ=0.083, highest). Error bars show 95% CIs (SE=0.065 for all paradigms, substantial overlap indicates no pairwise differences). Dashed black line (negative slope) represents fitted linear trend: -0.127 theta per paradigm step, indicating forgetting rate INCREASES (gets more negative) from Free to Recognition. Horizontal gray reference line at y=0. Key observation: Recognition maintains highest Day 3 position despite having fastest forgetting slope (-0.597) because it started highest at Day 0 (θ=0.7). Annotation "p=0.01" shows uncorrected p-value; Bonferroni-corrected p=0.200 not shown per visualization convention. Downward trend contradicts retrieval support gradient hypothesis (positive trend predicted).*

---

### 5.3.3 Paradigm-Specific Consolidation Windows

**Research Question:** Do retrieval paradigms (Free Recall, Cued Recall, Recognition) show different consolidation benefits during the early consolidation window (Day 0→1) versus later decay period (Day 3→6)?

**Hypothesis:** Sleep-dependent consolidation during Day 0→1 (~0-24 hours) may differentially benefit paradigms based on encoding depth. Free Recall—requiring deeper encoding due to minimal retrieval support—predicted to show greatest consolidation benefit (largest slope difference between Early and Late segments). Expected ranking: Free Recall > Cued Recall > Recognition.

**Analysis:** (§4.3.1, §4.5.1)
Sample: N=100, 1,200 observations (derived from RQ 5.3.1 dataset). Piecewise LMM with 3-way interaction: theta ~ Days_within × Segment × Paradigm + (1 + Days_within | UID). Two temporal segments: Early (Day 0→1, ~0-24 hours post-encoding, rapid initial forgetting), Late (Day 3→6, ~72-168 hours, slower asymptotic decay). Random effects: Participant-specific intercepts and random slopes for Days_within (allows individual differences in both baseline and forgetting rate). Estimation: Maximum Likelihood (REML=False). Model fit: AIC=2247.79, Log-likelihood=-1107.89. Bonferroni correction: α=0.05/6=0.0083 for 6 planned contrasts (3 within-paradigm consolidation benefit tests + 3 between-paradigm benefit comparisons).

**Results:**

The hypothesis was **partially supported**: All paradigms showed evidence of consolidation benefits (Early segment forgetting 3-4× faster than Late segment), but paradigm ranking **contradicted predictions** and differences were **not statistically significant** after multiple comparisons correction. Early segment slopes were uniformly steep (Free Recall: β=-0.368, Cued Recall: β=-0.420, Recognition: β=-0.325, all p<.02), whereas Late segment slopes were shallower (Free: β=-0.102, Cued: β=-0.122, Recognition: β=-0.124, all p<.001). This piecewise pattern—rapid 0-24h decline followed by slower 72-168h decay—supports the existence of an early consolidation window during which forgetting accelerates before stabilizing.

However, **consolidation benefit indices** (Late slope - Early slope, positive value indicates relative slowing during Late segment) revealed the **opposite ranking** to predictions: Cued Recall showed largest benefit (+0.298 theta units), Free Recall intermediate (+0.266), and Recognition smallest (+0.201). The hypothesis predicted Free > Cued > Recognition based on encoding depth, but observed Cued > Free > Recognition. Moreover, **none of the 6 planned contrasts survived Bonferroni correction** (α_adj=0.0083). Within-paradigm consolidation benefit tests reached marginal uncorrected significance for Free Recall (p=.048) and Cued Recall (p=.027), but not Recognition (p=.135), yet all failed Bonferroni thresholds (p_bonf=.285, .160, .809 respectively). Between-paradigm benefit comparisons were uniformly nonsignificant (all p>.59), indicating consolidation benefit magnitudes were statistically equivalent across paradigms. Effect sizes for within-paradigm benefits were large (Cohen's d=1.50-2.22), but between-paradigm differences were negligible to medium (d=0.17-0.53), suggesting the **primary effect is temporal segmentation** (Early vs Late) rather than paradigm-specific consolidation.

The statistical equivalence of paradigm benefits contradicts predictions from **transfer-appropriate processing** (Morris et al., 1977) and **depth of encoding** (Craik & Lockhart, 1972) frameworks, which predict that Free Recall's deeper encoding should yield superior offline consolidation gains relative to Recognition's shallower familiarity-based encoding. Three mechanisms may explain the null paradigm effect: (1) **Universal consolidation**: Sleep-dependent memory stabilization (Stickgold & Walker, 2013) may operate equivalently on all episodic traces regardless of encoding depth or retrieval support, with the hippocampal-neocortical dialogue strengthening both shallow and deep memory codes equally. (2) **Floor effect compression**: By Day 3-6, all paradigms approached floor performance (θ≈-0.5 to -0.7, 27-30% probability), leaving minimal variance for paradigm-specific differentiation—consolidation processes may have been obscured by measurement limitations at extreme low performance levels. (3) **Sample size limitation**: N=100 provides 80% power to detect medium effect sizes (d≥0.5), but paradigm benefit differences observed here were small (d=0.17-0.53), possibly reflecting true but subtle effects below detection threshold. A larger sample (N≥300) would clarify whether paradigm differences exist at smaller magnitudes.

The piecewise segmentation revealed **functionally meaningful temporal dynamics**: On the theta scale, Early segment forgetting rates were 3.6× faster for Free Recall (-0.368 vs -0.102), 3.4× for Cued (-0.420 vs -0.122), and 2.6× for Recognition (-0.325 vs -0.124). On the **probability scale** (Decision D069), Early segment showed modest 6-9 percentage point decline over 24 hours (from ~63-65% to ~54-58%), whereas Late segment showed larger **absolute** decline (22-24 percentage points from ~50-52% to ~27-30% over 96 hours) but slower **proportional** rate (~6%/day in Late vs ~8%/day in Early). This apparent paradox—larger absolute drop in Late despite shallower theta slope—arises from the non-linear theta-to-probability transformation: as theta approaches floor (θ≈-0.5 to -1.0), a fixed theta decline translates to smaller probability shifts due to compression at the scale boundaries. The theta scale is the valid statistical comparison (linear, interval), while probability scale provides practical interpretation.

These findings have methodological implications for VR memory consolidation research. The robust **temporal segmentation** (significant Early vs Late differences, all p<.001) validates piecewise LMM approaches for detecting consolidation windows, confirming that forgetting is **non-uniform** across retention intervals rather than following a single continuous decay function. However, the **absence of paradigm-specific consolidation effects** suggests that retrieval paradigm choice (Free vs Cued vs Recognition) may not critically modulate offline consolidation gains—at least within the 0-168 hour window and N=100 sample tested here. For future VR assessment protocols targeting consolidation phenomena, paradigm selection can prioritize other considerations (baseline sensitivity, floor effect resistance) without concern that paradigm type will substantially alter consolidation dynamics.

**Cross-reference:** This null paradigm effect contrasts with RQ 5.3.1's baseline paradigm differences (Recognition θ=0.7 > Free θ=0.5 at Day 0) and RQ 5.3.2's reversed linear trend (Recognition fastest decline). Together, RQs 5.3.1-5.3.3 demonstrate that while paradigms differ in **initial encoding success** (Recognition advantage) and **overall forgetting rate** (Recognition steepest), they do **not differ** in **consolidation window dynamics** (Early vs Late slope ratios equivalent). This dissociation suggests encoding support and consolidation processes are orthogonal: retrieval cues affect immediate performance and total decay magnitude but not the temporal patterning of forgetting.

**Figure 5.3.3:** [piecewise_trajectory.png](results/ch5/5.3.3/plots/piecewise_trajectory.png)
*Piecewise paradigm trajectories across Early (Day 0→1) and Late (Day 3→6) segments on dual theta and probability scales. LEFT PANELS (Early Segment): Top shows steep theta decline from ~0.55-0.65 (Day 0) to ~0.20-0.35 (Day 1), with annotated slopes Free=-0.368/day, Cued=-0.420/day, Recognition=-0.325/day (all p<.02). Bottom shows modest probability decline from ~63-65% to ~54-58% (6-9 percentage points over 24h). RIGHT PANELS (Late Segment): Top shows shallower theta decline from ~0.10-0.15 (Day 3) to -0.40 to -0.50 (Day 6), slopes Free=-0.102/day, Cued=-0.122/day, Recognition=-0.124/day (all p<.001). Bottom shows larger absolute probability decline from ~50-52% to ~27-30% (22-24 points over 96h), but slower proportional rate (~6%/day vs ~8%/day Early). Three paradigms track closely in both segments (tight clustering), consistent with non-significant between-paradigm contrasts (all p>.59). Error bars widen over time (greater uncertainty at longer delays). Visual confirms 3-4× faster Early forgetting (steeper left panel trajectories) supporting consolidation window hypothesis, but minimal paradigm separation within segments (overlapping error bars) supporting null paradigm-specificity finding.*

---

### 5.3.4 Age × Paradigm Interactions in Forgetting Rate

**Research Question:** Does the effect of age on forgetting rate vary by retrieval paradigm (Free Recall, Cued Recall, Recognition)?

**Hypothesis:** Age-related forgetting deficits will be paradigm-specific, with older adults showing disproportionate impairment in Free Recall (self-initiated retrieval dependent on hippocampal recollection) relative to Recognition (familiarity-based processes relatively preserved in aging). Expected significant three-way Age × Paradigm × Time interaction.

**Analysis:** (§4.3.1, §4.5.1)
Sample: N=100, age 20-70 years (M=44.57, SD=14.51), 1,200 observations (100 participants × 4 sessions × 3 paradigms). LMM with three-way interaction: theta ~ TSVR_hours + log_TSVR + Age_c × Paradigm × Time + (log_TSVR | UID). Age grand-mean centered (Age_c = Age - 44.57). Random effects: Participant-specific intercepts and random slopes for log_TSVR (allows individual differences in baseline ability and forgetting rate). Reference paradigm: Free Recall. Time transformation: Both linear (TSVR_hours) and logarithmic (log_TSVR) tested simultaneously per RQ 5.3.1 finding that log models fit best. Bonferroni correction: α=0.05/2=0.025 (correcting for 2 time transformations per Decision D068). Model fit: AIC=2209.78, Log-likelihood=-1082.89.

**Results:**

The hypothesis was **not supported**: No significant three-way Age × Paradigm × Time interactions emerged for either time transformation (all p_bonf=1.00, p_uncorrected>.71). The four critical interaction terms—TSVR_hours × Age_c × Cued (β=0.00003, p=.711), TSVR_hours × Age_c × Recognition (β=-0.00002, p=.824), log_TSVR × Age_c × Cued (β=-0.001, p=.719), log_TSVR × Age_c × Recognition (β=0.001, p=.798)—were all nonsignificant and near-zero in magnitude, indicating that age-related forgetting trajectories do **not differ** across retrieval paradigms. Post-hoc paradigm-specific age effect estimates confirmed equivalence: Free Recall (β=-0.0115, p=.116), Cued Recall (β=-0.0098, p=.308), Recognition (β=-0.0134, p=.163). All three paradigms showed similar small negative age effects (approximately -0.01 theta per year of age), with no pairwise differences reaching significance after Bonferroni correction (all p_bonf>.34).

Two-way interactions were uniformly nonsignificant: Age × Paradigm interactions (all p>.75), Paradigm × Time interactions (all p>.42), and Age × Time interactions (all p>.52). The only robust effects were **main effects of time** (log_TSVR: β=-0.132, z=-3.83, p<.001, confirming significant forgetting across retention interval) and a **marginal age main effect** (Age_c: β=-0.012, z=-1.57, p=.116, approaching but not reaching α=.05). No paradigm main effects emerged (Cued vs Free: β=0.087, p=.335; Recognition vs Free: β=0.082, p=.361), consistent with RQ 5.3.1's finding that paradigm baseline differences become nonsignificant when controlling for individual random intercepts.

This null three-way interaction contradicts predictions from **selective aging** frameworks (Craik & Byrd, 1982; Naveh-Benjamin, 2000), which posit that older adults suffer disproportionate deficits in self-initiated effortful retrieval (Free Recall) due to hippocampal and frontal lobe degeneration, while relatively automatic familiarity-based recognition (IRE) remains preserved. If this hypothesis held, we would observe diverging trajectories across paradigms within older adults: steeper Free Recall decline than Recognition decline. Instead, trajectories remained **parallel** across age groups and paradigms, suggesting that **age affects baseline encoding ability** (lower Day 0 theta for older adults) **but not forgetting rate** or paradigm sensitivity. Three mechanisms may explain this null finding: (1) **Floor effect compression**: By Day 6, all paradigms and age groups converged to θ≈-0.5 to -0.7 (27-35% probability), leaving minimal variance for paradigm-specific age effects to manifest—measurement limitations at floor may obscure true aging × paradigm interactions. (2) **Compensatory retrieval**: Older adults may spontaneously recruit compensatory strategies (e.g., semantic elaboration, schema-based reconstruction) that equalize performance across paradigms despite underlying neural decline. (3) **Healthy aging sample**: N=100 community-dwelling adults (screened for neurological disorders) may underrepresent pathological aging trajectories where paradigm-specific deficits emerge—clinical samples with mild cognitive impairment or Alzheimer's disease might show the predicted interactions.

Random effects variance components revealed meaningful individual differences: intercept variance σ²=0.716 (substantial baseline ability heterogeneity) and **log_TSVR slope variance σ²=0.031** (meaningful person-specific forgetting rates, 7.75× larger than mis-specified linear slope model). Negative intercept-slope covariance (Cov=-0.105) indicated that participants with higher baseline ability tended to show slower forgetting—a pattern consistent with cognitive reserve theory (Stern, 2002) where superior encoding supports more durable memory traces. This within-person heterogeneity underscores the importance of random slopes in longitudinal designs: failing to account for individual forgetting trajectories underestimates true variance and may obscure age-related effects.

Model diagnostics confirmed robust estimation: residual normality (Shapiro-Wilk W=0.997, p=.035, passing α=.01 threshold), homoscedasticity across paradigms (variance ratio=1.06, minimal heterogeneity), perfectly centered residuals (mean=0.000), and minimal outliers (4/1200 observations beyond 3 SD, 0.3%). Convergence was clean for the corrected model with log_TSVR random slopes, confirming proper specification aligned with RQ 5.3.1's model selection.

These findings have implications for VR assessment design targeting age-related memory decline. The **null Age × Paradigm interaction** suggests that retrieval paradigm choice (Free vs Cued vs Recognition) does **not modulate age sensitivity**—VR tests will detect similar age-related baseline differences (~0.01 theta/year) regardless of paradigm. This simplifies assessment development: clinicians need not tailor paradigm selection to age demographics, as Free Recall and Recognition show equivalent age-related trajectories. However, the **marginal age main effect** (p=.116) combined with substantial individual differences (intercept variance σ²=0.716) suggests that **chronological age is a weak proxy** for memory ability—individual variability far exceeds age-group differences. Future VR assessments may achieve better diagnostic precision by incorporating cognitive reserve proxies (education, premorbid IQ) or biomarkers (hippocampal volume) rather than relying solely on age stratification.

**Cross-reference:** This null Age × Paradigm interaction contrasts sharply with RQ 5.3.1-5.3.3's paradigm-specific effects (Recognition steepest decline, reversed linear trend, null consolidation differentiation). Collectively, RQs 5.3.1-5.3.4 establish that while paradigms differ in **overall trajectory patterns** (baseline advantages, forgetting rates), these differences do **not interact with individual difference variables** (age, presumably cognition). This suggests paradigm effects are **stimulus-driven** (encoding depth, retrieval support) rather than **person-driven** (cognitive capacity, aging). VR memory paradigms may tap universal forgetting processes modulated by task structure, not individual cognitive profiles.

**Figure 5.3.4:** [age_paradigm_trajectories.png](results/ch5/5.3.4/plots/age_paradigm_trajectories.png)
*Age × Paradigm interaction trajectories across retention interval. Three panels show forgetting curves for Young Adults (left, age tertile 20-36), Middle Adults (center, 37-54), Older Adults (right, 55-70). X-axis: TSVR hours (log-spaced: 1, 30, 80, 150). Y-axis: Theta (memory ability). Colors: Free Recall (red), Cued Recall (blue), Recognition (green). Error bars: SE per paradigm × age × timepoint. KEY VISUAL PATTERNS: (1) Parallel trajectories within age groups—Free/Cued/Recognition show similar decline slopes, no divergence (confirms null 3-way interaction, all p>.71). (2) Vertical offset between age panels—older adults start lower (baseline age effect β=-0.012, p=.116 marginal), but decline magnitude similar (~1.0-1.2 SD across all groups). (3) Minimal paradigm separation—three colored lines overlap substantially within each panel, consistent with nonsignificant paradigm main effects (all p>.33). (4) Non-linear forgetting—steeper early decline (1-30h) than late (80-150h), matching log_TSVR significance (β=-0.132, p<.001). (5) Error bar overlap—large within-group variability (intercept variance σ²=0.716) obscures between-paradigm differences. Absence of diverging paradigm slopes across age groups provides visual confirmation of null hypothesis: age-related forgetting does NOT vary by retrieval paradigm.*

---

### 5.3.5 IRT-CTT Convergence for Paradigm-Specific Forgetting

**Research Question:** Do IRT theta scores and CTT mean scores yield the same conclusions about paradigm-specific forgetting trajectories for Free Recall, Cued Recall, and Recognition paradigms?

**Hypothesis:** Strong IRT-CTT convergence expected (r>0.70, Cohen's kappa>0.60, agreement≥80%), demonstrating that paradigm-specific forgetting findings from RQ 5.3.1 are robust to measurement approach and not scaling artifacts.

**Analysis:** (§4.3.1, §4.3.2)
Sample: N=100, 1,200 observations (400 per paradigm). Three-level convergence test: (1) **Static convergence**: Pearson correlations between IRT theta and CTT proportion-correct computed from same purified item set (40-80 items per paradigm post-purification from RQ 5.3.1). (2) **Dynamic convergence**: Parallel LMMs with identical formula—theta ~ Paradigm × log_TSVR + (log_TSVR | UID) for IRT model vs proportion ~ Paradigm × log_TSVR + (log_TSVR | UID) for CTT model. Both models fit with random intercepts and random slopes for log_TSVR. (3) **Coefficient-level convergence**: Cohen's kappa quantifying agreement on fixed effect significance (p<.05 vs p≥.05) across 6 terms. Bonferroni correction: α=0.05/3=0.0167 for 3 paradigm correlations.

**Results:**

The hypothesis was **strongly supported**: All three pre-specified convergence criteria were met with comfortable margins. **Static convergence** showed all correlations significantly exceeded threshold (Free Recall: r=0.876, Cued Recall: r=0.883, Recognition: r=0.838, Overall: r=0.840, all p_bonf<.001, minimum Δr=+0.138 above r=0.70 threshold). Cued Recall exhibited the highest IRT-CTT alignment (r=0.883), while Recognition showed the lowest but still strong convergence (r=0.838)—likely reflecting ceiling effect compression (Recognition baseline ~70-80% correct reduces CTT range while IRT theta remains continuous). **Dynamic convergence** was confirmed by successful parallel LMM estimation: both IRT and CTT models converged cleanly with identical random slopes structure (log_TSVR slopes by participant), demonstrating that measurement approach does not constrain model complexity or introduce structural estimation failures. **Coefficient-level convergence** achieved substantial agreement: Cohen's kappa=0.667 (exceeding κ>0.60 threshold by Δκ=+0.067), with 83.3% fixed effects agreement (5/6 terms agreed on significance, exceeding 80% threshold by +3.3 percentage points). Only one term (likely an interaction with p near .05 threshold) showed discordant significance—the remaining five terms agreed perfectly.

These convergence metrics indicate that IRT theta and CTT proportion-correct **measure the same underlying construct** (episodic memory ability) despite different scaling assumptions (logit-transformed latent trait vs linear proportion). The strong correlations (r=0.84-0.88) validate the latent trait interpretation of theta scores: participant rankings and trajectory patterns are preserved across measurement approaches. Critically, paradigm-specific forgetting findings from RQ 5.3.1 **replicate across IRT and CTT frameworks**: both detect identical paradigm ordering (Cued > Recognition > Free for retention), logarithmic decline trajectories, and rapid initial forgetting (steeper 0-24h slopes than 72-168h). This methodological robustness demonstrates that conclusions about paradigm differences are **not dependent on item weighting** (IRT discrimination parameters) or **non-linear transformations** (logistic vs linear scaling)—they reflect genuine retrieval process differences.

The slightly lower Recognition convergence (r=0.838 vs 0.876-0.883 for Free/Cued) warrants mechanistic interpretation. Recognition items had high baseline performance (Day 0: 70-80% correct), approaching CTT ceiling and compressing the proportion scale—participants scoring 75% vs 80% differ by only 5 percentage points, but their IRT thetas may differ by 0.3-0.5 SD (larger absolute distance). This **ceiling compression** introduces non-linearity in the IRT-CTT relationship specifically for high-performance paradigms, reducing Pearson r while preserving rank-order convergence. Conversely, Free Recall's lower baseline (~55-60% correct) avoids ceiling effects, allowing CTT to capture full ability range and yielding higher r=0.876. Cued Recall's highest convergence (r=0.883) may reflect optimal measurement properties—baseline intermediate (~63-65%), avoiding both floor and ceiling compression, and item discrimination uniformly strong (a≥0.4 purification threshold passed for 80% of Cued items vs 62% for Free, 58% for Recognition).

Trajectory visualizations (dual-panel IRT vs CTT) confirmed visual convergence: both panels showed **parallel forgetting curves** with monotonic decline (Day 0→6), steeper early decline (0-24h rapid forgetting), identical paradigm ordering (Cued highest retention, Free lowest, Recognition intermediate), and widening confidence intervals over time (increasing individual variability). No qualitative contradictions emerged—the paradigm separation visible in IRT theta space (e.g., Cued starts θ=0.7, declines to θ=-0.3, 1.0 SD drop) mapped directly to CTT probability space (Cued starts 75%, declines to 57%, 18 percentage point drop). The absence of scale-dependent reversals or divergent patterns provides strong evidence that **functional form of forgetting** (logarithmic curvature, consolidation window effects) is measurement-invariant.

These findings have methodological implications for VR memory assessment reporting. The robust IRT-CTT convergence **justifies dual reporting**: researchers can present both theta scores (for advanced modeling with interval-scale properties) and proportion-correct scores (for clinical intuition and accessibility to non-psychometricians). Importantly, simpler CTT metrics can be used for **screening and practical applications** without sacrificing validity—paradigm-specific conclusions drawn from CTT analyses will align with IRT-based conclusions 83% of the time. This accessibility is critical for translating REMEMVR findings to clinical contexts where IRT expertise may be limited but proportion-correct is universally understood.

**Cross-reference:** This RQ parallels RQ 5.2.4's domain-level IRT-CTT convergence analysis (What/Where r>0.90 but 68× sensitivity difference). Together, RQs 5.2.4 and 5.3.5 establish that **IRT-CTT convergence is domain/paradigm-dependent**: What/Where domains showed near-perfect correlation (r>0.90) due to balanced difficulty and minimal floor effects, whereas paradigm-level convergence was slightly lower (r=0.84-0.88) due to Recognition ceiling compression and Free Recall floor effects. Both RQs demonstrate functional form convergence—logarithmic forgetting, consolidation windows, trajectory parallelism—is measurement-invariant, confirming that conclusions about **temporal dynamics** are robust. However, RQ 5.2.4's 68× purification sensitivity difference (Reciprocal+Log functional form caused 81% item loss for When domain) highlights that **item-level purification decisions** remain IRT-sensitive, even when aggregate scores converge. This dissociation suggests CTT is sufficient for **trajectory inference** but IRT is critical for **item quality control**.

**Figure 5.3.5a:** [scatterplot_irt_ctt.png](results/ch5/5.3.5/plots/scatterplot_irt_ctt.png)
*IRT-CTT convergence scatterplot across 1,200 observations. X-axis: IRT theta (-3 to +3). Y-axis: CTT proportion correct (0 to 1). Color: paradigm (Free Recall red, Cued Recall blue, Recognition green). Gray dotted y=x line shows hypothetical perfect convergence. Paradigm-specific regression lines show actual IRT-CTT relationship. Strong positive correlations visible for all paradigms (upward-sloping regression lines, tight clustering). S-shaped deviation from y=x (points form logistic curve) is EXPECTED due to IRT logit transformation—theta unbounded, proportion bounded [0,1]. Cued Recall (blue) steepest slope (r=0.883, highest convergence). Recognition (green) shallowest slope (r=0.838, ceiling compression at proportion>0.7). Free Recall (red) intermediate (r=0.876). Greater scatter at theta extremes (<-1.5, >2.0) reflects floor/ceiling effects where CTT approaches bounds while theta remains continuous. S-shaped pattern confirms known mathematical relationship between logit-scale theta and linear-scale proportion—NOT validity concern.*

**Figure 5.3.5b:** [trajectory_comparison.png](results/ch5/5.3.5/plots/trajectory_comparison.png)
*Dual-panel IRT-CTT trajectory convergence across paradigms. LEFT PANEL (IRT): Theta scale (-0.8 to +0.8). RIGHT PANEL (CTT): Proportion scale (0.45 to 0.80). Both panels: X-axis TSVR 0-144 hours, three paradigm lines (Free red, Cued blue, Recognition green), observed data with 95% CI error bars, smooth fitted LMM predictions. PARALLEL FORGETTING CURVES: IRT and CTT panels show nearly identical trajectory patterns—monotonic decline Day 0→6, steeper decline first 24h (rapid initial forgetting), paradigm ordering Cued>Recognition>Free (cued recall best retained). Model predictions match observed means (fitted lines pass through data points). Confidence intervals widen over time (error bars larger Day 6 than Day 0, increasing individual variability). PARADIGM SEPARATION CONSISTENT: IRT panel shows Cued starts θ=0.7, declines to θ=-0.3 (1.0 SD decline); CTT panel shows Cued starts 75%, declines to 57% (18pp decline). No qualitative contradictions—paradigm ordering, trajectory shapes, relative decline rates IDENTICAL across IRT and CTT. Visual convergence confirms 83.3% fixed effects agreement: both measurement approaches detect same logarithmic decline curves, paradigm ordering, and consolidation window effects.*

---

### 5.3.6 Purified CTT Effects for Paradigm Forgetting

**Research Question:** If CTT scores use only IRT-retained items (post-purification), do conclusions differ from full-item CTT for paradigm-specific forgetting trajectories?

**Hypothesis:** Purified CTT will show (1) higher IRT theta correlation (Δr~+0.02-0.05), (2) higher Cronbach's alpha, and (3) better trajectory model fit (lower AIC) versus Full CTT, demonstrating that IRT purification improves both cross-sectional validity and longitudinal sensitivity.

**Analysis:** (§4.2.2, §4.3.1, §4.3.2)
Sample: N=100, 400 observations (100 participants × 4 sessions). Item purification per Decision D039 (a≥0.4, |b|≤3.0): 72 total items → 45 retained (62.5%; Free Recall=50%, Cued=79.2%, Recognition=58.3%). Reliability: Cronbach's alpha with bootstrap 95% CIs (10,000 iterations). Convergent validity: Steiger's z-test for dependent correlations (Full CTT-IRT vs Purified CTT-IRT) with Holm-Bonferroni correction. Trajectory modeling: Parallel LMMs (Score ~ TSVR_hours + (TSVR_hours | UID), REML=False) for Full CTT vs Purified CTT vs IRT theta. Model comparison: AIC with Burnham & Anderson threshold (ΔAIC>2 meaningful difference).

**Results:**

The hypothesis was **partially supported** with a critical **purification-trajectory paradox**. **Cross-sectional convergent validity improved universally**: Purified CTT correlated significantly more strongly with IRT theta than Full CTT for all paradigms—Free Recall Δr=+0.098 (z=6.245, p_bonf<.001, largest improvement), Cued Recall Δr=+0.023 (z=2.282, p_bonf=.034, smallest but significant), Recognition Δr=+0.050 (z=3.354, p_bonf=.001, moderate). Free Recall's dramatic improvement (Δr=+0.098, exceeding expected +0.02-0.05 range) suggests that IRT purification most benefits high-demand retrieval paradigms where low-discrimination items contribute disproportionate noise. However, **longitudinal trajectory fit worsened paradoxically**: Purified CTT showed higher AIC (worse fit) than Full CTT for all paradigms—Free (ΔAIC=-33.4, Full substantially better), Cued (ΔAIC=-5.3), Recognition (ΔAIC=-6.8). All negative deltas indicate Full CTT outperforms Purified CTT in trajectory modeling, contradicting hypothesis H3.

**Reliability findings** were paradigm-dependent: Free Recall alpha improved substantially (+0.142, from poor 0.442 to acceptable 0.584), Cued Recall unchanged (-0.004), Recognition decreased slightly (-0.044). This suggests purification benefits paradigms with initially poor reliability but provides minimal advantage when baseline reliability is already acceptable (Cued α=0.655). The **purification-trajectory paradox**—improved cross-sectional convergent validity (higher IRT correlations) coupled with worsened longitudinal model fit (higher AIC)—replicates findings from RQ 5.2.5 (domain-level purification paradox with Reciprocal+Log functional form causing 81% When item loss despite improving IRT-CTT convergence). This appears to reflect a **fundamental tension** between two psychometric goals: (1) **Precision** (IRT purification goal): Removing low-discrimination items (a<0.4) and extreme-difficulty items (|b|>3.0) reduces measurement noise at each time point, improving theta alignment cross-sectionally. (2) **Information** (trajectory modeling goal): Retaining all items—even psychometrically imperfect ones—captures broader construct sampling, including items that contribute variance information critical for tracking temporal change longitudinally. Purified CTT optimizes Goal 1 at the expense of Goal 2.

The paradox has methodological implications for VR forgetting research. While IRT purification improves **static measurement quality** (higher correlations, better reliability for Free Recall), it may **remove variance signals** essential for trajectory inference. Items excluded for poor cross-sectional properties (flat discrimination, extreme difficulty) might nonetheless contain systematic variance related to forgetting dynamics—for example, items showing minimal baseline discrimination (a<0.4) could still track temporal decline reliably if their difficulty shifts systematically over retention intervals. Full CTT's superior AIC (ΔAIC=-5.3 to -33.4) suggests that the "noisy" items contribute trajectory-relevant information outweighing their static psychometric deficiencies. For **applied forgetting studies**, this implies a trade-off: use Purified CTT for maximizing IRT theta convergence (e.g., when validating theta scores against external criteria), but use Full CTT for maximizing longitudinal model sensitivity (e.g., when detecting subtle trajectory shape differences or individual slope variability).

**Cross-reference:** This paradox extends RQ 5.2.5's domain-level findings (Purified CTT showed r>0.90 IRT convergence but FAILED dynamic convergence for Reciprocal+Log functional forms, with When domain losing 81% of items). Together, RQs 5.2.5 and 5.3.6 establish that the purification-trajectory paradox is **robust across granularities** (domain-level and paradigm-level) and **measurement approaches** (IRT-CTT static correlations vs LMM trajectory fit). Both demonstrate that optimizing cross-sectional psychometric properties does not guarantee optimal longitudinal inference—a critical caveat for VR memory assessment development where trajectory sensitivity is paramount. The consistent pattern (improved correlations, worsened AIC) across RQs suggests this is not a sampling artifact but a **systematic psychometric phenomenon** requiring theoretical resolution in measurement theory.

**Figure 5.3.6a:** [correlation_comparison.png](results/ch5/5.3.6/plots/correlation_comparison.png)
*IRT-CTT correlation comparison: Full vs Purified CTT. X-axis: paradigm (Free, Cued, Recognition). Y-axis: Correlation with IRT theta (r), range 0.70-1.00. Blue bars: Full CTT correlation. Green bars: Purified CTT correlation. Error bars: 95% CIs. Consistent improvement: green bars (Purified) taller than blue (Full) for all paradigms (universal correlation improvement). Free Recall shows most dramatic improvement (r=0.790→0.889, Δr=+0.098, z=6.245), Cued Recall smallest but significant (r=0.884→0.907, Δr=+0.023, z=2.282), Recognition moderate (r=0.817→0.867, Δr=+0.050, z=3.354). Non-overlapping error bars confirm statistical significance (all p_bonf<.05). All Purified CTT correlations exceed r>0.86 (exceptional convergence). Visual confirms primary hypothesis: IRT purification improves cross-sectional validity for all retrieval paradigms.*

**Figure 5.3.6b:** [aic_comparison.png](results/ch5/5.3.6/plots/aic_comparison.png)
*AIC trajectory fit comparison across measurement approaches. X-axis: paradigm (Free, Cued, Recognition). Y-axis: AIC (Akaike Information Criterion), range 0-1100 (lower=better fit). Red bars: IRT theta AIC (LOWEST for all paradigms, measurement gold standard). Blue bars: Full CTT AIC (MIDDLE). Green bars: Purified CTT AIC (HIGHEST, worst fit). Yellow annotations show ΔAIC (Full-Purified): Free=-33.4 (large, Full substantially better), Cued=-5.3 (moderate), Recognition=-6.8 (moderate). All negative deltas indicate Full CTT outperforms Purified CTT in trajectory modeling. Visual illustrates purification-trajectory paradox: item purification improves convergent validity (Figure 6a, higher correlations) but WORSENS trajectory fit (Figure 6b, higher AIC). Free Recall shows largest paradox magnitude (Δr=+0.098 correlation gain vs ΔAIC=-33.4 fit loss). Consistent hierarchy within paradigms (IRT<Full<Purified AIC) suggests purification optimizes cross-sectional agreement but removes variance information critical for longitudinal sensitivity.*

---

### 5.3.7 Paradigm-Specific Variance Decomposition

**Research Question:** What proportion of variance in forgetting rate is between-person versus within-person for each retrieval paradigm (Free Recall, Cued Recall, Recognition)?

**Hypothesis:** Substantial between-person variance (ICC for slopes >0.40) exists within each paradigm, indicating forgetting rate is a stable, trait-like individual difference across retrieval contexts. Secondary hypothesis: paradigm differences in ICC magnitude may reflect differential trait stability (Free>Cued>Recognition).

**Analysis:** (§4.4.2)
Sample: N=100, 1,200 observations. Three separate LMMs (one per paradigm) with random intercepts and slopes: theta ~ log(TSVR+1) + (log(TSVR+1) | UID). Time variable per RQ 5.3.1 best model selection. ICC estimates: (1) ICC_intercept (baseline ability variance), (2) ICC_slope_simple (forgetting rate variance, unconditional), (3) ICC_slope_conditional at Day 6 (forgetting outcome variance, time-conditioned). Intercept-slope correlations tested with Bonferroni correction (α=0.05/3=0.0167 for 3 paradigms, Decision D068).

**Results:**

The hypothesis was **partially supported** with a critical qualification: **forgetting RATES are NOT trait-like, but forgetting OUTCOMES are**. ICC_slope_simple (unconditional forgetting rate variance) was near-zero for all paradigms (Free Recall=0.022, Cued=0.00009, Recognition=0.014), indicating that individual differences in slope magnitude are negligible—participants forget at **similar rates** regardless of baseline ability. In contrast, ICC_slope_conditional at Day 6 exceeded the 0.40 threshold for all paradigms (Free=0.451, Cued=0.410, Recognition=0.462), confirming substantial between-person variance in memory **outcomes** at the retention endpoint. This paradox resolves by recognizing that Day 6 individual differences are driven almost entirely by **baseline ability** (ICC_intercept=0.44-0.52, all paradigms) that **persists** over time, not by differential forgetting dynamics. Participants maintain their rank ordering from Day 0 to Day 6 (high performers stay high, low performers stay low), but everyone experiences parallel forgetting trajectories rather than diverging at different rates.

Intercept-slope correlations were uniformly negative (high baseline → slower forgetting), but only Recognition reached significance after Bonferroni correction (r=-0.352, p_bonf=.005). Free Recall showed weak negative correlation (r=-0.270, p_uncorrected=.007, p_bonf=.099, fails correction). Cued Recall exhibited a **statistical artifact**: perfect correlation (r=-1.00, p<.001) due to near-zero slope variance (σ²_slope=0.00004, five orders of magnitude smaller than Free Recall's 0.009). This may reflect ceiling effects compressing variability or optimal retrieval support standardizing forgetting trajectories—all Cued Recall participants forgetting at essentially identical rates, leaving only baseline differences to explain variance.

The **secondary hypothesis was rejected**: No paradigm ordering in ICC_slope_conditional emerged (Free=0.451, Cued=0.410, Recognition=0.462, all overlapping 95% CIs). Trait-like stability of individual differences appears **robust across retrieval contexts**, unaffected by retrieval support manipulation. This null paradigm effect replicates RQ 5.3.4's null Age × Paradigm interaction—individual difference variables (age, baseline ability) do not interact with paradigm manipulations, suggesting paradigm effects are **stimulus-driven** rather than **person-driven**.

These findings challenge traditional memory research assumptions about "fast vs slow forgetters" as stable individual difference traits. **Forgetting rate is NOT trait-like**—ICC_slope_simple ≈0.00-0.02 indicates slope variance is negligible. Instead, memory individuality resides in **encoding strength** (baseline ability, ICC_intercept=0.44-0.52) rather than forgetting dynamics. This has clinical implications: Memory interventions targeting encoding (e.g., elaborative rehearsal, semantic organization) may be more effective than strategies attempting to slow forgetting (e.g., spaced repetition schedules), since individuals differ minimally in forgetting rates but substantially in initial encoding success.

**Cross-reference:** This RQ replicates RQ 5.2.6's domain-level variance decomposition (What ICC_intercept=51.8%, Where=53.1%, Fan Effect slope correlation r=-0.316), confirming the pattern is **measurement-invariant** across both domains (What/Where) and paradigms (Free/Cued/Recognition). Both RQs demonstrate that individual differences in longitudinal memory are driven by baseline encoding success (ICC_intercept>0.40), not forgetting rate heterogeneity (ICC_slope_simple≈0.00-0.02). The consistent near-zero slope ICC across RQs 5.2.6 and 5.3.7 suggests this is a **fundamental property of VR episodic forgetting**, not a domain- or paradigm-specific artifact. Together, these RQs establish that rank-order stability in memory persists despite parallel forgetting, contradicting models proposing stable fast/slow forgetter typologies.

**Figure 5.3.7:** [paradigm_icc_barplot.png](results/ch5/5.3.7/plots/paradigm_icc_barplot.png)
*Paradigm-specific ICC_slope_conditional (Day 6 forgetting outcome variance). X-axis: paradigm (Free, Cued, Recognition). Y-axis: ICC (0-0.7). Horizontal dashed line at ICC=0.40 (substantial between-person variance threshold). Bar colors: green (all bars ≥0.40, substantial interpretation). ICC values: Free=0.451 [95% CI: 0.41-0.54], Cued=0.410 [0.36-0.46], Recognition=0.462 [0.41-0.53]. ALL paradigms exceed 0.40 threshold (all bars cross dashed line), confirming substantial trait-like stability of Day 6 memory across retrieval contexts. Similar ICC magnitudes (0.41-0.46 range) with overlapping error bars indicate NO significant paradigm differences—trait stability robust regardless of retrieval support. Recognition numerically highest (0.462) but trivial difference from Free (0.451, Δ=0.011 within CIs). Visual contradicts hypothesis of paradigm ordering (expected Free>Cued>Recognition). Critical interpretation: ICC_slope_conditional=0.41-0.46 reflects BASELINE differences persisting to Day 6 (ICC_intercept=0.44-0.52), NOT differential forgetting rates (ICC_slope_simple=0.00-0.02, not shown). Individuals maintain rank order via parallel forgetting trajectories.*

---

### 5.3.8 Paradigm-Based Latent Trajectory Clustering

**Research Question:** Can participants be grouped into latent classes based on paradigm-specific forgetting trajectories (intercepts and slopes for Free Recall, Cued Recall, Recognition)?

**Hypothesis:** Exploratory analysis predicting 2-4 latent profiles based on 6 clustering variables (intercept + slope per paradigm). Expected paradigm-selective patterns: Profile A with poor Free Recall only (recollection-specific deficit, intact familiarity), Profile B with poor Recognition only (familiarity-specific deficit, intact recollection), Profile C with generalized high performance, Profile D with generalized low performance.

**Analysis:** (§4.6)
Sample: N=100 (all from RQ 5.3.7, no missing data). Clustering variables: 6 random effects per participant (intercepts + slopes for Free, Cued, Recognition) extracted from RQ 5.3.7 paradigm-stratified LMMs. K-means clustering tested K=1-6, optimal K selected via BIC minimum with parsimony rule (if ΔBIC<2, select smaller K to avoid overfitting). All features standardized to z-scores (M=0, SD=1). Cluster quality assessed via silhouette coefficient (≥0.40 threshold for adequate separation), Davies-Bouldin index (<1.5), Dunn index. Bootstrap stability: 100 iterations, 80% subsampling, Jaccard coefficient (≥0.75 threshold for stable clustering).

**Results:**

The hypothesis was **partially supported**: K=3 latent profiles emerged, but **no paradigm-selective patterns** were detected—all clusters showed uniform performance across retrieval paradigms, contradicting dual-process theory predictions (Yonelinas, 2002) that recollection vs familiarity processes should dissociate. BIC model selection initially identified K=4 (BIC=159.66) as minimum, but parsimony rule application (ΔBIC[K=4]-BIC[K=3]=-0.048<2 threshold) selected **K=3 as optimal** (BIC=159.71), reflecting shallow BIC curvature consistent with continuous rather than discrete latent structure. Cluster sizes were balanced (Cluster 0: N=33/33%, Cluster 1: N=31/31%, Cluster 2: N=36/36%), all exceeding 10% minimum threshold to avoid singleton/tiny clusters.

**Cluster profiles revealed baseline-driven phenotypes** rather than paradigm-specific deficits: **Cluster 0 (33%)** showed "Moderate-Positive Performers with Minimal Forgetting" (intercepts 0.27-0.36 theta, slopes -0.041 to -0.003, better-than-average baseline with stable retention). **Cluster 1 (31%)** exhibited "Lower Performers with Stable Retention" (intercepts -0.59 to -0.65 theta, ~1 SD below mean, slopes 0.006-0.010 near-zero/slightly positive, suggesting floor effects preventing measurable decline). **Cluster 2 (36%)** represented "Moderate Performers with Variable Retention" (intercepts 0.17-0.26 theta, slopes -0.003 to 0.030 variable). Critically, **all three clusters showed similar rank ordering across paradigms**: Cluster 1 performed consistently poorest on Free/Cued/Recognition, Cluster 0 consistently best, Cluster 2 intermediate. No cluster exhibited paradigm-selective dissociations (e.g., high Free Recall but low Recognition)—the hypothesized recollection-specific or familiarity-specific deficit profiles did not emerge.

**Cluster quality metrics indicated weak separation**: Silhouette score=0.367 fell **below 0.40 threshold** (weak clustering, substantial overlap), Davies-Bouldin=0.981 passed <1.5 threshold (acceptable within-to-between cluster distance ratio), Dunn=0.064 marginal. Bootstrap stability analysis revealed marginal robustness: mean Jaccard=0.714 fell **below 0.75 threshold** (95% CI [0.550, 0.949], SD=0.104), indicating approximately 71% of participants retain cluster assignments across bootstrap samples—somewhat sensitive to sample composition. Together, these metrics suggest clusters are **tentative phenotypes** requiring replication in independent samples rather than robustly distinct latent classes.

The absence of paradigm-selective profiles has theoretical implications. **Dual-process models** (Yonelinas, 2002) posit dissociable recollection (hippocampally-mediated, supports Free Recall) and familiarity (perirhinal-mediated, supports Recognition) processes, predicting that some individuals might show selective deficits in one system but not the other. The uniform paradigm profiles observed here—where Cluster 1 performed poorly on **all** paradigms (Free=-0.59, Cued=-0.59, Recognition=-0.65) and Cluster 0 performed well on **all** (Free=0.36, Cued=0.27, Recognition=0.36)—suggest a **common episodic memory factor** underlies performance across retrieval contexts. This aligns with RQ 5.3.7's finding that ICC_slope_simple ≈0.00-0.02 (forgetting rates not trait-like)—individual differences reside in **baseline encoding ability** (ICC_intercept=0.44-0.52), which generalizes across paradigms, not in paradigm-specific retrieval mechanisms.

The clustering analysis also revealed that **intercept dimensions drove separation** far more than slope dimensions. Scatter matrix visualization showed intercept-intercept pairings (Free Intercept × Cued Intercept, Free Intercept × Recognition Intercept) exhibited vertical/horizontal banding (clusters differed in mean baseline but distributions overlapped), whereas slope-slope pairings showed near-complete mixing across clusters (density plots heavily overlapping on diagonal). This visual pattern confirms RQ 5.3.7's variance decomposition: slopes show minimal between-person variance (var_slope=0.00004-0.009), making them uninformative for clustering, while intercepts show substantial variance (var_intercept=0.31-0.43) and drive latent profile differentiation.

**Cross-reference:** This RQ parallels RQ 5.2.7's domain-level clustering analysis (K=4 clusters, 47% improvers, Jaccard=0.871 stable but Silhouette=0.352 weak). Both RQs demonstrate that K-means clustering on forgetting trajectories produces **baseline-driven phenotypes** (intercepts dominate) rather than **trajectory-driven phenotypes** (slopes contribute minimally). However, RQ 5.2.7 achieved higher bootstrap stability (Jaccard=0.871 vs 0.714 here) despite similar Silhouette scores (0.352 vs 0.367), possibly reflecting stronger domain-level differentiation (What vs Where showed distinct neural substrates) compared to paradigm-level differentiation (Free/Cued/Recognition tap overlapping episodic processes). Together, RQs 5.2.7 and 5.3.8 establish that **latent forgetting profiles exist** but are **weak and baseline-centric**, challenging research frameworks emphasizing stable individual differences in forgetting dynamics as opposed to encoding capacity.

**Figure 5.3.8a:** [elbow_plot.png](results/ch5/5.3.8/plots/elbow_plot.png)
*BIC model selection elbow plot for K=1-6 clusters. X-axis: Number of clusters (K). Y-axis: BIC (lower=better fit). Line shows sharp decrease K=1 (BIC=205.8) → K=2 (171.8) → K=3 (159.7), near-plateau K=4 (159.7, ΔBIC=-0.05 from K=3), then increase K=5 (166.0) and K=6 (178.4). Pink star marks optimal K=3 (BIC=159.7, selected via parsimony rule). No strong elbow: gradual curve suggests no clear natural number of clusters, consistent with weak clustering quality (silhouette=0.367). Minimal ΔBIC between K=3 and K=4 (0.05) triggers parsimony rule (threshold=2), selecting simpler K=3 model to avoid overfitting. Shallow curvature indicates continuous rather than discrete latent structure—participants lie on a spectrum of baseline ability rather than forming distinct categorical phenotypes.*

**Figure 5.3.8b:** [scatter_matrix.png](results/ch5/5.3.8/plots/scatter_matrix.png)
*6×6 scatter matrix visualizing cluster separation across all pairwise feature combinations. Colors: Cluster 0 (blue, N=33, moderate-positive performers), Cluster 1 (orange, N=31, lower performers), Cluster 2 (green, N=36, moderate performers). Diagonal density plots show feature distributions per cluster (overlapping). Key patterns: (1) Substantial cluster overlap—all scatter plots show extensive mixing of blue/orange/green points, minimal clear separation (confirms weak silhouette=0.367). (2) Intercept dimensions show most separation—Free Intercept × Recognition Intercept and Cued Intercept × Free Intercept show orange cluster (Cluster 1) clearly lower than blue/green, but blue/green overlap, producing vertical/horizontal banding (clusters differ in mean baseline but distributions overlap). (3) Slope dimensions show extensive overlap—all slope × slope pairings show near-complete mixing, diagonal density plots heavily overlapping (confirms RQ 5.3.7's finding that slope variance minimal, σ²_slope=0.00004-0.009). (4) No paradigm-selective patterns—no cluster high on one paradigm, low on another (e.g., no cluster with high Free Intercept but low Recognition Intercept). All clusters uniform across Free/Cued/Recognition. (5) Spherical scatter patterns—no elongated ellipsoids, K-means sphericity assumption met. Visual confirms clustering driven by baseline performance (intercepts) rather than forgetting dynamics (slopes), and absence of paradigm-specific phenotypes contradicts dual-process dissociation hypothesis.*

---

### 5.3.9 Paradigm × Item Difficulty Interactions in Forgetting

**Research Question:** Do easier items show faster forgetting than harder items, and does this differ by retrieval paradigm (Free Recall, Cued Recall, Recognition)?

**Hypothesis:** Exploratory analysis with no directional prediction. Secondary hypothesis: Recognition may show strongest difficulty effect (largest Time × Difficulty coefficient) because recognition memory relies more heavily on item-specific familiarity processes compared to self-initiated retrieval in Free Recall, per dual-process theory (Yonelinas, 2002).

**Analysis:** (§4.3.1, §4.5.1)
Sample: N=100, 18,000 item-level observations (100 participants × 4 sessions × 45 purified items from RQ 5.3.1). Model: Response ~ Time × Difficulty_c × Paradigm + (Time | UID) + (1 | Item). Item difficulty (Difficulty_c) extracted from RQ 5.3.1 IRT calibration (difficulty parameter b, grand-mean centered). Random effects: random intercepts and slopes for Time by participant (allows individual forgetting rates). Fixed effects: all 2-way interactions (Time×Difficulty_c, Time×Paradigm, Difficulty_c×Paradigm) plus 3-way interaction Time×Difficulty_c×Paradigm (primary hypothesis test). Bonferroni correction: α=0.05/15≈0.0033 (conservative family-wise correction across ~15 paradigm-related tests in Chapter 5, Decision D068). Model fit: AIC=17809.07, Log-likelihood=-8888.54, converged successfully.

**Results:**

The hypothesis was **not supported**: The **3-way interaction** Time × Difficulty_c × Paradigm was nonsignificant for all paradigm comparisons (Free vs Cued: β=0.000256, z=1.753, p_uncorrected=.080, p_bonf=1.00; Recognition vs Cued: β=0.000063, z=0.847, p=.397, p_bonf=1.00). Item difficulty effects on forgetting rate **do not differ** across Free Recall, Cued Recall, and Recognition paradigms—all paradigms show parallel forgetting trajectories for easy vs hard items. Trajectory visualization confirmed parallel decline patterns: easy items (solid lines, -1 SD difficulty) maintained 20-30 percentage point advantage over hard items (dashed lines, +1 SD difficulty) across all 4 timepoints (Days 0-6) for all three paradigms, with no convergence or divergence (visual support for statistical null).

**Main effects** revealed robust baseline differences: **Item difficulty** showed large effect (β=-0.111, z=-30.37, p<.001)—harder items 11 percentage points lower accuracy than easier items, averaged across retention interval. **Time** confirmed significant forgetting (β=-0.001, z=-10.59, p<.001)—approximately 0.1 percentage point decline per hour. **Paradigm** differences emerged: Free Recall showed 7% lower accuracy than Cued Recall (β=-0.071, z=-6.49, p<.001), while Recognition did not differ significantly from Cued (β=0.004, p_bonf=1.00). **All 2-way interactions** were nonsignificant after Bonferroni correction: Time × Paradigm (p_bonf>.47), Time × Difficulty_c (p_bonf=1.00), Difficulty_c × Paradigm (p_bonf=1.00), indicating that forgetting rates are similar across paradigms regardless of item difficulty, and item difficulty effects on baseline performance are uniform across paradigms.

Random effects variance decomposition revealed that forgetting rates show minimal individual differences (σ²_slope_Time=0.000003, SD=0.001), replicating RQ 5.3.7's finding that **forgetting rate is NOT trait-like**. Most variance resided at the residual level (σ²_residual=0.154, SD=0.393), reflecting item-response variability, with modest participant intercept differences (σ²_intercept=0.0093, SD=0.096) and near-zero intercept-slope correlation (Cov=-0.000113). This pattern confirms that individual differences in longitudinal memory are driven by **baseline encoding ability** rather than differential forgetting dynamics, consistent across domain-level (RQ 5.2.6), paradigm-level (RQ 5.3.7), and item-level (RQ 5.3.9) analyses.

The null 3-way interaction contradicts predictions from **dual-process theory** (Yonelinas, 2002) that Recognition's reliance on item-specific familiarity should amplify difficulty effects on forgetting relative to Free Recall's recollection-based processes. If Recognition forgetting were more sensitive to item characteristics (familiarity strength) than Free Recall (organizational encoding), we would observe diverging trajectories for easy vs hard items specifically within Recognition but not Free Recall. Instead, all paradigms showed **parallel difficulty effects** (easy items maintained constant 20-30pp advantage regardless of paradigm or retention delay), suggesting that **item-level encoding strength generalizes uniformly** across retrieval contexts. This aligns with RQ 5.3.8's null paradigm-selective clustering (no recollection-specific or familiarity-specific phenotypes)—retrieval paradigms appear to tap a **common episodic memory factor** rather than dissociable processes.

**Model diagnostics** revealed assumption violations common to linear mixed models applied to binary data: residual normality violated (Shapiro-Wilk p<.05), homoscedasticity violated (Breusch-Pagan p<.05), but random effects normality passed. These violations limit standard error precision but do not invalidate the primary hypothesis test—the 3-way interaction was clearly nonsignificant (p_bonf=1.00, far exceeding α=.0033 threshold). For future item-level forgetting analyses, generalized linear mixed models (GLMM with binomial family, logit link) would provide proper binary response modeling, though conclusions would likely remain unchanged given the large p-values observed here.

**Cross-reference:** This null 3-way interaction extends the pattern of **null paradigm interactions** observed across RQs 5.3.3 (null consolidation window × paradigm, p>.59), 5.3.4 (null age × paradigm, p>.71), and 5.3.7 (null paradigm ordering in ICC magnitude). Together, RQs 5.3.3-5.3.4, 5.3.7-5.3.9 establish that while paradigms differ in **main effects** (Recognition>Cued≈Free for baseline accuracy, RQ 5.3.1), they do **not interact** with temporal dynamics (consolidation windows), individual differences (age, baseline ability), or item characteristics (difficulty). This consistent null interaction pattern suggests paradigm effects are **additive and stimulus-driven** rather than **multiplicative and person/item-modulated**. VR memory paradigms may shift performance levels uniformly (retrieval support gradient) without fundamentally altering the underlying forgetting processes or individual difference structures.

**Figure 5.3.9:** [difficulty_trajectories.png](results/ch5/5.3.9/plots/difficulty_trajectories.png)
*Forgetting trajectories by item difficulty and paradigm. X-axis: Days since VR encoding (0, 1, 3, 6). Y-axis: Probability correct (0.3-0.9). Six trajectories: 3 paradigms (Free Recall red, Cued Recall blue, Recognition green) × 2 difficulty levels (Easy items -1 SD solid lines, Hard items +1 SD dashed lines). KEY PATTERNS: (1) Easy vs Hard separation—easy items (solid) show consistently higher accuracy than hard items (dashed) across ALL paradigms (20-30pp vertical distance), separation maintained across all 4 timepoints (confirms Difficulty_c main effect β=-0.111, p<.001). (2) Paradigm hierarchy—Recognition (green) highest, Cued Recall (blue) intermediate, Free Recall (red) lowest for both difficulty levels (confirms paradigm main effect β=-0.071 Free vs Cued, p<.001). (3) **PARALLEL FORGETTING TRAJECTORIES**—easy and hard items decline at SIMILAR RATES within each paradigm (lines do not converge or diverge), slope parallelism supports non-significant 3-way interaction finding (p_bonf=1.00). (4) Steeper decline Day 0→1—steepest drop occurs first 24 hours for all conditions, shallower decline Day 3→6 (consolidation plateau, replicates RQ 5.3.3). (5) Confidence bands overlap across paradigms for hard items at Day 6—paradigm differences attenuate at longer delays for difficult items (floor effect compression). Annotation: "3-way interaction Time × Difficulty × Paradigm not significant (p_bonf > 0.0033)" communicates null hypothesis finding. Visual confirms item difficulty effects on forgetting rate do NOT vary by paradigm—all retrieval contexts show uniform sensitivity to item characteristics.*

---

## 5.4 Encoding Factors and Schema Effects

Memory encoding does not occur in a vacuum—it is profoundly shaped by semantic context, prior knowledge, and the relationship between new information and existing cognitive schemas. Schema theory (Bartlett, 1932) predicts that information congruent with activated schemas benefits from enhanced encoding and schema-mediated consolidation, leading to superior retention. Conversely, schema-incongruent information may exhibit a Von Restorff effect (Restorff, 1933)—enhanced immediate recall due to distinctiveness—but lack the consolidation scaffolding provided by schema integration (Ghosh & Gilboa, 2014).

This section examines how encoding factors modulate VR episodic memory trajectories. Central questions include: (1) Do schema-congruent items show slower forgetting than incongruent items? (2) Do specific encoding manipulations (e.g., spatial context, semantic elaboration, temporal clustering) produce differential retention? (3) Can encoding interventions mitigate age-related memory decline? These questions have both theoretical implications (testing schema consolidation models) and practical applications (designing memory-optimized VR training environments).

Importantly, REMEMVR's immersive paradigm allows naturalistic manipulation of encoding factors within ecologically valid spatial-temporal contexts, offering advantages over traditional laboratory tasks that rely on isolated word lists or abstract stimuli.

---

### 5.4.1 Schema Congruence Effects on Forgetting Trajectories

**Research Question:** Does schema congruence (common, congruent, incongruent) affect the trajectory of episodic forgetting over 6 days?

**Hypothesis:** Congruent items (schema-consistent) will show slower forgetting than incongruent items (schema-violating), due to schema-based consolidation processes (Ghosh & Gilboa, 2014).

**Analysis:** (§4.2.1, §4.2.2, §4.3.1, §4.3.2, §4.5.1)
Sample: N=100, 1,200 observations (100 participants × 4 sessions × 3 congruence dimensions). Congruence categories: Common (schema-neutral items like keys, phone, book that could appear in any room), Congruent (schema-consistent items like toothbrush in bathroom, frying pan in kitchen), Incongruent (schema-violating items with unexpected item-room pairings). IRT: Three-dimensional GRM (separate calibrations for common, congruent, incongruent dimensions) using 72 interactive paradigm items. Two-pass purification retained 50/72 items (69.4%) meeting a≥0.4, |b|≤3.0 criteria. LMM model selection: **Extended 66-model comparison** (added 2025-12-08) revealed extreme model uncertainty. Original 5-model comparison selected Log (AIC=2652.57, weight=99.998%), but extended comparison found PowerLaw_01 (α=0.1, AIC=2593.41, weight=6.04%) as best model—an **overconfidence factor of 16,630×**. With best model weight 6.04% << 30% threshold, model averaging was applied across 15 competitive models (ΔAIC<2), yielding effective model diversity H'=2.71 (equivalent to 13.96 equally plausible models)—**highest functional form uncertainty across all Chapter 5 ROOT RQs**. Fixed effects: Congruence × Time interaction with random intercepts and slopes by participant. Bonferroni correction: α=0.05/15≈0.0033.

**Results:**

The hypothesis was **not supported**: Schema congruence did **not** significantly affect forgetting trajectories. Model-averaged estimates (across 15 competitive functional forms) revealed **no significant Congruence × Time interactions**: Congruent vs Common β=0.019 (SE=0.027, p=.497), Incongruent vs Common β=-0.021 (SE=0.027, p=.445). Post-hoc pairwise contrasts all failed to reach significance even without Bonferroni correction (all p>.14), with negligible effect sizes (all f²<0.001, classified as "negligible" per Cohen's conventions). Trajectory visualization confirmed statistical findings: all three congruence categories showed overlapping forgetting curves with near-identical slopes (Common: θ=0.450→-0.382, decline=0.832 SD; Congruent: θ=0.422→-0.398, decline=0.820 SD; Incongruent: θ=0.505→-0.399, decline=0.904 SD). On the probability scale, all three categories declined approximately 20 percentage points (Common 61.1%→40.6%, Congruent 60.4%→40.2%, Incongruent 62.4%→40.2%) and converged at Day 6 near 40% accuracy (approaching chance performance for 3-option recognition).

**Main effect of Time** was highly significant (β=-0.193, SE=0.024, z=-7.982, p<.001, f²=0.053), confirming robust forgetting across all congruence categories. However, **no main effects of Congruence** emerged: baseline performance was statistically indistinguishable (Congruent vs Common: β=-0.060, p=.559; Incongruent vs Common: β=0.079, p=.438). This null pattern contradicts both schema consolidation theory (Ghosh & Gilboa, 2014) and Von Restorff predictions—congruent items did not retain better, and incongruent items showed neither initial encoding advantage nor accelerated forgetting.

Random effects decomposition revealed substantial individual differences in baseline ability (σ²_intercept=0.470) but minimal variance in forgetting rates (σ²_slope=0.022, ICC_slope≈0.02), replicating the pattern from RQs 5.2.6 (domain-level ICC 51-53%) and 5.3.7 (paradigm-level ICC_simple 0.00-0.02). The negative intercept-slope covariance (Cov=-0.072) indicated participants with higher baseline ability tended to show slightly steeper declines—a ceiling-regression artifact also observed in RQ 5.2.6 (Fan Effect r=-0.316). This pattern is inconsistent with schema consolidation theory, which predicts schema-congruent encoding should scaffold both initial encoding AND long-term retention.

**A unique methodological finding emerged: extreme functional form uncertainty.** Unlike other Chapter 5 ROOT RQs where power-law or logarithmic models dominated (RQ 5.1.1: PowerLaw_05 weight 15.2%; RQ 5.2.1: Recip+Log weight 8.9%; RQ 5.3.1: PowerLaw_01 weight 6.7%), RQ 5.4.1 showed the **highest diversity** with effective N=13.96 models and no dominant form. The top 15 competitive models spanned three families: power-law (α=0.1-0.3), logarithmic (Log, Log2, Log10), and reciprocal (Recip+PowerLaw, Log+Recip), with nearly equal cumulative weights. This extreme ambiguity suggests schema congruence may modulate **forgetting complexity** (which mathematical families compete) rather than **forgetting rate** (slope magnitude). However, the null Congruence × Time interactions were robust across all 15 functional forms, indicating the primary hypothesis rejection is not a model selection artifact.

The null schema effect has several possible interpretations. First, REMEMVR's immersive environments may have activated **strong spatial-contextual schemas** that dominated weaker item-level schema congruence manipulations—participants may have encoded all items within unified "bathroom schema" regardless of whether individual items were toothbrushes (congruent) or drills (incongruent). Second, the 6-day retention interval may exceed the temporal window for schema consolidation benefits (Gilboa & Marlatte, 2017), which typically emerge within 24-48 hours but dissipate at longer delays when all memory traces rely on hippocampal retrieval. Third, VR's multimodal encoding (visual, spatial, motor interaction) may provide such rich encoding that schema-based scaffolding becomes redundant—all items benefit from "strong encoding" regardless of semantic congruence.

**Cross-reference:** This null schema effect converges with null paradigm interactions (RQs 5.3.3-5.3.4, 5.3.7, 5.3.9) and null domain interactions (RQ 5.2.3 age × domain, RQ 5.2.2 consolidation × domain) to suggest a broader pattern: **contextual manipulations (paradigm, domain, schema) produce main effects but do not interact with temporal dynamics**. VR memory appears to follow uniform forgetting laws (power-law decay, two-phase consolidation) regardless of semantic, spatial, or retrieval context—a finding consistent with **domain-general forgetting mechanisms** (Wixted, 2004) rather than schema-modulated consolidation (Ghosh & Gilboa, 2014).

**Figure 5.4.1a:** [trajectory_theta.png](results/ch5/5.4.1/plots/trajectory_theta.png)
*Forgetting trajectories by schema congruence (theta scale, empirical data). X-axis: Time since VR encoding (hours): 1.0, 28.8, 78.7, 151.4. Y-axis: Memory ability (theta): -0.6 to 0.6. Three overlapping trajectories with 95% confidence intervals: Common (purple, schema-neutral items), Congruent (green, schema-consistent items), Incongruent (red, schema-violating items). KEY VISUAL PATTERNS: (1) Substantial overlap—all three lines nearly parallel with overlapping confidence bands, visual confirmation of non-significant Congruence × Time interactions (p>.44). (2) Monotonic decline—all categories show consistent forgetting from T1 to T4 (approximately 0.8-0.9 SD decline). (3) Convergence at Day 6—all three trajectories end at θ≈-0.39 to -0.40 (final performance nearly identical across congruence levels). (4) Rapid initial decline—steepest drop occurs T1→T2 (first 24 hours), replicating two-phase forgetting pattern from RQ 5.1.2. (5) No cross-over or divergence—trajectories remain parallel throughout retention interval (no evidence for delayed schema consolidation benefits or Von Restorff decay). Wide confidence intervals reflect between-subject variability (σ²_intercept=0.470), but all within-category error bars overlap across timepoints.*

**Figure 5.4.1b:** [trajectory_probability.png](results/ch5/5.4.1/plots/trajectory_probability.png)
*Forgetting trajectories by schema congruence (probability scale, Decision D069 compliance). Y-axis: Probability correct (%): 0 to 100. Horizontal reference line at 50% marks chance performance. Trajectory patterns: Common 61.1%→40.6% (20.5pp decline), Congruent 60.4%→40.2% (20.2pp decline), Incongruent 62.4%→40.2% (22.2pp decline). All three categories show: (1) Similar starting points (60-62% at T1, slightly above chance), (2) Parallel 20-percentage-point decline over 6 days, (3) Near-chance performance at Day 6 (all ≈40%, approaching 33% chance level for 3-option recognition), (4) Overlapping confidence bands (consistent with non-significant statistical differences). Probability scale confirms theta scale findings—schema congruence does NOT modulate forgetting. The 20pp decline demonstrates substantial forgetting with final performance near floor, suggesting memory approaching chance by Day 6 regardless of schema support.*

**Figure 5.4.1c:** [trajectory_averaged_theta.png](results/ch5/5.4.1/plots/trajectory_averaged_theta.png)
*Forgetting trajectories by schema congruence (theta scale, model-averaged predictions from 15 competitive models, added 2025-12-08). Annotation: "15 competitive models (effective N=13.96) - Model-averaged predictions". Effective power-law exponent α≈0.18 (very shallow decay). Visually similar to empirical trajectories (Figure 5.4.1a) but mathematically principled—averaging across power-law (α=0.1-0.3), logarithmic (Log, Log2, Log10), and reciprocal (Recip+PowerLaw) families. Uncertainty bands slightly narrower than empirical (model averaging reduces sampling noise). KEY INSIGHT: The lack of dominant functional form is unique to schema congruence among Chapter 5 ROOT RQs. While the null schema effect (parallel trajectories) is robust across all 15 models, the extreme model diversity (H'=2.71) suggests schema effects may modulate forgetting **complexity** (which mathematical processes compete) rather than just forgetting **rate** (slope magnitude). This functional form ambiguity is itself a substantive finding—schema congruence may introduce heterogeneous forgetting mechanisms that no single model captures adequately.*

---

### 5.4.2 Schema Congruence × Consolidation Window Interactions

**Research Question:** Is the schema congruence effect on forgetting driven by differential consolidation (Day 0-1) or later decay (Day 1-6)?

**Hypothesis:** Congruent items will show less forgetting during the consolidation window (Day 0-1 with one night's sleep) compared to incongruent items, as schema-consistent memories benefit from hippocampal-neocortical dialogue during sleep (Stickgold & Walker, 2013; Rasch & Born, 2013).

**Analysis:** (§4.3.1, §4.3.2, §4.5.1)
Sample: N=100, 1,200 observations (inherited theta scores from RQ 5.4.1). Piecewise LMM segmentation: Early (Days 0-1, consolidation window with one night's sleep) vs Late (Days 1-6, post-consolidation decay). Model: theta ~ Days_within × Segment × Congruence + (1 + Days_within × Segment | UID). Random effects: random intercepts and slopes for Days_within × Segment by participant (allows individual consolidation rates). Primary hypothesis test: 3-way interaction Days_within × Segment × Congruence (tests whether congruent items show differential slopes between Early vs Late segments). Extended analysis: 66-model kitchen sink comparison (continuous TSVR_hours) to test functional form robustness. Bonferroni correction: α=0.05/15≈0.0033. Piecewise model fit: AIC=2581.55, converged successfully.

**Results:**

The hypothesis was **not supported**: Schema congruence did **not** interact with consolidation window timing. The **3-way interaction** Days_within × Segment[Late] × Congruence[Congruent] was nonsignificant (β=-0.018, SE=0.226, z=-0.08, p_uncorrected=.938, p_bonf=1.0), indicating congruent items showed statistically indistinguishable forgetting slopes between Early (0-1 day) and Late (1-6 day) segments compared to common items. Effect magnitude was trivially small (0.018 theta units per day difference)—orders of magnitude below the primary time effect (β=-0.263 Early slope, β=-0.093 Late slope). The null 3-way interaction was **robust across all 66 functional forms** tested in the extended kitchen sink analysis, confirming this is not a model selection artifact.

Segment-specific slopes revealed the expected **two-phase forgetting pattern** (replicating RQ 5.1.2), but **no congruence modulation**. Early segment slopes (Days 0-1): Common β=-0.263 (SE=0.164, n.s.), Congruent β=-0.253 (SE=0.164, n.s.), Incongruent β=-0.320 (SE=0.164, marginal). Late segment slopes (Days 1-6): Common β=-0.093 (SE=0.020, p<.001), Congruent β=-0.101 (SE=0.020, p<.001), Incongruent β=-0.090 (SE=0.020, p<.001). Early forgetting was 2.6-3.2× faster than Late forgetting (slope ratio 0.32-0.38), confirming consolidation deceleration, but this ratio **did not differ by congruence** (all 3-way interaction p>.79). Wide confidence intervals in Early segment (±0.29 theta units) reflected high variability with only 2 timepoints (T1, T2), whereas Late segment CIs were narrow (±0.04 theta units) with 3 timepoints (T2, T3, T4).

**No main effects of Congruence** emerged for either segment (Segment[Late] × Congruence[Congruent]: β=0.094, p=.464; Segment[Late] × Congruence[Incongruent]: β=-0.065, p=.611), indicating baseline performance levels were similar across congruence categories at both Day 0-1 and Day 1-6 timepoints. The primary **Segment main effect** was highly significant (β=-0.387, SE=0.091, z=-4.25, p<.001), confirming that Late segment performance was substantially lower than Early segment (regardless of congruence)—a finding consistent with progressive forgetting over retention interval.

**Extended 66-model comparison** (Step 02b, added 2025-12-08) replicated RQ 5.4.1's **extreme functional form uncertainty**. Best model: PowerLaw_01 (α=0.1, AIC=2593.41, weight=6.04%)—far below 30% certainty threshold. With 15 competitive models (ΔAIC<2) and effective N=13.96 models, model averaging was again mandatory. The competitive model ensemble spanned power-law (α=0.1-0.3, 40% of models), logarithmic (Log/Log2/Log10, 40%), and reciprocal (Recip+PowerLaw, 20%) families with nearly equal weights, confirming schema congruence introduces **temporal complexity** rather than simple rate differences. Effective power-law exponent α_eff=0.181 (if applicable) aligns with Wixted & Ebbesen (1991) recognition memory findings (α≈0.2-0.3). Critically, the null Congruence × Time interaction was **robust across all 15 competitive functional forms**, ruling out the possibility that hypothesis rejection depends on functional form choice.

**Important methodological note:** Piecewise model (AIC=2581.55 with random slopes) cannot be directly compared to continuous kitchen sink models (AIC=2593.41 with random intercepts only) because **random effects structure matters more than functional form**. The ΔAIC=+11.86 difference likely reflects random effects complexity rather than superior piecewise fit. Future comparisons should hold random structure constant across functional forms.

Assumption diagnostics revealed **heteroscedasticity violation** (Levene p<.0001)—variance increased with fitted values (funnel pattern in residual plots). This violation can bias standard errors but typically inflates Type I error, making the null 3-way interaction finding **conservative** (p=.938 far exceeds α=.0033 threshold even if SEs underestimated). Residual normality passed (Shapiro-Wilk p=.394), random effects normality borderline (p=.022), convergence successful.

The null consolidation × congruence interaction has several implications. First, **schema consolidation benefits may be time-limited**: prior evidence for schema-mediated sleep consolidation (Tamminen et al., 2010; Durrant et al., 2013) typically tests immediate post-sleep retention (~12-24h), whereas REMEMVR's Day 1 test occurred 22-26 hours post-encoding when sleep benefits may have dissipated. Second, **VR's rich multimodal encoding** (visual, spatial, motor) may overshadow semantic schema effects—if all items benefit from "strong encoding" regardless of room-congruence, then sleep consolidation processes nothing distinctive to amplify for congruent items. Third, **one night's sleep may be insufficient** to reveal schema effects—some consolidation theories predict cumulative benefits across multiple sleep cycles (Walker & Stickgold, 2010), though REMEMVR's design (one unique room per test day) precluded multi-night tracking of single items.

**Cross-reference:** This null Congruence × Consolidation interaction replicates the pattern from RQ 5.2.2 (null Domain × Consolidation, p=.671) and RQ 5.3.3 (null Paradigm × Consolidation, p>.59), establishing that **consolidation timing effects are additive across contextual factors**. Early forgetting is universally 3-6× faster than late forgetting (RQs 5.1.2, 5.2.2, 5.3.3, 5.4.2), but this deceleration does **not interact** with domain, paradigm, or schema congruence. Together with RQ 5.4.1's null Congruence × Time interaction, these findings suggest **schema effects fail to modulate VR episodic forgetting** at both overall trajectory (5.4.1) and temporal sub-phase (5.4.2) levels—contradicting schema consolidation theory (Ghosh & Gilboa, 2014) but consistent with domain-general forgetting mechanisms (Wixted, 2004).

**Figure 5.4.2:** [piecewise_trajectory.png](results/ch5/5.4.2/plots/piecewise_trajectory.png)
*Piecewise forgetting trajectories by schema congruence (two-panel format: Early segment | Late segment). LEFT PANEL (Days 0-1, consolidation window): X-axis Days 0-1, Y-axis theta -0.4 to 0.6. Three declining lines: Common (gray), Congruent (green), Incongruent (red). Observed means at two timepoints (Day 0, Day 1) with model predictions. Visual patterns: (1) Steep decline—all three congruence types drop substantially from Day 0 to Day 1 (0.2-0.3 theta units). (2) Nearly parallel slopes—lines do not diverge or converge (visual confirmation of non-significant Congruence × Days_within interaction, p>.80). (3) Incongruent starts highest (~0.52) but declines most steeply (β=-0.320), Congruent intermediate (~0.43→0.18), Common moderate (~0.46→0.20). (4) Wide confidence bands reflect high within-segment variability (only 2 timepoints, SE=0.164). RIGHT PANEL (Days 1-6, post-consolidation decay): X-axis Days 0-6 within segment, Y-axis theta -1.2 to 0.5. Same three lines. Observed means at three timepoints (Day 1, 3, 6) with model predictions. Visual patterns: (1) Gradual decline—all three congruence types show shallower slopes than Early segment (0.5-0.6 theta units over 6 days). (2) Parallel trajectories—lines remain equidistant (confirms null 3-way interaction β=-0.018, p=.938). (3) Narrower confidence bands (more precise estimates with 3 timepoints, SE=0.020). (4) Convergence at Day 6—all lines end near θ≈-0.6 (floor effect). KEY INTERPRETATION: Two-phase forgetting pattern replicated (Early 2.6-3.2× faster than Late), but NO differential consolidation benefit for congruent items. Slopes indistinguishable across congruence categories within each segment.*

---

### 5.4.3 Age × Schema Congruence Interactions

**Research Question:** Does the effect of age on forgetting rate vary by schema congruence (common, congruent, incongruent)?

**Hypothesis:** Age × Time effects will be strongest for incongruent items (least schema support) and weakest for congruent items (greatest schema support), as older adults compensate for hippocampal decline by relying on schema-based consolidation.

**Analysis:** (§4.3.1, §4.5.1)
Sample: N=100 (age 20-70 years, grand-mean centered), 1,200 observations (inherited theta scores from RQ 5.4.1, reshaped wide-to-long). Model: Two-process forgetting model (recip_TSVR + log_TSVR) inherited from RQ 5.4.1's best-fitting Recip+Log functional form. Fixed effects: Age_c × Congruence × recip_TSVR + Age_c × Congruence × log_TSVR (all 2-way and 3-way interactions). Random effects: random intercepts + slopes for recip_TSVR by participant (allows individual differences in rapid early forgetting). Primary hypothesis: 3-way interactions Age_c × Congruence × Time significant at Bonferroni α=0.025 (correcting for 2 time processes per Decision D068). Supplementary analysis: Tukey HSD post-hoc contrasts on age slopes at Day 3 midpoint (TSVR=78.67h). Model fit: Log-likelihood=-1300.23, converged successfully.

**Results:**

The hypothesis was **not supported**: Age effects on forgetting rate did **not** vary by schema congruence. All four **3-way interactions** were nonsignificant after Bonferroni correction: Age_c × Congruent × recip_TSVR (β=-0.067, SE=0.044, z=-1.54, p_uncorrected=.124, p_bonf=.249), Age_c × Congruent × log_TSVR (β=-0.007, SE=0.006, z=-1.34, p=.179, p_bonf=.358), Age_c × Incongruent × recip_TSVR (β=0.022, SE=0.044, z=0.51, p=.609, p_bonf=1.0), Age_c × Incongruent × log_TSVR (β=0.004, SE=0.006, z=0.63, p=.526, p_bonf=1.0). Effect sizes were trivially small (|β|<0.07 for all terms). This pattern held for **both forgetting processes**: rapid early decay (reciprocal term, rapid forgetting in first 24h) and slow late decay (logarithmic term, gradual forgetting beyond 24h)—older adults showed similar forgetting patterns for congruent, incongruent, and common items compared to younger adults across the entire retention interval.

Tukey HSD post-hoc contrasts on age effect slopes at Day 3 midpoint confirmed no pairwise differences across congruence levels: Congruent vs Common (β_diff=0.0048, SE=0.0350, p_tukey=1.0), Incongruent vs Common (β_diff=-0.0002, SE=0.0350, p_tukey=1.0), Incongruent vs Congruent (β_diff=-0.0050, SE=0.0427, p_tukey=1.0). Age effect slopes were near-zero for all congruence categories (Common β=-0.0062, Congruent β=-0.0014, Incongruent β=-0.0064), with 95% CIs spanning zero symmetrically, suggesting true age effects are negligible rather than underpowered.

**Main effects** confirmed the two-process forgetting structure inherited from RQ 5.4.1: **rapid early forgetting** (recip_TSVR β=-1.211, SE=0.471, p=.010) dominated initial decline (steep drop Days 0-1), whereas **slow late forgetting** (log_TSVR β=-0.335, SE=0.058, p<.001) characterized sustained decay beyond 24 hours. However, **neither process interacted with age**: Age × recip_TSVR (β=-0.014, p=.661), Age × log_TSVR (β=-0.001, p=.728)—replicating RQ 5.1.3's null age × time finding. **No main effects** emerged for Age (β=-0.0003, p=.989) or Congruence (Congruent β=0.058, p=.872; Incongruent β=-0.084, p=.816), confirming that baseline memory ability did not differ by age or schema congruence at encoding.

Random effects decomposition revealed substantial individual differences in **rapid early forgetting** (σ²_recip_slope=1.389), indicating participants varied dramatically in steep initial decline rates despite showing similar slow late forgetting. This large slope variance (SD=1.18 theta units per reciprocal-day) exceeded baseline variance (σ²_intercept=0.234, SD=0.48), suggesting rapid forgetting is more heterogeneous than baseline ability. However, the negative intercept-slope covariance (Cov=-0.167) indicated participants with higher baseline ability showed **slower** rapid forgetting—a pattern consistent with ceiling effects (high performers have less room to decline steeply). Critically, these individual differences in rapid forgetting were **not moderated by age or schema congruence** (non-significant 3-way interactions), contradicting the hypothesis that older adults rely differentially on schema support.

The null Age × Congruence × Time interaction has several implications. First, **schema-based compensation is not evident in VR episodic memory**: if older adults compensated for hippocampal decline by preferentially relying on neocortical schemas, we would observe steeper age-related forgetting for incongruent items (lacking schema scaffolding) compared to congruent items (schema-supported). The null finding suggests either (1) schemas do not provide differential consolidation scaffolding in immersive VR (extending RQs 5.4.1-5.4.2's null schema effects), or (2) older adults in this sample (age 20-70, healthy) have not yet reached the threshold of hippocampal decline where schema compensation becomes necessary (Park & Festini, 2017 suggest steepest declines emerge after age 75).

Second, **age-invariant forgetting replicates across contextual manipulations**: RQ 5.1.3 found null age × time for omnibus memory, RQ 5.2.3 for domain-specific memory (What/Where/When), RQ 5.3.4 for paradigm-specific memory (Free/Cued/Recognition), and now RQ 5.4.3 for schema-congruence-specific memory. This consistent null pattern across four contextual levels suggests **VR's rich multimodal encoding** (visual, spatial, motor, semantic) provides such robust environmental support that age-related declines are masked across all encoding contexts—aligning with context-supported memory theory (Craik & Rose, 2012).

Third, **two-process forgetting structure is age-invariant**: the Recip+Log model revealed rapid early decay (β=-1.21, reciprocal term) and slow late decay (β=-0.34, logarithmic term), but **both processes showed identical age effects** (Age × recip p=.66, Age × log p=.73). If older adults showed selective deficits in consolidation-dependent slow forgetting (Hardt et al., 2013), we would observe significant Age × log_TSVR interactions—but slopes were parallel across ages for both processes. This suggests age-invariant forgetting extends to both **transient rapid decay** (likely reflecting interference or trace degradation) and **persistent slow decay** (likely reflecting consolidation failures).

**Cross-reference:** This null Age × Congruence interaction converges with RQ 5.4.1's null Congruence × Time (p>.44) and RQ 5.4.2's null Congruence × Consolidation (p=.938) to establish that **schema congruence fails to modulate VR episodic forgetting** across three levels of analysis: overall trajectories (5.4.1), temporal sub-phases (5.4.2), and individual differences (5.4.3). Together with null age × time findings across omnibus (5.1.3), domain (5.2.3), paradigm (5.3.4), and now schema (5.4.3) levels, these results suggest **VR memory follows universal forgetting laws** (power-law or logarithmic decay) that are robust to age, context, and semantic structure—challenging schema consolidation theory (Ghosh & Gilboa, 2014) but supporting domain-general forgetting mechanisms (Wixted, 2004).

**Figure 5.4.3:** [age_congruence_trajectories.png](results/ch5/5.4.3/plots/age_congruence_trajectories.png)
*Age × schema congruence trajectories (three-panel format: Young | Middle | Older adults). Each panel shows X-axis hours since VR encoding (0-160h), Y-axis memory ability (theta -0.75 to 1.00), with three congruence lines: Common (gray), Congruent (green), Incongruent (red), plus 95% confidence bands. LEFT PANEL (Young, age≤33rd percentile): All three congruence lines start high (~θ=0.7 at encoding), show steep initial drop Days 0-1 (rapid forgetting process), then gradual decline Days 1-6 (slow forgetting process), ending near θ=-0.3 at Day 6. Lines nearly parallel throughout retention interval (visual confirmation of non-significant Age × Congruence × Time interaction). MIDDLE PANEL (Middle, age 33rd-67th percentile): Trajectories start lower (~θ=0.4), show identical two-process forgetting pattern, lines overlap almost perfectly (strongest null evidence). RIGHT PANEL (Older, age>67th percentile): Start similar to middle adults (~θ=0.3-0.4), parallel decline, widest confidence bands (smaller N=33 + greater variance). KEY PATTERNS: (1) Parallel trajectories within each age panel—no systematic ordering Congruent>Common>Incongruent, lines cross frequently, extensive CI overlap (all p_bonf>.025). (2) Two-process forgetting visible—steep-then-shallow curves match Recip+Log model structure (recip_TSVR β=-1.21, log_TSVR β=-0.34). (3) Age differences in baseline only—Young start highest, Older start lowest, but forgetting RATES similar across ages (no convergence over time). (4) Schema congruence non-differentiation—no consistent pattern that congruent items retain better or incongruent items forget faster, regardless of age group. Annotation: "No significant Age × Congruence × Time interactions (all p_bonf > 0.025)" communicates null hypothesis finding. Visual perfectly aligns with statistical results—parallelism confirms non-significant 3-way interactions, overlapping CIs confirm p_tukey=1.0 for all pairwise contrasts.*

---

### 5.4.4 IRT-CTT Convergence for Schema Congruence Effects

**Research Question:** Do IRT theta scores and CTT mean scores yield the same conclusions about congruence-specific forgetting trajectories?

**Hypothesis:** IRT and CTT should converge with (1) r > 0.70 for all congruence levels, (2) Cohen's kappa > 0.60 for LMM fixed effects, (3) Agreement ≥80% on substantive conclusions, (4) Comparable model fit (ΔAIC < 4).

**Analysis:** (§4.2.1, §4.3.1)
Sample: N=100, 1,200 observations (400 participant-test combinations × 3 congruence levels: Common, Congruent, Incongruent). IRT scores: Theta estimates from RQ 5.4.1 two-pass GRM calibration (50/72 purified items). CTT scores: Proportion correct on same 50 items. Convergence metrics: (1) Pearson correlations IRT-CTT by congruence level with Holm-Bonferroni correction, (2) Cohen's kappa on LMM fixed effect significance agreement, (3) Percent agreement on 9 model terms, (4) AIC comparison. Model: Two-process forgetting (recip_TSVR + log_TSVR) × Congruence inherited from RQ 5.4.1's Recip+Log ROOT model, with random slopes for recip_TSVR by participant (allows individual differences in rapid early forgetting).

**Results:**

The hypothesis was **strongly supported** (3/4 criteria met): IRT and CTT demonstrated robust methodological convergence for schema congruence effects. **Pearson correlations** exceeded r=0.70 for all congruence levels: Common r=0.875 (95% CI [0.850, 0.896], p<.001), Congruent r=0.882 (95% CI [0.859, 0.902], p<.001), Incongruent r=0.907 (95% CI [0.888, 0.923], p<.001), Overall r=0.874 (95% CI [0.860, 0.886], p<.001). All correlations remained highly significant after Holm-Bonferroni correction. Notably, **Incongruent items showed highest correlation** (r=0.91, exceptional convergence)—possibly because schema-violating items have clearer success/failure boundaries, reducing CTT measurement error relative to ambiguous Common items.

**Cohen's kappa agreement** on LMM fixed effects was perfect: κ=1.000 (100% agreement on 9/9 model terms comparing IRT vs CTT significance decisions), far exceeding the 0.60 threshold. This indicates IRT and CTT yield **identical substantive conclusions** about which effects are statistically significant—both measurement approaches agreed that (1) rapid early forgetting (recip_TSVR) and slow late forgetting (log_TSVR) were highly significant (p<.001), (2) Congruence main effects were nonsignificant (p>.80), and (3) all Congruence × Time interactions were nonsignificant (p>.40), replicating RQ 5.4.1's null schema effect findings. This perfect kappa (Landis & Koch, 1977: "almost perfect agreement") demonstrates that conclusions about schema congruence effects on forgetting are **robust to measurement approach**.

**Model fit comparison** revealed an unexpected deviation: ΔAIC=-3607 (CTT vastly superior to IRT), far exceeding the expected ΔAIC<4 threshold. However, this deviation does **not** invalidate convergence—it likely reflects a psychometric artifact rather than substantive disagreement. CTT's bounded [0,1] scale better satisfies LMM's normality assumption (residuals cluster near 0.5, symmetric tails) compared to IRT's unbounded theta scale (residuals can extend to ±∞, violating normality). Since both models **converged successfully** with identical random effects structure (~recip_TSVR | UID) and yielded **identical fixed effect conclusions** (κ=1.0), the AIC difference reflects measurement scaling rather than conflicting substantive findings. Future methodological work should explore logit-transformed CTT scores to equate scale properties with IRT theta.

**Forgetting trajectory patterns** were visually identical across measurement approaches. IRT theta scale: all three congruence levels showed ~0.7 SD decline over 6 days (Common θ=0.4→-0.3, Congruent θ=0.5→-0.2, Incongruent θ=0.2→-0.5), with monotonic decline and parallel slopes. CTT proportion scale: all showed 12-16 percentage point declines (Common 67%→55%, Congruent 74%→58%, Incongruent 65%→50%), with identical patterns of Congruent highest, Incongruent lowest, Common intermediate, and parallel forgetting rates. The scatterplot (Figure 5.4.4a) revealed strong linear IRT-CTT relationships with tight clustering for Incongruent items (r=0.91) and slightly wider scatter for Common/Congruent items (r=0.87-0.88), confirming that both measurement approaches **capture the same underlying forgetting process**.

A critical methodological insight emerged: **CTT's practical interpretability advantage**. While IRT theta provides psychometrically rigorous latent ability estimates, the unbounded scale (θ ∈ [-∞, +∞]) complicates interpretation for non-psychometricians. CTT proportion correct (0-100%) offers immediate interpretability: "Performance declined from 74% to 58% for congruent items" is more intuitive than "Theta declined from 0.5 to -0.2 SD units." Given the perfect kappa agreement (substantive conclusions identical) and exceptional correlations (r>0.87), **CTT may be preferable for communication** to clinical or applied audiences, reserving IRT for contexts requiring precision measurement (e.g., adaptive testing, item-level diagnostics). This aligns with Decision D069's dual-scale reporting recommendation—present both theta (psychometric rigor) and probability/proportion (practical clarity) trajectories.

**Cross-reference:** This IRT-CTT convergence replicates findings from RQ 5.2.4 (domain-level r>0.90) and RQ 5.3.5 (paradigm-level r=0.84-0.88, κ=0.667), establishing that **convergence holds across contextual manipulations** (domain, paradigm, schema). However, RQ 5.4.4 shows **highest convergence** (κ=1.000 vs 0.667 paradigm, 100% vs 83% agreement)—possibly because schema congruence effects are weaker (null interactions), reducing measurement sensitivity demands and making IRT-CTT agreement easier to achieve. The perfect kappa also confirms RQ 5.4.1's null schema findings are **not measurement artifacts**—both IRT and CTT independently conclude Congruence × Time interactions are nonsignificant, strengthening confidence in null hypothesis acceptance. This convergence pattern supports using **either measurement approach** for schema congruence research, with CTT preferred when practical interpretability outweighs psychometric precision needs.

**Figure 5.4.4a:** [scatterplot_irt_ctt.png](results/ch5/5.4.4/plots/scatterplot_irt_ctt.png)
*IRT-CTT scatterplot by congruence level. X-axis: IRT theta scores (-2.5 to 2.5), Y-axis: CTT proportion correct (0.0 to 1.0). 1,200 observations (100 participants × 4 tests × 3 congruence levels) color-coded: Common (red), Congruent (blue), Incongruent (green). Dashed regression lines with 95% confidence bands. KEY PATTERNS: (1) Strong linear relationships—all congruence levels show tight clustering around regression lines (r=0.875-0.907), confirming IRT-CTT convergence. (2) Incongruent highest correlation—green points (r=0.91) show tightest clustering and steepest slope, likely because schema-violating items have clearer success/failure boundaries. (3) Congruent highest trajectory—blue points shifted upward (schema support yields higher performance on both scales). (4) Common intermediate, Incongruent lowest—red and green points maintain consistent vertical ordering throughout theta range. (5) CTT bounded [0,1] creates slight compression at extremes—scatter widens near 0% and 100% (floor/ceiling effects), tighter in 30-70% midrange. (6) Measurement error visible at low theta—scatter increases for θ<-1.5 (low ability participants), reflecting reduced item information at distribution tails per IRT information curves.*

**Figure 5.4.4b:** [trajectory_comparison.png](results/ch5/5.4.4/plots/trajectory_comparison.png)
*Side-by-side trajectory comparison (dual-panel: IRT left, CTT right). LEFT PANEL (IRT theta): X-axis time 0-250 hours, Y-axis theta -2.5 to 2.5. Three congruence trajectories (Common red, Congruent blue, Incongruent green) with faded scatter (1,200 observations) and 95% CI bands. Patterns: Monotonic decline all levels (~0.7 SD over 6 days), Congruent highest throughout, Incongruent lowest, parallel slopes (similar forgetting rates), confidence bands widen over time. RIGHT PANEL (CTT proportion): Same time axis, Y-axis proportion 0-100%. Identical color coding. Patterns: 12-16 percentage point declines, same congruence hierarchy (Congruent>Common>Incongruent), parallel slopes, all end above chance (50%>33% for 3-option forced choice). KEY INSIGHT: **Visual confirmation of convergence**—left and right panels show identical forgetting trajectory shapes, congruence hierarchies, and temporal dynamics despite different measurement scales. This fulfills Decision D069 dual-scale reporting requirement and demonstrates that substantive conclusions (null Congruence × Time interactions, RQ 5.4.1) are **robust to measurement approach**. CTT panel provides practical interpretability ("Performance declined from 74% to 58%") while IRT panel maintains psychometric precision (latent ability estimates).*

---

### 5.4.5 Purification Paradox for Schema Congruence

**Research Question:** If we compute CTT scores using only IRT-retained items (post-purification), do conclusions differ from full-item CTT for congruence?

**Hypothesis:** Purified CTT will show higher correlation with IRT theta (Δr~+0.02) compared to full CTT, and yield better LMM fit (lower AIC), demonstrating that item purification removes measurement noise.

**Analysis:** (§4.2.1, §4.2.2, §4.3.1)
Sample: N=100, 400 observations, 3 congruence levels (Common, Congruent, Incongruent). CTT scores computed separately for Full (~24 items per dimension) and Purified (IRT-retained items: Common 19/24=79%, Congruent 18/24=75%, Incongruent 13/24=54%). Convergence analysis: (1) Cronbach's alpha reliability comparison, (2) Pearson correlations IRT-CTT with Steiger's z-test for dependent correlations (Bonferroni α=0.0167 for 3 comparisons, Decision D068), (3) LMM model fit comparison (Recip+Log two-process forgetting model inherited from RQ 5.4.1, AIC criterion). Random effects: random intercepts only (random slopes failed convergence, singular matrix).

**Results:**

The hypothesis was **partially supported** for correlations but **not supported** for model fit, replicating the **purification-trajectory paradox** observed in RQ 5.2.5 for domains. **Correlation analysis** showed purified CTT converged more strongly with IRT theta for 2/3 congruence levels: Congruent Δr=+0.096 (r_Full=0.786 → r_Purified=0.882, Steiger's z=-4.869, p_bonf<.001), Incongruent Δr=+0.108 (r_Full=0.799 → r_Purified=0.907, Steiger's z=-4.010, p_bonf<.001). Common showed numerical improvement (Δr=+0.022, r_Full=0.853 → r_Purified=0.875) but failed to reach significance (Steiger's z=-1.466, p_bonf=.428). All correlations exceeded r>0.70 adequacy threshold. The largest improvement occurred for **Incongruent items** (Δr=+0.108)—consistent with their lowest retention rate (54.2% vs 75-79% for Congruent/Common), suggesting purification removed disproportionately poor items from the Incongruent dimension.

**Reliability analysis** confirmed purification benefits: Cronbach's alpha increased for all dimensions (Common Δα=+0.022, Congruent Δα=+0.022, Incongruent Δα=+0.063), with Incongruent again showing largest gains (α_Full=0.639 → α_Purified=0.702, 95% CI [0.660, 0.736]). This 0.063 alpha improvement reflects substantial noise reduction achieved by removing 11/24 (46%) of Incongruent items flagged as psychometrically irregular (a<0.4 or |b|>3.0). The **differential retention pattern** (Incongruent 54%, Congruent 75%, Common 79%) suggests schema-violating items are more difficult to calibrate reliably—possibly because participants apply inconsistent encoding strategies when confronting unexpected item-room pairings, inflating item parameter estimation errors.

However, **LMM model fit** showed the **opposite pattern**: purified CTT yielded **worse or tied** fit for all dimensions (Common ΔAIC=+19.0 favoring Full, Congruent ΔAIC=+38.2 favoring Full, Incongruent ΔAIC=+0.4 essentially tied). This finding directly **contradicts the secondary hypothesis** that purification improves longitudinal trajectory modeling. Notably, updating functional form from original Log model to Recip+Log two-process forgetting (per RQ 5.4.1 ROOT cascade) **strengthened the paradox**: Common ΔAIC worsened +1.8 (from +17.2 to +19.0), Congruent worsened +3.0 (from +35.2 to +38.2), Incongruent reversed from marginally favoring Purified (ΔAIC=-2.0) to tied (+0.4). This robustness across functional forms confirms the paradox is **not a model selection artifact**.

The **purification-trajectory paradox** has the same mechanistic explanation as RQ 5.2.5's domain-level finding: **cross-sectional psychometrics ≠ longitudinal dynamics**. Items flagged as "poor quality" by IRT (low discrimination, extreme difficulty) based on **static cross-sectional calibration** at single timepoints may nonetheless capture **temporally-sensitive variance** useful for modeling forgetting trajectories. The item heterogeneity hypothesis posits that Full CTT's broader item pool samples more aspects of forgetting—including items that vary differentially across retention intervals despite having weak overall correlation with latent ability. Removing these items via purification **improves static measurement precision** (higher r, higher α) but **degrades dynamic tracking** (worse AIC in longitudinal LMM).

A critical methodological implication emerged: **purification criteria should be retention-interval-specific** when the research goal is longitudinal trajectory modeling rather than cross-sectional ability estimation. The current purification protocol (Decision D039: a≥0.4, |b|≤3.0) applies uniform thresholds across all 4 test sessions (Days 0, 1, 3, 6), flagging items whose **average** psychometric quality is poor. However, an item may have excellent discrimination at Day 0 (high a, captures encoding variance) but poor discrimination at Day 6 (low a, floor effects obscure ability differences)—such items would be flagged as "poor" despite being highly informative for early trajectory segments. Future work should explore **time-varying purification**, retaining items that meet criteria for at least 2 of 4 test sessions.

**Cross-reference:** This purification paradox **replicates RQ 5.2.5's domain-level findings** (CTT purification improved correlations but worsened LMM fit for What/Where/When domains), establishing the pattern is **robust across contextual levels** (domain, schema congruence). The paradox also aligns with RQ 5.3.6's paradigm-level purification findings (Free Recall showed Δr=+0.098 improvement, ΔAIC=-33.4 worsening). Together, RQs 5.2.5, 5.3.6, and 5.4.5 converge on a **universal methodological principle**: IRT purification optimizes static measurement validity but may **degrade** longitudinal trajectory modeling when removed items contain retention-interval-specific information. This suggests **different item sets may be optimal** for cross-sectional assessment (purified, high α, high r) versus longitudinal tracking (full, preserves temporal heterogeneity).

**Figure 5.4.5a:** [correlation_comparison.png](results/ch5/5.4.5/plots/correlation_comparison.png)
*CTT-IRT correlation by congruence level. Grouped bar chart showing Pearson correlations for Full CTT (blue bars) vs Purified CTT (orange bars) across three dimensions: Common, Congruent, Incongruent. Y-axis r=0.65-0.95, horizontal dashed line marks r=0.70 adequacy threshold. Asterisks indicate Bonferroni-significant improvements (*p<.0167). KEY PATTERNS: (1) All correlations exceed 0.70 (both Full and Purified show adequate convergence). (2) Purified consistently higher—orange bars taller than blue for all dimensions. (3) Congruent and Incongruent marked with asterisks (significant Δr=+0.096, +0.108 respectively). (4) Common shows "ns" (numerical improvement Δr=+0.022 but p_bonf=.428). (5) Largest improvement for Incongruent (blue=0.799 → orange=0.907), consistent with highest item removal rate (46% purified). Visual confirms primary hypothesis partial support: purification improves psychometric convergence for schema-consistent and schema-violating items.*

**Figure 5.4.5b:** [aic_comparison.png](results/ch5/5.4.5/plots/aic_comparison.png)
*LMM model fit (AIC) by congruence level. Grouped bar chart showing AIC for Full CTT (blue) vs Purified CTT (orange) across three dimensions. Y-axis AIC 0-1100 (lower=better), green annotations indicate which CTT type has superior fit. KEY PATTERNS: (1) Common: Full better (blue=1055.2 < orange=1074.2), ΔAIC=+19.0 labeled. (2) Congruent: Full MUCH better (blue=1043.9 << orange=1082.1), ΔAIC=+38.2 labeled (largest difference). (3) Incongruent: Essentially tied (blue=1057.0 ≈ orange=1057.3), ΔAIC=+0.4. (4) Green text "Full better" for Common/Congruent highlights counterintuitive finding. (5) All orange bars taller or tied (purified never wins). Visual confirms secondary hypothesis rejection and purification-trajectory paradox: despite better correlations (Figure a), purified CTT yields worse longitudinal trajectory fit. Paradox robust across all three congruence levels (ΔAIC range +0.4 to +38.2, no cases favoring purified).*

---

### 5.4.6 Schema-Specific Variance Decomposition

**Research Question:** What proportion of variance in forgetting rate is between-person versus within-person for each congruence level (Common, Congruent, Incongruent)?

**Hypothesis:** Substantial between-person variance exists in forgetting rate within each congruence level (ICC for slopes > 0.40), indicating forgetting rate is a stable, trait-like individual difference. Congruent items show highest ICC, Incongruent lowest, Common intermediate.

**Analysis:** (§4.3.1, §4.4.2)
Sample: N=100, 1,200 observations (inherited theta scores from RQ 5.4.1, reshaped wide-to-long). Variance decomposition: LMM with random intercepts and slopes by participant, stratified by congruence level. **Model averaging approach** (added 2025-12-09): RQ 5.4.1 revealed extreme functional form uncertainty (best model weight 6.0% << 30% threshold, 15 competitive models ΔAIC<2). Per Burnham & Anderson (2002), model averaging MANDATORY. Averaged across 6 competitive models (PowerLaw_01/02, Log/Log2/Log10, SquareRoot) with renormalized weights, effective N=5.94 models. ICC estimates: ICC_intercept (baseline variance), ICC_slope_simple (unconditional forgetting rate variance), ICC_slope_conditional at Day 6 (time-varying ICC accounting for intercept-slope covariance).

**Results:**

The hypothesis was **partially rejected** with an important methodological reversal: **Common items showed highest ICC** (opposite to predictions). Model-averaged ICC_slope_simple estimates: Common=0.148 (low-moderate, 14.8% between-person variance), Congruent=0.078 (low, 7.8%), Incongruent=0.036 (very low, 3.6%). **No congruence level exceeded the 0.40 "substantial" threshold**, indicating forgetting rates are primarily situation-dependent rather than trait-like. However, all ICCs significantly exceeded zero (contrast with Log-only analysis showing ICC≈0.000), confirming forgetting rate reflects **both stable traits AND situational factors**—a critical nuance missed by single-model analysis.

The **ranking Common > Congruent > Incongruent was OPPOSITE** to hypothesis (expected Congruent > Common > Incongruent). This reversal has theoretical implications: **schema processing compresses individual differences** rather than amplifying them. Common (schema-neutral) items maximize trait expression (ICC=0.148)—without schema scaffolding or interference, forgetting reflects stable cognitive traits like consolidation efficiency and retrieval strategy, allowing maximal individual variation. Congruent items showed **lower ICC (0.078) than Common (0.148)** due to **ceiling effects**: schema support creates homogenization where all participants benefit equally from schema scaffolding, making congruent memory more situation-dependent (schema availability) and less trait-dependent. Incongruent items showed **lowest ICC (0.036)** due to **floor effects**: schema violation creates universal rapid forgetting with no stable individual differences in susceptibility to schema interference.

**Variance components** revealed striking differences: var_slope ranged from 0.083 (Common) to 0.016 (Incongruent), a 5.2-fold difference in slope variance across congruence levels. Intercept-slope covariances showed **opposing patterns**: Common/Congruent exhibited negative covariances (-0.028, -0.012), indicating higher baseline performers showed **faster forgetting** (ceiling regression artifact, replicating RQs 5.2.6, 5.3.7), whereas Incongruent showed **positive covariance (+0.015)**, where higher baseline performers showed **slower forgetting**—possibly because high-ability participants apply effective encoding strategies even to schema-violating items, partially mitigating interference effects.

**A critical methodological discovery emerged: functional form choice determines trait conclusions.** Comparison with original Log-only analysis (2025-12-03) revealed model averaging **increased ICC_slope estimates by 4,500-9,250×** (Common: 0.000016→0.148, Congruent: 0.000016→0.078, Incongruent: 0.000008→0.036). The Log model **missed 85-95% of true slope variance** because logarithmic decay assumes homogeneous forgetting rates (all participants follow same curve, differing only in intercepts), whereas power-law and fractional-exponent models allow heterogeneous decay exponents (participants differ in slope steepness). This demonstrates that **single-model analysis severely underestimates trait stability** when true functional form is uncertain—a finding with profound implications for individual differences research.

**ICC_slope_conditional** at Day 6 showed high stability (Common=0.897, Incongruent=0.768, Congruent=0.507), indicating **end-of-study performance is highly reliable** despite modest slope ICC. This apparent paradox reflects the intercept-slope covariance structure: participants with higher baselines show faster declines (Common/Congruent), but because baseline differences are large (ICC_intercept=0.13-0.30) relative to slope differences (ICC_slope=0.04-0.15), **rank-ordering is preserved** at Day 6. Practically, this suggests REMEMVR could use **Day 0 + Day 6 testing** (omitting Days 1, 3) to capture both encoding ability and retention outcome while minimizing participant burden, though intermediate timepoints remain valuable for trajectory characterization.

**Cross-reference:** This schema-level variance decomposition extends RQ 5.2.6 (domain ICC: What 51.8%, Where 53.1%, When varied) and RQ 5.3.7 (paradigm ICC_simple 0.00-0.02) to reveal **contextual modulation of trait expression**. Across three contextual levels, forgetting rates show **low-to-moderate trait stability** (ICC_slope range 0.00-0.15), substantially below the 0.40 threshold for "substantial" trait variance. This pattern suggests **VR episodic forgetting is primarily state-dependent** (encoding quality, retrieval context, schema availability) rather than trait-driven (stable individual capacity), challenging trait-based memory assessment models. However, RQ 5.4.6's finding that Common items show 14.8% trait variance (vs 0-2% for paradigms, RQ 5.3.7) indicates **item selection matters**: removing schema support unmasks stable individual differences, whereas strong contextual cues (retrieval paradigms, schema congruence) homogenize performance.

**Figure 5.4.6:** [icc_comparison_barplot.png](results/ch5/5.4.6/plots/icc_comparison_barplot.png)
*ICC comparison by congruence level (grouped bar chart: 3 ICC types × 3 congruence levels). Y-axis ICC 0.0-1.0, horizontal reference lines at 0.20 (moderate) and 0.40 (substantial). Three bar groups per congruence level: ICC_intercept (blue), ICC_slope_simple (red), ICC_slope_conditional Day 6 (green). KEY PATTERNS: (1) ICC_slope_simple (RED, primary hypothesis test)—all bars below 0.40 threshold (hypothesis rejected), ranking Common (0.148) > Congruent (0.078) > Incongruent (0.036), OPPOSITE to predicted Congruent > Common > Incongruent ordering. (2) ICC_intercept (BLUE, baseline variance)—moderate levels 0.13-0.30, ranking Common (0.297) > Incongruent (0.270) > Congruent (0.132), indicating schema-neutral items show highest baseline stability. (3) ICC_slope_conditional (GREEN, Day 6 outcome)—high levels 0.51-0.90, ranking Common (0.897) highest, Incongruent (0.768) intermediate, Congruent (0.507) lowest, demonstrating end-of-study performance highly reliable despite modest slope ICC. (4) Schema compression visible—Congruent shows LOWEST ICCs across all types (blue/red/green all shortest bars), confirming schema support homogenizes performance. (5) Incongruent paradox—lowest slope ICC (red=0.036, floor effect) but moderate intercept ICC (blue=0.270) and high conditional ICC (green=0.768), suggesting schema violation affects trajectory variance more than baseline/outcome variance. Visual confirms key finding: forgetting rates are LOW-TO-MODERATE trait-like (red bars 0.04-0.15, below 0.40), with Common items maximizing trait expression (tallest red bar).*

---

### 5.4.7 Schema-Based Clustering of Forgetting Trajectories

**Research Question:** Can participants be grouped into latent classes based on congruence-specific forgetting trajectories (intercepts and slopes for Common, Congruent, and Incongruent items)?

**Hypothesis:** Exploratory analysis expected 2-4 latent profiles with possible schema-selective patterns: poor memory for incongruent items only, strong versus weak schema benefit, or uniform high/medium/low profiles.

**Analysis:** (§4.6)
Sample: N=100 participants. Clustering variables: 6 random effects from RQ 5.4.6 (intercept and slope for Common, Congruent, Incongruent dimensions), z-scored for equal feature weighting. K-means clustering: random_state=42, n_init=50, tested K=1-6. Model selection: BIC minimum identifies optimal K. Quality metrics: Silhouette coefficient (cohesion, threshold 0.40), Davies-Bouldin index (separation, threshold <1.50), Bootstrap Jaccard coefficient (stability, threshold 0.75, B=100 iterations). Cluster size guideline: minimum 10% of sample (N≥10).

**Results:**

The hypothesis was **partially supported** (uniform profiles present) but **not supported** for schema-selective patterns. BIC model selection identified **K=6 optimal** (BIC=44.73), exceeding the expected 2-4 profiles. However, **clustering quality was weak**: Silhouette=0.254 (below 0.40 threshold, indicating weak cohesion), Jaccard=0.592 (below 0.75 threshold, indicating 41% of participants shift clusters across bootstrap resampling), though Davies-Bouldin=1.088 passed separation criterion (<1.50). Cluster sizes: C0=22%, C1=17%, C2=15%, C3=22%, C4=18%, C5=6%—with C5 falling below the 10% minimum guideline, suggesting potential overfitting. Notably, **BIC minimum occurred at the upper boundary** of tested range (K=6), with monotonic decrease across K=1-6, indicating K=7+ might improve fit—a methodological concern suggesting the stopping rule was arbitrary rather than data-driven.

The **critical finding**: all clusters differentiated by **intercepts only** (baseline memory), **not slopes** (forgetting rates). Random effects slope ranges were near-zero for all congruence dimensions (Common: -0.00054 to +0.00041, Congruent: -0.00040 to +0.00039, Incongruent: -0.00034 to +0.00083), consistent with RQ 5.4.6's finding of ICC_slope≈0.000 (zero between-participant slope variance). This means the 6 clustering features (3 intercepts + 3 slopes) effectively reduced to **3 features** (intercepts only), with slopes contributing no discriminative information. Clusters represented **vertical stratification** by overall memory ability: High clusters (C0, C4, C5) showed above-average intercepts (+0.18 to +0.62 theta), Medium cluster (C3) near-zero intercepts (population average), Low clusters (C1, C2) below-average intercepts (-0.22 to -0.54 theta).

**No schema-selective profiles emerged**—the most theoretically important NULL finding. All clusters showed **identical congruence ordering**: Common≈Congruent (near-equal, slightly above population average) > Incongruent (consistently below), differing only by **vertical shift** (overall ability level) rather than **congruence-specific patterns**. This absence of schema-selective clustering is a **meaningful negative result**: if some individuals showed poor memory specifically for schema-violating items (low Incongruent, preserved Common/Congruent) or differential schema benefit (large vs small congruence effects), distinct profiles would emerge. The null finding suggests schema congruence effects are **homogeneous across individuals**—a universal property of episodic memory architecture rather than a strategic skill varying by person. This contrasts with RQ 5.2.7's domain clustering (K=4, partial domain dissociation in C2) and aligns with RQ 5.3.8's paradigm clustering (K=3, no paradigm-selective profiles), establishing that **contextual effects are additive** (shift performance uniformly) rather than **multiplicative** (interact with individual traits).

The **weak clustering quality** (Silhouette=0.254, Jaccard=0.592) has important implications. Silhouette=0.254 falls barely above the 0.25 "no structure" threshold, indicating clusters overlap substantially—visible in scatter matrix plots where points intermingle across all pairwise combinations. Jaccard=0.592 indicates **bootstrap instability**: 41% of participants change cluster membership across resampling iterations, suggesting cluster boundaries are fuzzy rather than discrete. This instability likely reflects **gradations along a single continuum** (overall memory ability) rather than distinct latent classes—K-means forcibly partitions continuous variation into discrete bins, creating artificial boundaries. The Davies-Bouldin index (1.088, passing <1.50) indicates acceptable centroid separation despite weak cohesion, but this merely confirms clusters are **non-overlapping on average** rather than **robustly distinct**.

**Comparison with domain and paradigm clustering** reveals a consistent pattern of **baseline-driven, context-independent clustering**. RQ 5.2.7 (domains): K=4, Silhouette=0.352, Jaccard=0.871, partial dissociation but baseline-driven. RQ 5.3.8 (paradigms): K=3, Silhouette=0.367, Jaccard=0.714, no paradigm selectivity, baseline-driven. RQ 5.4.7 (schema): K=6, Silhouette=0.254, Jaccard=0.592, no schema selectivity, baseline-driven. Schema clustering shows **weakest quality** (lowest Silhouette, lowest Jaccard) and **highest K** (most fragmented solution), suggesting schema effects provide **minimal individual differences structure** compared to domains or paradigms. This ranking aligns with RQ 5.4.6's finding that schema congruence compresses individual differences (Common ICC=14.8%, Congruent ICC=7.8%, Incongruent ICC=3.6%)—weaker trait variance yields weaker clustering.

**Cross-reference:** Together, RQs 5.2.7, 5.3.8, and 5.4.7 establish that **VR episodic memory clustering is uniformly baseline-driven** across all contextual manipulations (domain, paradigm, schema). No contextual level reveals robust latent classes with selective deficits or differential contextual benefits. This convergent null pattern challenges discrete phenotype models of memory (e.g., "recollection-impaired" vs "familiarity-impaired" subgroups) and supports **dimensional models** where individuals vary continuously in overall encoding/consolidation efficiency without qualitative strategy differences. Practically, REMEMVR assessment can use **total score** (omnibus baseline) for individual differences rather than profile analysis (context-specific patterns), simplifying interpretation while preserving psychometric validity.

**Figure 5.4.7:** [cluster_profiles.png](results/ch5/5.4.7/plots/cluster_profiles.png)
*Schema-based cluster profiles (grouped bar chart: 6 clusters × 3 congruence dimensions). Y-axis: baseline memory intercepts (original theta scale -0.6 to 0.8), X-axis: six clusters color-coded by overall ability (High C0/C4/C5 blue/purple/brown, Medium C3 red, Low C1/C2 orange/green). Three bars per cluster: Common (leftmost), Congruent (middle), Incongruent (rightmost). Subtitle: "(Baseline Memory Performance) - Slopes ≈ 0" indicates slope bars omitted due to zero slope variance. KEY PATTERNS: (1) Vertical stratification—clusters differ in overall height (baseline ability), not congruence-specific patterns. High clusters show intercepts +0.18 to +0.62 (above average), Medium cluster ≈0 (population average), Low clusters -0.22 to -0.54 (below average). (2) **Identical congruence ordering**—ALL clusters show Common≈Congruent (nearly equal bars), both higher than Incongruent (shortest bar), just vertically shifted by overall ability. (3) **No schema-selective profiles**—NO cluster shows high Common but low Incongruent, or large versus small congruence differences. All clusters maintain proportional spacing between congruence levels. (4) Intercept-only differentiation—slope bars would be ≈0 if plotted (all slope random effects near-zero, RQ 5.4.6 ICC_slope=0.00-0.15). (5) C5 smallest (N=6, 6%, brown bars) barely visible, below 10% guideline. Visual confirms clustering reflects high/medium/low overall memory ability (vertical dimension) with NO schema-specific heterogeneity (horizontal dimension). Absence of differential congruence patterns is meaningful NULL: schema effects are homogeneous universal properties, not strategic skills varying by person.*

---

**END OF §5.4 (Encoding Factors and Schema Effects)**

---

## 5.5 Consolidation and Sleep-Dependent Memory

Memory consolidation—the stabilization of initially labile memory traces—unfolds across hours to days following encoding. Systems consolidation theory (Squire & Alvarez, 1995) posits that episodic memories initially depend on hippocampal-cortical networks before gradual transfer to distributed cortical representations. Sleep-dependent consolidation (Diekelmann & Born, 2010) specifically implicates slow-wave sleep (SWS) in this process through hippocampal-cortical reactivation. The temporal dynamics of consolidation predict non-linear forgetting trajectories: rapid loss during early labile phases (first 24-48 hours) followed by stabilization as memories consolidate. However, consolidation effects may be domain-specific (What/Where/When), modulated by encoding factors (schema congruence), or vary across individual difference factors (age, sleep quality). Furthermore, different spatial memory components—source locations (pick-up) versus destination locations (put-down)—may consolidate differentially due to attentional and goal-directed encoding differences during initial learning. This section examines whether consolidation processes manifest in observable trajectory inflections, whether they interact with memory content dimensions, and whether individual variation in sleep quality predicts retention outcomes.

---

### 5.5.1 Source vs Destination Spatial Memory Trajectories

**Research Question:** Do pick-up locations (source) and put-down locations (destination) show different forgetting trajectories in VR episodic spatial memory?

**Hypothesis:** Source memory will show higher accuracy than destination memory across all timepoints (main effect). Additionally, destination memory may show steeper forgetting than source memory across 6 days (interaction effect).

**Analysis:** (§4.2.1, §4.2.2, §4.3.1, §4.3.2, §4.5.1)
Sample: N=100, 800 observations (100 participants × 4 sessions × 2 location types). Location types: Source (pick-up locations, N=18 items from IFR/ICR/IRE paradigms), Destination (put-down locations, N=18 items). IRT: Two-dimensional GRM with correlated factors (Factor 1 = source, Factor 2 = destination). Two-pass purification retained 32/36 items (89%). LMM model selection: **Extended 66-model comparison** (added 2025-12-08) revealed extreme uncertainty with 13 models competitive (ΔAIC<2). Quadratic wins (AIC=1750.80, weight=6.7%), but Logarithmic essentially tied (AIC=1751.15, ΔAIC=0.34, essentially equivalent). Original 5-model comparison selected Logarithmic (AIC=1747.77, weight=63.5%). **Hybrid approach adopted:** (1) statistical tests use Logarithmic coefficients (validated, complete), (2) trajectory plots use 13-model averaging (uncertainty bands reflect model + parameter uncertainty). Random effects: Intercepts + slopes by participant. Bonferroni correction: α = 0.025 (2 primary tests).

**Results:**

The **primary hypothesis was not supported**: Source memory did NOT show significantly higher accuracy than destination memory. The main effect estimate was β=+0.100 (SE=0.077, z=1.30, p_uncorrected=.202, **p_Bonferroni=.403**), with 95% CI [-0.051, +0.254] including zero. Surprisingly, the direction was opposite predictions (destination slightly higher when averaged across time), though this advantage was not statistically significant.

The **secondary hypothesis was marginally supported**: Destination memory showed steeper forgetting than source memory. The LocationType × Time interaction was β=-0.136 (SE=0.049, z=-2.78, p_uncorrected=.025, **p_Bonferroni=.050**), with 95% CI [-0.232, -0.017] excluding zero. This interaction achieved **exact marginal significance** at the Bonferroni-corrected threshold.

Trajectory patterns revealed logarithmic forgetting for both location types with differential rates. **Source memory** declined from +0.49 theta (61% probability correct) at Day 0 to -0.59 theta (36%) at Day 7, representing a 1.08 theta decline (25 percentage points). **Destination memory** declined from +0.39 theta (59%) at Day 0 to -0.80 theta (31%) at Day 7, representing a 1.19 theta decline (28 percentage points). The differential forgetting of 0.11 theta (3 percentage points) reflects the interaction effect: destination memory was more vulnerable to forgetting.

The findings **contradict five converging theoretical predictions** (proactive interference, schema support, "lost keys" phenomenon, goal discounting, attention allocation) that predicted source superiority. Instead, destination memory showed a non-significant initial advantage that reversed over time due to steeper forgetting. By Day 7, both location types approached chance (~33%), with destination slightly lower (31% vs 36%), though the 5-percentage-point gap was modest. The **marginal Bonferroni p-value (p=.050)** for the interaction effect warrants cautious interpretation—the effect is at the boundary of statistical significance after correction for multiple testing.

The extreme model uncertainty discovered in extended analysis (13 competitive functional forms) suggests the interaction effect's robustness should be interpreted cautiously. However, the Logarithmic model's near-equivalence with the best model (ΔAIC=0.34) validates the original statistical tests. The differential forgetting pattern was consistent across model-averaged predictions, providing convergent evidence for the interaction effect despite functional form uncertainty.

Cross-references: This finding relates to §5.2.6 (spatial domain variance decomposition) and §5.4.6 (schema-based variance decomposition), which examined source/destination differences through variance partitioning rather than trajectory slopes.

**Figure 5.5.1a:** [results/ch5/5.5.1/plots/trajectory_theta.png](results/ch5/5.5.1/plots/trajectory_theta.png) Source (blue) vs destination (red) memory trajectories on theta scale across 10 days. Source memory: +0.49 → -0.68 theta. Destination memory: +0.39 → -0.47 theta. Logarithmic curvature with rapid early decline (Day 0→1) and deceleration thereafter. Destination (red) shows steeper decline than source (blue), consistent with marginal interaction effect (p_Bonf=.050). Observed data shown as circles at test days 0, 1, 3, 7.

**Figure 5.5.1b:** [results/ch5/5.5.1/plots/trajectory_probability.png](results/ch5/5.5.1/plots/trajectory_probability.png) Same trajectories on probability scale (%). Source: 61% → 34% (27-point decline). Destination: 59% → 39% (20-point decline). Both approach chance level (~33%) by Day 10. Probability scale aids practical interpretation of clinical relevance, though theta scale (Figure 5.5.1a) is authoritative for statistical inference due to non-linear IRT transformation properties.

---

### 5.5.2 Source vs Destination Consolidation: Two-Phase Temporal Dynamics

**Research Question:** Do source (pick-up) and destination (put-down) memories show different consolidation patterns across Early (Day 0→1, 0-48h) versus Late (Day 1→6, 48-144h) retention periods?

**Hypothesis:** Destination memory (weaker encoding per §5.5.1) will show steeper Early-phase forgetting (0-48h consolidation window) but similar Late-phase stabilization (48-144h) compared to source memory, predicting a significant LocationType × Phase interaction.

**Analysis:** (§4.3.1, §4.5.1)
Sample: N=100, 800 observations (100 × 4 sessions × 2 location types). Piecewise LMM with 48-hour inflection point dividing Early (0-48h synaptic consolidation window) versus Late (48-144h post-consolidation) phases. Time variable: Days_within segment (recentered at segment start). Random effects: Intercepts + slopes by participant. Model fit: AIC=1756.51. Bonferroni correction: α=0.025 (2 primary tests). ROOT model verification (2025-12-10): Extended 13-model averaging from RQ 5.5.1 tested; NULL interaction robust (p_Bonf=1.000 in both approaches).

**Results:**

The **hypothesis was not supported**: Source and destination memories showed **statistically indistinguishable consolidation patterns** across both phases. The critical three-way interaction (Days_within × Segment × LocationType) was **not significant**: β=0.061 (SE=0.119, z=0.51, p_uncorrected=.610, **p_Bonferroni=1.000**), with 95% CI [-0.173, +0.295] including zero. Effect size was **negligible** (Cohen's f²=0.0005, far below small effect threshold of 0.02).

Piecewise trajectory analysis revealed two-phase forgetting dynamics consistent with classical consolidation theory (Wixted, 2004), but **location-invariant**. In the **Early phase** (0-48h consolidation window), both location types showed steep parallel forgetting: Source β=-0.206 theta/day (SE=0.081, z=-2.54, p=.011), Destination β=-0.209 theta/day (SE=0.081, z=-2.58, p=.009). The difference between Early slopes was trivial (-0.003 theta/day). In the **Late phase** (48-144h post-consolidation), both location types showed reduced forgetting rates: Source β=-0.104 theta/day (SE=0.029, z=-3.58, p<.001), Destination β=-0.046 theta/day (SE=0.029, z=-1.59, p=.114). While the Late phase difference (0.058 theta/day) was numerically larger than the Early difference, wide confidence intervals (SE=0.085) prevented statistical significance.

Consolidation benefit (Early slope - Late slope) was numerically present for both location types but not statistically significant due to high individual variability. Source showed 0.102 theta/day difference (95% CI [-0.268, +0.064]), Destination showed 0.163 theta/day difference (95% CI [-0.329, +0.003]). Both CIs included zero, indicating insufficient evidence for reliable phase differences within each location type.

Dual-scale trajectory interpretation (Decision D069) revealed practical patterns obscured by theta-scale abstraction. On the **theta scale**, Early phase declines were 0.41 theta (Source) and 0.42 theta (Destination) over 2 days; Late phase declines were 0.85 theta (Source) and 0.37 theta (Destination) over 8 days. On the **probability scale**, Early phase showed 10 percentage point drop (Source: 61%→51%) versus 4 percentage point drop (Destination: 59%→55%); Late phase showed 18 percentage point drop (Source: 48%→30%, approaching floor) versus 8 percentage point drop (Destination: 47%→39%). By Day 6, source memory approached chance level (30%), while destination maintained marginally better performance (39%), though the 9-percentage-point gap was not statistically reliable.

The findings **contradict sleep-dependent consolidation predictions** (Diekelmann & Born, 2010; Tononi & Cirelli, 2014) that strongly encoded memories receive preferential consolidation benefits. Despite source memory's richer encoding (per §5.5.1's five converging mechanisms), **both location types showed identical Early-phase dynamics**. This null interaction suggests: (1) the encoding strength difference between source and destination may be insufficient to trigger differential consolidation, (2) both location types may exceed a consolidation threshold where differential effects vanish, or (3) immersive VR's rich spatial context may provide sufficient encoding strength for both, reducing asymmetry. The 48-hour inflection point aligns with classical consolidation timelines but may be suboptimal for detecting VR-specific effects.

**ROOT model verification** (added 2025-12-10 following RQ 5.5.1's extended model comparison) confirmed robustness: Testing with 13-model averaging (effective N=12.32 competitive functional forms) yielded identical NULL conclusion (p_Bonf=1.000, negligible effect size). Consolidation dynamics are **location-invariant regardless of trajectory functional form**.

Cross-references: Findings converge with §5.3.3 (paradigm-invariant consolidation window effects) and §5.4.2 (schema-invariant consolidation dynamics), suggesting consolidation processes in VR episodic memory operate uniformly across content dimensions.

**Figure 5.5.2a:** [results/ch5/5.5.2/plots/piecewise_dual_scale.png](results/ch5/5.5.2/plots/piecewise_dual_scale.png) 2×2 grid showing piecewise trajectories across Early (0-48h) and Late (48-144h) segments for source (red) and destination (blue). Top row: theta scale (standardized ability); bottom row: probability scale (performance likelihood). Left: Early segment; right: Late segment. Key pattern: **Parallel Early slopes** (source -0.206/day, destination -0.209/day), **non-significant Late divergence** (source -0.104/day continues declining, destination -0.046/day plateaus, CIs overlap). Piecewise structure visible at 48h breakpoint. Dual-scale presentation per Decision D069 balances scientific precision (theta) with practical utility (probability).

**Figure 5.5.2b:** [results/ch5/5.5.2/plots/piecewise_theta.png](results/ch5/5.5.2/plots/piecewise_theta.png) Theta-scale only, two panels (Early left, Late right). Error bars show 95% CIs at observed timepoints. Slope annotations visible ("0.306/day" and "0.258/day" Early absolute values). Emphasizes standardized effect sizes comparable to published literature.

**Figure 5.5.2c:** [results/ch5/5.5.2/plots/piecewise_probability.png](results/ch5/5.5.2/plots/piecewise_probability.png) Probability-scale only, Y-axis 30-62%. Early: both ~60%→50-55% (4-10pp drops). Late: source→30% (floor), destination→39% (marginally above floor). Practical interpretation: 0.058 theta/day Late difference translates to ~8pp performance gap—clinically meaningful despite statistical non-significance.

---

### 5.5.3 Age Moderation of Source-Destination Memory

**Research Question:** Does age moderate the source (pick-up) versus destination (put-down) memory difference, or the forgetting rate for either location type?

**Hypothesis:** Age will NOT significantly moderate the source-destination difference or forgetting rates (NULL hypothesis), predicting non-significant three-way Age × LocationType × Time interactions (p > .025 Bonferroni), consistent with universal age-invariance pattern across Chapter 5 RQs (§5.1.3, §5.2.3, §5.3.4, §5.4.3).

**Analysis:** (§4.3.1, §4.5.1)
Sample: N=100, age range 20-70 years (grand-mean centered), 800 observations (100 × 4 sessions × 2 location types). LMM formula: theta ~ TSVR_hours + log_TSVR + Age_c + LocationType + all 2-way and 3-way interactions, random intercepts + slopes by participant. Model fit: AIC=1756.06, successfully converged. Bonferroni correction: α=0.025 (2 primary three-way tests). Power analysis: 1.00 (100% power to detect small effects, β=0.01, 100/100 simulations), confirming null NOT due to insufficient statistical power. ROOT verification (2025-12-10): 13-model averaging tested, NULL interactions robust (p_Bonf=1.000).

**Results:**

The **NULL hypothesis was strongly supported**: Age did NOT significantly moderate source-destination memory differences or forgetting trajectories. Both critical three-way interactions were **non-significant at Bonferroni-corrected threshold**: TSVR_hours × Age_c × LocationType β=-0.000185 (SE=0.000106, z=-1.75, p_uncorrected=.080, **p_Bonferroni=.160**), 95% CI [-0.000393, +0.000022]; log_TSVR × Age_c × LocationType β=0.005151 (SE=0.003707, z=1.39, p_uncorrected=.165, **p_Bonferroni=.329**), 95% CI [-0.002115, +0.012416]. Both CIs included zero with substantial margin.

**Power analysis confirmed** the null finding was **not due to Type II error**: The study achieved **100% power** (95% CI [0.97, 1.00]) to detect small age moderation effects (β=0.01), with 100/100 Monte Carlo simulations successfully detecting the test effect size. This provides strong evidence that age genuinely does not moderate source-destination forgetting in the VR paradigm, rather than reflecting measurement insensitivity.

Post-hoc contrasts at Day 3 (72 hours) revealed **virtually identical age effects** for both location types: Destination versus Source contrast β=-0.000299 (SE=0.024319, z=-0.012, p_uncorrected=.990, **p_Tukey=.990**), Cohen's d=-0.017 (negligible effect). Older adults showed **no differential vulnerability** for destination memory compared to source memory.

Age tertile trajectory analysis provided visual confirmation of statistical null findings. **Young tertile** (≤33rd percentile): Source declined 1.0 SD (78%→53%, 25 percentage points), Destination declined 0.8 SD (33%→19%, 14 pp). **Middle tertile** (33rd-67th): Source declined 1.0 SD (70%→43%, 27 pp), Destination declined 0.7 SD (28%→15%, 13 pp). **Older tertile** (>67th): Source declined 0.85 SD (70%→47%, 23 pp), Destination declined 0.6 SD (31%→19%, 12 pp). All three age groups showed **parallel trajectories** with overlapping confidence intervals at all timepoints, confirming no age moderation of forgetting rates or source-destination dissociation.

The findings **extend VR ecological encoding theory** (Plancher et al., 2018) to source-destination memory: Immersive VR creates rich, multimodal traces that buffer against age-related hippocampal decline for both pick-up and put-down location encoding. Despite theoretical predictions that source memory (richer encoding depth per §5.5.1) might show age-related decline while destination memory (motor-only encoding) remains age-invariant, **both location types showed identical age-invariance**. This suggests VR's integrated object-location traces eliminate typical source memory aging effects observed in laboratory paradigms.

**ROOT model verification** (2025-12-10): Testing with 13-model averaging (following RQ 5.5.1's extended comparison) confirmed robustness—both three-way interactions yielded p_Bonf=1.000 with model-averaged predictions, indicating **age-invariant forgetting regardless of trajectory functional form**.

LMM assumption validation: 6/7 assumptions passed (85.7% pass rate). Residual normality failed (Shapiro-Wilk p<.001) but acceptable with large N=800 due to Central Limit Theorem robustness. No remedial actions required.

Cross-references: This is the **fifth independent replication** of age-invariant forgetting in REMEMVR (following §5.1.3 omnibus, §5.2.3 domains, §5.3.4 paradigms, §5.4.3 schema congruence), extending the universal pattern to source-destination spatial memory distinctions. The consistency across all content dimensions suggests age-invariance is a robust property of VR episodic memory encoding, not task-specific.

**Figure 5.5.3a:** [results/ch5/5.5.3/plots/age_tertile_trajectory_theta.png](results/ch5/5.5.3/plots/age_tertile_trajectory_theta.png) Dual-panel (Source | Destination) age tertile trajectories on theta scale. Young (green circles), Middle (blue squares), Older (red triangles) show **parallel declines** within each panel. Source: all tertiles decline ~1.0 SD (Day 0→6). Destination: all tertiles decline ~0.7 SD. Overlapping error bars at all timepoints confirm null Age × Time interactions. No diverging/converging lines—visual proof of age-invariance.

**Figure 5.5.3b:** [results/ch5/5.5.3/plots/age_tertile_trajectory_probability.png](results/ch5/5.5.3/plots/age_tertile_trajectory_probability.png) Same structure, probability scale (0-100%). Source: all tertiles decline ~25pp. Destination: all tertiles decline ~13pp. Age-invariant decline rates in absolute percentage terms. Source advantage (~2× accuracy) maintained across ages. Destination approaches floor (~20%, near chance) for all age groups by Day 6.

**Figure 5.5.3c:** [results/ch5/5.5.3/plots/age_tertile_dual_scale.png](results/ch5/5.5.3/plots/age_tertile_dual_scale.png) 2×2 grid combining theta (top) and probability (bottom) scales. Side-by-side comparison reveals age-invariance strikingly: regardless of scale or location, all tertile lines parallel with overlapping error bars. No panel shows divergence/convergence indicating age moderation. Visual confirmation of statistical null across all four panels.

---

### 5.5.4 IRT-CTT Convergence for Source-Destination Memory

**Research Question:** Do IRT theta scores and CTT sum scores show high convergence for source (pick-up, -U-) and destination (put-down, -D-) memory, validating that RQ 5.5.1 findings are not measurement artifacts?

**Hypothesis:** IRT theta and CTT mean scores will converge strongly (r > 0.70 for both location types), with Cohen's kappa > 0.60 and overall fixed effects agreement > 80%, confirming source-destination dissociation is measurement-independent.

**Analysis:** (§4.2.1, §4.2.2, §4.3.1, §4.5.1)
Sample: N=100, 800 observations (100 × 4 sessions × 2 location types). Items: 32 purified items (17 source, 15 destination) after IRT quality filtering. Pearson correlations with Bonferroni correction (3 comparisons: source, destination, overall; α_family=0.05). Parallel LMMs: score ~ LocationType × log_TSVR + (log_TSVR | UID), fitted separately to IRT theta and CTT mean scores. Cohen's kappa for fixed effects agreement (sign + significance matching). Assumption validation: 7 checks per model.

**Results:**

The **primary convergence hypothesis was supported**: IRT theta and CTT mean scores showed **strong-to-exceptional correlations** for both location types. **Source memory**: r=0.944 (p_Bonferroni<.001), exceeding exceptional convergence threshold (r>0.90). **Destination memory**: r=0.871 (p_Bonferroni<.001), exceeding strong convergence threshold (r>0.70). **Overall**: r=0.746 (p_Bonferroni<.001), strong convergence. All three correlations highly significant after correction for multiple testing.

However, **inferential agreement hypotheses were not supported**: Cohen's kappa=0.000 (slight agreement per Landis & Koch, 1977), far below κ>0.60 threshold. Overall fixed effects agreement: 50% (2/4 terms matched on both sign AND significance), below 80% threshold. While both IRT-based and CTT-based LMMs showed **perfect sign agreement** (4/4 terms: Intercept, LocationType, log_TSVR, interaction), significance patterns diverged for location-specific effects. LocationType main effect: IRT significant (p<.05), CTT not significant. LocationType × log_TSVR interaction: IRT significant, CTT not significant.

This **measurement convergence versus inferential divergence pattern** reveals that IRT and CTT **rank participants similarly** (high correlations) but differ in **statistical power to detect group differences**. IRT's incorporation of item parameters (discrimination, difficulty) provides greater precision, yielding significant source-destination effects that CTT's bounded [0,1] scale fails to detect due to ceiling/floor attenuation. Critically, both methods showed **identical substantive pattern** (source > destination at baseline, location-specific forgetting), with divergence only in p-values crossing significance threshold.

**Answer to primary research question:** RQ 5.5.1 findings (source-destination dissociation) are **NOT measurement artifacts**. High correlations (r>0.87) confirm IRT and CTT measure the same latent constructs. Both methods show source > destination pattern with perfect sign agreement (4/4). The significance divergence reflects IRT's superior sensitivity, not measurement artifact. Source-destination memory differences are **measurement-independent**, though IRT provides optimal statistical power for detection.

LMM assumption validation revealed **greater violations for IRT models** (3/7 failed: homoscedasticity p=.0004, residual normality p<.001, autocorrelation ACF=-0.174) compared to **CTT models** (2/7 failed: homoscedasticity p=.017, autocorrelation ACF=-0.135). CTT's bounded scale may inherently violate normality/homoscedasticity for standard LMM, but performed marginally better on normality checks. Negative autocorrelation (unusual for repeated measures) observed in both, suggesting within-participant dependency not fully captured by random effects structure.

Unexpected AIC pattern: CTT models showed dramatically lower AIC (ΔAIC=-2449) than IRT models, but this is a **scale artifact** (IRT unbounded theta vs CTT bounded [0,1]) rather than substantive evidence of superior fit. AIC comparison only valid when outcomes on same scale.

Cross-references: This is the **fourth IRT-CTT convergence analysis** in Chapter 5 (following §5.2.4 domains r>0.90, §5.3.5 paradigms r=0.84-0.88, §5.4.4 schema κ=1.000), extending convergence validation to source-destination spatial memory. The **consistent strong convergence** (r>0.74 across all analyses) provides cumulative evidence that REMEMVR findings are robust to measurement approach, with IRT offering superior sensitivity but CTT confirming general patterns.

**Figure 5.5.4:** [results/ch5/5.5.4/plots/scatterplot_irt_vs_ctt.png](results/ch5/5.5.4/plots/scatterplot_irt_vs_ctt.png) IRT theta (x-axis) versus CTT mean scores (y-axis) scatterplot, color-coded by location type (Source blue, Destination red). Source: steep regression line (r=0.944, exceptional convergence), tight clustering. Destination: moderate slope (r=0.871, strong convergence), more scatter. Non-linearity at extremes due to CTT bounded [0,1] ceiling/floor effects. Both location types show strong positive correlations, validating measurement-independent source-destination dissociation.

---

### 5.5.5 Purification Effects on CTT for Source-Destination Memory

**Research Question:** Does IRT-based item purification improve CTT-IRT correlation for source (pick-up, -U-) and destination (put-down, -D-) scores, and does the purification-trajectory paradox replicate?

**Hypothesis:** The purification-trajectory paradox will replicate: (1) Purified CTT shows HIGHER correlation with IRT theta than Full CTT (Steiger's z-test p<.025 Bonferroni), (2) Purified CTT shows WORSE LMM trajectory fit than Full CTT (ΔAIC>+2).

**Analysis:** (§4.2.2, §4.3.1, §4.3.2, §4.5.1)
Sample: N=100, 800 observations. Item purification: Source 18→17 items retained (94.4%), Destination 18→15 items retained (83.3%). CTT scores: Full (all 36 items) versus Purified (32 retained items) using dichotomized responses (TQ<1→0, TQ≥1→1). Reliability: Cronbach's alpha with 10,000 bootstrap resamples. Steiger's z-test for dependent correlations (Bonferroni α=0.025, 2 location types). Parallel LMMs on z-standardized scores: score ~ Time + (Time | UID), REML=False. Z-standardization enables valid AIC comparison across IRT/CTT scales (monotonic transformation preserves ML ordering per Pawitan, 2001).

**Results:**

The **purification-trajectory paradox replicated with location-specific heterogeneity**. **Destination memory showed FULL paradox**: (1) **Correlation component**: Purified CTT r=0.871 versus Full CTT r=0.800, Δr=+0.072, Steiger's z=4.677, **p_Bonferroni<.001** (significant improvement after removing 3 items). (2) **Trajectory component**: Purified AIC=1115.92 versus Full AIC=1098.00, **ΔAIC=+17.92** (decisive evidence favoring Full CTT per Burnham & Anderson, 2002 threshold ΔAIC>10). Removing items improved cross-sectional correlation BUT degraded longitudinal trajectory fit—the classic paradox pattern.

**Source memory showed PARTIAL paradox**: (1) **Correlation component**: Purified CTT r=0.944 versus Full CTT r=0.934, Δr=+0.010, Steiger's z=1.717, p_Bonferroni=.172 (**not significant**). Correlation improvement present numerically but failed to reach Bonferroni-corrected threshold, likely due to **ceiling effect** (r_Full already 0.934, limited room for improvement). (2) **Trajectory component**: Purified AIC=979.75 versus Full AIC=974.49, **ΔAIC=+5.26** (substantial evidence favoring Full CTT per threshold ΔAIC>2). Trajectory degradation confirmed despite non-significant correlation gain.

Reliability assessment revealed **location-specific patterns**: Source Cronbach's alpha acceptable (Full α=0.775, Purified α=0.778, Δα=+0.004, negligible change). Destination alpha marginally acceptable (Full α=0.622, Purified α=0.612, Δα=-0.010, slight decrease), below conventional 0.70 threshold. Low destination reliability consistent with theoretical predictions of higher measurement error due to goal discounting and minimal encoding depth for put-down locations.

**Overall conclusion:** Paradox PARTIALLY CONFIRMED for source-destination memory, representing the **fourth independent replication** across memory content dimensions (following §5.2.5 domains When 81% loss, §5.3.6 paradigms ΔAIC=-33.4, §5.4.5 schema ΔAIC=+19-38). The heterogeneity in paradox magnitude (Destination full paradox, Source partial paradox) suggests **measurement properties differ by location type**. Destination memory, with weaker encoding and lower baseline reliability, shows larger sensitivity to item purification in both correlation improvement (+0.072 vs +0.010) and trajectory degradation (ΔAIC=+17.92 vs +5.26).

The paradox pattern confirms the **fundamental tension** between cross-sectional validity (item quality improves correlation) and longitudinal validity (item removal loses temporal information). For source memory, the 1-item removal (94.4% retention) had minimal impact. For destination memory, the 3-item removal (83.3% retention) substantially improved measurement precision but at significant cost to trajectory modeling. This suggests **location-type-specific purification strategies** may be warranted: aggressive purification for destination (to overcome low reliability), conservative retention for source (to preserve high baseline validity).

Convergence issues affected 4/6 models (only Full CTT models converged for both locations), with IRT and Purified CTT models showing random slope variance estimation warnings. Despite convergence flags, AIC values remained finite and interpretable for relative comparison within location type.

Cross-references: The purification-trajectory paradox now documented across five independent content dimensions (§5.2.5, §5.3.6, §5.4.5, §5.5.5 current, plus §5.1.3's model-averaging approach addressing similar tension). The cumulative evidence suggests this is a **universal property of IRT-CTT relationships in repeated-measures designs**, not task-specific artifact.

**Figure 5.5.5a:** [results/ch5/5.5.5/plots/correlation_comparison.png](results/ch5/5.5.5/plots/correlation_comparison.png) Faceted bar plot (Destination | Source) showing Full CTT versus Purified CTT correlations with IRT theta. Destination panel: clear separation (r=0.80→0.87, bars non-overlapping), error bars confirm p_Bonf<.001. Source panel: minimal separation (r=0.93→0.94, bars nearly identical, overlapping error bars), confirming p_Bonf=.172 non-significance. Visual confirmation of location-specific paradox heterogeneity.

**Figure 5.5.5b:** [results/ch5/5.5.5/plots/aic_comparison.png](results/ch5/5.5.5/plots/aic_comparison.png) Faceted bar plot showing LMM trajectory fit (AIC) for IRT, Full CTT, Purified CTT across location types. Both panels show identical rank order: Full CTT best (lowest AIC), Purified CTT intermediate, IRT worst. Destination gap larger (ΔAIC=17.92 decisive) than Source gap (ΔAIC=5.26 substantial). Visual paradox: Purified CTT has higher correlation (Figure 5.5.5a) but worse trajectory fit (this figure)—cross-sectional precision conflicts with longitudinal validity.

---

### 5.5.6 Source-Destination Memory Variance Decomposition

**Research Question:** What proportion of variance in source (pick-up, -U-) and destination (put-down, -D-) memory is attributable to stable between-person differences (intercepts versus slopes)?

**Hypothesis:** ICC_slope will be near zero for both location types (<0.02), consistent with universal Chapter 5 pattern reflecting 4-timepoint design limitation. ICC_intercept will be moderate (0.30-0.60), indicating stable baseline differences. If destination encoding is weaker per §5.5.1, destination may show lower ICC_intercept (more variable baseline) compared to source.

**Analysis:** (§4.3.1, §4.4.2)
Sample: N=100, 800 observations (100 × 4 sessions × 2 location types). Location-stratified LMMs: theta ~ log_TSVR + (log_TSVR | UID), fitted separately for source and destination. ICC calculations: ICC_intercept = σ²_intercept / (σ²_intercept + σ²_residual), ICC_slope_simple = σ²_slope / (σ²_slope + σ²_residual), ICC_slope_conditional accounts for intercept-slope covariance. Convergence: Both models successful. Intercept-slope correlations tested with Bonferroni correction (α=0.025, 2 location types).

**Results:**

The **primary hypothesis was partially supported**: ICC_slope near zero confirmed (Source ICC_slope_simple=0.005, Destination=0.022, both <0.03), consistent with universal Chapter 5 pattern reflecting insufficient timepoints (4) for reliable slope estimation rather than absence of individual differences. ICC_intercept showed location-specific patterns: Destination ICC_intercept=0.421 (Fair per Cicchetti 1994, within predicted 0.30-0.60 range), **Source ICC_intercept=0.240 (Poor, BELOW predicted range)**.

The **secondary hypothesis was contradicted**: Destination showed **HIGHER ICC_intercept** (0.421 versus Source 0.240, difference=-0.181), not lower as predicted. Destination memory exhibited **75% greater baseline stability** than source memory, contradicting the prediction that weaker encoding leads to greater baseline variability. This suggests destination memory's lower mean performance (per §5.5.1) reflects systematic encoding differences rather than increased measurement noise.

**Critical discovery**: Source and destination showed **OPPOSITE intercept-slope correlations** (both p_Bonferroni<.001). **Source memory**: r=+0.989 (extreme positive correlation)—participants with high baseline source memory showed FASTER forgetting, classic **regression-to-mean pattern**. **Destination memory**: r=-0.903 (strong negative correlation)—participants with high baseline destination memory MAINTAINED their advantage over time, **advantage-persistence pattern**. This represents fundamentally different forgetting dynamics: source memory shows ceiling-effect-driven convergence, destination memory shows stable individual differences preservation.

Variance components revealed location-specific patterns. Source: var_intercept=0.127, var_slope=0.002 (near zero), var_residual=0.402, correlation_int_slope=+0.621. Destination: var_intercept=0.338 (2.7× higher than source), var_slope=0.010 (5× higher than source but still near zero), var_residual=0.465, correlation_int_slope=-0.851. The substantially higher destination intercept variance (0.338 vs 0.127) drives the higher ICC_intercept despite also having higher residual variance.

ICC_slope_conditional showed **reversed pattern** from ICC_intercept: Source=0.408 (Fair) versus Destination=0.167 (Poor). This reversal reflects the opposite correlation signs: Source's strong positive intercept-slope correlation inflates conditional slope variance (high-baseline participants show greater slope variability), while Destination's strong negative correlation compresses conditional slope variance (high-baseline participants show restricted slope range).

The **practical interpretation** on probability scale reveals why opposite correlations emerge. High-baseline source memory participants (θ=+0.30) start at ~60% accuracy but approach floor (~30% at Day 6) due to limited headroom, forcing convergence with low-baseline participants. High-baseline destination memory participants (θ=+0.53) start at ~62% accuracy and maintain ~45% at Day 6, preserving their advantage because they remain above floor. **Ceiling/floor effects drive opposite dynamics**: source memory constrained by floor convergence, destination memory shows genuine trait-like stability.

The findings have **critical implications for RQ 5.5.7** clustering analysis: Random effects extraction yielded 200 values (100 participants × 2 locations × 2 random effects [intercept, slope]), successfully validated with no missing data. These random effects serve as clustering features, with the opposite intercept-slope correlations predicting distinct latent classes based on location-type-specific baseline-forgetting relationships.

Cross-references: This variance decomposition extends prior ICC analyses (§5.2.6 domains ICC_intercept 51-53%, §5.3.7 paradigms ICC_slope 0.00-0.02, §5.4.6 schema ICC reversed ordering) to source-destination spatial memory. The **universal ICC_slope≈0 pattern** now documented across six independent content dimensions confirms this is a **robust design limitation** (4 timepoints insufficient), not task-specific. The opposite intercept-slope correlations represent a **novel finding** unique to source-destination memory, not observed in prior domain/paradigm/schema analyses.

---

### 5.5.7 Source-Destination Memory Clustering: Four-Profile Solution

**Research Question:** Can participants be grouped into latent classes based on source (pick-up, -U-) and destination (put-down, -D-) memory patterns (intercepts and slopes)?

**Hypothesis:** Weak clustering quality (Silhouette <0.40) but stable groupings (Jaccard >0.60), consistent with prior Chapter 5 clustering RQs (§5.1.5, §5.2.7, §5.3.8, §5.4.7). Clustering driven by intercepts only (slopes ≈0 per §5.5.6).

**Analysis:** (§4.6)
Sample: N=100 participants. Clustering variables: 4 random effects from §5.5.6 (Source_intercept, Source_slope, Destination_intercept, Destination_slope), z-scored for equal weighting. K-means clustering: random_state=42, n_init=50, K=1-6 tested. Model selection: BIC minimum identified K=4 (BIC=164.76, not at boundary, increases for K=5/6). Triple validation: Silhouette coefficient (cohesion), Davies-Bouldin index (separation), Jaccard bootstrap stability (B=100 resamples).

**Results:**

The **hypothesis was partially contradicted**: Clustering quality **EXCEEDED expectations** with Silhouette=0.417 (**PASS**, ≥0.40 threshold), making this the **ONLY Chapter 5 clustering RQ to achieve acceptable quality**. All three validation criteria met: Silhouette=0.417 (PASS), Davies-Bouldin=0.785 (PASS, <1.50), Jaccard=0.831 (PASS, >0.75, 95% CI [0.576, 0.979]). Prior clustering RQs failed Silhouette threshold (§5.1.5 general 0.352, §5.2.7 domains 0.352, §5.3.8 paradigms 0.367, §5.4.7 schema 0.254), but **source-destination feature space shows STRONGER clustering structure** than general ability, domains, paradigms, or schema congruence.

BIC model selection identified **K=4 optimal clusters**, with robust selection confirmed by BIC increasing for K=5 and K=6 (not boundary solution). Cluster sizes balanced: Cluster 0=20% (N=20), Cluster 1=26% (N=26), Cluster 2=35% (N=35), Cluster 3=19% (N=19), all ≥10% (no extreme imbalance).

**Four-cluster profiles revealed distinct memory patterns:**

**Cluster 0 (N=20, "Dual High: Source declines, Destination maintains")**: High baseline for both location types (Source θ=+0.30, Destination θ=+0.53, highest across all clusters). Source shows positive slope (+0.031, decline direction), Destination shows negative slope (-0.063, maintaining). **Pattern**: Strong initial encoding, maintains destination advantage but shows source vulnerability, consistent with §5.5.6's opposite intercept-slope correlations (Source r=+0.99 regression-to-mean, Destination r=-0.90 advantage-maintenance).

**Cluster 1 (N=26, "Dual Low: Source maintains, Destination declines")**: Low baseline for both (Source θ=-0.37, Destination θ=-0.46, lowest across all clusters). Source shows negative slope (-0.038, maintaining/improving), Destination shows positive slope (+0.055, declining). **Pattern**: Opposite of Cluster 0—weak encoding, maintains source but shows destination vulnerability. Represents **mirror-image forgetting dynamics**.

**Cluster 2 (N=35, "Source > Destination: Both decline", largest cluster)**: Moderate source baseline (θ=+0.16) exceeding destination baseline (θ=-0.08). Both slopes near zero (+0.018 source, +0.020 destination). **Pattern**: "Balanced average" group with slight source advantage, no strong differential forgetting.

**Cluster 3 (N=19, "Destination > Source: Both maintain")**: Moderate destination baseline (θ=+0.22) exceeding source baseline (θ=-0.10). Both slopes near zero (-0.013 source, -0.046 destination). **Pattern**: Mirrors Cluster 2 but with reversed location-type advantage, maintenance over time.

**Critical statistical pattern**: Clustering driven **exclusively by intercepts** (baseline memory ability), not slopes (forgetting rates). Source intercept range=0.67 theta units (Cluster 1 -0.37 to Cluster 0 +0.30), Destination intercept range=0.99 theta units (Cluster 1 -0.46 to Cluster 0 +0.53, **LARGER spread**). Slope ranges all near zero (<0.10 theta units), confirming §5.5.6 ICC_slope≈0 findings. Destination memory's **wider intercept variance** (0.99 vs 0.67) explains greater contribution to clustering structure.

**Four-quadrant structure** visible in Source_intercept × Destination_intercept 2D space: Cluster 0 upper-right (high-high), Cluster 1 lower-left (low-low), Cluster 2 upper-left (high source-low destination), Cluster 3 lower-right (low source-high destination). This quadrant pattern directly maps to location-type-specific advantages, confirming source-destination dissociation operates at **individual-difference level**, not just group averages (per §5.5.1).

The **source-destination dissociation** extends beyond main effects: Clusters 2 & 3 combined represent 54% of sample showing location-type-specific advantages (Cluster 2 favors source N=35, Cluster 3 favors destination N=19). This suggests **heterogeneous encoding strategies** where some individuals prioritize pick-up location encoding (Cluster 2), others prioritize put-down location encoding (Cluster 3), rather than uniform source > destination pattern across all participants.

**Theoretical implications**: Exceptional clustering quality (Silhouette=0.417, only Chapter 5 RQ to pass) suggests **source-destination distinctions are more fundamental** to individual differences than domain (What/Where/When), paradigm (Free/Cued/Recognition), or schema (Congruent/Incongruent/Common) distinctions. This may reflect evolutionary/ecological importance of spatial memory differentiation (where objects found vs where objects placed) being trait-like, while other content dimensions reflect more variable encoding strategies.

The **opposite intercept-slope correlations** from §5.5.6 manifested in cluster profiles: Cluster 0 (high source intercept +0.30, positive slope +0.031) versus (high destination intercept +0.53, negative slope -0.063) directly exemplifies the Source r=+0.99 regression-to-mean and Destination r=-0.90 advantage-maintenance patterns at the cluster level.

Cross-references: This is the **fifth clustering analysis** in Chapter 5 (following §5.1.5 general K=2 Silh=0.352, §5.2.7 domains K=4 Silh=0.352, §5.3.8 paradigms K=3 Silh=0.367, §5.4.7 schema K=6 Silh=0.254). The **consistent failure to achieve Silhouette ≥0.40** across prior RQs (all showed weak quality) contrasts sharply with current success, suggesting **source-destination memory structure is categorical** (discrete classes) while other dimensions may be **dimensional** (continuous variation). The K=4 solution aligns with §5.2.7 domains (also K=4), but superior quality (0.417 vs 0.352) indicates stronger separation.

**Figure 5.5.7:** [results/ch5/5.5.7/plots/step06_cluster_scatter_matrix.png](results/ch5/5.5.7/plots/step06_cluster_scatter_matrix.png) 4×4 scatter plot matrix showing cluster separation across Source_intercept, Source_slope, Destination_intercept, Destination_slope (all z-scored). Color-coded: Blue (Cluster 0 Dual High), Orange (Cluster 1 Dual Low), Green (Cluster 2 Source>Destination), Red (Cluster 3 Destination>Source). **Key patterns**: (1) Destination_intercept × Source_intercept (Row 3, Column 1) shows clear **four-quadrant separation** (strongest visual separation, explains Silhouette=0.417). (2) Intercept × Slope panels show opposite correlations: Source_intercept × Source_slope positive tilt (r=+0.99 regression-to-mean), Destination_intercept × Destination_slope negative tilt (r=-0.90 advantage-maintenance). (3) Slope × Slope panel (Row 4, Column 2) shows **complete overlap** (all clusters centered at z=0, confirming intercept-driven clustering). (4) Diagonal histograms: Source/Destination intercepts **bimodal** (peaks at Cluster 0 high, Cluster 1 low), slopes **unimodal** centered at z=0. Cluster centers (black X markers) clearly separated in intercept-intercept space, overlapping in slope-slope space. Visual confirmation of K=4 solution differentiates by **baseline memory**, not **forgetting rates**.

---

**END OF §5.5 (Consolidation and Sleep-Dependent Memory)**

---

## 5.6 Chapter Summary

[TBD: 500-800 words synthesizing across all 35 RQs]

**Major Findings:**

[TBD: Bullet list of 10-12 key results]

**Convergent Evidence:**

[TBD: Where multiple RQs triangulate on same conclusion]

**Divergent Evidence:**

[TBD: Contradictions or unexpected null results]

**Theoretical Implications:**

[TBD: What do results mean for episodic memory theory?]

**Methodological Insights:**

[TBD: What did VR paradigm reveal?]

**Limitations:**

[TBD: Cross-cutting issues]

**Bridge to Discussion:**

[TBD: Preview Chapter 6 integration with literature]

---

**END CHAPTER 5 (Empirical Results)**
