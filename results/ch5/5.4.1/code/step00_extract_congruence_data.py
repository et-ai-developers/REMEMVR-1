#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step00
Step Name: Extract Congruence Data
RQ: results/ch5/5.4.1 (RQ 5.4.1: Schema Congruence Effects on Forgetting Trajectories)
Generated: 2025-11-24

PURPOSE:
Extract interactive paradigm items from RQ 5.1 data and create Q-matrix mapping
items to congruence categories (common, congruent, incongruent).

EXPECTED INPUTS:
  - results/ch5/5.1.1/data/step00_irt_input.csv
    Columns: composite_ID + item columns (TQ_IFR-*, TQ_ICR-*, TQ_IRE-*)
    Format: Wide-format IRT input from RQ 5.1
    Expected rows: ~400 (100 participants x 4 tests)

  - results/ch5/5.1.1/data/step00_tsvr_mapping.csv
    Columns: composite_ID, UID, test, TSVR_hours
    Format: TSVR time mapping
    Expected rows: ~400

EXPECTED OUTPUTS:
  - data/step00_irt_input.csv
    Columns: composite_ID + interactive paradigm item columns only
    Format: Wide-format IRT input filtered to TQ_IFR, TQ_ICR, TQ_IRE items only
    Expected rows: ~400

  - data/step00_q_matrix.csv
    Columns: item_name, common, congruent, incongruent
    Format: Q-matrix with binary loadings (each item loads on exactly 1 dimension)
    Expected rows: ~72 items (24 items x 3 paradigms)

  - data/step00_tsvr_mapping.csv
    Columns: composite_ID, UID, test, TSVR_hours
    Format: Copy of TSVR mapping from RQ 5.1
    Expected rows: ~400

VALIDATION CRITERIA:
  - All RQ 5.1 input files exist
  - Output files created
  - Row count preserved (~400)
  - Q-matrix structure valid (each item loads on exactly 1 dimension)
  - All congruence categories present (common, congruent, incongruent)

g_code REASONING:
- Approach: Filter RQ 5.1 IRT input to interactive paradigms, create Q-matrix from item suffixes
- Why this approach: Schema congruence is encoded in item numbers (i1-i2=common, i3-i4=congruent, i5-i6=incongruent)
- Data flow: RQ 5.1 wide-format -> filter columns -> extract item names -> create Q-matrix
- Expected performance: ~seconds (simple filtering)

IMPLEMENTATION NOTES:
- Item naming: TQ_{paradigm}-{domain}-{item} (e.g., TQ_IFR-N-i1)
- Interactive paradigms: IFR (Free Recall), ICR (Cued Recall), IRE (Recognition)
- Excludes: RFR (Room Free Recall), TCR (Task Cued Recall) - different format
- Congruence mapping: i1,i2 -> common; i3,i4 -> congruent; i5,i6 -> incongruent
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback
import shutil

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (5 levels deep from project root)
# parents[4] = REMEMVR/ (code -> rq5 -> ch5 -> results -> REMEMVR)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.4.1
LOG_FILE = RQ_DIR / "logs" / "step00_extract_congruence_data.log"

# RQ 5.1 input paths (cross-RQ dependency)
RQ1_DIR = PROJECT_ROOT / "results" / "ch5" / "5.1.1"
RQ1_IRT_INPUT = RQ1_DIR / "data" / "step00_irt_input.csv"
RQ1_TSVR_MAPPING = RQ1_DIR / "data" / "step00_tsvr_mapping.csv"

# Output paths
OUTPUT_IRT_INPUT = RQ_DIR / "data" / "step00_irt_input.csv"
OUTPUT_Q_MATRIX = RQ_DIR / "data" / "step00_q_matrix.csv"
OUTPUT_TSVR_MAPPING = RQ_DIR / "data" / "step00_tsvr_mapping.csv"

# Interactive paradigm prefixes to KEEP
PARADIGM_PREFIXES_KEEP = ["TQ_IFR-", "TQ_ICR-", "TQ_IRE-"]

# Prefixes to explicitly EXCLUDE (Room Free Recall, Task Cued Recall)
PARADIGM_PREFIXES_EXCLUDE = ["TQ_RFR-", "TQ_TCR-", "TQ_RRE-"]

# Congruence mapping based on item suffix
CONGRUENCE_MAPPING = {
    "common": ["-i1", "-i2"],
    "congruent": ["-i3", "-i4"],
    "incongruent": ["-i5", "-i6"]
}

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 00: Extract Congruence Data")
        log(f"RQ Directory: {RQ_DIR}")
        log(f"Project Root: {PROJECT_ROOT}")

        # =========================================================================
        # STEP 1: Validate RQ 5.1 Input Files Exist
        # =========================================================================
        log("\n[VALIDATE] Checking RQ 5.1 input files...")

        if not RQ1_IRT_INPUT.exists():
            raise FileNotFoundError(f"RQ 5.1 IRT input not found: {RQ1_IRT_INPUT}")
        log(f"[PASS] Found: {RQ1_IRT_INPUT}")

        if not RQ1_TSVR_MAPPING.exists():
            raise FileNotFoundError(f"RQ 5.1 TSVR mapping not found: {RQ1_TSVR_MAPPING}")
        log(f"[PASS] Found: {RQ1_TSVR_MAPPING}")

        # =========================================================================
        # STEP 2: Load RQ 5.1 IRT Input
        # =========================================================================
        log("\n[LOAD] Loading RQ 5.1 IRT input...")
        df_rq1_irt = pd.read_csv(RQ1_IRT_INPUT)
        log(f"[LOADED] {RQ1_IRT_INPUT.name} ({len(df_rq1_irt)} rows, {len(df_rq1_irt.columns)} cols)")

        # =========================================================================
        # STEP 3: Filter to Interactive Paradigm Items Only
        # =========================================================================
        log("\n[FILTER] Filtering to interactive paradigm items...")

        # Get all columns
        all_columns = df_rq1_irt.columns.tolist()

        # Keep composite_ID and interactive paradigm columns
        keep_columns = ["composite_ID"]

        for col in all_columns:
            if col == "composite_ID":
                continue

            # Check if column starts with any of the KEEP prefixes
            is_interactive = any(col.startswith(prefix) for prefix in PARADIGM_PREFIXES_KEEP)

            # Check it's NOT in the exclude list
            is_excluded = any(col.startswith(prefix) for prefix in PARADIGM_PREFIXES_EXCLUDE)

            if is_interactive and not is_excluded:
                keep_columns.append(col)

        df_irt_input = df_rq1_irt[keep_columns].copy()

        n_items = len(keep_columns) - 1  # Exclude composite_ID
        log(f"[FILTERED] Kept {n_items} interactive paradigm items")
        log(f"[FILTERED] Removed {len(all_columns) - len(keep_columns)} non-interactive columns")

        # =========================================================================
        # STEP 4: Create Q-Matrix (Item-to-Congruence Dimension Mapping)
        # =========================================================================
        log("\n[Q-MATRIX] Creating congruence Q-matrix...")

        item_columns = [col for col in keep_columns if col != "composite_ID"]

        q_matrix_data = []
        for item_name in item_columns:
            # Determine congruence category from item suffix
            congruence_found = None
            for congruence, suffixes in CONGRUENCE_MAPPING.items():
                if any(item_name.endswith(suffix) for suffix in suffixes):
                    congruence_found = congruence
                    break

            if congruence_found is None:
                log(f"[WARN] Item '{item_name}' doesn't match any congruence suffix - skipping")
                continue

            q_matrix_data.append({
                "item_name": item_name,
                "common": 1 if congruence_found == "common" else 0,
                "congruent": 1 if congruence_found == "congruent" else 0,
                "incongruent": 1 if congruence_found == "incongruent" else 0
            })

        df_q_matrix = pd.DataFrame(q_matrix_data)

        # Validate Q-matrix structure
        row_sums = df_q_matrix[["common", "congruent", "incongruent"]].sum(axis=1)
        if not all(row_sums == 1):
            invalid_items = df_q_matrix[row_sums != 1]["item_name"].tolist()
            raise ValueError(f"Q-matrix invalid: items don't load on exactly 1 dimension: {invalid_items}")

        # Count items per congruence category
        n_common = df_q_matrix["common"].sum()
        n_congruent = df_q_matrix["congruent"].sum()
        n_incongruent = df_q_matrix["incongruent"].sum()

        log(f"[Q-MATRIX] Created Q-matrix with {len(df_q_matrix)} items:")
        log(f"  - common: {n_common} items")
        log(f"  - congruent: {n_congruent} items")
        log(f"  - incongruent: {n_incongruent} items")

        # =========================================================================
        # STEP 5: Copy TSVR Mapping
        # =========================================================================
        log("\n[COPY] Copying TSVR mapping from RQ 5.1...")
        df_tsvr = pd.read_csv(RQ1_TSVR_MAPPING)
        log(f"[COPIED] {RQ1_TSVR_MAPPING.name} ({len(df_tsvr)} rows)")

        # =========================================================================
        # STEP 6: Save Outputs
        # =========================================================================
        log("\n[SAVE] Saving output files...")

        # Ensure data directory exists
        (RQ_DIR / "data").mkdir(parents=True, exist_ok=True)

        # Save IRT input (filtered)
        df_irt_input.to_csv(OUTPUT_IRT_INPUT, index=False, encoding='utf-8')
        log(f"[SAVED] {OUTPUT_IRT_INPUT.name} ({len(df_irt_input)} rows, {len(df_irt_input.columns)} cols)")

        # Save Q-matrix
        df_q_matrix.to_csv(OUTPUT_Q_MATRIX, index=False, encoding='utf-8')
        log(f"[SAVED] {OUTPUT_Q_MATRIX.name} ({len(df_q_matrix)} rows)")

        # Save TSVR mapping
        df_tsvr.to_csv(OUTPUT_TSVR_MAPPING, index=False, encoding='utf-8')
        log(f"[SAVED] {OUTPUT_TSVR_MAPPING.name} ({len(df_tsvr)} rows)")

        # =========================================================================
        # STEP 7: Final Validation
        # =========================================================================
        log("\n[VALIDATE] Final validation checks...")

        # Check row count preserved
        assert len(df_irt_input) == len(df_rq1_irt), f"Row count mismatch: {len(df_irt_input)} vs {len(df_rq1_irt)}"
        log(f"[PASS] Row count preserved: {len(df_irt_input)} rows")

        # Check all congruence categories present
        assert n_common > 0, "No common items found"
        assert n_congruent > 0, "No congruent items found"
        assert n_incongruent > 0, "No incongruent items found"
        log("[PASS] All congruence categories present")

        # Check item values are valid (0, 1, or NaN)
        item_values = df_irt_input.drop(columns=["composite_ID"]).values.flatten()
        valid_values = {0.0, 1.0}
        unique_values = set(item_values[~np.isnan(item_values)])
        invalid_values = unique_values - valid_values
        if invalid_values:
            log(f"[WARN] Found unexpected item values: {invalid_values}")
        else:
            log("[PASS] Item values valid (0, 1, NaN only)")

        # Check output files exist
        assert OUTPUT_IRT_INPUT.exists(), f"Output file not created: {OUTPUT_IRT_INPUT}"
        assert OUTPUT_Q_MATRIX.exists(), f"Output file not created: {OUTPUT_Q_MATRIX}"
        assert OUTPUT_TSVR_MAPPING.exists(), f"Output file not created: {OUTPUT_TSVR_MAPPING}"
        log("[PASS] All output files created")

        log("\n[SUCCESS] Step 00 complete")
        sys.exit(0)

    except Exception as e:
        log(f"\n[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
