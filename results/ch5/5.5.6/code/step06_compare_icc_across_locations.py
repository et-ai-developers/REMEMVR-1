#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step06
Step Name: Compare ICC Across Locations
RQ: results/ch5/5.5.6
Generated: 2025-12-05

PURPOSE:
Compare ICC_intercept between Source and Destination locations to test whether
destination memory shows different stability (secondary hypothesis from 1_concept.md).

EXPECTED INPUTS:
  - data/step03_icc_estimates.csv
    Columns: ['location', 'icc_type', 'value', 'interpretation']
    Format: CSV with 6 rows (3 ICC types x 2 locations)
    Expected rows: 6

EXPECTED OUTPUTS:
  - data/step06_location_icc_comparison.csv
    Columns: ['icc_type', 'source_value', 'destination_value', 'difference', 'interpretation']
    Format: CSV with 3 rows (one per ICC type)
    Expected rows: 3

VALIDATION CRITERIA:
  - Exactly 3 rows (one per ICC type)
  - source_value in [0, 1]
  - destination_value in [0, 1]
  - difference correctly computed (source_value - destination_value)
  - No NaN values

g_code REASONING:
- Approach: Simple pandas DataFrame filtering and merging to create ICC comparison table
- Why this approach: Descriptive comparison only (no formal inferential test per 2_plan.md)
- Data flow: Load step03 ICC estimates -> filter by location -> merge on icc_type -> compute difference
- Expected performance: ~seconds (simple pandas operations)

IMPLEMENTATION NOTES:
- Analysis tool: stdlib pandas operations (no custom tool needed)
- Validation tool: tools.validation.validate_dataframe_structure
- Parameters: Compare ALL 3 ICC types (ICC_intercept, ICC_slope_simple, ICC_slope_conditional)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/ (5.5.6)
#   parents[2] = chX/ (ch5)
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Note: validation done manually (no external validation tool call)

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.5.6
LOG_FILE = RQ_DIR / "logs" / "step06_compare_icc_across_locations.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step06_location_icc_comparison.csv
#   CORRECT: logs/step06_compare_icc_across_locations.log
#   WRONG:   results/icc_comparison.csv  (wrong folder + no prefix)
#   WRONG:   data/icc_comparison.csv     (missing step prefix)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 06: Compare ICC Across Locations")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: ICC estimates from Step 3 (6 rows: 3 ICC types x 2 locations)
        # Purpose: Extract Source and Destination ICC values for comparison

        log("[LOAD] Loading ICC estimates from Step 3...")
        input_path = RQ_DIR / "data" / "step03_icc_estimates.csv"

        if not input_path.exists():
            log(f"[ERROR] Input file not found: {input_path}")
            sys.exit(1)

        icc_estimates = pd.read_csv(input_path, encoding='utf-8')
        log(f"[LOADED] {input_path.name} ({len(icc_estimates)} rows, {len(icc_estimates.columns)} cols)")

        # Check expected structure
        if len(icc_estimates) != 6:
            log(f"[WARNING] Expected 6 rows, got {len(icc_estimates)}")

        expected_cols = ['location', 'icc_type', 'value', 'interpretation']
        if not all(col in icc_estimates.columns for col in expected_cols):
            log(f"[ERROR] Missing expected columns. Expected: {expected_cols}, Got: {list(icc_estimates.columns)}")
            sys.exit(1)

        # =========================================================================
        # STEP 2: Filter by Location
        # =========================================================================
        # Tool: pandas DataFrame filtering
        # What it does: Separate Source and Destination ICC estimates
        # Expected output: Two DataFrames (3 rows each)

        log("[FILTER] Separating Source and Destination ICC estimates...")

        source_df = icc_estimates[icc_estimates['location'] == 'Source'].copy()
        destination_df = icc_estimates[icc_estimates['location'] == 'Destination'].copy()

        log(f"[FILTERED] Source: {len(source_df)} rows, Destination: {len(destination_df)} rows")

        if len(source_df) != 3:
            log(f"[WARNING] Expected 3 Source ICC types, got {len(source_df)}")
        if len(destination_df) != 3:
            log(f"[WARNING] Expected 3 Destination ICC types, got {len(destination_df)}")

        # =========================================================================
        # STEP 3: Merge on ICC Type
        # =========================================================================
        # Tool: pandas merge (inner join)
        # What it does: Combine Source and Destination values for each ICC type
        # Expected output: DataFrame with 3 rows (one per ICC type)

        log("[MERGE] Merging Source and Destination on icc_type...")

        # Rename value columns before merge
        source_df = source_df.rename(columns={'value': 'source_value', 'interpretation': 'source_interpretation'})
        destination_df = destination_df.rename(columns={'value': 'destination_value', 'interpretation': 'destination_interpretation'})

        # Merge on icc_type
        comparison_df = source_df[['icc_type', 'source_value', 'source_interpretation']].merge(
            destination_df[['icc_type', 'destination_value', 'destination_interpretation']],
            on='icc_type',
            how='inner'
        )

        log(f"[MERGED] Combined table: {len(comparison_df)} rows")

        # =========================================================================
        # STEP 4: Compute Difference
        # =========================================================================
        # Formula: difference = source_value - destination_value
        # Interpretation:
        #   diff > 0: Source shows higher stability
        #   diff < 0: Destination shows higher stability
        #   diff near 0: Equivalent stability

        log("[COMPUTE] Computing difference (source_value - destination_value)...")

        comparison_df['difference'] = comparison_df['source_value'] - comparison_df['destination_value']

        log(f"[COMPUTED] Difference column added")

        # =========================================================================
        # STEP 5: Generate Interpretation String
        # =========================================================================
        # Describe difference magnitude and direction

        log("[INTERPRET] Generating interpretation strings...")

        def generate_interpretation(row):
            """Generate descriptive interpretation based on difference magnitude."""
            diff = row['difference']
            icc_type = row['icc_type']

            if icc_type == 'ICC_intercept':
                # Primary comparison of interest (baseline stability)
                if diff > 0.10:
                    return "Source shows substantially higher baseline stability than Destination"
                elif diff > 0.05:
                    return "Source shows moderately higher baseline stability than Destination"
                elif diff > 0:
                    return "Source shows slightly higher baseline stability than Destination"
                elif diff > -0.05:
                    return "Source and Destination show approximately equal baseline stability"
                elif diff > -0.10:
                    return "Destination shows moderately higher baseline stability than Source"
                else:
                    return "Destination shows substantially higher baseline stability than Source"
            elif 'slope' in icc_type.lower():
                # Slope ICCs expected near zero (both locations)
                if abs(diff) < 0.01:
                    return "Both locations show near-zero slope variance (expected pattern)"
                else:
                    return f"Difference in slope variance: {diff:.4f} (both near zero)"
            else:
                # Generic interpretation
                if diff > 0:
                    return f"Source higher by {diff:.4f}"
                elif diff < 0:
                    return f"Destination higher by {abs(diff):.4f}"
                else:
                    return "Equivalent"

        comparison_df['interpretation'] = comparison_df.apply(generate_interpretation, axis=1)

        log(f"[INTERPRETED] Interpretation column added")

        # =========================================================================
        # STEP 6: Select Output Columns
        # =========================================================================
        # Output format: icc_type, source_value, destination_value, difference, interpretation

        log("[SELECT] Selecting output columns...")

        output_df = comparison_df[['icc_type', 'source_value', 'destination_value', 'difference', 'interpretation']].copy()

        # Sort by icc_type for consistent output (intercept, slope_conditional, slope_simple)
        output_df = output_df.sort_values('icc_type').reset_index(drop=True)

        log(f"[SELECTED] Final output: {len(output_df)} rows, {len(output_df.columns)} cols")

        # =========================================================================
        # STEP 7: Save Output
        # =========================================================================
        # Output: data/step06_location_icc_comparison.csv

        log("[SAVE] Saving ICC comparison table...")
        output_path = RQ_DIR / "data" / "step06_location_icc_comparison.csv"
        output_df.to_csv(output_path, index=False, encoding='utf-8')
        log(f"[SAVED] {output_path.name} ({len(output_df)} rows, {len(output_df.columns)} cols)")

        # =========================================================================
        # STEP 8: Run Validation
        # =========================================================================
        # Validate: 3 rows, 5 columns, correct structure, value bounds

        log("[VALIDATION] Checking output structure...")

        # Check row count
        if len(output_df) != 3:
            log(f"[VALIDATION] FAIL - Expected 3 rows, got {len(output_df)}")
            sys.exit(1)
        log("[VALIDATION] PASS - Row count: 3")

        # Check column count
        expected_cols = ['icc_type', 'source_value', 'destination_value', 'difference', 'interpretation']
        if list(output_df.columns) != expected_cols:
            log(f"[VALIDATION] FAIL - Expected columns {expected_cols}, got {list(output_df.columns)}")
            sys.exit(1)
        log("[VALIDATION] PASS - All expected columns present")

        # Additional value range checks
        log("[VALIDATION] Checking ICC value bounds...")

        # Check source_value in [0, 1]
        if not all((output_df['source_value'] >= 0) & (output_df['source_value'] <= 1)):
            invalid_rows = output_df[(output_df['source_value'] < 0) | (output_df['source_value'] > 1)]
            log(f"[VALIDATION] FAIL - source_value out of bounds [0, 1]:")
            log(f"{invalid_rows}")
            sys.exit(1)
        log("[VALIDATION] PASS - source_value in [0, 1]")

        # Check destination_value in [0, 1]
        if not all((output_df['destination_value'] >= 0) & (output_df['destination_value'] <= 1)):
            invalid_rows = output_df[(output_df['destination_value'] < 0) | (output_df['destination_value'] > 1)]
            log(f"[VALIDATION] FAIL - destination_value out of bounds [0, 1]:")
            log(f"{invalid_rows}")
            sys.exit(1)
        log("[VALIDATION] PASS - destination_value in [0, 1]")

        # Check difference correctly computed
        expected_diff = output_df['source_value'] - output_df['destination_value']
        if not all(np.abs(output_df['difference'] - expected_diff) < 1e-10):
            log("[VALIDATION] FAIL - difference not correctly computed")
            sys.exit(1)
        log("[VALIDATION] PASS - difference correctly computed")

        # Check for NaN values
        if output_df.isna().any().any():
            log("[VALIDATION] FAIL - NaN values detected")
            log(f"NaN counts per column:\n{output_df.isna().sum()}")
            sys.exit(1)
        log("[VALIDATION] PASS - No NaN values")

        # =========================================================================
        # STEP 9: Report Summary
        # =========================================================================

        log("\n[SUMMARY] ICC Comparison Results:")
        log("=" * 60)
        for _, row in output_df.iterrows():
            log(f"{row['icc_type']}:")
            log(f"  Source:      {row['source_value']:.4f}")
            log(f"  Destination: {row['destination_value']:.4f}")
            log(f"  Difference:  {row['difference']:+.4f}")
            log(f"  {row['interpretation']}")
            log("")

        # Highlight ICC_intercept (primary comparison)
        intercept_row = output_df[output_df['icc_type'] == 'ICC_intercept'].iloc[0]
        log("[PRIMARY COMPARISON] ICC_intercept (baseline stability):")
        log(f"  Source:      {intercept_row['source_value']:.4f}")
        log(f"  Destination: {intercept_row['destination_value']:.4f}")
        log(f"  Difference:  {intercept_row['difference']:+.4f}")

        if intercept_row['difference'] > 0:
            log(f"  -> Source shows HIGHER baseline stability (supports hypothesis if destination encoding weaker)")
        elif intercept_row['difference'] < 0:
            log(f"  -> Destination shows HIGHER baseline stability (contradicts hypothesis)")
        else:
            log(f"  -> Equivalent baseline stability (null finding)")

        log("\n[SUCCESS] Step 06 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
