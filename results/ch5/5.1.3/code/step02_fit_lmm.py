#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step02
Step Name: step02_fit_lmm
RQ: results/ch5/rq9
Generated: 2025-11-28

PURPOSE:
Fit Linear Mixed Model (LMM) testing age effects on baseline memory and
forgetting rate using Lin+Log functional form. Tests whether older adults
have lower baseline memory (Age_c main effect) and/or faster forgetting
(Age_c × Time interaction).

EXPECTED INPUTS:
  - data/step01_lmm_input_prepared.csv
    Columns: ['composite_ID', 'UID', 'TEST', 'TSVR_hours', 'theta', 'se_all',
              'age', 'Age_c', 'Time', 'Time_log']
    Format: Long-format LMM input with grand-mean centered Age and time
            transformations (linear Time + log-transformed Time_log)
    Expected rows: ~400 (100 participants × 4 test sessions)

EXPECTED OUTPUTS:
  - data/step02_lmm_model.pkl
    Format: Pickle file containing fitted statsmodels MixedLMResults object
    Description: Fitted LMM for downstream analysis (extraction, predictions)

  - results/step02_lmm_summary.txt
    Format: Plain text human-readable model summary
    Description: Fixed effects, random effects, fit statistics
    Expected content: ~50-100 lines of statsmodels summary output

  - data/step02_fixed_effects.csv
    Columns: ['term', 'coef', 'se', 'z', 'p']
    Format: Fixed effects table with 6 rows (Intercept + 5 predictors)
    Expected rows: 6 (Intercept, Time, Time_log, Age_c, Time:Age_c, Time_log:Age_c)

VALIDATION CRITERIA:
  - Model convergence: lmm_result.converged == True
  - Residuals approximately normal (Shapiro-Wilk test)
  - Homoscedasticity (Breusch-Pagan test)
  - Random effects approximately normal
  - No strong autocorrelation (ACF lag-1 < 0.1)
  - No influential outliers (Cook's distance < 1.0)

g_code REASONING:
- Approach: Fit LMM with Lin+Log functional form to capture both linear and
  logarithmic components of forgetting trajectory. Test Age effects on baseline
  (main effect) and forgetting rate (interactions with Time and Time_log).

- Why this approach: Lin+Log model allows flexible forgetting curve while
  maintaining interpretability. Age × Time interactions test whether older
  adults forget faster than younger adults.

- Data flow: Load prepared data (Age_c, Time, Time_log) → Fit LMM using
  statsmodels mixedlm → Extract fixed effects → Save model + summary + table

- Expected performance: ~30-90 seconds (LMM fitting for N=100, 400 observations)

IMPLEMENTATION NOTES:
- Analysis tool: statsmodels.formula.api.mixedlm (stdlib, not custom tool)
- Validation tools:
  - validate_model_convergence from tools.validation
  - validate_lmm_assumptions_comprehensive from tools.validation
- Parameters:
  - Formula: theta ~ (Time + Time_log) * Age_c
  - Random effects: (Time | UID) - random intercepts + random slopes for Time
  - REML: False (use Maximum Likelihood for model comparison compatibility)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import pickle
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = chX/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import statsmodels for LMM fitting
from statsmodels.formula.api import mixedlm
from statsmodels.regression.mixed_linear_model import MixedLMResults

# Import validation tools
from tools.validation import validate_model_convergence, validate_lmm_assumptions_comprehensive

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/rq9 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step02_fit_lmm.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step02_lmm_model.pkl
#   CORRECT: data/step02_fixed_effects.csv
#   WRONG:   results/lmm_model.pkl         (wrong folder + no prefix)
#   WRONG:   data/fixed_effects.csv        (missing step prefix)
#   WRONG:   logs/step02_model.pkl         (pkl in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 02: Fit LMM (Age × Time Interaction with Lin+Log)")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Prepared LMM input with Age_c (centered), Time, Time_log
        # Purpose: Input for LMM fitting with age effects on baseline and forgetting

        log("[LOAD] Loading prepared LMM input data...")
        input_path = RQ_DIR / "data" / "step01_lmm_input_prepared.csv"
        df_lmm = pd.read_csv(input_path)
        log(f"[LOADED] {input_path.name} ({len(df_lmm)} rows, {len(df_lmm.columns)} cols)")

        # Validate expected columns present
        required_cols = ['composite_ID', 'UID', 'TEST', 'TSVR_hours', 'theta',
                        'se_all', 'age', 'Age_c', 'Time', 'Time_log']
        missing_cols = [col for col in required_cols if col not in df_lmm.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")
        log(f"[VALIDATION] All required columns present: {required_cols}")

        # Report data summary
        log(f"[INFO] Data summary:")
        log(f"  - N participants: {df_lmm['UID'].nunique()}")
        log(f"  - N observations: {len(df_lmm)}")
        log(f"  - Age_c range: [{df_lmm['Age_c'].min():.2f}, {df_lmm['Age_c'].max():.2f}]")
        log(f"  - Age_c mean: {df_lmm['Age_c'].mean():.4f} (should be ~0)")
        log(f"  - Time range: [{df_lmm['Time'].min():.2f}, {df_lmm['Time'].max():.2f}] hours")
        log(f"  - Time_log range: [{df_lmm['Time_log'].min():.2f}, {df_lmm['Time_log'].max():.2f}]")

        # =========================================================================
        # STEP 2: Fit LMM with Age × Time Interaction (Lin+Log)
        # =========================================================================
        # Formula: theta ~ (Time + Time_log) * Age_c
        # Expands to: theta ~ Time + Time_log + Age_c + Time:Age_c + Time_log:Age_c
        # Random effects: (Time | UID) - random intercepts + random slopes for Time
        # REML: False - use ML for model comparison compatibility

        log("[ANALYSIS] Fitting LMM with formula: theta ~ (Time + Time_log) * Age_c")
        log("[ANALYSIS] Random effects: (Time | UID)")
        log("[ANALYSIS] REML: False (using Maximum Likelihood)")

        # Define formula components
        formula = "theta ~ (Time + Time_log) * Age_c"
        re_formula = "Time"  # Random intercepts + random slopes for Time
        groups = df_lmm['UID']

        # Fit LMM
        log("[FITTING] Model fitting in progress (may take 30-90 seconds)...")
        lmm_model = mixedlm(formula=formula,
                           data=df_lmm,
                           groups=groups,
                           re_formula=re_formula,
                           missing='drop')
        lmm_result = lmm_model.fit(reml=False)
        log("[DONE] LMM fitting complete")

        # Check convergence
        if hasattr(lmm_result, 'converged') and lmm_result.converged:
            log("[CONVERGENCE] Model converged successfully")
        elif hasattr(lmm_result, 'converged'):
            log("[WARNING] Model did NOT converge (converged=False)")
        else:
            log("[WARNING] Convergence status unknown (no converged attribute)")

        # =========================================================================
        # STEP 3: Save LMM Model and Summary
        # =========================================================================
        # Outputs:
        # 1. data/step02_lmm_model.pkl - Fitted model object for downstream use
        # 2. results/step02_lmm_summary.txt - Human-readable summary
        # 3. data/step02_fixed_effects.csv - Fixed effects table

        # Save fitted model as pickle
        model_path = RQ_DIR / "data" / "step02_lmm_model.pkl"
        log(f"[SAVE] Saving fitted model to {model_path.name}...")
        lmm_result.save(str(model_path))
        log(f"[SAVED] {model_path.name}")

        # Save model summary as text
        summary_path = RQ_DIR / "results" / "step02_lmm_summary.txt"
        log(f"[SAVE] Saving model summary to {summary_path.name}...")
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(str(lmm_result.summary()))
        log(f"[SAVED] {summary_path.name}")

        # Extract and save fixed effects table
        log("[EXTRACT] Extracting fixed effects table...")
        fixed_effects = lmm_result.fe_params
        fixed_effects_se = lmm_result.bse_fe
        fixed_effects_z = lmm_result.tvalues
        fixed_effects_p = lmm_result.pvalues

        # Create fixed effects DataFrame using index alignment
        df_fixed = pd.DataFrame({
            'term': fixed_effects.index.tolist(),
            'coef': fixed_effects.tolist(),
            'se': [fixed_effects_se[idx] for idx in fixed_effects.index],
            'z': [fixed_effects_z[idx] for idx in fixed_effects.index],
            'p': [fixed_effects_p[idx] for idx in fixed_effects.index]
        })

        # Save fixed effects table
        fixed_path = RQ_DIR / "data" / "step02_fixed_effects.csv"
        log(f"[SAVE] Saving fixed effects table to {fixed_path.name}...")
        df_fixed.to_csv(fixed_path, index=False, encoding='utf-8')
        log(f"[SAVED] {fixed_path.name} ({len(df_fixed)} rows)")

        # Report fixed effects summary
        log("[INFO] Fixed effects summary:")
        for _, row in df_fixed.iterrows():
            sig_flag = "***" if row['p'] < 0.001 else "**" if row['p'] < 0.01 else "*" if row['p'] < 0.05 else ""
            log(f"  - {row['term']}: coef={row['coef']:.4f}, SE={row['se']:.4f}, z={row['z']:.2f}, p={row['p']:.4f} {sig_flag}")

        # =========================================================================
        # STEP 4: Run Validation - Model Convergence
        # =========================================================================
        # Tool: validate_model_convergence
        # Validates: lmm_result.converged == True

        log("[VALIDATION] Running validate_model_convergence...")
        convergence_result = validate_model_convergence(lmm_result)

        if convergence_result['valid']:
            log(f"[VALIDATION] PASS - {convergence_result['message']}")
        else:
            log(f"[VALIDATION] FAIL - {convergence_result['message']}")
            raise ValueError(f"Model convergence validation failed: {convergence_result['message']}")

        # =========================================================================
        # STEP 5: Run Validation - LMM Assumptions (Comprehensive)
        # =========================================================================
        # Tool: validate_lmm_assumptions_comprehensive
        # Validates:
        #   - Residual normality (Shapiro-Wilk)
        #   - Homoscedasticity (Breusch-Pagan)
        #   - Random effects normality
        #   - No strong autocorrelation (ACF lag-1 < 0.1)
        #   - No influential outliers (Cook's distance < 1.0)
        # Generates diagnostic plots in logs/ folder

        log("[VALIDATION] Running validate_lmm_assumptions_comprehensive...")
        log("[VALIDATION] This will generate 6 diagnostic plots in logs/ folder")

        assumptions_result = validate_lmm_assumptions_comprehensive(
            lmm_result=lmm_result,
            data=df_lmm,
            output_dir=RQ_DIR / "logs",
            acf_lag1_threshold=0.1,
            alpha=0.05
        )

        # Report validation results
        if assumptions_result['valid']:
            log(f"[VALIDATION] PASS - All LMM assumptions validated")
            log(f"[VALIDATION] Diagnostic plots saved:")
            for plot_path in assumptions_result.get('plot_paths', []):
                log(f"  - {Path(plot_path).name}")
        else:
            log(f"[VALIDATION] WARNING - {assumptions_result['message']}")
            log(f"[VALIDATION] Diagnostic details:")
            for key, value in assumptions_result.get('diagnostics', {}).items():
                log(f"  - {key}: {value}")
            log("[INFO] Assumption violations noted but not fatal - proceeding with analysis")
            log("[INFO] Violations will be reported in results summary")

        log("[SUCCESS] Step 02 complete - LMM fitted and validated")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
