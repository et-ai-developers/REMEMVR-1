#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step08
Step Name: Prepare Trajectory Comparison Plot Data
RQ: results/ch5/rq11
Generated: 2025-11-29

PURPOSE:
Create plot source CSV for trajectory comparison showing IRT vs CTT trajectories
over time per domain (Option B architecture). Aggregates observed scores by
TSVR_hours and domain for both IRT and CTT models, computes means with 95% CIs.

EXPECTED INPUTS:
  - data/step03_irt_lmm_input.csv
    Columns: ['composite_ID', 'UID', 'test', 'domain', 'TSVR_hours', 'IRT_score']
    Format: Long-format IRT LMM input (1200 rows = 400 participants x 3 domains)
    Expected rows: 1200

  - data/step03_ctt_lmm_input.csv
    Columns: ['composite_ID', 'UID', 'test', 'domain', 'TSVR_hours', 'CTT_score']
    Format: Long-format CTT LMM input (1200 rows = 400 participants x 3 domains)
    Expected rows: 1200

EXPECTED OUTPUTS:
  - data/step08_trajectory_data.csv
    Columns: ['TSVR_hours', 'domain', 'model', 'mean_score', 'CI_lower', 'CI_upper', 'n']
    Format: Aggregated trajectory data (~4 timepoints x 3 domains x 2 models)
    Expected rows: 20-30 (depends on number of unique TSVR_hours values)

VALIDATION CRITERIA:
  - All 3 domains present (What, Where, When)
  - Both models present (IRT, CTT)
  - No missing categories (complete factorial design)
  - CI_lower < mean_score < CI_upper (confidence bounds bracket mean)

g_code REASONING:
- Approach: Aggregate observed scores by TSVR_hours + domain for IRT and CTT separately,
  compute group means and 95% CIs, then stack into single long-format CSV for plotting
- Why this approach: Option B architecture separates data prep (g_code) from visualization
  (rq_plots), enabling flexible plot styling without recomputation
- Data flow: Load IRT/CTT inputs -> Group by time+domain -> Compute stats -> Stack -> Save
- Expected performance: <5 seconds (simple aggregation on 1200 rows)

IMPLEMENTATION NOTES:
- Analysis tool: stdlib (pandas groupby aggregation)
- Validation tool: validate_plot_data_completeness from tools.validation
- Parameters: 95% CI using scipy.stats.sem + 1.96 multiplier
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = chX/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import validation tool
from tools.validation import validate_plot_data_completeness

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/rq11 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step08_prepare_trajectory.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step08_trajectory_data.csv
#   CORRECT: logs/step08_prepare_trajectory.log
#   WRONG:   results/trajectory_data.csv  (wrong folder + no prefix)
#   WRONG:   data/trajectory_data.csv     (missing step prefix)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 8: Prepare Trajectory Comparison Plot Data")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Long-format IRT and CTT LMM inputs from Step 3
        # Purpose: Aggregate observed scores by timepoint and domain for plotting

        log("[LOAD] Loading IRT LMM input...")
        irt_lmm_input = pd.read_csv(RQ_DIR / "data" / "step03_irt_lmm_input.csv", encoding='utf-8')
        log(f"[LOADED] step03_irt_lmm_input.csv ({len(irt_lmm_input)} rows, {len(irt_lmm_input.columns)} cols)")

        log("[LOAD] Loading CTT LMM input...")
        ctt_lmm_input = pd.read_csv(RQ_DIR / "data" / "step03_ctt_lmm_input.csv", encoding='utf-8')
        log(f"[LOADED] step03_ctt_lmm_input.csv ({len(ctt_lmm_input)} rows, {len(ctt_lmm_input.columns)} cols)")

        # =========================================================================
        # STEP 2: Aggregate IRT Scores by TSVR_hours + Domain
        # =========================================================================
        # Tool: pandas groupby with mean and SEM for 95% CI
        # What it does: Group IRT scores by timepoint and domain, compute descriptive stats
        # Expected output: ~12 rows (4 timepoints x 3 domains)

        log("[AGGREGATE] Aggregating IRT scores by TSVR_hours + domain...")

        irt_agg = irt_lmm_input.groupby(['TSVR_hours', 'domain'])['IRT_score'].agg([
            ('mean_score', 'mean'),
            ('sem', lambda x: x.sem()),  # Standard error of the mean
            ('n', 'count')
        ]).reset_index()

        # Compute 95% CI using SEM * 1.96
        irt_agg['CI_lower'] = irt_agg['mean_score'] - 1.96 * irt_agg['sem']
        irt_agg['CI_upper'] = irt_agg['mean_score'] + 1.96 * irt_agg['sem']

        # Add model identifier
        irt_agg['model'] = 'IRT'

        # Drop SEM column (not needed for output)
        irt_agg = irt_agg[['TSVR_hours', 'domain', 'model', 'mean_score', 'CI_lower', 'CI_upper', 'n']]

        log(f"[AGGREGATED] IRT: {len(irt_agg)} aggregated rows")

        # =========================================================================
        # STEP 3: Aggregate CTT Scores by TSVR_hours + Domain
        # =========================================================================
        # Tool: pandas groupby (identical to IRT aggregation)
        # What it does: Group CTT scores by timepoint and domain, compute descriptive stats
        # Expected output: ~12 rows (4 timepoints x 3 domains)

        log("[AGGREGATE] Aggregating CTT scores by TSVR_hours + domain...")

        ctt_agg = ctt_lmm_input.groupby(['TSVR_hours', 'domain'])['CTT_score'].agg([
            ('mean_score', 'mean'),
            ('sem', lambda x: x.sem()),  # Standard error of the mean
            ('n', 'count')
        ]).reset_index()

        # Compute 95% CI using SEM * 1.96
        ctt_agg['CI_lower'] = ctt_agg['mean_score'] - 1.96 * ctt_agg['sem']
        ctt_agg['CI_upper'] = ctt_agg['mean_score'] + 1.96 * ctt_agg['sem']

        # Add model identifier
        ctt_agg['model'] = 'CTT'

        # Drop SEM column (not needed for output)
        ctt_agg = ctt_agg[['TSVR_hours', 'domain', 'model', 'mean_score', 'CI_lower', 'CI_upper', 'n']]

        log(f"[AGGREGATED] CTT: {len(ctt_agg)} aggregated rows")

        # =========================================================================
        # STEP 4: Stack IRT and CTT Aggregations
        # =========================================================================
        # These outputs will be used by: rq_plots for trajectory comparison visualization

        log("[STACK] Combining IRT and CTT aggregations...")

        trajectory_data = pd.concat([irt_agg, ctt_agg], axis=0, ignore_index=True)

        # Sort by domain, model, TSVR_hours for consistent plotting
        trajectory_data = trajectory_data.sort_values(by=['domain', 'model', 'TSVR_hours']).reset_index(drop=True)

        log(f"[STACKED] Combined trajectory data: {len(trajectory_data)} rows")

        # =========================================================================
        # STEP 5: Save Trajectory Plot Data
        # =========================================================================
        # Output: data/step08_trajectory_data.csv
        # Contains: Aggregated means and CIs for all domain x model x timepoint combinations
        # Columns: TSVR_hours, domain, model, mean_score, CI_lower, CI_upper, n

        output_path = RQ_DIR / "data" / "step08_trajectory_data.csv"
        log(f"[SAVE] Saving trajectory data to {output_path.name}...")

        trajectory_data.to_csv(output_path, index=False, encoding='utf-8')

        log(f"[SAVED] {output_path.name} ({len(trajectory_data)} rows, {len(trajectory_data.columns)} cols)")
        log(f"[INFO] Unique TSVR_hours values: {sorted(trajectory_data['TSVR_hours'].unique())}")
        log(f"[INFO] Domains: {sorted(trajectory_data['domain'].unique())}")
        log(f"[INFO] Models: {sorted(trajectory_data['model'].unique())}")

        # =========================================================================
        # STEP 6: Run Validation Tool
        # =========================================================================
        # Tool: validate_plot_data_completeness
        # Validates: All domains and models present (complete factorial design)
        # Threshold: All 3 domains (What, Where, When), both models (IRT, CTT)

        log("[VALIDATION] Running validate_plot_data_completeness...")

        validation_result = validate_plot_data_completeness(
            plot_data=trajectory_data,
            required_domains=['What', 'Where', 'When'],
            required_groups=['IRT', 'CTT'],
            domain_col='domain',
            group_col='model'
        )

        # Report validation results
        # Expected: All domains and models present, no missing categories
        if validation_result['valid']:
            log(f"[VALIDATION] PASS - {validation_result['message']}")
        else:
            log(f"[VALIDATION] FAIL - {validation_result['message']}")
            if 'missing_domains' in validation_result and validation_result['missing_domains']:
                log(f"[VALIDATION] Missing domains: {validation_result['missing_domains']}")
            if 'missing_groups' in validation_result and validation_result['missing_groups']:
                log(f"[VALIDATION] Missing models: {validation_result['missing_groups']}")
            raise ValueError(f"Validation failed: {validation_result['message']}")

        # Additional sanity check: CI_lower < mean_score < CI_upper
        log("[VALIDATION] Checking CI bounds bracket mean...")
        ci_violations = trajectory_data[
            (trajectory_data['CI_lower'] > trajectory_data['mean_score']) |
            (trajectory_data['CI_upper'] < trajectory_data['mean_score'])
        ]

        if len(ci_violations) > 0:
            log(f"[VALIDATION] FAIL - {len(ci_violations)} rows have invalid CI bounds")
            log(f"[VALIDATION] Violations:\n{ci_violations}")
            raise ValueError("CI bounds do not bracket mean for some rows")
        else:
            log("[VALIDATION] PASS - All CI bounds bracket means correctly")

        log("[SUCCESS] Step 8 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
