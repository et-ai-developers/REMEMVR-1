#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step00
Step Name: Load RQ 5.3 Outputs
RQ: results/ch5/rq4
Generated: 2025-11-24

PURPOSE:
Load fitted LMM model and theta data from RQ 5.3 for contrast analysis.
This step establishes the foundation for RQ 5.4's linear trend contrast by
loading the best-fitting model (Log model) from RQ 5.3.

EXPECTED INPUTS:
  - results/ch5/rq3/data/step05_lmm_fitted_model.pkl
    Description: Fitted MixedLM model object (Log model, best AIC)
    Source: RQ 5.3 Step 5
  - results/ch5/rq3/data/step04_lmm_input.csv
    Columns: [composite_ID, UID, test, TSVR_hours, TSVR_hours_sq, TSVR_hours_log, paradigm, theta]
    Expected rows: ~1200 (100 participants x 4 tests x 3 paradigms)
    Source: RQ 5.3 Step 4
  - results/ch5/rq3/data/step05_model_comparison.csv
    Columns: [model_name, AIC, delta_AIC, AIC_weight, converged]
    Source: RQ 5.3 Step 5

EXPECTED OUTPUTS:
  - data/step00_model_loaded.txt
    Description: Text file confirming successful model load with model details

VALIDATION CRITERIA:
  - Model converged (no convergence warnings)
  - Model has valid parameters (not None, not NaN)
  - Model has accessible covariance matrix
  - Dependency files exist
  - Data has exactly 3 paradigm levels
  - Data has ~1200 observations

g_code REASONING:
- Approach: Load pre-fitted LMM from pickle, validate attributes before proceeding
- Why this approach: RQ 5.4 is a SECONDARY analysis on RQ 5.3's model - we don't refit
- Data flow: RQ 5.3 outputs -> load -> validate -> proceed to contrast analysis
- Expected performance: ~1-2 seconds (just file loading, no computation)

IMPLEMENTATION NOTES:
- Uses statsmodels MixedLMResults.load() method (NOT pickle.load)
- Validates model has params, cov_params, nobs attributes
- Confirms Log model was best by checking model_comparison.csv
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (5 levels deep from project root)
# parents[4] = REMEMVR/ (code -> rqY -> chX -> results -> REMEMVR)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import validation tool
from tools.validation import validate_lmm_convergence

# Statsmodels for loading model
from statsmodels.regression.mixed_linear_model import MixedLMResults

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/rq4
RQ3_DIR = RQ_DIR.parent / "rq3"  # results/ch5/rq3 (dependency)
LOG_FILE = RQ_DIR / "logs" / "step00_load_rq53_outputs.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.log

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 00: Load RQ 5.3 Outputs")

        # =========================================================================
        # STEP 1: Verify Dependency Files Exist
        # =========================================================================
        # Expected: Three files from RQ 5.3 - model pickle, LMM input, model comparison
        # Purpose: Ensure RQ 5.3 completed successfully before proceeding

        log("[CHECK] Verifying RQ 5.3 dependency files...")

        model_path = RQ3_DIR / "data" / "step05_lmm_fitted_model.pkl"
        input_path = RQ3_DIR / "data" / "step04_lmm_input.csv"
        comparison_path = RQ3_DIR / "data" / "step05_model_comparison.csv"

        for path, name in [(model_path, "LMM model"),
                           (input_path, "LMM input data"),
                           (comparison_path, "Model comparison")]:
            if not path.exists():
                raise FileNotFoundError(f"RQ 5.3 dependency missing: {name} at {path}")
            log(f"[PASS] Found {name}: {path}")

        # =========================================================================
        # STEP 2: Load Model Comparison and Verify Best Model
        # =========================================================================
        # Expected: Log model should be best (lowest AIC)
        # Purpose: Confirm we're loading the correct model

        log("[LOAD] Loading model comparison results...")
        model_comparison = pd.read_csv(comparison_path)
        log(f"[LOADED] model_comparison: {len(model_comparison)} models compared")

        # Find best model (lowest AIC = first row after sorting by delta_AIC)
        best_model_name = model_comparison.loc[model_comparison['delta_AIC'] == 0, 'model_name'].iloc[0]
        best_aic = model_comparison.loc[model_comparison['delta_AIC'] == 0, 'AIC'].iloc[0]

        log(f"[INFO] Best model: {best_model_name} (AIC = {best_aic:.2f})")

        if best_model_name != "Log":
            log(f"[WARNING] Expected Log model to be best, but found {best_model_name}")
            log("[WARNING] Proceeding anyway - contrast analysis will use whatever model was fit")

        # =========================================================================
        # STEP 3: Load Fitted LMM Model
        # =========================================================================
        # Tool: statsmodels MixedLMResults.load() (NOT pickle.load)
        # What it does: Reconstructs the fitted model object from pickle
        # Expected output: MixedLMResults object with params, cov_params, nobs

        log("[LOAD] Loading fitted LMM model...")
        lmm_model = MixedLMResults.load(str(model_path))
        log("[LOADED] LMM model object successfully loaded")

        # Verify model attributes exist
        if not hasattr(lmm_model, 'params'):
            raise ValueError("Model missing 'params' attribute")
        if not hasattr(lmm_model, 'cov_params'):
            raise ValueError("Model missing 'cov_params' method")
        if not hasattr(lmm_model, 'nobs'):
            raise ValueError("Model missing 'nobs' attribute")

        log(f"[INFO] Model observations: {lmm_model.nobs}")
        log(f"[INFO] Number of fixed effects: {len(lmm_model.params)}")

        # =========================================================================
        # STEP 4: Load Theta Data
        # =========================================================================
        # Expected: ~1200 rows (100 participants x 4 tests x 3 paradigms)
        # Purpose: Have original data available for verification

        log("[LOAD] Loading theta data...")
        theta_data = pd.read_csv(input_path)
        log(f"[LOADED] theta_data: {len(theta_data)} rows, {len(theta_data.columns)} cols")

        # Verify required columns
        required_cols = ["composite_ID", "UID", "test", "TSVR_hours", "TSVR_hours_log", "paradigm", "theta"]
        missing_cols = [c for c in required_cols if c not in theta_data.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")

        # Check paradigm levels
        paradigms = theta_data['paradigm'].unique()
        log(f"[INFO] Paradigm levels: {list(paradigms)}")

        if len(paradigms) != 3:
            raise ValueError(f"Expected 3 paradigm levels, found {len(paradigms)}: {paradigms}")

        # =========================================================================
        # STEP 5: Run Validation Tool
        # =========================================================================
        # Tool: validate_lmm_convergence
        # Validates: Model convergence status

        log("[VALIDATION] Running validate_lmm_convergence...")
        validation_result = validate_lmm_convergence(lmm_model)

        for key, value in validation_result.items():
            log(f"[VALIDATION] {key}: {value}")

        if not validation_result.get('converged', False):
            raise ValueError(f"Model validation failed: {validation_result.get('message', 'Unknown error')}")

        # =========================================================================
        # STEP 6: Save Confirmation File
        # =========================================================================
        # Output: data/step00_model_loaded.txt
        # Contains: Model details confirming successful load

        log("[SAVE] Writing confirmation file...")
        confirmation_path = RQ_DIR / "data" / "step00_model_loaded.txt"
        confirmation_path.parent.mkdir(parents=True, exist_ok=True)

        confirmation_text = f"""RQ 5.4 - Step 00: Model Load Confirmation
==========================================

Source Files:
- Model: {model_path}
- Input Data: {input_path}
- Model Comparison: {comparison_path}

Best Model: {best_model_name}
Best Model AIC: {best_aic:.4f}

Model Statistics:
- Number of observations: {lmm_model.nobs}
- Number of fixed effects: {len(lmm_model.params)}
- Converged: {validation_result.get('converged', False)}

Fixed Effect Names:
{chr(10).join(['- ' + str(p) for p in lmm_model.params.index])}

Paradigm Levels in Data:
{chr(10).join(['- ' + str(p) for p in sorted(paradigms)])}

Theta Data Summary:
- Total rows: {len(theta_data)}
- Unique participants: {theta_data['UID'].nunique()}
- Tests per participant: ~{len(theta_data) // theta_data['UID'].nunique() // len(paradigms)}

Validation Status: PASSED
"""

        with open(confirmation_path, 'w', encoding='utf-8') as f:
            f.write(confirmation_text)

        log(f"[SAVED] {confirmation_path}")

        log("[SUCCESS] Step 00 complete - RQ 5.3 outputs loaded and validated")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
