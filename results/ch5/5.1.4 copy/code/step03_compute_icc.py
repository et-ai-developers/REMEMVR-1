#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step03
Step Name: compute_icc
RQ: results/ch5/5.1.4
Generated: 2025-11-30

PURPOSE:
Quantify proportion of variance that is between-person (stable individual
differences) vs within-person (measurement error) for both intercepts and slopes.
Computes three ICC estimates to answer RQ 5.13's primary question about whether
forgetting rates reflect stable traits or measurement noise.

EXPECTED INPUTS:
  - data/step02_variance_components.csv
    Columns: ['component', 'estimate']
    Format: CSV with 5 rows (var_intercept, var_slope, cov_int_slope, var_residual, cor_int_slope)
    Expected rows: 5

EXPECTED OUTPUTS:
  - data/step03_icc_estimates.csv
    Columns: ['icc_type', 'icc_value', 'interpretation']
    Format: 3 rows with ICC estimates (intercept, slope_simple, slope_conditional)
    Expected rows: 3

  - results/step03_icc_summary.txt
    Format: Plain text summary of ICC estimates with interpretations

  - logs/step03_icc_computation.log
    Format: Text log with computation formulas, intermediate values, validation

VALIDATION CRITERIA:
  - All ICC values in [0, 1] range (mathematical constraint)
  - No NaN values (all ICCs must be computed)
  - No infinite values (indicates computation error)

g_code REASONING:
- Approach: Use tools.analysis_lmm.compute_icc_from_variance_components to compute
  three ICC estimates from variance components extracted in Step 2
- Why this approach: ICC quantifies proportion of variance due to between-person
  differences (trait-like) vs within-person residual (measurement noise/state fluctuation)
- Data flow: Step 2 variance components → ICC computation → three estimates with interpretations
- Expected performance: <1 minute (mathematical computation only, no model fitting)

IMPLEMENTATION NOTES:
- Analysis tool: compute_icc_from_variance_components from tools.analysis_lmm
- Validation tool: validate_icc_bounds from tools.validation
- Parameters: time_point=None (triggers simple ICC without conditional adjustment),
  slope_name='TSVR_hours' (matches LMM time variable from RQ 5.7)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = chX/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_lmm import compute_icc_from_variance_components

# Import validation tool
from tools.validation import validate_icc_bounds

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/chX/rqY (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step03_icc_computation.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step03_icc_estimates.csv
#   CORRECT: results/step03_icc_summary.txt
#   WRONG:   results/icc_estimates.csv  (wrong folder + no prefix)
#   WRONG:   data/icc_estimates.csv     (missing step prefix)
#   WRONG:   logs/step03_icc_estimates.csv (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 03: Compute ICC")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Variance components from Step 2 (5 rows)
        # Purpose: ICC computation requires variance components as input

        log("[LOAD] Loading variance components from Step 2...")
        variance_components = pd.read_csv(RQ_DIR / "data" / "step02_variance_components.csv")
        log(f"[LOADED] step02_variance_components.csv ({len(variance_components)} rows, {len(variance_components.columns)} cols)")

        # Validate input format
        expected_cols = ['component', 'estimate']
        if list(variance_components.columns) != expected_cols:
            raise ValueError(f"Input columns mismatch. Expected {expected_cols}, got {list(variance_components.columns)}")

        if len(variance_components) != 5:
            raise ValueError(f"Expected 5 variance components, got {len(variance_components)} rows")

        log("[INPUT VALIDATION] Variance components format validated")

        # =========================================================================
        # STEP 2: Run Analysis Tool
        # =========================================================================
        # Tool: compute_icc_from_variance_components
        # What it does: Computes 3 ICC estimates from variance components:
        #   1. ICC_intercept: Baseline stability (between-person variance in intercepts)
        #   2. ICC_slope_simple: Forgetting rate stability (simple ratio of slope variance)
        #   3. ICC_slope_conditional: Conditional ICC (accounts for intercept-slope correlation at timepoint)
        # Expected output: DataFrame with 3 rows (icc_type, icc_value, interpretation)

        log("[ANALYSIS] Running compute_icc_from_variance_components...")
        log(f"[PARAMS] time_point=None (simple ICC, no conditional adjustment)")
        log(f"[PARAMS] slope_name='TSVR_hours' (matches LMM time variable from RQ 5.7)")

        # Transform component names to match function expectations
        # Function expects: 'Intercept', 'Residual', slope_name (e.g., 'TSVR_hours')
        # We have: 'var_intercept', 'var_residual', 'var_slope', 'cov_int_slope', 'cor_int_slope'
        component_mapping = {
            'var_intercept': 'Intercept',
            'var_residual': 'Residual',
            'var_slope': 'TSVR_hours',  # slope_name parameter
            'cov_int_slope': 'Intercept:TSVR_hours',  # Covariance between intercept and slope
            'cor_int_slope': 'correlation'  # Not used by function, keep for completeness
        }

        variance_components_renamed = variance_components.copy()
        variance_components_renamed['component'] = variance_components_renamed['component'].map(component_mapping)
        variance_components_renamed = variance_components_renamed.rename(columns={'estimate': 'variance'})

        log("[TRANSFORM] Mapped component names for function compatibility:")
        log(f"  var_intercept → Intercept")
        log(f"  var_residual → Residual")
        log(f"  var_slope → TSVR_hours")
        log(f"  cov_int_slope → Intercept:TSVR_hours")
        log("[TRANSFORM] Renamed 'estimate' → 'variance'")

        icc_estimates = compute_icc_from_variance_components(
            variance_components_df=variance_components_renamed,
            time_point=None,  # None triggers simple ICC (ICC_intercept, ICC_slope_simple only - no conditional)
            slope_name='TSVR_hours'  # Matches LMM time variable from RQ 5.7
        )

        log("[DONE] ICC computation complete")
        log(f"[OUTPUT] Computed {len(icc_estimates)} ICC estimates")

        # =========================================================================
        # STEP 3: Save Analysis Outputs
        # =========================================================================
        # These outputs answer RQ 5.13's primary question about trait stability

        log(f"[SAVE] Saving data/step03_icc_estimates.csv...")
        # Output: data/step03_icc_estimates.csv
        # Contains: ICC estimates with interpretations (intercept, slope_simple, slope_conditional)
        # Columns: icc_type, icc_value, interpretation
        icc_estimates.to_csv(RQ_DIR / "data" / "step03_icc_estimates.csv", index=False, encoding='utf-8')
        log(f"[SAVED] step03_icc_estimates.csv ({len(icc_estimates)} rows, {len(icc_estimates.columns)} cols)")

        # Generate plain text summary
        log(f"[SAVE] Saving results/step03_icc_summary.txt...")
        summary_lines = []
        summary_lines.append("=" * 80)
        summary_lines.append("RQ 5.13: Intraclass Correlation Coefficient (ICC) Estimates")
        summary_lines.append("=" * 80)
        summary_lines.append("")
        summary_lines.append("PURPOSE:")
        summary_lines.append("Quantify proportion of variance in forgetting trajectories that reflects")
        summary_lines.append("stable individual differences (between-person variance) vs measurement")
        summary_lines.append("noise or within-person fluctuation (residual variance).")
        summary_lines.append("")
        summary_lines.append("METHODOLOGY:")
        summary_lines.append("ICC = Between-person variance / (Between-person + Within-person variance)")
        summary_lines.append("")
        summary_lines.append("INTERPRETATION THRESHOLDS:")
        summary_lines.append("  - ICC < 0.20: Low (forgetting rate mostly noise)")
        summary_lines.append("  - 0.20 <= ICC < 0.40: Moderate (mixed trait/state)")
        summary_lines.append("  - ICC >= 0.40: Substantial (forgetting rate is trait-like)")
        summary_lines.append("")
        summary_lines.append("-" * 80)
        summary_lines.append("RESULTS:")
        summary_lines.append("-" * 80)
        summary_lines.append("")

        for _, row in icc_estimates.iterrows():
            icc_type = row['icc_type']
            icc_value = row['icc_value']
            interpretation = row['interpretation']

            summary_lines.append(f"{icc_type.upper()}:")
            summary_lines.append(f"  ICC = {icc_value:.3f}")
            summary_lines.append(f"  Interpretation: {interpretation}")

            # Add implications
            if icc_type == 'intercept':
                summary_lines.append(f"  Implication: {icc_value*100:.1f}% of variance in baseline memory ability")
                summary_lines.append(f"                reflects stable individual differences (trait-like)")
            elif 'slope' in icc_type:
                summary_lines.append(f"  Implication: {icc_value*100:.1f}% of variance in forgetting rate")
                summary_lines.append(f"                reflects stable individual differences (trait-like)")

            summary_lines.append("")

        summary_lines.append("-" * 80)
        summary_lines.append("HYPOTHESIS EVALUATION:")
        summary_lines.append("-" * 80)
        summary_lines.append("")

        # Find slope ICC (either slope_simple or slope_conditional)
        slope_icc_rows = icc_estimates[icc_estimates['icc_type'].str.contains('slope')]
        if len(slope_icc_rows) > 0:
            # Use first slope ICC for hypothesis test
            slope_icc = slope_icc_rows.iloc[0]['icc_value']

            if slope_icc >= 0.40:
                summary_lines.append(f"HYPOTHESIS SUPPORTED: ICC_slope = {slope_icc:.3f} >= 0.40")
                summary_lines.append("Forgetting rates reflect substantial stable individual differences")
                summary_lines.append("(trait-like property, not just measurement noise).")
            elif slope_icc >= 0.20:
                summary_lines.append(f"HYPOTHESIS PARTIALLY SUPPORTED: ICC_slope = {slope_icc:.3f}")
                summary_lines.append("Forgetting rates show moderate individual differences")
                summary_lines.append("(mixed trait/state property).")
            else:
                summary_lines.append(f"HYPOTHESIS NOT SUPPORTED: ICC_slope = {slope_icc:.3f} < 0.20")
                summary_lines.append("Forgetting rates primarily reflect measurement noise")
                summary_lines.append("(low between-person stability).")

        summary_lines.append("")
        summary_lines.append("=" * 80)

        summary_text = "\n".join(summary_lines)
        with open(RQ_DIR / "results" / "step03_icc_summary.txt", 'w', encoding='utf-8') as f:
            f.write(summary_text)

        log(f"[SAVED] results/step03_icc_summary.txt")

        # =========================================================================
        # STEP 4: Run Validation Tool
        # =========================================================================
        # Tool: validate_icc_bounds
        # Validates: All ICC values in [0, 1] range, no NaN/infinite values
        # Threshold: Mathematical constraint (ICC is proportion of variance)

        log("[VALIDATION] Running validate_icc_bounds...")
        validation_result = validate_icc_bounds(
            icc_df=icc_estimates,
            icc_col='icc_value'  # Column containing ICC estimates
        )

        # Report validation results
        # Expected: valid=True, all ICCs in [0,1]
        if isinstance(validation_result, dict):
            for key, value in validation_result.items():
                log(f"[VALIDATION] {key}: {value}")
        else:
            log(f"[VALIDATION] {validation_result}")

        # Check validation passed
        if not validation_result.get('valid', False):
            error_msg = validation_result.get('message', 'ICC validation failed')
            raise ValueError(f"ICC validation failed: {error_msg}")

        log("[SUCCESS] Step 03 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
