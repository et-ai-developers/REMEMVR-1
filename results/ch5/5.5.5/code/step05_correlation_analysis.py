#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step05
Step Name: Correlation Analysis with Steiger's Z-Test
RQ: results/ch5/5.5.5
Generated: 2025-12-05

PURPOSE:
Test whether Purified CTT shows higher correlation with IRT theta compared to
Full CTT, using Steiger's z-test for dependent correlations. Implements
Decision D068 dual p-value reporting (uncorrected + Bonferroni correction).

EXPECTED INPUTS:
1. results/ch5/5.5.1/data/step03_theta_scores.csv
   - Columns: composite_ID, theta_source, theta_destination, se_source, se_destination
   - Format: IRT theta estimates from RQ 5.5.1 Pass 2 calibration
   - Expected rows: 400 (100 UID x 4 test)
   - composite_ID format: UID_test (e.g., A010_1)

2. data/step02_ctt_full_scores.csv
   - Columns: UID, test, location_type, ctt_full_score
   - Format: Full CTT scores (all 18 items per location)
   - Expected rows: 800 (100 UID x 4 test x 2 location_type)

3. data/step03_ctt_purified_scores.csv
   - Columns: UID, test, location_type, ctt_purified_score
   - Format: Purified CTT scores (retained items only)
   - Expected rows: 800 (100 UID x 4 test x 2 location_type)

EXPECTED OUTPUTS:
1. data/step05_correlation_analysis.csv
   - Columns: location_type, r_full, r_purified, delta_r, r_full_purified,
              steiger_z, p_uncorrected, p_bonferroni, n
   - Format: Steiger's z-test results with Decision D068 dual p-values
   - Expected rows: 2 (source, destination)

VALIDATION CRITERIA:
- All correlations in range [0.50, 1.00] (moderate to exceptional convergence)
- BOTH p_uncorrected and p_bonferroni present (Decision D068 compliance)
- p_bonferroni >= p_uncorrected (correction cannot reduce p-value)
- All correlations positive (CTT and IRT agree on ability ordering)

g_code REASONING:
- Approach: Use Steiger's (1980) z-test for dependent correlations
- Why this approach: Tests if r(IRT, Purified_CTT) differs from r(IRT, Full_CTT)
  when both correlations share IRT as common variable (dependent correlations)
- Data flow:
  1. Parse composite_ID from theta_scores into UID and test
  2. Merge theta with Full CTT and Purified CTT on (UID, test)
  3. For each location_type (source, destination):
     a. Compute r12 = corr(theta, ctt_full)
     b. Compute r13 = corr(theta, ctt_purified)
     c. Compute r23 = corr(ctt_full, ctt_purified) [needed for Steiger formula]
     d. Apply Steiger's z-test
     e. Compute p_uncorrected (2-sided)
     f. Compute p_bonferroni = p_uncorrected * 2 (2 location types)
- Expected performance: ~1 second (simple correlation computations)

IMPLEMENTATION NOTES:
- Analysis tool: compare_correlations_dependent from tools.analysis_ctt
- Validation tool: validate_correlation_test_d068 from tools.validation
- Parameters: Bonferroni correction factor = 2 (2 location types)
- Steiger's z-test appropriate for dependent correlations sharing common variable
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = 5.5.5/
#   parents[2] = ch5/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_ctt import compare_correlations_dependent

# Import validation tool
from tools.validation import validate_correlation_test_d068

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.5.5 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step05_correlation_analysis.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_correlation_analysis.csv
#   CORRECT: data/step03_theta_scores.csv
#   WRONG:   results/correlation_analysis.csv  (wrong folder + no prefix)
#   WRONG:   data/correlation_results.csv      (missing step prefix)
#   WRONG:   logs/step05_correlations.csv      (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 5: Correlation Analysis with Steiger's Z-Test")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: IRT theta scores from RQ 5.5.1, Full CTT scores from Step 2,
        #           Purified CTT scores from Step 3
        # Purpose: Merge all three measurements to compute correlations

        log("[LOAD] Loading theta scores from RQ 5.5.1...")
        theta_file = PROJECT_ROOT / "results" / "ch5" / "5.5.1" / "data" / "step03_theta_scores.csv"
        df_theta = pd.read_csv(theta_file, encoding='utf-8')
        log(f"[LOADED] Theta scores: {len(df_theta)} rows, {len(df_theta.columns)} cols")
        log(f"[INFO] Theta columns: {df_theta.columns.tolist()}")

        # Parse composite_ID into UID and test
        log("[TRANSFORM] Parsing composite_ID into UID and test...")
        df_theta[['UID', 'test_num']] = df_theta['composite_ID'].str.split('_', expand=True)
        df_theta['test'] = 'T' + df_theta['test_num']
        df_theta = df_theta.drop(columns=['test_num', 'composite_ID'])
        log(f"[DONE] Parsed UID and test from composite_ID")

        log("[LOAD] Loading Full CTT scores from Step 2...")
        ctt_full_file = RQ_DIR / "data" / "step02_ctt_full_scores.csv"
        df_ctt_full = pd.read_csv(ctt_full_file, encoding='utf-8')
        log(f"[LOADED] Full CTT scores: {len(df_ctt_full)} rows, {len(df_ctt_full.columns)} cols")

        log("[LOAD] Loading Purified CTT scores from Step 3...")
        ctt_purified_file = RQ_DIR / "data" / "step03_ctt_purified_scores.csv"
        df_ctt_purified = pd.read_csv(ctt_purified_file, encoding='utf-8')
        log(f"[LOADED] Purified CTT scores: {len(df_ctt_purified)} rows, {len(df_ctt_purified.columns)} cols")

        # =========================================================================
        # STEP 2: Merge Data by Location Type
        # =========================================================================
        # Tool: pandas merge operations
        # What it does: Combine theta, Full CTT, and Purified CTT on (UID, test)
        # Expected output: Unified dataframe with all three measurements

        log("[MERGE] Merging theta with CTT scores...")

        # Reshape theta from wide to long format (source vs destination)
        df_theta_long = pd.concat([
            df_theta[['UID', 'test', 'theta_source']].assign(location_type='source').rename(columns={'theta_source': 'theta'}),
            df_theta[['UID', 'test', 'theta_destination']].assign(location_type='destination').rename(columns={'theta_destination': 'theta'})
        ], ignore_index=True)
        log(f"[RESHAPE] Theta reshaped to long format: {len(df_theta_long)} rows")

        # Merge theta with Full CTT
        df_merged = df_theta_long.merge(
            df_ctt_full,
            on=['UID', 'test', 'location_type'],
            how='inner'
        )
        log(f"[MERGED] Theta + Full CTT: {len(df_merged)} rows")

        # Merge with Purified CTT
        df_merged = df_merged.merge(
            df_ctt_purified,
            on=['UID', 'test', 'location_type'],
            how='inner'
        )
        log(f"[MERGED] All three measurements: {len(df_merged)} rows")
        log(f"[INFO] Merged columns: {df_merged.columns.tolist()}")

        # =========================================================================
        # STEP 3: Compute Correlations and Run Steiger's Z-Test
        # =========================================================================
        # Tool: compare_correlations_dependent from tools.analysis_ctt
        # What it does: Tests if r(IRT, Purified) differs from r(IRT, Full)
        # Expected output: Steiger's z-statistic, p_uncorrected, p_bonferroni

        log("[ANALYSIS] Running Steiger's z-test per location type...")

        results = []
        bonferroni_factor = 2  # 2 location types (Decision D068)

        for location_type in ['source', 'destination']:
            log(f"[ANALYSIS] Processing {location_type} memory...")

            # Filter to current location_type
            df_loc = df_merged[df_merged['location_type'] == location_type].copy()
            n = len(df_loc)
            log(f"[INFO] {location_type}: n={n} observations")

            # Compute correlations
            r_full = df_loc['theta'].corr(df_loc['ctt_full_score'])
            r_purified = df_loc['theta'].corr(df_loc['ctt_purified_score'])
            r_full_purified = df_loc['ctt_full_score'].corr(df_loc['ctt_purified_score'])

            log(f"[CORRELATION] {location_type} r(theta, Full_CTT) = {r_full:.4f}")
            log(f"[CORRELATION] {location_type} r(theta, Purified_CTT) = {r_purified:.4f}")
            log(f"[CORRELATION] {location_type} r(Full_CTT, Purified_CTT) = {r_full_purified:.4f}")

            # Steiger's z-test
            # r12 = r(theta, Full_CTT)
            # r13 = r(theta, Purified_CTT)
            # r23 = r(Full_CTT, Purified_CTT)
            steiger_result = compare_correlations_dependent(
                r12=r_full,
                r13=r_purified,
                r23=r_full_purified,
                n=n
            )

            # Extract results
            steiger_z = steiger_result['z_statistic']
            p_uncorrected = steiger_result['p_value']
            delta_r = r_purified - r_full

            # Bonferroni correction (capped at 1.0)
            p_bonferroni = min(p_uncorrected * bonferroni_factor, 1.0)

            log(f"[STEIGER] {location_type} z={steiger_z:.4f}, p_uncorrected={p_uncorrected:.4f}, p_bonferroni={p_bonferroni:.4f}")
            log(f"[DELTA] {location_type} delta_r={delta_r:.4f} (Purified - Full)")

            # Store results
            results.append({
                'location_type': location_type,
                'r_full': r_full,
                'r_purified': r_purified,
                'delta_r': delta_r,
                'r_full_purified': r_full_purified,
                'steiger_z': steiger_z,
                'p_uncorrected': p_uncorrected,
                'p_bonferroni': p_bonferroni,
                'n': n
            })

        # Convert to DataFrame
        df_results = pd.DataFrame(results)
        log("[DONE] Steiger's z-test complete for both location types")

        # =========================================================================
        # STEP 4: Save Analysis Outputs
        # =========================================================================
        # Output: data/step05_correlation_analysis.csv
        # Contains: Steiger's z-test results with dual p-values (Decision D068)
        # Columns: location_type, r_full, r_purified, delta_r, r_full_purified,
        #          steiger_z, p_uncorrected, p_bonferroni, n

        output_file = RQ_DIR / "data" / "step05_correlation_analysis.csv"
        log(f"[SAVE] Saving results to {output_file}...")
        df_results.to_csv(output_file, index=False, encoding='utf-8')
        log(f"[SAVED] {output_file.name} ({len(df_results)} rows, {len(df_results.columns)} cols)")

        # =========================================================================
        # STEP 5: Run Validation Tool
        # =========================================================================
        # Tool: validate_correlation_test_d068 from tools.validation
        # Validates: Decision D068 compliance (dual p-value reporting)
        # Threshold: p_bonferroni >= p_uncorrected

        log("[VALIDATION] Running validate_correlation_test_d068...")
        validation_result = validate_correlation_test_d068(
            correlation_df=df_results,
            required_cols=['p_uncorrected', 'p_bonferroni']
        )

        # Report validation results
        if validation_result['valid']:
            log(f"[VALIDATION] PASS - Decision D068 compliant")
            log(f"[VALIDATION] d068_compliant: {validation_result['d068_compliant']}")
            log(f"[VALIDATION] All required columns present")
        else:
            log(f"[VALIDATION] FAIL - {validation_result['message']}")
            if validation_result.get('missing_cols'):
                log(f"[VALIDATION] Missing columns: {validation_result['missing_cols']}")
            sys.exit(1)

        # Additional validation checks
        log("[VALIDATION] Running additional checks...")

        # Check correlation ranges
        all_corrs = df_results[['r_full', 'r_purified', 'r_full_purified']].values.flatten()
        if np.any(all_corrs < 0.50) or np.any(all_corrs > 1.00):
            log(f"[VALIDATION] WARNING - Some correlations outside expected range [0.50, 1.00]")
            log(f"[VALIDATION] Range: [{all_corrs.min():.4f}, {all_corrs.max():.4f}]")
        else:
            log(f"[VALIDATION] PASS - All correlations in reasonable range [0.50, 1.00]")

        # Check p_bonferroni >= p_uncorrected
        if np.all(df_results['p_bonferroni'] >= df_results['p_uncorrected']):
            log(f"[VALIDATION] PASS - p_bonferroni >= p_uncorrected (as expected)")
        else:
            log(f"[VALIDATION] FAIL - p_bonferroni < p_uncorrected (correction error)")
            sys.exit(1)

        # Check all correlations positive
        if np.all(all_corrs > 0):
            log(f"[VALIDATION] PASS - All correlations positive (CTT and IRT agree)")
        else:
            log(f"[VALIDATION] WARNING - Some correlations negative or zero")

        log("[SUCCESS] Step 5 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
