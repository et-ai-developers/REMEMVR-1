#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step03
Step Name: Compute Purified CTT Sum Scores
RQ: results/ch5/5.5.5
Generated: 2025-12-05

PURPOSE:
Compute Classical Test Theory (CTT) sum scores using ONLY IRT-retained items
(post-purification) to test whether item purification improves measurement
precision. This analysis compares purified CTT (retained items only) against
Full CTT (all items) to evaluate the effect of removing poor-quality items
identified during IRT calibration.

EXPECTED INPUTS:
  - data/step01_item_mapping.csv
    Columns: ['item_name', 'location_type', 'a', 'b', 'retained', 'removal_reason']
    Format: Item retention status per location_type (source/destination)
    Expected rows: 36 (18 source + 18 destination items)

  - data/cache/dfData.csv
    Columns: UID, TEST, TQ_IFR-U-i1 through TQ_IRE-D-i6 (VR item responses), age
    Format: Raw binary responses (0/1) for all VR items
    Expected rows: 400 (100 UID x 4 tests)

EXPECTED OUTPUTS:
  - data/step03_ctt_purified_scores.csv
    Columns: ['UID', 'test', 'location_type', 'ctt_purified_score']
    Format: Purified CTT scores (retained items only) per UID x test x location_type
    Expected rows: 800 (100 UID x 4 tests x 2 location types)

VALIDATION CRITERIA:
  - 800 rows exactly (100 UID x 4 tests x 2 location types)
  - No NaN values
  - ctt_purified_score in [0, 1] (proportion correct)
  - location_type and test match Full CTT exactly
  - UID set matches Full CTT exactly
  - Correlation with Full CTT r > 0.85 (high convergence expected)

g_code REASONING:
- Approach: Filter dfData to retained items only (from item_mapping where retained=True),
  then compute mean binary responses per UID x test x location_type. This creates
  purified CTT scores using only the high-quality items identified by IRT.

- Why this approach: Item purification removes items with low discrimination (a < 0.4)
  or extreme difficulty (|b| > 3.0). Purified CTT should have higher reliability
  and stronger correlation with IRT theta compared to Full CTT.

- Data flow: item_mapping (identify retained items) -> dfData (filter to retained
  columns) -> compute mean per UID x test x location -> reshape to long format

- Expected performance: ~5 seconds (simple filtering and aggregation)

IMPLEMENTATION NOTES:
- Analysis tool: Standard pandas operations (no custom tool function)
- Validation tool: Correlation with Full CTT from step02
- Parameters: retained = True (filter criterion)
- Item naming pattern: TQ_{paradigm}-{U|D}-{item} where U=source, D=destination
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/ (5.5.5)
#   parents[2] = chX/ (ch5)
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.5.5
LOG_FILE = RQ_DIR / "logs" / "step03_ctt_purified_scores.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step03_ctt_purified_scores.csv
#   CORRECT: logs/step03_ctt_purified_scores.log
#   WRONG:   results/ctt_purified_scores.csv  (wrong folder + no prefix)
#   WRONG:   data/ctt_purified_scores.csv     (missing step prefix)
#   WRONG:   logs/step03_purified_items.csv   (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 3: Compute Purified CTT Sum Scores")

        # =========================================================================
        # STEP 1: Load Item Mapping and Identify Retained Items
        # =========================================================================
        # Expected: Item retention status from IRT purification (Step 1)
        # Purpose: Identify which items to include in purified CTT computation

        log("[LOAD] Loading item mapping from Step 1...")
        item_mapping_path = RQ_DIR / "data" / "step01_item_mapping.csv"
        df_items = pd.read_csv(item_mapping_path, encoding='utf-8')
        log(f"[LOADED] item_mapping: {len(df_items)} items")

        # Filter to retained items only
        df_retained = df_items[df_items['retained'] == True].copy()
        log(f"[FILTER] Retained items: {len(df_retained)} / {len(df_items)} items")

        # Separate by location_type
        source_retained = df_retained[df_retained['location_type'] == 'source']['item_name'].tolist()
        dest_retained = df_retained[df_retained['location_type'] == 'destination']['item_name'].tolist()

        log(f"[RETAINED] Source items: {len(source_retained)}")
        log(f"[RETAINED] Destination items: {len(dest_retained)}")

        # Validate retention counts
        if len(source_retained) < 10 or len(dest_retained) < 10:
            log(f"[ERROR] Insufficient retained items (source={len(source_retained)}, dest={len(dest_retained)})")
            log("[ERROR] Need at least 10 items per location_type for reliable CTT")
            sys.exit(1)

        # =========================================================================
        # STEP 2: Load Raw Binary Responses
        # =========================================================================
        # Expected: Raw binary responses for all VR items from master data
        # Purpose: Extract responses for retained items only

        log("[LOAD] Loading raw binary responses from dfData.csv...")
        dfData_path = PROJECT_ROOT / "data" / "cache" / "dfData.csv"
        df_raw = pd.read_csv(dfData_path, encoding='utf-8')
        log(f"[LOADED] dfData: {len(df_raw)} rows, {len(df_raw.columns)} columns")

        # Map item_name to TQ_ column names in dfData
        # Item mapping uses: TQ_ICR-D-i1, TQ_ICR-U-i2, etc.
        # dfData columns use: TQ_ICR-D-i1, TQ_ICR-U-i2, etc. (same format)

        # Verify all retained items exist as columns in dfData
        all_retained_items = source_retained + dest_retained
        missing_items = [item for item in all_retained_items if item not in df_raw.columns]
        if missing_items:
            log(f"[ERROR] Missing items in dfData: {missing_items}")
            sys.exit(1)

        log("[VALIDATED] All retained items found in dfData")

        # =========================================================================
        # STEP 3: Compute Purified CTT Scores
        # =========================================================================
        # Tool: pandas aggregation (mean of binary responses)
        # What it does: Compute proportion correct for retained items only
        # Expected output: CTT scores in [0, 1] range per UID x test x location_type

        log("[COMPUTE] Computing purified CTT scores...")

        results = []

        # Process each UID x TEST combination
        for _, row in df_raw.iterrows():
            uid = row['UID']
            test_val = row['TEST']

            # Convert TEST column (1-4) to test format (T1-T4)
            if pd.notna(test_val):
                test = f"T{int(test_val)}"
            else:
                log(f"[WARNING] Skipping row with NaN TEST value for UID {uid}")
                continue

            # Compute source CTT (mean of retained source items)
            source_responses = row[source_retained]
            # Handle NaN values: only count non-NaN responses
            source_valid = source_responses[source_responses.notna()]
            if len(source_valid) > 0:
                source_ctt = source_valid.mean()
            else:
                source_ctt = np.nan

            # Compute destination CTT (mean of retained destination items)
            dest_responses = row[dest_retained]
            dest_valid = dest_responses[dest_responses.notna()]
            if len(dest_valid) > 0:
                dest_ctt = dest_valid.mean()
            else:
                dest_ctt = np.nan

            # Append results
            results.append({
                'UID': uid,
                'test': test,
                'location_type': 'source',
                'ctt_purified_score': source_ctt
            })
            results.append({
                'UID': uid,
                'test': test,
                'location_type': 'destination',
                'ctt_purified_score': dest_ctt
            })

        df_purified_ctt = pd.DataFrame(results)
        log(f"[COMPUTED] Purified CTT scores: {len(df_purified_ctt)} rows")

        # =========================================================================
        # STEP 4: Validate Purified CTT Scores
        # =========================================================================
        # Validates: row count, value range, no NaN values
        # Threshold: correlation with Full CTT > 0.85

        log("[VALIDATION] Validating purified CTT scores...")

        # Check row count
        expected_rows = 800  # 100 UID x 4 tests x 2 location_types
        if len(df_purified_ctt) != expected_rows:
            log(f"[ERROR] Expected {expected_rows} rows, got {len(df_purified_ctt)}")
            sys.exit(1)

        # Check for NaN values
        nan_count = df_purified_ctt['ctt_purified_score'].isna().sum()
        if nan_count > 0:
            log(f"[ERROR] Found {nan_count} NaN values in ctt_purified_score")
            sys.exit(1)

        # Check value range [0, 1]
        min_score = df_purified_ctt['ctt_purified_score'].min()
        max_score = df_purified_ctt['ctt_purified_score'].max()
        if min_score < 0.0 or max_score > 1.0:
            log(f"[ERROR] CTT scores out of [0,1] range: min={min_score:.4f}, max={max_score:.4f}")
            sys.exit(1)

        log(f"[PASS] Row count: {len(df_purified_ctt)} = {expected_rows}")
        log(f"[PASS] No NaN values")
        log(f"[PASS] CTT scores in [0,1]: min={min_score:.4f}, max={max_score:.4f}")

        # Validate correlation with Full CTT
        log("[VALIDATION] Computing correlation with Full CTT...")
        full_ctt_path = RQ_DIR / "data" / "step02_ctt_full_scores.csv"
        df_full_ctt = pd.read_csv(full_ctt_path, encoding='utf-8')

        # Merge on UID, test, location_type
        df_merged = pd.merge(
            df_purified_ctt,
            df_full_ctt,
            on=['UID', 'test', 'location_type'],
            how='inner'
        )

        if len(df_merged) != expected_rows:
            log(f"[ERROR] Merge mismatch: expected {expected_rows} rows, got {len(df_merged)}")
            sys.exit(1)

        # Compute correlation
        corr = df_merged['ctt_purified_score'].corr(df_merged['ctt_full_score'])
        log(f"[CORRELATION] Purified vs Full CTT: r = {corr:.4f}")

        if corr < 0.85:
            log(f"[WARNING] Correlation below expected threshold (r < 0.85)")
            log(f"[WARNING] This may indicate poor convergence between purified and full CTT")
        else:
            log(f"[PASS] Correlation r = {corr:.4f} > 0.85 (high convergence)")

        # =========================================================================
        # STEP 5: Save Purified CTT Scores
        # =========================================================================
        # Output: CSV file with purified CTT scores
        # Contains: UID, test, location_type, ctt_purified_score

        log("[SAVE] Saving purified CTT scores...")
        output_path = RQ_DIR / "data" / "step03_ctt_purified_scores.csv"
        df_purified_ctt.to_csv(output_path, index=False, encoding='utf-8')
        log(f"[SAVED] {output_path}")
        log(f"[SAVED] {len(df_purified_ctt)} rows, {len(df_purified_ctt.columns)} columns")

        # Report summary statistics
        log("[SUMMARY] Purified CTT Score Statistics:")
        for loc_type in ['source', 'destination']:
            subset = df_purified_ctt[df_purified_ctt['location_type'] == loc_type]['ctt_purified_score']
            log(f"  {loc_type.capitalize()}: mean={subset.mean():.4f}, SD={subset.std():.4f}, "
                f"min={subset.min():.4f}, max={subset.max():.4f}")

        log("[SUCCESS] Step 3 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
