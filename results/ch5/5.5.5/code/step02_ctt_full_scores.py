#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step02
Step Name: ctt_full_scores
RQ: results/ch5/5.5.5
Generated: 2025-12-05

PURPOSE:
Compute Classical Test Theory (CTT) sum scores using ALL source and destination
items (before purification) to establish baseline measurement. This provides the
"Full CTT" scores that will be compared against "Purified CTT" scores (using only
IRT-retained items) in downstream analyses.

EXPECTED INPUTS:
  - data/cache/dfData.csv
    Columns: UID, TEST, TQ_IFR-U-i1...i6, TQ_ICR-U-i1...i6, TQ_IRE-U-i1...i6,
             TQ_IFR-D-i1...i6, TQ_ICR-D-i1...i6, TQ_IRE-D-i1...i6
    Format: CSV with UTF-8 encoding, binary responses (0/1), NaN for missing
    Expected rows: ~400 (100 participants × 4 test sessions)

  - data/step01_item_mapping.csv
    Columns: item_name, location_type, a, b, retained, removal_reason
    Format: Item metadata to identify source vs destination items
    Expected rows: 36 items (18 source + 18 destination)

EXPECTED OUTPUTS:
  - data/step02_ctt_full_scores.csv
    Columns: UID, test, location_type, ctt_full_score
    Format: Long format with proportion correct per UID × test × location
    Expected rows: 800 (100 participants × 4 tests × 2 location types)

VALIDATION CRITERIA:
  - 800 rows exactly (100 UIDs × 4 tests × 2 location_types)
  - ctt_full_score in [0, 1] (proportion correct)
  - No NaN values in ctt_full_score
  - 400 rows per location_type
  - 100 unique UIDs
  - 4 tests per UID (T1, T2, T3, T4)

g_code REASONING:
- Approach: Load raw binary responses, compute mean per UID × TEST × location type
- Why this approach: CTT sum scores are simple proportion correct (mean of 0/1)
- Data flow: Wide format (items as columns) → compute means → long format (location_type factor)
- Expected performance: ~5 seconds (simple arithmetic on 400 rows × 36 items)

IMPLEMENTATION NOTES:
- Analysis tool: stdlib (no custom tool needed for simple mean computation)
- Validation tool: Range checks, row counts, missing data checks
- Parameters: NaN-tolerant mean (pandas.mean() handles missing items automatically)
- Item naming convention: TQ_{paradigm}-{location}-{item_id}
  - Paradigms: IFR, ICR, IRE
  - Locations: U (source), D (destination)
  - Item IDs: i1, i2, i3, i4, i5, i6
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/ (5.5.5/)
#   parents[2] = chX/ (ch5/)
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.5.5 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step02_ctt_full_scores.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step02_ctt_full_scores.csv
#   CORRECT: logs/step02_ctt_full_scores.log
#   WRONG:   data/ctt_scores.csv             (missing step prefix)
#   WRONG:   results/step02_ctt_scores.csv   (CSV in results/ instead of data/)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 02: Compute Full CTT Sum Scores")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Raw binary responses (0/1) for all 36 VR items (18 source + 18 destination)
        # Purpose: Compute proportion correct per UID × TEST × location type

        log("[LOAD] Loading raw binary responses...")
        dfData_path = PROJECT_ROOT / "data" / "cache" / "dfData.csv"
        dfData = pd.read_csv(dfData_path, encoding='utf-8')
        log(f"[LOADED] dfData.csv ({len(dfData)} rows, {len(dfData.columns)} cols)")

        # Load item mapping to get complete list of source and destination items
        log("[LOAD] Loading item mapping...")
        item_mapping_path = RQ_DIR / "data" / "step01_item_mapping.csv"
        item_mapping = pd.read_csv(item_mapping_path, encoding='utf-8')
        log(f"[LOADED] step01_item_mapping.csv ({len(item_mapping)} rows)")

        # =========================================================================
        # STEP 2: Identify Source and Destination Items
        # =========================================================================
        # Tool: Pattern matching on item_name column
        # What it does: Extract all source items (TQ_*-U-*) and destination items (TQ_*-D-*)
        # Expected output: 18 source items, 18 destination items

        log("[IDENTIFY] Identifying source and destination items...")

        # Get item names from item_mapping (authoritative source)
        source_items = item_mapping[item_mapping['location_type'] == 'source']['item_name'].tolist()
        destination_items = item_mapping[item_mapping['location_type'] == 'destination']['item_name'].tolist()

        log(f"[IDENTIFIED] {len(source_items)} source items (location_type='source')")
        log(f"[IDENTIFIED] {len(destination_items)} destination items (location_type='destination')")

        # Verify all items exist in dfData
        missing_source = [item for item in source_items if item not in dfData.columns]
        missing_destination = [item for item in destination_items if item not in dfData.columns]

        if missing_source:
            log(f"[ERROR] Missing source items in dfData: {missing_source}")
            sys.exit(1)
        if missing_destination:
            log(f"[ERROR] Missing destination items in dfData: {missing_destination}")
            sys.exit(1)

        log("[PASS] All items present in dfData.csv")

        # =========================================================================
        # STEP 3: Compute CTT Sum Scores
        # =========================================================================
        # Tool: pandas mean() with axis=1 (row-wise mean)
        # What it does: Compute proportion correct per UID × TEST
        # Expected output: 2 columns (source_ctt, destination_ctt) added to dfData

        log("[COMPUTE] Computing CTT sum scores (proportion correct)...")

        # Source CTT score: mean of 18 source item responses (NaN-tolerant)
        # Values are already 0/1 binary (TQ columns pre-dichotomized)
        # NaN values are excluded from mean automatically by pandas
        dfData['ctt_source'] = dfData[source_items].mean(axis=1)

        # Destination CTT score: mean of 18 destination item responses
        dfData['ctt_destination'] = dfData[destination_items].mean(axis=1)

        log(f"[COMPUTED] Source CTT mean={dfData['ctt_source'].mean():.4f}, SD={dfData['ctt_source'].std():.4f}")
        log(f"[COMPUTED] Destination CTT mean={dfData['ctt_destination'].mean():.4f}, SD={dfData['ctt_destination'].std():.4f}")

        # =========================================================================
        # STEP 4: Reshape to Long Format
        # =========================================================================
        # Tool: pandas melt() for wide-to-long transformation
        # What it does: Convert from wide (ctt_source, ctt_destination columns) to long (location_type factor)
        # Expected output: 800 rows (400 observations × 2 location types)

        log("[RESHAPE] Converting to long format...")

        # Convert TEST column from numeric (1,2,3,4) to string (T1,T2,T3,T4)
        # This matches the format from theta_scores.csv (RQ 5.5.1 output)
        dfData['test'] = 'T' + dfData['TEST'].astype(str)

        # Select relevant columns for reshaping
        df_wide = dfData[['UID', 'test', 'ctt_source', 'ctt_destination']].copy()

        # Reshape to long format: UID, test, location_type, ctt_full_score
        df_long = pd.melt(
            df_wide,
            id_vars=['UID', 'test'],
            value_vars=['ctt_source', 'ctt_destination'],
            var_name='location_type',
            value_name='ctt_full_score'
        )

        # Clean up location_type column: 'ctt_source' -> 'source', 'ctt_destination' -> 'destination'
        df_long['location_type'] = df_long['location_type'].str.replace('ctt_', '')

        log(f"[RESHAPED] Long format: {len(df_long)} rows, {len(df_long.columns)} cols")

        # =========================================================================
        # STEP 5: Validation
        # =========================================================================
        # Tool: Manual checks on row counts, value ranges, missing data
        # Validates: Shape, range, completeness per specification

        log("[VALIDATION] Validating output...")

        # Check 1: 800 rows exactly
        expected_rows = 800  # 100 UIDs × 4 tests × 2 location_types
        if len(df_long) != expected_rows:
            log(f"[FAIL] Expected {expected_rows} rows, got {len(df_long)}")
            sys.exit(1)
        log(f"[PASS] Row count: {len(df_long)} rows")

        # Check 2: ctt_full_score in [0, 1]
        min_score = df_long['ctt_full_score'].min()
        max_score = df_long['ctt_full_score'].max()
        if min_score < 0 or max_score > 1:
            log(f"[FAIL] ctt_full_score out of range [0,1]: min={min_score}, max={max_score}")
            sys.exit(1)
        log(f"[PASS] ctt_full_score in [0, 1]: min={min_score:.4f}, max={max_score:.4f}")

        # Check 3: No NaN values
        n_missing = df_long['ctt_full_score'].isna().sum()
        if n_missing > 0:
            log(f"[FAIL] {n_missing} NaN values in ctt_full_score")
            sys.exit(1)
        log("[PASS] No NaN values in ctt_full_score")

        # Check 4: 400 rows per location_type
        location_counts = df_long['location_type'].value_counts()
        for location_type, count in location_counts.items():
            if count != 400:
                log(f"[FAIL] Expected 400 rows for {location_type}, got {count}")
                sys.exit(1)
        log("[PASS] 400 rows per location_type")

        # Check 5: 100 unique UIDs
        n_unique_uids = df_long['UID'].nunique()
        if n_unique_uids != 100:
            log(f"[FAIL] Expected 100 unique UIDs, got {n_unique_uids}")
            sys.exit(1)
        log("[PASS] 100 unique UIDs")

        # Check 6: 4 tests per UID
        tests_per_uid = df_long.groupby('UID')['test'].nunique()
        if not (tests_per_uid == 4).all():
            log(f"[FAIL] Not all UIDs have 4 tests: {tests_per_uid.value_counts()}")
            sys.exit(1)
        log("[PASS] 4 tests per UID (T1, T2, T3, T4)")

        log("[VALIDATION] All checks passed")

        # =========================================================================
        # STEP 6: Save Output
        # =========================================================================
        # Output: data/step02_ctt_full_scores.csv
        # Contains: UID, test, location_type, ctt_full_score
        # These scores will be used for: Correlation analysis (Step 5), LMM comparison (Step 7)

        log("[SAVE] Saving output...")
        output_path = RQ_DIR / "data" / "step02_ctt_full_scores.csv"
        df_long.to_csv(output_path, index=False, encoding='utf-8')
        log(f"[SAVED] {output_path} ({len(df_long)} rows, {len(df_long.columns)} cols)")

        # Report summary statistics
        log("[SUMMARY] CTT Full Scores Summary:")
        for location_type in ['source', 'destination']:
            subset = df_long[df_long['location_type'] == location_type]
            mean_score = subset['ctt_full_score'].mean()
            sd_score = subset['ctt_full_score'].std()
            min_score_loc = subset['ctt_full_score'].min()
            max_score_loc = subset['ctt_full_score'].max()
            log(f"  {location_type.capitalize()}: mean={mean_score:.4f}, SD={sd_score:.4f}, range=[{min_score_loc:.4f}, {max_score_loc:.4f}]")

        log("[SUCCESS] Step 02 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
