#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step08
Step Name: prepare_trajectory_comparison_data
RQ: results/ch5/5.5.4
Generated: 2025-12-05

PURPOSE:
Create plot source CSV for trajectory comparison showing mean IRT theta and mean
CTT score over time (4 tests) for both location types. Aggregates data by
location_type × test for both measurement methods to enable visual comparison
of forgetting trajectories.

EXPECTED INPUTS:
  - data/step00_irt_theta_from_rq551.csv
    Columns: ['composite_ID', 'UID', 'test', 'location_type', 'irt_theta', 'irt_se', 'TSVR_hours']
    Format: Long format IRT theta scores (800 rows = 100 participants × 4 tests × 2 location types)
    Expected rows: ~800

  - data/step01_ctt_scores.csv
    Columns: ['composite_ID', 'UID', 'test', 'location_type', 'ctt_mean_score', 'n_items', 'TSVR_hours']
    Format: CTT proportion correct scores (800 rows = 100 participants × 4 tests × 2 location types)
    Expected rows: ~800

EXPECTED OUTPUTS:
  - data/step08_trajectory_comparison_data.csv
    Columns: ['location_type', 'test', 'method', 'mean_score', 'ci_lower', 'ci_upper', 'time', 'n']
    Format: Aggregated means and 95% CIs for both methods (16 rows = 2 locations × 4 tests × 2 methods)
    Expected rows: ~16

VALIDATION CRITERIA:
  - Exactly 16 rows (2 location types × 4 tests × 2 methods)
  - All combinations present: {'source', 'destination'} × {1,2,3,4} × {'IRT', 'CTT'}
  - No NaN in mean_score, ci_lower, ci_upper, time
  - CI bounds valid: ci_upper > ci_lower
  - n = 100 for all rows (all participants per location × test)
  - IRT mean_score in [-3, 3], CTT mean_score in [0, 1]

g_code REASONING:
- Approach: Aggregate both IRT and CTT data by location_type × test, compute
  means and 95% confidence intervals using standard error propagation
  (CI = mean ± 1.96 × SE, where SE = std / sqrt(n))
- Why this approach: Enables direct visual comparison of forgetting trajectories
  measured by IRT vs CTT methods to assess convergent validity
- Data flow: Load IRT theta scores → aggregate by location × test → add method='IRT'
             Load CTT scores → aggregate by location × test → add method='CTT'
             Stack both → 16 rows for trajectory plotting
- Expected performance: ~1-2 seconds (simple aggregation)

IMPLEMENTATION NOTES:
- Analysis tool: pandas groupby + aggregation (stdlib operations)
- Validation: inline checks (row count, combinations, ranges)
- Parameters: 95% CI using 1.96 multiplier (z-score for 95% confidence)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = 5.5.4/
#   parents[2] = ch5/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.5.4 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step08_prepare_trajectory_comparison_data.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step08_trajectory_comparison_data.csv
#   CORRECT: data/step01_ctt_scores.csv
#   WRONG:   results/trajectory_comparison_data.csv  (wrong folder + no prefix)
#   WRONG:   data/trajectory_data.csv                (missing step prefix)
#   WRONG:   logs/step08_trajectory_data.csv         (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 8: Prepare trajectory comparison data")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: IRT theta scores (800 rows) and CTT scores (800 rows)
        # Purpose: Aggregate by location_type × test for trajectory plotting

        log("[LOAD] Loading IRT theta scores from step 0...")
        theta_long = pd.read_csv(RQ_DIR / "data" / "step00_irt_theta_from_rq551.csv", encoding='utf-8')
        log(f"[LOADED] IRT theta data ({len(theta_long)} rows, {len(theta_long.columns)} cols)")

        log("[LOAD] Loading CTT scores from step 1...")
        ctt_scores = pd.read_csv(RQ_DIR / "data" / "step01_ctt_scores.csv", encoding='utf-8')
        log(f"[LOADED] CTT scores data ({len(ctt_scores)} rows, {len(ctt_scores.columns)} cols)")

        # =========================================================================
        # STEP 2: Aggregate IRT Data
        # =========================================================================
        # Tool: pandas groupby
        # What it does: Group by location_type × test, compute mean theta, mean TSVR,
        #               95% CI using SE = std / sqrt(n)
        # Expected output: 8 rows (2 locations × 4 tests)

        log("[ANALYSIS] Aggregating IRT data by location_type + test...")
        irt_agg = theta_long.groupby(['location_type', 'test']).agg({
            'irt_theta': ['mean', 'std', 'count'],
            'TSVR_hours': 'mean'
        }).reset_index()

        # Flatten column names
        irt_agg.columns = ['location_type', 'test', 'mean_score', 'std_score', 'n', 'time']

        # Compute 95% CI: mean ± 1.96 × SE, where SE = std / sqrt(n)
        irt_agg['se'] = irt_agg['std_score'] / np.sqrt(irt_agg['n'])
        irt_agg['ci_lower'] = irt_agg['mean_score'] - 1.96 * irt_agg['se']
        irt_agg['ci_upper'] = irt_agg['mean_score'] + 1.96 * irt_agg['se']

        # Add method label
        irt_agg['method'] = 'IRT'

        # Select final columns
        irt_agg = irt_agg[['location_type', 'test', 'method', 'mean_score', 'ci_lower', 'ci_upper', 'time', 'n']]

        log(f"[AGGREGATED] IRT data ({len(irt_agg)} rows)")

        # =========================================================================
        # STEP 3: Aggregate CTT Data
        # =========================================================================
        # Tool: pandas groupby
        # What it does: Group by location_type × test, compute mean CTT score,
        #               mean TSVR, 95% CI using SE = std / sqrt(n)
        # Expected output: 8 rows (2 locations × 4 tests)

        log("[ANALYSIS] Aggregating CTT data by location_type + test...")
        ctt_agg = ctt_scores.groupby(['location_type', 'test']).agg({
            'ctt_mean_score': ['mean', 'std', 'count'],
            'TSVR_hours': 'mean'
        }).reset_index()

        # Flatten column names
        ctt_agg.columns = ['location_type', 'test', 'mean_score', 'std_score', 'n', 'time']

        # Compute 95% CI: mean ± 1.96 × SE, where SE = std / sqrt(n)
        ctt_agg['se'] = ctt_agg['std_score'] / np.sqrt(ctt_agg['n'])
        ctt_agg['ci_lower'] = ctt_agg['mean_score'] - 1.96 * ctt_agg['se']
        ctt_agg['ci_upper'] = ctt_agg['mean_score'] + 1.96 * ctt_agg['se']

        # Add method label
        ctt_agg['method'] = 'CTT'

        # Select final columns
        ctt_agg = ctt_agg[['location_type', 'test', 'method', 'mean_score', 'ci_lower', 'ci_upper', 'time', 'n']]

        log(f"[AGGREGATED] CTT data ({len(ctt_agg)} rows)")

        # =========================================================================
        # STEP 4: Stack Both Datasets
        # =========================================================================
        # Combine IRT and CTT aggregated data
        # Expected: 16 rows (8 IRT + 8 CTT)

        log("[ANALYSIS] Stacking IRT and CTT aggregated data...")
        trajectory_data = pd.concat([irt_agg, ctt_agg], ignore_index=True)
        log(f"[STACKED] Combined data ({len(trajectory_data)} rows)")

        # =========================================================================
        # STEP 5: Save Output
        # =========================================================================
        # Output: data/step08_trajectory_comparison_data.csv
        # Contains: Aggregated means and 95% CIs for trajectory plotting

        output_path = RQ_DIR / "data" / "step08_trajectory_comparison_data.csv"
        log(f"[SAVE] Saving trajectory comparison data to {output_path}...")
        trajectory_data.to_csv(output_path, index=False, encoding='utf-8')
        log(f"[SAVED] {output_path.name} ({len(trajectory_data)} rows, {len(trajectory_data.columns)} cols)")

        # =========================================================================
        # STEP 6: Run Validation (Inline)
        # =========================================================================
        # Validates: Row count, combinations, ranges, CI bounds

        log("[VALIDATION] Running inline validation...")

        # Check 1: Exactly 16 rows
        if len(trajectory_data) != 16:
            raise ValueError(f"Expected 16 rows, got {len(trajectory_data)}")
        log("[VALIDATION] Row count: 16 [PASS]")

        # Check 2: All combinations present
        expected_combinations = set()
        for location in ['source', 'destination']:
            for test in [1, 2, 3, 4]:
                for method in ['IRT', 'CTT']:
                    expected_combinations.add((location, test, method))

        actual_combinations = set(zip(trajectory_data['location_type'],
                                     trajectory_data['test'],
                                     trajectory_data['method']))

        if expected_combinations != actual_combinations:
            missing = expected_combinations - actual_combinations
            extra = actual_combinations - expected_combinations
            raise ValueError(f"Combination mismatch. Missing: {missing}, Extra: {extra}")
        log("[VALIDATION] All combinations present [PASS]")

        # Check 3: No NaN in critical columns
        critical_cols = ['mean_score', 'ci_lower', 'ci_upper', 'time']
        for col in critical_cols:
            if trajectory_data[col].isna().any():
                raise ValueError(f"NaN values found in {col}")
        log("[VALIDATION] No NaN in critical columns [PASS]")

        # Check 4: CI bounds valid (ci_upper > ci_lower)
        if not (trajectory_data['ci_upper'] > trajectory_data['ci_lower']).all():
            invalid_rows = trajectory_data[trajectory_data['ci_upper'] <= trajectory_data['ci_lower']]
            raise ValueError(f"Invalid CI bounds in {len(invalid_rows)} rows:\n{invalid_rows}")
        log("[VALIDATION] CI bounds valid (ci_upper > ci_lower) [PASS]")

        # Check 5: n = 100 for all rows
        if not (trajectory_data['n'] == 100).all():
            invalid_counts = trajectory_data[trajectory_data['n'] != 100]
            raise ValueError(f"Expected n=100 for all rows, found violations:\n{invalid_counts}")
        log("[VALIDATION] All n = 100 [PASS]")

        # Check 6: IRT mean_score in [-3, 3]
        irt_rows = trajectory_data[trajectory_data['method'] == 'IRT']
        if not ((irt_rows['mean_score'] >= -3) & (irt_rows['mean_score'] <= 3)).all():
            invalid_irt = irt_rows[(irt_rows['mean_score'] < -3) | (irt_rows['mean_score'] > 3)]
            raise ValueError(f"IRT mean_score out of [-3, 3] range:\n{invalid_irt}")
        log("[VALIDATION] IRT mean_score in [-3, 3] [PASS]")

        # Check 7: CTT mean_score in [0, 1]
        ctt_rows = trajectory_data[trajectory_data['method'] == 'CTT']
        if not ((ctt_rows['mean_score'] >= 0) & (ctt_rows['mean_score'] <= 1)).all():
            invalid_ctt = ctt_rows[(ctt_rows['mean_score'] < 0) | (ctt_rows['mean_score'] > 1)]
            raise ValueError(f"CTT mean_score out of [0, 1] range:\n{invalid_ctt}")
        log("[VALIDATION] CTT mean_score in [0, 1] [PASS]")

        # Check 8: time in [0, 168] hours
        if not ((trajectory_data['time'] >= 0) & (trajectory_data['time'] <= 168)).all():
            invalid_time = trajectory_data[(trajectory_data['time'] < 0) | (trajectory_data['time'] > 168)]
            raise ValueError(f"TSVR_hours out of [0, 168] range:\n{invalid_time}")
        log("[VALIDATION] time in [0, 168] hours [PASS]")

        log("[SUCCESS] Step 8 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
