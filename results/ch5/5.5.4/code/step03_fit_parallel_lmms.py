#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step03
Step Name: Fit Parallel LMMs (IRT-based and CTT-based)
RQ: results/ch5/5.5.4
Generated: 2025-12-05

PURPOSE:
Fit identical Linear Mixed Models to IRT theta scores and CTT mean scores for
structural equivalence assessment. This tests whether IRT and CTT measurement
approaches produce structurally equivalent models when analyzing the same
source-destination memory dissociation.

EXPECTED INPUTS:
  - data/step00_irt_theta_from_rq551.csv
    Columns: ['composite_ID', 'UID', 'test', 'irt_theta', 'irt_se', 'location_type', 'TSVR_hours']
    Format: IRT theta scores from RQ 5.5.1 (800 rows = 100 participants x 4 tests x 2 location types)
    Expected rows: ~800

  - data/step01_ctt_scores.csv
    Columns: ['composite_ID', 'UID', 'test', 'location_type', 'ctt_mean_score', 'n_items', 'TSVR_hours']
    Format: CTT mean scores (proportion correct) per location type (800 rows)
    Expected rows: ~800

EXPECTED OUTPUTS:
  - data/step03_irt_lmm_model.pkl
    Format: Pickled MixedLMResults object (IRT-based LMM)

  - data/step03_ctt_lmm_model.pkl
    Format: Pickled MixedLMResults object (CTT-based LMM)

  - data/step03_irt_lmm_summary.txt
    Format: Text summary of IRT model (fixed effects, random effects, AIC, BIC)

  - data/step03_ctt_lmm_summary.txt
    Format: Text summary of CTT model (fixed effects, random effects, AIC, BIC)

  - data/step03_model_metadata.yaml
    Format: Model specifications (formula, convergence status, simplification flag)

  - data/step03_irt_coefficients.csv
    Format: IRT model fixed effects table (for Step 5 comparison without pickle loading)
    Columns: ['term', 'coef', 'std_err', 'z', 'p_value', 'ci_lower', 'ci_upper']

  - data/step03_ctt_coefficients.csv
    Format: CTT model fixed effects table (for Step 5 comparison without pickle loading)
    Columns: ['term', 'coef', 'std_err', 'z', 'p_value', 'ci_lower', 'ci_upper']

VALIDATION CRITERIA:
  - Both models converge OR both simplified identically
  - AIC, BIC are finite (not NaN, not inf)
  - 4 fixed effects (Intercept, LocationType, log_TSVR, interaction)
  - Convergence check: model.converged == True

g_code REASONING:
- Approach: Fit identical LMMs to IRT and CTT scores using statsmodels MixedLM
- Why this approach: Tests structural equivalence between measurement methods
- Data flow: Load IRT theta + CTT scores → create log_TSVR → fit parallel models with
  identical formula (score ~ LocationType * log_TSVR) → if convergence fails for
  EITHER model, simplify BOTH to ~1|UID (random intercepts only) → save models and summaries
- Expected performance: ~30-60 seconds per model (fast for 800 rows)
- Key decision: Use statsmodels directly (NOT fit_lmm_trajectory_tsvr tool) because
  we need explicit control over convergence handling and symmetric simplification

IMPLEMENTATION NOTES:
- Analysis tool: statsmodels.formula.api.mixedlm (direct usage)
- Validation tool: tools.validation.validate_model_convergence
- Parameters:
  - Formula: score ~ C(location_type, Treatment('source')) * log_TSVR
  - Random effects (full): ~log_TSVR | UID (random intercepts + slopes)
  - Random effects (simplified): ~1 | UID (random intercepts only)
  - REML: False (required for AIC/BIC comparison in Step 6)
  - Treatment coding: 'source' is reference level (Intercept = source baseline)
- Critical constraint: BOTH models must have identical random structure (no asymmetry)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback
import yaml
import pickle

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = 5.5.4/
#   parents[2] = ch5/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import statsmodels for LMM fitting
import statsmodels.formula.api as smf
from statsmodels.regression.mixed_linear_model import MixedLMResults

# Import validation tool
from tools.validation import validate_model_convergence

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.5.4 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step03_fit_parallel_lmms.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step03_irt_lmm_model.pkl
#   CORRECT: data/step03_ctt_coefficients.csv
#   WRONG:   results/lmm_model.pkl  (wrong folder + no prefix)
#   WRONG:   data/irt_model.pkl     (missing step prefix)
#   WRONG:   logs/step03_model.pkl  (pkl in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 3: Fit Parallel LMMs (IRT-based and CTT-based)")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: IRT theta scores and CTT mean scores (800 rows each)
        # Purpose: Fit identical LMMs to both measurement approaches

        log("[LOAD] Loading IRT theta scores...")
        irt_data = pd.read_csv(RQ_DIR / "data" / "step00_irt_theta_from_rq551.csv")
        log(f"[LOADED] step00_irt_theta_from_rq551.csv ({len(irt_data)} rows, {len(irt_data.columns)} cols)")
        log(f"[INFO] IRT theta range: [{irt_data['irt_theta'].min():.2f}, {irt_data['irt_theta'].max():.2f}]")

        log("[LOAD] Loading CTT mean scores...")
        ctt_data = pd.read_csv(RQ_DIR / "data" / "step01_ctt_scores.csv")
        log(f"[LOADED] step01_ctt_scores.csv ({len(ctt_data)} rows, {len(ctt_data.columns)} cols)")
        log(f"[INFO] CTT score range: [{ctt_data['ctt_mean_score'].min():.3f}, {ctt_data['ctt_mean_score'].max():.3f}]")

        # =========================================================================
        # STEP 2: Prepare Data for LMM Fitting
        # =========================================================================
        # Create log_TSVR transformation for nonlinear time effects
        # Note: TSVR already in hours (0-168), add 1 to avoid log(0)

        log("[PREP] Creating log_TSVR transformation...")
        irt_data['log_TSVR'] = np.log(irt_data['TSVR_hours'] + 1)
        ctt_data['log_TSVR'] = np.log(ctt_data['TSVR_hours'] + 1)
        log(f"[PREP] log_TSVR range (IRT): [{irt_data['log_TSVR'].min():.3f}, {irt_data['log_TSVR'].max():.3f}]")
        log(f"[PREP] log_TSVR range (CTT): [{ctt_data['log_TSVR'].min():.3f}, {ctt_data['log_TSVR'].max():.3f}]")

        # Verify data integrity
        log("[VALIDATE] Checking data integrity...")
        assert len(irt_data) == 800, f"Expected 800 IRT rows, got {len(irt_data)}"
        assert len(ctt_data) == 800, f"Expected 800 CTT rows, got {len(ctt_data)}"
        assert irt_data['irt_theta'].notna().all(), "Missing values in irt_theta"
        assert ctt_data['ctt_mean_score'].notna().all(), "Missing values in ctt_mean_score"
        assert set(irt_data['location_type'].unique()) == {'source', 'destination'}, "Invalid location types (IRT)"
        assert set(ctt_data['location_type'].unique()) == {'source', 'destination'}, "Invalid location types (CTT)"
        log("[VALIDATE] Data integrity checks passed")

        # =========================================================================
        # STEP 3: Fit IRT-Based LMM (Full Random Structure)
        # =========================================================================
        # Model: irt_theta ~ LocationType * log_TSVR
        # Random: ~log_TSVR | UID (random intercepts + slopes)
        # REML: False (for AIC/BIC comparison in Step 6)

        log("[ANALYSIS] Fitting IRT-based LMM with full random structure...")
        log("[INFO] Formula: irt_theta ~ C(location_type, Treatment('source')) * log_TSVR")
        log("[INFO] Random: ~log_TSVR (random intercepts + slopes for TSVR)")
        log("[INFO] Groups: UID")
        log("[INFO] REML: False (for AIC comparison)")

        try:
            irt_model_full = smf.mixedlm(
                formula="irt_theta ~ C(location_type, Treatment('source')) * log_TSVR",
                data=irt_data,
                groups=irt_data['UID'],
                re_formula="~log_TSVR"
            )
            irt_result_full = irt_model_full.fit(reml=False)
            irt_converged = irt_result_full.converged
            log(f"[FIT] IRT model (full) convergence: {irt_converged}")
        except Exception as e:
            log(f"[ERROR] IRT model (full) fitting failed: {str(e)}")
            irt_converged = False
            irt_result_full = None

        # =========================================================================
        # STEP 4: Fit CTT-Based LMM (Full Random Structure)
        # =========================================================================
        # Model: ctt_mean_score ~ LocationType * log_TSVR
        # Random: ~log_TSVR | UID (random intercepts + slopes)
        # REML: False (for AIC/BIC comparison in Step 6)

        log("[ANALYSIS] Fitting CTT-based LMM with full random structure...")
        log("[INFO] Formula: ctt_mean_score ~ C(location_type, Treatment('source')) * log_TSVR")
        log("[INFO] Random: ~log_TSVR (random intercepts + slopes for TSVR)")
        log("[INFO] Groups: UID")
        log("[INFO] REML: False (for AIC comparison)")

        try:
            ctt_model_full = smf.mixedlm(
                formula="ctt_mean_score ~ C(location_type, Treatment('source')) * log_TSVR",
                data=ctt_data,
                groups=ctt_data['UID'],
                re_formula="~log_TSVR"
            )
            ctt_result_full = ctt_model_full.fit(reml=False)
            ctt_converged = ctt_result_full.converged
            log(f"[FIT] CTT model (full) convergence: {ctt_converged}")
        except Exception as e:
            log(f"[ERROR] CTT model (full) fitting failed: {str(e)}")
            ctt_converged = False
            ctt_result_full = None

        # =========================================================================
        # STEP 5: Handle Convergence Failures (Symmetric Simplification)
        # =========================================================================
        # CRITICAL: If EITHER model fails, simplify BOTH to ~1|UID (random intercepts only)

        simplified = False

        if not irt_converged or not ctt_converged:
            log("[WARNING] At least one model failed to converge with full random structure")
            log("[ACTION] Simplifying BOTH models to ~1|UID (random intercepts only)")
            simplified = True

            # Fit IRT model with simplified random structure
            log("[ANALYSIS] Re-fitting IRT-based LMM with simplified random structure...")
            log("[INFO] Random: ~1 (random intercepts only)")

            irt_model_simple = smf.mixedlm(
                formula="irt_theta ~ C(location_type, Treatment('source')) * log_TSVR",
                data=irt_data,
                groups=irt_data['UID']
                # re_formula defaults to "~1" (random intercepts only)
            )
            irt_result = irt_model_simple.fit(reml=False)
            log(f"[FIT] IRT model (simplified) convergence: {irt_result.converged}")

            # Fit CTT model with simplified random structure
            log("[ANALYSIS] Re-fitting CTT-based LMM with simplified random structure...")
            log("[INFO] Random: ~1 (random intercepts only)")

            ctt_model_simple = smf.mixedlm(
                formula="ctt_mean_score ~ C(location_type, Treatment('source')) * log_TSVR",
                data=ctt_data,
                groups=ctt_data['UID']
                # re_formula defaults to "~1" (random intercepts only)
            )
            ctt_result = ctt_model_simple.fit(reml=False)
            log(f"[FIT] CTT model (simplified) convergence: {ctt_result.converged}")

            if not irt_result.converged or not ctt_result.converged:
                raise ValueError("Models failed to converge even with simplified random structure")

        else:
            # Both models converged with full random structure
            log("[SUCCESS] Both models converged with full random structure")
            irt_result = irt_result_full
            ctt_result = ctt_result_full

        # =========================================================================
        # STEP 6: Extract Fixed Effects Tables for Step 5 Comparison
        # =========================================================================
        # Save fixed effects as CSV so Step 5 doesn't need to unpickle models

        log("[EXTRACT] Extracting fixed effects from IRT model...")
        irt_fe = irt_result.fe_params
        irt_se = irt_result.bse_fe
        # Note: tvalues and pvalues include random effects, need to slice to fixed effects only
        n_fe = len(irt_fe)
        irt_z = irt_result.tvalues.iloc[:n_fe]
        irt_p = irt_result.pvalues.iloc[:n_fe]
        irt_ci = irt_result.conf_int().iloc[:n_fe]

        irt_coef_df = pd.DataFrame({
            'term': irt_fe.index,
            'coef': irt_fe.values,
            'std_err': irt_se.values,
            'z': irt_z.values,
            'p_value': irt_p.values,
            'ci_lower': irt_ci.iloc[:, 0].values,
            'ci_upper': irt_ci.iloc[:, 1].values
        })
        log(f"[INFO] IRT model: {len(irt_coef_df)} fixed effects")

        log("[EXTRACT] Extracting fixed effects from CTT model...")
        ctt_fe = ctt_result.fe_params
        ctt_se = ctt_result.bse_fe
        # Note: tvalues and pvalues include random effects, need to slice to fixed effects only
        n_fe_ctt = len(ctt_fe)
        ctt_z = ctt_result.tvalues.iloc[:n_fe_ctt]
        ctt_p = ctt_result.pvalues.iloc[:n_fe_ctt]
        ctt_ci = ctt_result.conf_int().iloc[:n_fe_ctt]

        ctt_coef_df = pd.DataFrame({
            'term': ctt_fe.index,
            'coef': ctt_fe.values,
            'std_err': ctt_se.values,
            'z': ctt_z.values,
            'p_value': ctt_p.values,
            'ci_lower': ctt_ci.iloc[:, 0].values,
            'ci_upper': ctt_ci.iloc[:, 1].values
        })
        log(f"[INFO] CTT model: {len(ctt_coef_df)} fixed effects")

        # =========================================================================
        # STEP 7: Save Model Outputs
        # =========================================================================

        log("[SAVE] Saving IRT model...")
        with open(RQ_DIR / "data" / "step03_irt_lmm_model.pkl", 'wb') as f:
            pickle.dump(irt_result, f)
        log("[SAVED] data/step03_irt_lmm_model.pkl")

        log("[SAVE] Saving CTT model...")
        with open(RQ_DIR / "data" / "step03_ctt_lmm_model.pkl", 'wb') as f:
            pickle.dump(ctt_result, f)
        log("[SAVED] data/step03_ctt_lmm_model.pkl")

        log("[SAVE] Saving IRT model summary...")
        with open(RQ_DIR / "data" / "step03_irt_lmm_summary.txt", 'w', encoding='utf-8') as f:
            f.write(str(irt_result.summary()))
        log("[SAVED] data/step03_irt_lmm_summary.txt")

        log("[SAVE] Saving CTT model summary...")
        with open(RQ_DIR / "data" / "step03_ctt_lmm_summary.txt", 'w', encoding='utf-8') as f:
            f.write(str(ctt_result.summary()))
        log("[SAVED] data/step03_ctt_lmm_summary.txt")

        log("[SAVE] Saving IRT fixed effects table...")
        irt_coef_df.to_csv(RQ_DIR / "data" / "step03_irt_coefficients.csv", index=False, encoding='utf-8')
        log(f"[SAVED] data/step03_irt_coefficients.csv ({len(irt_coef_df)} rows)")

        log("[SAVE] Saving CTT fixed effects table...")
        ctt_coef_df.to_csv(RQ_DIR / "data" / "step03_ctt_coefficients.csv", index=False, encoding='utf-8')
        log(f"[SAVED] data/step03_ctt_coefficients.csv ({len(ctt_coef_df)} rows)")

        # Create model metadata
        log("[SAVE] Creating model metadata...")
        metadata = {
            'timestamp': pd.Timestamp.now().isoformat(),
            'formula': "score ~ C(location_type, Treatment('source')) * log_TSVR",
            'random_structure': '~1 (intercepts only)' if simplified else '~log_TSVR (intercepts + slopes)',
            'simplified': simplified,
            'reml': False,
            'irt_model': {
                'converged': bool(irt_result.converged),
                'aic': float(irt_result.aic),
                'bic': float(irt_result.bic),
                'n_obs': int(irt_result.nobs),
                'n_groups': len(irt_result.model.group_labels)
            },
            'ctt_model': {
                'converged': bool(ctt_result.converged),
                'aic': float(ctt_result.aic),
                'bic': float(ctt_result.bic),
                'n_obs': int(ctt_result.nobs),
                'n_groups': len(ctt_result.model.group_labels)
            }
        }

        with open(RQ_DIR / "data" / "step03_model_metadata.yaml", 'w', encoding='utf-8') as f:
            yaml.dump(metadata, f, default_flow_style=False)
        log("[SAVED] data/step03_model_metadata.yaml")

        # =========================================================================
        # STEP 8: Run Validation
        # =========================================================================
        # Validate: Both models converged, AIC/BIC finite, 4 fixed effects

        log("[VALIDATION] Running validation checks...")

        # Validate IRT model convergence
        irt_validation = validate_model_convergence(irt_result)
        if not irt_validation['valid']:
            raise ValueError(f"IRT model validation failed: {irt_validation['message']}")
        log(f"[VALIDATION] IRT model convergence: {irt_validation['message']}")

        # Validate CTT model convergence
        ctt_validation = validate_model_convergence(ctt_result)
        if not ctt_validation['valid']:
            raise ValueError(f"CTT model validation failed: {ctt_validation['message']}")
        log(f"[VALIDATION] CTT model convergence: {ctt_validation['message']}")

        # Validate AIC/BIC are finite
        assert np.isfinite(irt_result.aic), f"IRT model AIC is not finite: {irt_result.aic}"
        assert np.isfinite(irt_result.bic), f"IRT model BIC is not finite: {irt_result.bic}"
        assert np.isfinite(ctt_result.aic), f"CTT model AIC is not finite: {ctt_result.aic}"
        assert np.isfinite(ctt_result.bic), f"CTT model BIC is not finite: {ctt_result.bic}"
        log(f"[VALIDATION] IRT model AIC={irt_result.aic:.2f}, BIC={irt_result.bic:.2f}")
        log(f"[VALIDATION] CTT model AIC={ctt_result.aic:.2f}, BIC={ctt_result.bic:.2f}")

        # Validate 4 fixed effects (Intercept, LocationType, log_TSVR, interaction)
        assert len(irt_coef_df) == 4, f"Expected 4 IRT fixed effects, got {len(irt_coef_df)}"
        assert len(ctt_coef_df) == 4, f"Expected 4 CTT fixed effects, got {len(ctt_coef_df)}"
        log("[VALIDATION] Both models have 4 fixed effects (Intercept, LocationType, log_TSVR, interaction)")

        # Report validation summary
        log("[VALIDATION] All validation checks passed:")
        log("  [PASS] IRT model converged")
        log("  [PASS] CTT model converged")
        log("  [PASS] Both models have identical random structure (symmetric)")
        log("  [PASS] AIC and BIC are finite for both models")
        log("  [PASS] Both models have 4 fixed effects")

        log("[SUCCESS] Step 3 complete")
        log(f"[INFO] Random structure: {'Simplified (~1)' if simplified else 'Full (~log_TSVR)'}")
        log("[INFO] Next: Run step04_validate_lmm_assumptions.py")

        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
