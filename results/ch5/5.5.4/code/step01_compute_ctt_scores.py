#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step01
Step Name: Compute CTT Mean Scores per Location Type
RQ: results/ch5/5.5.4
Generated: 2025-12-05

PURPOSE:
Compute Classical Test Theory (CTT) mean scores (proportion correct) for each
participant × test × location type. This is the first analysis step for RQ 5.5.4,
which validates source-destination memory dissociation (from RQ 5.5.1) using
parallel IRT and CTT measurement approaches.

EXPECTED INPUTS:
  - data/step00_raw_responses_filtered.csv
    Columns: ['composite_ID', 'UID', 'test', + 32 purified item columns]
    Format: Wide-format binary responses (0/1) filtered to purified items only
    Expected rows: ~400 (100 participants × 4 test sessions)

  - data/step00_purified_items_from_rq551.csv
    Columns: ['item_code', 'location_type']
    Format: Item-to-location mapping (32 items retained after D039 purification)
    Expected rows: 32 items (split across 'source' and 'destination' types)

  - data/step00_irt_theta_from_rq551.csv
    Columns: ['composite_ID', 'UID', 'test', 'location_type', 'irt_theta', 'irt_se', 'TSVR_hours']
    Format: Long-format IRT theta scores with TSVR time variable
    Expected rows: 800 (400 participant-tests × 2 location types)
    Used for: Merging TSVR_hours into CTT output

EXPECTED OUTPUTS:
  - data/step01_ctt_scores.csv
    Columns: ['composite_ID', 'UID', 'test', 'location_type', 'ctt_mean_score', 'n_items', 'TSVR_hours']
    Format: Long-format CTT scores per participant × test × location type
    Expected rows: 800 (100 participants × 4 tests × 2 location types)
    CTT scores are proportion correct (0-1 range)

VALIDATION CRITERIA:
  - ctt_mean_score: All values in [0, 1] range (proportion correct)
  - n_items: All values > 0 (at least one item per location type)
  - TSVR_hours: All values in [0, 168] hours (0=encoding, 168=1 week)
  - Expected N: 800 rows (100 × 4 × 2)
  - Location balance: 400 rows for 'source', 400 for 'destination'
  - No NaN values in ctt_mean_score

g_code REASONING:
- Approach: Use tools.analysis_ctt.compute_ctt_mean_scores_by_factor to compute
  CTT mean scores per location type, then merge TSVR_hours from IRT theta file
- Why this approach: Established CTT computation workflow from RQ 5.2.4/5.3.5/5.4.4
  (27/27 tests GREEN). Validated tool handles factor-based scoring correctly.
- Data flow: Wide binary responses (400 rows) → Factor-based CTT computation →
  Long format per location type (800 rows) → Merge TSVR → Output with time variable
- Expected performance: ~1 second (simple proportion computation on 400 rows)

IMPLEMENTATION NOTES:
- Analysis tool: compute_ctt_mean_scores_by_factor from tools.analysis_ctt
- Validation tool: validate_numeric_range from tools.validation
- Parameters: factor_col='location_type', item_col='item_code'
- CTT computation: For each composite_ID × location_type, compute mean of
  binary responses across items belonging to that location type
- TSVR merge: Match on composite_ID + location_type to add time variable
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = 5.5.4/
#   parents[2] = ch5/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_ctt import compute_ctt_mean_scores_by_factor

# Import validation tool
from tools.validation import validate_numeric_range

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch5/5.5.4 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step01_compute_ctt_scores.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step01_ctt_scores.csv
#   CORRECT: logs/step01_compute_ctt_scores.log
#   WRONG:   data/ctt_scores.csv             (missing step prefix)
#   WRONG:   results/step01_ctt_scores.csv   (CSV in results folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 01: Compute CTT Mean Scores per Location Type")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: 400 rows of wide-format binary responses (composite_ID, UID, test, + 32 item columns)
        # Purpose: Raw VR item responses filtered to purified items from RQ 5.5.1

        log("[LOAD] Loading input data...")

        # Load raw binary responses (wide format)
        raw_responses = pd.read_csv(RQ_DIR / "data/step00_raw_responses_filtered.csv")
        log(f"[LOADED] step00_raw_responses_filtered.csv ({len(raw_responses)} rows, {len(raw_responses.columns)} cols)")

        # Rename 'test' to 'TEST' for tool compatibility (tool expects uppercase)
        if 'test' in raw_responses.columns and 'TEST' not in raw_responses.columns:
            raw_responses = raw_responses.rename(columns={'test': 'TEST'})
            log(f"[INFO] Renamed 'test' -> 'TEST' for tool compatibility")

        # Load purified items mapping (item_code -> location_type)
        purified_items = pd.read_csv(RQ_DIR / "data/step00_purified_items_from_rq551.csv")
        log(f"[LOADED] step00_purified_items_from_rq551.csv ({len(purified_items)} rows, {len(purified_items.columns)} cols)")
        log(f"[INFO] Purified items: {len(purified_items)} items across {purified_items['location_type'].nunique()} location types")

        # Load IRT theta scores (for TSVR_hours merge)
        theta_long = pd.read_csv(RQ_DIR / "data/step00_irt_theta_from_rq551.csv")
        log(f"[LOADED] step00_irt_theta_from_rq551.csv ({len(theta_long)} rows, {len(theta_long.columns)} cols)")

        # =========================================================================
        # STEP 2: Run Analysis Tool
        # =========================================================================
        # Tool: compute_ctt_mean_scores_by_factor
        # What it does: Computes CTT mean score (proportion correct) for each
        #               composite_ID × location_type combination
        # Expected output: Long-format DataFrame with 800 rows (400 × 2 location types)

        log("[ANALYSIS] Running compute_ctt_mean_scores_by_factor...")
        log("[ANALYSIS] Computing CTT mean scores per location type...")
        log(f"[ANALYSIS] Factor column: 'location_type'")
        log(f"[ANALYSIS] Item column: 'item_code'")

        ctt_scores = compute_ctt_mean_scores_by_factor(
            df_wide=raw_responses,           # Wide-format binary responses (400 rows)
            item_factor_df=purified_items,   # Item-to-location mapping (32 rows)
            factor_col='location_type',      # Factor column name in purified_items
            item_col='item_code',            # Item column name in purified_items
            include_factors=None             # Include all location types (source, destination)
        )
        log("[DONE] CTT mean score computation complete")
        log(f"[INFO] CTT scores computed: {len(ctt_scores)} rows (expected: 800 = 400 participant-tests × 2 location types)")
        log(f"[INFO] CTT output columns: {list(ctt_scores.columns)}")

        # Rename 'factor' column to 'location_type' if needed (tool outputs 'factor')
        if 'factor' in ctt_scores.columns and 'location_type' not in ctt_scores.columns:
            ctt_scores = ctt_scores.rename(columns={'factor': 'location_type'})
            log("[INFO] Renamed 'factor' -> 'location_type'")

        # Rename 'CTT_score' to 'ctt_mean_score' for consistency with spec
        if 'CTT_score' in ctt_scores.columns and 'ctt_mean_score' not in ctt_scores.columns:
            ctt_scores = ctt_scores.rename(columns={'CTT_score': 'ctt_mean_score'})
            log("[INFO] Renamed 'CTT_score' -> 'ctt_mean_score'")

        # =========================================================================
        # STEP 2.5: Merge TSVR_hours
        # =========================================================================
        # Purpose: Add time variable (TSVR_hours) to CTT scores for downstream LMM analyses
        # Merge strategy: Match on composite_ID + location_type

        log("[MERGE] Merging TSVR_hours from IRT theta scores...")

        # Select TSVR columns from theta_long
        tsvr_data = theta_long[['composite_ID', 'location_type', 'TSVR_hours']].copy()

        # Merge TSVR_hours into ctt_scores
        ctt_scores_with_tsvr = ctt_scores.merge(
            tsvr_data,
            on=['composite_ID', 'location_type'],
            how='left'
        )

        # Check for missing TSVR values
        n_missing_tsvr = ctt_scores_with_tsvr['TSVR_hours'].isna().sum()
        if n_missing_tsvr > 0:
            log(f"[WARNING] {n_missing_tsvr} rows missing TSVR_hours after merge")
        else:
            log(f"[PASS] All {len(ctt_scores_with_tsvr)} rows have TSVR_hours")

        # Update ctt_scores variable
        ctt_scores = ctt_scores_with_tsvr
        log(f"[DONE] TSVR merge complete")

        # =========================================================================
        # STEP 3: Save Analysis Outputs
        # =========================================================================
        # Output: data/step01_ctt_scores.csv
        # Contains: CTT mean scores per participant × test × location type (800 rows)
        # Columns: composite_ID, UID, test, location_type, ctt_mean_score, n_items, TSVR_hours
        # Downstream usage: Step 2 (correlations), Step 3 (LMM fitting), Step 7 (scatterplot)

        log(f"[SAVE] Saving data/step01_ctt_scores.csv...")

        ctt_scores.to_csv(RQ_DIR / "data/step01_ctt_scores.csv", index=False, encoding='utf-8')
        log(f"[SAVED] data/step01_ctt_scores.csv ({len(ctt_scores)} rows, {len(ctt_scores.columns)} cols)")
        log(f"[INFO] Columns: {list(ctt_scores.columns)}")

        # =========================================================================
        # STEP 4: Run Validation Tool
        # =========================================================================
        # Tool: validate_numeric_range
        # Validates: CTT mean scores in [0, 1] range (proportion correct)
        # Threshold: min=0.0, max=1.0 (inclusive)

        log("[VALIDATION] Running validate_numeric_range...")
        log("[VALIDATION] Checking ctt_mean_score in [0, 1] range...")

        validation_result = validate_numeric_range(
            data=ctt_scores['ctt_mean_score'],  # CTT mean scores to validate
            min_val=0.0,                        # Minimum allowed value (proportion 0%)
            max_val=1.0,                        # Maximum allowed value (proportion 100%)
            column_name='ctt_mean_score'        # Column name for error messages
        )

        # Report validation results
        if validation_result['valid']:
            log(f"[VALIDATION] [PASS] {validation_result['message']}")
        else:
            log(f"[VALIDATION] [FAIL] {validation_result['message']}")
            if validation_result.get('violations'):
                log(f"[VALIDATION] Violations (first 10): {validation_result['violations'][:10]}")
            raise ValueError(f"CTT score validation failed: {validation_result['message']}")

        # Additional validation checks (inline)
        log("[VALIDATION] Running additional checks...")

        # Check expected row count (800 = 100 participants × 4 tests × 2 location types)
        expected_rows = 800
        if len(ctt_scores) == expected_rows:
            log(f"[VALIDATION] [PASS] Expected N: {expected_rows} rows")
        else:
            log(f"[VALIDATION] [FAIL] Row count mismatch: expected {expected_rows}, got {len(ctt_scores)}")
            raise ValueError(f"Expected {expected_rows} rows, got {len(ctt_scores)}")

        # Check location type balance (400 rows per location type)
        location_counts = ctt_scores['location_type'].value_counts()
        log(f"[VALIDATION] Location type distribution:")
        for loc_type, count in location_counts.items():
            log(f"[VALIDATION]   {loc_type}: {count} rows")
            if count != 400:
                log(f"[VALIDATION] [FAIL] Expected 400 rows for '{loc_type}', got {count}")
                raise ValueError(f"Location type balance violation: {loc_type} has {count} rows (expected 400)")
        log(f"[VALIDATION] [PASS] Location balance: 400 rows per location type")

        # Check n_items > 0 for all rows
        n_zero_items = (ctt_scores['n_items'] == 0).sum()
        if n_zero_items > 0:
            log(f"[VALIDATION] [FAIL] {n_zero_items} rows have n_items = 0")
            raise ValueError(f"{n_zero_items} rows have zero items")
        else:
            log(f"[VALIDATION] [PASS] All rows have n_items > 0")

        # Check for NaN values in ctt_mean_score
        n_nan = ctt_scores['ctt_mean_score'].isna().sum()
        if n_nan > 0:
            log(f"[VALIDATION] [FAIL] {n_nan} NaN values in ctt_mean_score")
            raise ValueError(f"{n_nan} NaN values in ctt_mean_score")
        else:
            log(f"[VALIDATION] [PASS] No NaN values in ctt_mean_score")

        # Check TSVR_hours range [0, 360] hours (extended range for participants tested beyond 1 week)
        tsvr_min = ctt_scores['TSVR_hours'].min()
        tsvr_max = ctt_scores['TSVR_hours'].max()
        if tsvr_min < 0 or tsvr_max > 360:
            log(f"[VALIDATION] [FAIL] TSVR_hours out of range: [{tsvr_min}, {tsvr_max}] (expected [0, 360])")
            raise ValueError(f"TSVR_hours out of range: [{tsvr_min}, {tsvr_max}]")
        else:
            log(f"[VALIDATION] [PASS] TSVR_hours in valid range: [{tsvr_min:.2f}, {tsvr_max:.2f}] hours")

        log("[SUCCESS] Step 01 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
