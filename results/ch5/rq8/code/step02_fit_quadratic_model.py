#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step02
Step Name: fit_quadratic_model
RQ: results/ch5/rq8
Generated: 2025-11-28

PURPOSE:
Fit theta ~ Time + Time_squared + (Time | UID), test if quadratic term significant
(p < 0.0033 Bonferroni). This is Test 1 for two-phase forgetting hypothesis:
if Time_squared is significant, it suggests non-linear trajectory inconsistent
with simple exponential decay.

EXPECTED INPUTS:
  - data/step01_time_transformed.csv
    Columns: ['UID', 'test', 'TSVR_hours', 'theta', 'Time', 'Time_squared',
              'Time_log', 'Segment', 'Days_within']
    Format: CSV with time transformations from Step 1
    Expected rows: ~400 (100 participants x 4 tests)

EXPECTED OUTPUTS:
  - data/step02_quadratic_model_summary.txt
    Format: Plain text model summary
    Content: Fixed effects, random effects, AIC, BIC, convergence status,
             Time_squared significance test
    Expected: Convergence status + p-value for Time_squared term
  - data/step02_quadratic_predictions.csv
    Columns: ['Time', 'predicted_theta', 'CI_lower', 'CI_upper']
    Format: CSV with model predictions at 11 timepoints
    Expected rows: 11 (prediction grid: 0, 24, 48, ..., 240 hours)

VALIDATION CRITERIA:
  - Model converged (or fallback documented)
  - All fixed effects finite (no NaN)
  - Predictions generated for all 11 timepoints
  - Time_squared p-value in [0, 1]
  - AIC > 0

g_code REASONING:
- Approach: Fit quadratic LMM with random slopes using fit_lmm_trajectory_tsvr
  - Maximal random effects: (Time | UID) allows individual variation in slopes
  - Fallback strategy: (Time || UID) -> (1 | UID) if convergence fails
  - ML estimation (REML=False) for valid AIC comparison with piecewise model
- Why this approach:
  - Quadratic term tests for non-linearity in forgetting trajectory
  - If Time_squared significant, suggests acceleration/deceleration in forgetting
  - Random slopes account for individual differences in trajectory shape
  - Bonferroni correction (alpha=0.0033) controls family-wise error for 15 tests
- Data flow:
  - Load time_transformed data from Step 1 (has Time, Time_squared columns)
  - Fit LMM with formula "theta ~ Time + Time_squared + (Time | UID)"
  - Generate predictions on grid [0, 24, 48, ..., 240] for plotting
  - Save model summary + predictions for Step 3 AIC comparison
- Expected performance: ~30-60 seconds (statsmodels MixedLM convergence)

IMPLEMENTATION NOTES:
- Analysis tool: fit_lmm_trajectory_tsvr from tools.analysis_lmm
- Validation tool: validate_lmm_convergence from tools.validation
- Parameters:
  - formula: "theta ~ Time + Time_squared + (Time | UID)"
  - REML=False (ML for AIC comparison)
  - Bonferroni alpha=0.0033 (15 planned comparisons)
  - Fallback strategy handles convergence failures gracefully
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback
import pickle

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = chX/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_lmm import fit_lmm_trajectory_tsvr

# Import validation tool
from tools.validation import validate_lmm_convergence

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/chX/rqY (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step02_fit_quadratic_model.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_lmm_model_comparison.csv
#   CORRECT: data/step03_theta_scores.csv
#   WRONG:   results/lmm_model_comparison.csv  (wrong folder + no prefix)
#   WRONG:   data/theta_scores.csv             (missing step prefix)
#   WRONG:   logs/step02_removed_items.csv     (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 2: Fit Quadratic Model")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Time transformations from Step 1 (Time, Time_squared columns)
        # Purpose: Fit quadratic LMM to test non-linearity in forgetting trajectory

        log("[LOAD] Loading time-transformed data from Step 1...")
        time_data = pd.read_csv(RQ_DIR / "data/step01_time_transformed.csv", encoding='utf-8')
        log(f"[LOADED] step01_time_transformed.csv ({len(time_data)} rows, {len(time_data.columns)} cols)")
        log(f"[INFO] Columns: {list(time_data.columns)}")

        # Verify required columns present
        required_cols = ['UID', 'test', 'TSVR_hours', 'theta', 'Time', 'Time_squared']
        missing = [c for c in required_cols if c not in time_data.columns]
        if missing:
            raise ValueError(f"Missing required columns: {missing}")
        log(f"[PASS] All required columns present: {required_cols}")

        # =========================================================================
        # STEP 2: Run Analysis Tool
        # =========================================================================
        # Tool: fit_lmm_trajectory_tsvr
        # What it does: Fits LMM with quadratic term, tests Time_squared significance
        # Expected output: MixedLMResults object with convergence status, fixed effects, AIC

        log("[ANALYSIS] Fitting quadratic model: theta ~ Time + Time_squared + (Time | UID)...")
        log("[INFO] Using ML estimation (REML=False) for valid AIC comparison")
        log("[INFO] Bonferroni alpha = 0.0033 (15 planned comparisons)")

        # Fit quadratic LMM using fit_lmm_trajectory (simpler, takes data directly)
        from tools.analysis_lmm import fit_lmm_trajectory
        quadratic_model = fit_lmm_trajectory(
            data=time_data,
            formula="theta ~ Time + Time_squared",  # Fixed effects
            groups="UID",
            re_formula="~Time",  # Random slopes: (Time | UID)
            reml=False  # ML estimation for AIC comparison
        )

        log("[DONE] Quadratic model fitted")
        log(f"[INFO] Convergence: {quadratic_model.converged}")
        log(f"[INFO] AIC: {quadratic_model.aic:.2f}")
        log(f"[INFO] BIC: {quadratic_model.bic:.2f}")

        # =========================================================================
        # STEP 3: Extract Model Summary and Test Time_squared Significance
        # =========================================================================
        # Test: Is Time_squared significant at Bonferroni-corrected alpha=0.0033?
        # Interpretation: Significant quadratic term suggests non-linear forgetting

        log("[EXTRACT] Extracting fixed effects and significance tests...")

        # Get fixed effects summary
        fe_summary = quadratic_model.summary().tables[1]  # Fixed effects table
        log(f"[INFO] Fixed Effects:\n{fe_summary}")

        # Extract Time_squared p-value
        fe_params = quadratic_model.fe_params
        fe_pvalues = quadratic_model.pvalues

        time_squared_coef = fe_params.get('Time_squared', np.nan)
        time_squared_pval = fe_pvalues.get('Time_squared', np.nan)

        log(f"[RESULT] Time_squared coefficient: {time_squared_coef:.6f}")
        log(f"[RESULT] Time_squared p-value: {time_squared_pval:.6f}")

        # Test significance at Bonferroni alpha
        bonferroni_alpha = 0.0033
        is_significant = time_squared_pval < bonferroni_alpha

        if is_significant:
            log(f"[RESULT] Time_squared is SIGNIFICANT (p={time_squared_pval:.6f} < {bonferroni_alpha})")
            log("[INTERPRETATION] Non-linear trajectory detected -> supports two-phase forgetting")
        else:
            log(f"[RESULT] Time_squared is NOT significant (p={time_squared_pval:.6f} >= {bonferroni_alpha})")
            log("[INTERPRETATION] Linear trajectory -> does NOT support two-phase forgetting")

        # =========================================================================
        # STEP 4: Generate Predictions for Plotting
        # =========================================================================
        # Purpose: Create predictions at 11 timepoints (0, 24, 48, ..., 240 hours)
        # Used by: Step 6 (plotting) and Step 3 (AIC comparison)

        log("[PREDICT] Generating predictions on grid [0, 24, 48, ..., 240] hours...")

        prediction_grid = np.array([0, 24, 48, 72, 96, 120, 144, 168, 192, 216, 240])

        # Create prediction dataframe
        pred_df = pd.DataFrame({
            'Time': prediction_grid,
            'Time_squared': prediction_grid ** 2
        })

        # Generate predictions with confidence intervals
        predictions = quadratic_model.predict(exog=pred_df)

        # Get prediction standard errors (for 95% CI)
        # Note: statsmodels MixedLM doesn't have predict(return_var=True)
        # Use fixed effects standard errors as approximation
        se_time = quadratic_model.bse['Time']
        se_time_sq = quadratic_model.bse['Time_squared']

        # Propagate uncertainty (simplified - assumes no covariance)
        pred_se = np.sqrt(
            (se_time * prediction_grid) ** 2 +
            (se_time_sq * prediction_grid ** 2) ** 2
        )

        # 95% CI (z=1.96 for normal approximation)
        ci_lower = predictions - 1.96 * pred_se
        ci_upper = predictions + 1.96 * pred_se

        # Create predictions dataframe
        quadratic_predictions = pd.DataFrame({
            'Time': prediction_grid,
            'predicted_theta': predictions,
            'CI_lower': ci_lower,
            'CI_upper': ci_upper
        })

        log(f"[DONE] Generated {len(quadratic_predictions)} predictions")

        # =========================================================================
        # STEP 5: Save Analysis Outputs
        # =========================================================================
        # These outputs will be used by: Step 3 (AIC comparison), Step 6 (plotting)

        log("[SAVE] Saving model summary...")

        # Save model summary as text file
        summary_path = RQ_DIR / "data/step02_quadratic_model_summary.txt"
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("QUADRATIC LMM SUMMARY - RQ 5.8 Step 2\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"Formula: theta ~ Time + Time_squared + (Time | UID)\n")
            f.write(f"Estimation: ML (REML=False)\n")
            f.write(f"Bonferroni alpha: {bonferroni_alpha}\n\n")
            f.write(f"Convergence: {quadratic_model.converged}\n")
            f.write(f"AIC: {quadratic_model.aic:.2f}\n")
            f.write(f"BIC: {quadratic_model.bic:.2f}\n")
            f.write(f"Log-Likelihood: {quadratic_model.llf:.2f}\n\n")
            f.write("FIXED EFFECTS:\n")
            f.write("-" * 80 + "\n")
            f.write(str(fe_summary) + "\n\n")
            f.write("TIME_SQUARED SIGNIFICANCE TEST:\n")
            f.write("-" * 80 + "\n")
            f.write(f"Coefficient: {time_squared_coef:.6f}\n")
            f.write(f"P-value: {time_squared_pval:.6f}\n")
            f.write(f"Significant (alpha={bonferroni_alpha}): {is_significant}\n\n")
            f.write("RANDOM EFFECTS:\n")
            f.write("-" * 80 + "\n")
            f.write(str(quadratic_model.random_effects) + "\n\n")
            f.write("FULL MODEL SUMMARY:\n")
            f.write("-" * 80 + "\n")
            f.write(str(quadratic_model.summary()) + "\n")

        log(f"[SAVED] step02_quadratic_model_summary.txt")

        # Save predictions
        pred_path = RQ_DIR / "data/step02_quadratic_predictions.csv"
        quadratic_predictions.to_csv(pred_path, index=False, encoding='utf-8')
        log(f"[SAVED] step02_quadratic_predictions.csv ({len(quadratic_predictions)} rows)")

        # Also save model object as pickle for Step 3
        model_path = RQ_DIR / "data/step02_quadratic_model.pkl"
        with open(model_path, 'wb') as f:
            pickle.dump(quadratic_model, f)
        log(f"[SAVED] step02_quadratic_model.pkl (for Step 3 AIC comparison)")

        # =========================================================================
        # STEP 6: Run Validation Tool
        # =========================================================================
        # Tool: validate_lmm_convergence
        # Validates: Model convergence, parameter finiteness, AIC validity
        # Threshold: All checks must pass

        log("[VALIDATION] Running validate_lmm_convergence...")
        validation_result = validate_lmm_convergence(
            lmm_result=quadratic_model
        )

        # Report validation results
        if isinstance(validation_result, dict):
            for key, value in validation_result.items():
                log(f"[VALIDATION] {key}: {value}")
        else:
            log(f"[VALIDATION] {validation_result}")

        # Additional manual checks
        log("[VALIDATION] Additional checks:")
        log(f"  - Predictions count: {len(quadratic_predictions)} (expected 11)")
        log(f"  - Time_squared p-value finite: {np.isfinite(time_squared_pval)}")
        log(f"  - AIC positive: {quadratic_model.aic > 0}")

        # Verify all critical checks passed
        all_passed = (
            quadratic_model.converged or 'fallback' in str(quadratic_model.cov_re),
            len(quadratic_predictions) == 11,
            np.isfinite(time_squared_pval),
            quadratic_model.aic > 0,
            all(np.isfinite(quadratic_model.fe_params))
        )

        if all(all_passed):
            log("[VALIDATION] All checks PASSED")
        else:
            log("[VALIDATION] Some checks FAILED - review results carefully")

        log("[SUCCESS] Step 2 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
