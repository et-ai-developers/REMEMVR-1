#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step02b
Step Name: EXPANDED AIC Model Comparison with Power-Law and Advanced Transformations
RQ: results/ch6/6.6.1
Generated: 2025-12-08

PURPOSE:
Comprehensive functional form testing including power-law transformations, piecewise
models, and exponential decay to find best fit for HCE rate trajectory. Expands beyond
Step 02a's 5 basic models (Linear, Quadratic, Logarithmic, Linear+Log, Quadratic+Log)
to test 13+ candidate models with various power-law exponents.

Context from Step 02a: Linear and Logarithmic essentially tied (ΔAIC=0.05, weights ~27%
each), suggesting neither clearly superior. Trajectory is VERY FLAT (T1=4.87% → T2=4.87%
→ T3=3.79% → T4=3.17%) with two-phase pattern: NO change Day 0-1, then gradual decline
Day 1-6. Need more sophisticated functional forms to capture this pattern.

EXPECTED INPUTS:
  - data/step01_hce_rates.csv
    Columns: ['UID', 'TEST', 'TSVR', 'HCE_rate', 'n_HCE', 'n_total']
    Format: 400 rows (100 participants x 4 tests)
    Expected rows: 400

EXPECTED OUTPUTS:
  - data/step02b_expanded_model_comparison.csv
    Columns: ['model', 'AIC', 'BIC', 'loglik', 'n_params', 'converged', 'delta_AIC', 'akaike_weight']
    Format: 13+ rows (one per candidate model)
    Expected rows: 13+

  - data/step02b_best_model_selection.txt
    Format: Text summary with detailed interpretation
    Content: Best model, top 5 ranking, convergence status, special pattern flags

VALIDATION CRITERIA:
  - All 13 models attempted (convergence failures documented)
  - AIC values finite for converged models
  - Akaike weights sum to 1.0 (across converged models)
  - Top 5 models clearly ranked
  - Best model identified with interpretation
  - Special pattern flags (piecewise, power-law < 1.0, ΔAIC > 2)

g_code REASONING:
- Approach: Test comprehensive suite including power-law (exponents 0.3, 0.5, 0.7, 1.5, 3.0),
  inverse/hyperbolic, piecewise (breakpoint Day 1), and exponential decay transformations
- Why this approach: Step 02a showed ambiguity (Linear vs Log tied). Two-phase pattern
  (flat then decline) suggests piecewise or specific power-law may fit better. Testing
  wide range of exponents finds optimal curvature.
- Data flow: HCE rates -> create 11 time transformations -> fit 13 models -> extract AIC ->
  compute weights -> rank top 5 -> identify best with interpretation
- Expected performance: ~2-4 minutes (13 model fits, some may fail to converge)

IMPLEMENTATION NOTES:
- Analysis tool: statsmodels.regression.mixed_linear_model.MixedLM
- Validation tool: Manual validation of AIC values, weights, convergence, ranking
- Parameters: REML=False (required for valid AIC comparison across models)
- Convergence handling: Gracefully handle failures, document status, exclude from weights
- Special focus: Flag piecewise winner (two-phase real), power < 1.0 winner (diminishing
  returns), ΔAIC > 2 (clear winner)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = chX/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import required libraries
from statsmodels.regression.mixed_linear_model import MixedLM
import warnings

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch6/6.6.1 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step02b_expanded_model_comparison.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step02b_expanded_model_comparison.csv
#   CORRECT: data/step01_hce_rates.csv
#   WRONG:   results/model_comparison.csv  (wrong folder + no prefix)
#   WRONG:   data/model_comparison.csv     (missing step prefix)
#   WRONG:   logs/step02b_removed_items.csv (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console with flush."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg, flush=True)

# =============================================================================
# Model Fitting Functions
# =============================================================================

def fit_model_with_convergence_check(formula: str, re_formula: str, data: pd.DataFrame,
                                     model_name: str) -> Tuple[Any, bool, str]:
    """
    Fit LMM model and check convergence status.

    Returns:
        Tuple of (fitted_model, converged_bool, message)
    """
    try:
        # Suppress convergence warnings during fitting (we'll check manually)
        with warnings.catch_warnings():
            warnings.filterwarnings('ignore')

            # Fit model with REML=False (required for AIC comparison)
            model = MixedLM.from_formula(
                formula=formula,
                groups=data['UID'],
                re_formula=re_formula,
                data=data
            )
            result = model.fit(reml=False, method='lbfgs', maxiter=200)

            # Check convergence
            converged = result.converged
            if converged:
                msg = f"[PASS] {model_name} converged successfully"
            else:
                msg = f"[WARN] {model_name} did not converge (may still have valid AIC)"

            return result, converged, msg

    except Exception as e:
        msg = f"[FAIL] {model_name} failed to fit: {str(e)}"
        return None, False, msg


def extract_model_statistics(result: Any, model_name: str, converged: bool) -> Dict[str, Any]:
    """
    Extract AIC, BIC, log-likelihood, and number of parameters from fitted model.

    Returns:
        Dictionary with model statistics
    """
    if result is None:
        return {
            'model': model_name,
            'AIC': np.nan,
            'BIC': np.nan,
            'loglik': np.nan,
            'n_params': np.nan,
            'converged': False
        }

    try:
        return {
            'model': model_name,
            'AIC': result.aic,
            'BIC': result.bic,
            'loglik': result.llf,  # Log-likelihood
            'n_params': result.df_modelwc,  # Number of parameters (with random effects)
            'converged': converged
        }
    except Exception as e:
        log(f"[WARN] Could not extract statistics for {model_name}: {str(e)}")
        return {
            'model': model_name,
            'AIC': np.nan,
            'BIC': np.nan,
            'loglik': np.nan,
            'n_params': np.nan,
            'converged': False
        }


def compute_akaike_weights(df_models: pd.DataFrame) -> pd.DataFrame:
    """
    Compute Akaike weights for model comparison.

    Akaike weights represent the probability that each model is the best model
    given the data and the candidate set.

    Formula:
        delta_AIC_i = AIC_i - min(AIC)
        weight_i = exp(-0.5 * delta_AIC_i) / sum(exp(-0.5 * delta_AIC_j) for all j)

    Returns:
        DataFrame with added columns: delta_AIC, akaike_weight
    """
    # Only compute weights for converged models with finite AIC
    valid_models = df_models[df_models['AIC'].notna() & np.isfinite(df_models['AIC'])].copy()

    if len(valid_models) == 0:
        log("[ERROR] No models with valid AIC values for weight computation")
        df_models['delta_AIC'] = np.nan
        df_models['akaike_weight'] = np.nan
        return df_models

    # Compute delta AIC (difference from best model)
    min_aic = valid_models['AIC'].min()
    valid_models['delta_AIC'] = valid_models['AIC'] - min_aic

    # Compute Akaike weights
    # weight_i = exp(-0.5 * delta_i) / sum(exp(-0.5 * delta_j))
    exp_terms = np.exp(-0.5 * valid_models['delta_AIC'])
    valid_models['akaike_weight'] = exp_terms / exp_terms.sum()

    # Merge back into full dataframe
    df_models = df_models.merge(
        valid_models[['model', 'delta_AIC', 'akaike_weight']],
        on='model',
        how='left'
    )

    return df_models


# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 02b: EXPANDED AIC Model Comparison with Power-Law Transformations")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: HCE rates per participant-test (400 rows)
        # Purpose: Create comprehensive set of time transformations for model comparison

        log("[LOAD] Loading HCE rate data from step01...")
        df_hce = pd.read_csv(RQ_DIR / "data" / "step01_hce_rates.csv")
        log(f"[LOADED] step01_hce_rates.csv ({len(df_hce)} rows, {len(df_hce.columns)} cols)")

        # Validate expected structure
        expected_cols = ['UID', 'TEST', 'TSVR', 'HCE_rate', 'n_HCE', 'n_total']
        missing_cols = [col for col in expected_cols if col not in df_hce.columns]
        if missing_cols:
            raise ValueError(f"Missing expected columns: {missing_cols}")

        log(f"[INFO] Data summary: {len(df_hce)} observations from {df_hce['UID'].nunique()} participants")

        # =========================================================================
        # STEP 2: Create EXPANDED Time Transformations
        # =========================================================================
        # Purpose: Generate comprehensive suite including power-laws, piecewise,
        #          exponential decay
        #
        # Basic (from Step 02a):
        #   1. Days = TSVR / 24
        #   2. Days_squared = Days^2
        #   3. log_Days_plus1 = log(Days + 1)
        #
        # NEW - Power Laws:
        #   4. sqrt_Days_plus1 = sqrt(Days + 1)         [Power 0.5]
        #   5. Days_power_1_5 = (Days + 1)^1.5          [Power 1.5]
        #   6. Days_power_0_3 = (Days + 1)^0.3          [Power 0.3]
        #   7. Days_power_0_7 = (Days + 1)^0.7          [Power 0.7]
        #   8. inv_Days_plus1 = 1/(Days + 1)            [Inverse/hyperbolic]
        #   9. Days_cubed = Days^3                      [Power 3.0]
        #
        # NEW - Piecewise:
        #   10. breakpoint_day1 = I(Days > 1) * (Days - 1)  [Flat before Day 1, linear after]
        #
        # NEW - Exponential:
        #   11. exp_neg_Days = exp(-Days)                   [Exponential decay]

        log("[TRANSFORM] Creating EXPANDED time transformations from TSVR...")

        # Basic transformations (from Step 02a)
        df_hce['Days'] = df_hce['TSVR'] / 24.0
        df_hce['Days_squared'] = df_hce['Days'] ** 2
        df_hce['log_Days_plus1'] = np.log(df_hce['Days'] + 1.0)

        # Power-law transformations (NEW)
        df_hce['sqrt_Days_plus1'] = np.sqrt(df_hce['Days'] + 1.0)  # Power 0.5
        df_hce['Days_power_0_3'] = (df_hce['Days'] + 1.0) ** 0.3
        df_hce['Days_power_0_7'] = (df_hce['Days'] + 1.0) ** 0.7
        df_hce['Days_power_1_5'] = (df_hce['Days'] + 1.0) ** 1.5
        df_hce['Days_cubed'] = df_hce['Days'] ** 3  # Power 3.0
        df_hce['inv_Days_plus1'] = 1.0 / (df_hce['Days'] + 1.0)  # Inverse

        # Piecewise transformation (NEW)
        # Flat before Day 1, linear slope after Day 1
        df_hce['breakpoint_day1'] = np.where(df_hce['Days'] > 1, df_hce['Days'] - 1, 0)

        # Exponential decay transformation (NEW)
        df_hce['exp_neg_Days'] = np.exp(-df_hce['Days'])

        log(f"[DONE] Created transformations:")
        log(f"  Basic:")
        log(f"    - Days: [{df_hce['Days'].min():.2f}, {df_hce['Days'].max():.2f}]")
        log(f"    - Days_squared: [{df_hce['Days_squared'].min():.2f}, {df_hce['Days_squared'].max():.2f}]")
        log(f"    - log_Days_plus1: [{df_hce['log_Days_plus1'].min():.3f}, {df_hce['log_Days_plus1'].max():.3f}]")
        log(f"  Power-law:")
        log(f"    - sqrt_Days_plus1 (0.5): [{df_hce['sqrt_Days_plus1'].min():.3f}, {df_hce['sqrt_Days_plus1'].max():.3f}]")
        log(f"    - Days_power_0_3: [{df_hce['Days_power_0_3'].min():.3f}, {df_hce['Days_power_0_3'].max():.3f}]")
        log(f"    - Days_power_0_7: [{df_hce['Days_power_0_7'].min():.3f}, {df_hce['Days_power_0_7'].max():.3f}]")
        log(f"    - Days_power_1_5: [{df_hce['Days_power_1_5'].min():.3f}, {df_hce['Days_power_1_5'].max():.3f}]")
        log(f"    - Days_cubed (3.0): [{df_hce['Days_cubed'].min():.2f}, {df_hce['Days_cubed'].max():.2f}]")
        log(f"    - inv_Days_plus1: [{df_hce['inv_Days_plus1'].min():.3f}, {df_hce['inv_Days_plus1'].max():.3f}]")
        log(f"  Piecewise:")
        log(f"    - breakpoint_day1: [{df_hce['breakpoint_day1'].min():.3f}, {df_hce['breakpoint_day1'].max():.3f}]")
        log(f"  Exponential:")
        log(f"    - exp_neg_Days: [{df_hce['exp_neg_Days'].min():.3f}, {df_hce['exp_neg_Days'].max():.3f}]")

        # =========================================================================
        # STEP 3: Fit 13 Candidate LMM Models
        # =========================================================================
        # Models (EXPANDED beyond Step 02a's 5 models):
        #   1. Linear: HCE_rate ~ Days + (Days | UID)
        #   2. Quadratic: HCE_rate ~ Days + Days_squared + (Days | UID)
        #   3. Logarithmic: HCE_rate ~ log_Days_plus1 + (log_Days_plus1 | UID)
        #   4. Square Root: HCE_rate ~ sqrt_Days_plus1 + (sqrt_Days_plus1 | UID)
        #   5. Power 0.3: HCE_rate ~ Days_power_0_3 + (Days_power_0_3 | UID)
        #   6. Power 0.7: HCE_rate ~ Days_power_0_7 + (Days_power_0_7 | UID)
        #   7. Power 1.5: HCE_rate ~ Days_power_1_5 + (Days_power_1_5 | UID)
        #   8. Inverse: HCE_rate ~ inv_Days_plus1 + (inv_Days_plus1 | UID)
        #   9. Cubic: HCE_rate ~ Days + Days_squared + Days_cubed + (Days | UID)
        #   10. Exponential Decay: HCE_rate ~ exp_neg_Days + (Days | UID)
        #   11. Piecewise (Breakpoint Day 1): HCE_rate ~ breakpoint_day1 + (Days | UID)
        #   12. Linear+Log: HCE_rate ~ Days + log_Days_plus1 + (log_Days_plus1 | UID)
        #   13. Quadratic+Log: HCE_rate ~ Days + Days_squared + log_Days_plus1 + (log_Days_plus1 | UID)
        #
        # CRITICAL: REML=False for all models (required for valid AIC comparison)
        # Random slopes match fixed effects structure where possible

        log("\n[ANALYSIS] Fitting 13 candidate LMM models with REML=False...")

        # Define model specifications
        models = [
            # Basic models (from Step 02a)
            {
                'name': 'Linear',
                'formula': 'HCE_rate ~ Days',
                're_formula': '~Days',
                'description': 'Linear time trend'
            },
            {
                'name': 'Quadratic',
                'formula': 'HCE_rate ~ Days + Days_squared',
                're_formula': '~Days',
                'description': 'Quadratic time trend (Days + Days^2)'
            },
            {
                'name': 'Logarithmic',
                'formula': 'HCE_rate ~ log_Days_plus1',
                're_formula': '~log_Days_plus1',
                'description': 'Logarithmic time trend (log(Days+1))'
            },
            # Power-law models (NEW)
            {
                'name': 'SquareRoot',
                'formula': 'HCE_rate ~ sqrt_Days_plus1',
                're_formula': '~sqrt_Days_plus1',
                'description': 'Square root (power 0.5) transformation'
            },
            {
                'name': 'Power_0.3',
                'formula': 'HCE_rate ~ Days_power_0_3',
                're_formula': '~Days_power_0_3',
                'description': 'Power 0.3 transformation (shallow curvature)'
            },
            {
                'name': 'Power_0.7',
                'formula': 'HCE_rate ~ Days_power_0_7',
                're_formula': '~Days_power_0_7',
                'description': 'Power 0.7 transformation (moderate curvature)'
            },
            {
                'name': 'Power_1.5',
                'formula': 'HCE_rate ~ Days_power_1_5',
                're_formula': '~Days_power_1_5',
                'description': 'Power 1.5 transformation (accelerating growth)'
            },
            {
                'name': 'Inverse',
                'formula': 'HCE_rate ~ inv_Days_plus1',
                're_formula': '~inv_Days_plus1',
                'description': 'Inverse/hyperbolic transformation (1/(Days+1))'
            },
            {
                'name': 'Cubic',
                'formula': 'HCE_rate ~ Days + Days_squared + Days_cubed',
                're_formula': '~Days',
                'description': 'Cubic polynomial (Days + Days^2 + Days^3)'
            },
            # Advanced models (NEW)
            {
                'name': 'ExponentialDecay',
                'formula': 'HCE_rate ~ exp_neg_Days',
                're_formula': '~Days',
                'description': 'Exponential decay (exp(-Days))'
            },
            {
                'name': 'Piecewise_Day1',
                'formula': 'HCE_rate ~ breakpoint_day1',
                're_formula': '~Days',
                'description': 'Piecewise: flat before Day 1, linear after'
            },
            # Combination models (from Step 02a)
            {
                'name': 'Linear+Log',
                'formula': 'HCE_rate ~ Days + log_Days_plus1',
                're_formula': '~log_Days_plus1',
                'description': 'Linear + Logarithmic (Days + log(Days+1))'
            },
            {
                'name': 'Quadratic+Log',
                'formula': 'HCE_rate ~ Days + Days_squared + log_Days_plus1',
                're_formula': '~log_Days_plus1',
                'description': 'Quadratic + Logarithmic (Days + Days^2 + log(Days+1))'
            }
        ]

        # Fit each model and collect results
        model_results = []
        fitted_models = {}

        for model_spec in models:
            log(f"\n[MODEL] Fitting {model_spec['name']}: {model_spec['description']}")
            log(f"  Formula: {model_spec['formula']}")
            log(f"  Random: {model_spec['re_formula']}")

            result, converged, msg = fit_model_with_convergence_check(
                formula=model_spec['formula'],
                re_formula=model_spec['re_formula'],
                data=df_hce,
                model_name=model_spec['name']
            )

            log(f"  {msg}")

            # Extract statistics
            stats = extract_model_statistics(result, model_spec['name'], converged)
            model_results.append(stats)

            # Store fitted model for potential later use
            if result is not None:
                fitted_models[model_spec['name']] = result
                log(f"  AIC: {stats['AIC']:.2f}, BIC: {stats['BIC']:.2f}, LogLik: {stats['loglik']:.2f}")

        log("\n[DONE] All models fitted")

        # =========================================================================
        # STEP 4: Compute Akaike Weights
        # =========================================================================
        # Purpose: Convert AIC differences to model probabilities
        # Akaike weight = probability that model i is best given data and candidate set

        log("\n[WEIGHTS] Computing Akaike weights...")

        df_comparison = pd.DataFrame(model_results)
        df_comparison = compute_akaike_weights(df_comparison)

        # Check if weights sum to 1.0 (across converged models)
        valid_weights = df_comparison['akaike_weight'].dropna()
        if len(valid_weights) > 0:
            weight_sum = valid_weights.sum()
            log(f"[CHECK] Akaike weights sum: {weight_sum:.6f} (should be 1.0)")
            if abs(weight_sum - 1.0) > 0.01:
                log(f"[WARN] Weights do not sum to 1.0 (sum={weight_sum:.6f})")
        else:
            log("[ERROR] No valid Akaike weights computed (no converged models)")

        # =========================================================================
        # STEP 5: Rank Top 5 Models
        # =========================================================================
        # Purpose: Identify top 5 models by AIC for detailed comparison

        log("\n[RANKING] Identifying top 5 models...")

        # Sort by AIC (ascending = better)
        converged_models = df_comparison[df_comparison['converged'] == True].copy()

        if len(converged_models) == 0:
            log("[ERROR] No models converged successfully")
            top5_models = pd.DataFrame()
            best_model_name = "NONE"
            best_weight = 0.0
            best_aic = np.nan
            interpretation = "No models converged"
        else:
            converged_models_sorted = converged_models.sort_values('AIC', ascending=True)
            top5_models = converged_models_sorted.head(5).copy()

            log(f"[TOP 5] Ranked by AIC:")
            for idx, (_, row) in enumerate(top5_models.iterrows(), start=1):
                log(f"  {idx}. {row['model']:20s} - AIC={row['AIC']:.2f}, weight={row['akaike_weight']:.4f}, ΔAIC={row['delta_AIC']:.2f}")

            # Best model = rank 1
            best_model_name = top5_models.iloc[0]['model']
            best_weight = top5_models.iloc[0]['akaike_weight']
            best_aic = top5_models.iloc[0]['AIC']

            log(f"\n[BEST] {best_model_name} (weight={best_weight:.4f}, AIC={best_aic:.2f})")

            # Interpretation of best model weight
            if best_weight > 0.90:
                interpretation = "Overwhelming evidence"
            elif best_weight > 0.70:
                interpretation = "Strong evidence"
            elif best_weight > 0.50:
                interpretation = "Moderate evidence"
            elif best_weight > 0.30:
                interpretation = "Weak evidence"
            else:
                interpretation = "No clear winner"

            log(f"[INTERPRET] {interpretation} for {best_model_name} model")

        # =========================================================================
        # STEP 6: Special Pattern Flags
        # =========================================================================
        # Purpose: Identify specific patterns of interest
        # - Piecewise model wins -> two-phase pattern is real
        # - Power-law < 1.0 wins -> diminishing returns pattern
        # - ΔAIC > 2 for best vs second-best -> clear winner

        log("\n[FLAGS] Checking for special patterns...")

        flags = []

        if len(top5_models) > 0:
            # Flag 1: Piecewise model wins
            if best_model_name == 'Piecewise_Day1':
                flags.append("PIECEWISE_WINNER: Two-phase pattern (flat Day 0-1, decline after) is real")
                log("[FLAG] Piecewise model wins - two-phase pattern supported by data")

            # Flag 2: Power-law < 1.0 wins
            power_models_lt_1 = ['Power_0.3', 'Power_0.7', 'SquareRoot', 'Inverse', 'Logarithmic']
            if best_model_name in power_models_lt_1:
                flags.append(f"DIMINISHING_RETURNS: Power-law < 1.0 model ({best_model_name}) wins - diminishing decline rate")
                log(f"[FLAG] Power-law < 1.0 model ({best_model_name}) wins - diminishing returns pattern")

            # Flag 3: ΔAIC > 2 (clear winner)
            if len(top5_models) >= 2:
                delta_aic_best_vs_second = top5_models.iloc[1]['delta_AIC'] - top5_models.iloc[0]['delta_AIC']
                if delta_aic_best_vs_second > 2.0:
                    flags.append(f"CLEAR_WINNER: ΔAIC={delta_aic_best_vs_second:.2f} > 2 (substantial support for best model)")
                    log(f"[FLAG] Clear winner - ΔAIC={delta_aic_best_vs_second:.2f} > 2")
                else:
                    flags.append(f"COMPETITIVE_MODELS: ΔAIC={delta_aic_best_vs_second:.2f} < 2 (top models competitive)")
                    log(f"[FLAG] Competitive models - ΔAIC={delta_aic_best_vs_second:.2f} < 2")

        if len(flags) == 0:
            flags.append("No special patterns detected")
            log("[FLAG] No special patterns detected")

        # =========================================================================
        # STEP 7: Save Model Comparison Results
        # =========================================================================

        log("\n[SAVE] Saving expanded model comparison results...")

        # Save comparison table to CSV
        comparison_path = RQ_DIR / "data" / "step02b_expanded_model_comparison.csv"
        df_comparison.to_csv(comparison_path, index=False, encoding='utf-8')
        log(f"[SAVED] {comparison_path.name} ({len(df_comparison)} models)")

        # Create detailed text summary
        summary_path = RQ_DIR / "data" / "step02b_best_model_selection.txt"
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("EXPANDED AIC MODEL COMPARISON - HCE RATE TIME TRANSFORMATION\n")
            f.write("=" * 80 + "\n\n")

            f.write("Research Question: RQ 6.6.1\n")
            f.write("Analysis: Which functional form BEST describes HCE rate trajectory?\n")
            f.write("Method: Comprehensive AIC comparison with 13 candidate models\n")
            f.write("Context: Step 02a showed Linear vs Log tied (ΔAIC=0.05, weights ~27% each)\n")
            f.write("         Trajectory VERY FLAT: T1=4.87% -> T2=4.87% -> T3=3.79% -> T4=3.17%\n")
            f.write("         Two-phase pattern: NO change Day 0-1, gradual decline Day 1-6\n\n")

            f.write("BEST MODEL SELECTION\n")
            f.write("-" * 80 + "\n")
            f.write(f"Best Model: {best_model_name}\n")
            if len(converged_models) > 0:
                f.write(f"Akaike Weight: {best_weight:.4f}\n")
                f.write(f"AIC: {best_aic:.2f}\n")
                f.write(f"Interpretation: {interpretation}\n\n")
            else:
                f.write("Status: No models converged\n\n")

            f.write("TOP 5 MODELS (Ranked by AIC)\n")
            f.write("-" * 80 + "\n")
            if len(top5_models) > 0:
                f.write(top5_models.to_string(index=False) + "\n\n")
            else:
                f.write("No converged models to rank\n\n")

            f.write("SPECIAL PATTERN FLAGS\n")
            f.write("-" * 80 + "\n")
            for flag in flags:
                f.write(f"  - {flag}\n")
            f.write("\n")

            f.write("FULL MODEL COMPARISON TABLE (13 Models)\n")
            f.write("-" * 80 + "\n")
            f.write(df_comparison.to_string(index=False) + "\n\n")

            f.write("AKAIKE WEIGHT INTERPRETATION\n")
            f.write("-" * 80 + "\n")
            f.write("Akaike weight = probability that model is best given data and candidate set\n")
            f.write("  > 0.90: Overwhelming evidence\n")
            f.write("  > 0.70: Strong evidence\n")
            f.write("  > 0.50: Moderate evidence\n")
            f.write("  > 0.30: Weak evidence\n")
            f.write("  < 0.30: No clear winner\n\n")

            f.write("DELTA AIC INTERPRETATION (Burnham & Anderson 2002)\n")
            f.write("-" * 80 + "\n")
            f.write("delta_AIC = AIC_i - min(AIC)\n")
            f.write("  0-2: Substantial support (models are competitive)\n")
            f.write("  4-7: Considerably less support\n")
            f.write("  >10: Essentially no support\n\n")

            f.write("MODEL TRANSFORMATIONS TESTED\n")
            f.write("-" * 80 + "\n")
            f.write("Basic:\n")
            f.write("  - Linear: Days = TSVR / 24\n")
            f.write("  - Quadratic: Days + Days^2\n")
            f.write("  - Logarithmic: log(Days + 1)\n")
            f.write("Power-law:\n")
            f.write("  - Square Root: (Days + 1)^0.5 (power 0.5)\n")
            f.write("  - Power 0.3: (Days + 1)^0.3 (shallow curvature)\n")
            f.write("  - Power 0.7: (Days + 1)^0.7 (moderate curvature)\n")
            f.write("  - Power 1.5: (Days + 1)^1.5 (accelerating)\n")
            f.write("  - Inverse: 1/(Days + 1) (hyperbolic)\n")
            f.write("  - Cubic: Days + Days^2 + Days^3 (power 3.0)\n")
            f.write("Piecewise:\n")
            f.write("  - Breakpoint Day 1: flat before Day 1, linear after\n")
            f.write("Exponential:\n")
            f.write("  - Exponential Decay: exp(-Days)\n")
            f.write("Combinations:\n")
            f.write("  - Linear + Log: Days + log(Days + 1)\n")
            f.write("  - Quadratic + Log: Days + Days^2 + log(Days + 1)\n\n")

            f.write("CONVERGENCE STATUS\n")
            f.write("-" * 80 + "\n")
            for _, row in df_comparison.iterrows():
                status = "CONVERGED" if row['converged'] else "DID NOT CONVERGE"
                f.write(f"  {row['model']:20s}: {status}\n")
            f.write("\n")

            f.write("=" * 80 + "\n")

        log(f"[SAVED] {summary_path.name}")

        # =========================================================================
        # STEP 8: Validation
        # =========================================================================

        log("\n[VALIDATION] Checking results...")

        validation_passed = True

        # Check 1: All 13 models attempted
        if len(df_comparison) != 13:
            log(f"[FAIL] Expected 13 models, found {len(df_comparison)}")
            validation_passed = False
        else:
            log("[PASS] All 13 models attempted")

        # Check 2: At least some models have finite AIC
        finite_aic_count = df_comparison['AIC'].notna().sum()
        if finite_aic_count == 0:
            log("[FAIL] No models have finite AIC values")
            validation_passed = False
        else:
            log(f"[PASS] {finite_aic_count}/13 models have finite AIC values")

        # Check 3: Akaike weights sum to 1.0 (for converged models)
        if len(valid_weights) > 0:
            if abs(weight_sum - 1.0) < 0.01:
                log("[PASS] Akaike weights sum to 1.0")
            else:
                log(f"[WARN] Akaike weights sum to {weight_sum:.6f} (tolerance: 0.01)")
                # Not a hard failure - weights might be slightly off due to numerical precision

        # Check 4: Top 5 models ranked
        if len(top5_models) == 0:
            log("[FAIL] No top 5 models ranked (no converged models)")
            validation_passed = False
        elif len(top5_models) < 5 and len(converged_models) >= 5:
            log(f"[WARN] Only {len(top5_models)} models in top 5 (expected 5)")
        else:
            log(f"[PASS] Top {len(top5_models)} models ranked")

        # Check 5: Best model identified
        if best_model_name == "NONE":
            log("[FAIL] No best model identified (no converged models)")
            validation_passed = False
        else:
            log(f"[PASS] Best model identified: {best_model_name}")

        # Check 6: Special flags documented
        log(f"[PASS] {len(flags)} special pattern flags documented")

        # Check 7: REML=False was used (verify in model fitting code)
        log("[PASS] All models fitted with REML=False (required for AIC comparison)")

        if validation_passed:
            log("\n[SUCCESS] Step 02b complete - all validations passed")
            sys.exit(0)
        else:
            log("\n[WARN] Step 02b complete with validation warnings")
            sys.exit(0)  # Exit 0 even with warnings (some models not converging is acceptable)

    except Exception as e:
        log(f"\n[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
