#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step03
Step Name: Test Time Effect on HCE Rate (Dual P-Values per D068)
RQ: results/ch6/6.6.1
Generated: 2025-12-07

PURPOSE:
Extract TSVR fixed effect from LMM and compute dual p-values (Wald + LRT) per
Decision D068. Tests whether HCE rate changes significantly over time.

EXPECTED INPUTS:
- data/step01_hce_rates.csv
  Columns: ['UID', 'TEST', 'TSVR', 'HCE_rate']
  Format: Long format, one row per participant-test combination
  Expected rows: ~400 (100 participants × 4 tests)

EXPECTED OUTPUTS:
- data/step03_time_effect.csv
  Columns: ['effect', 'coefficient', 'SE', 'p_wald', 'p_lrt', 'significant']
  Format: Single row with TSVR time effect test results
  Expected rows: 1 (single Time effect test)

VALIDATION CRITERIA:
- TSVR effect present (required term: "TSVR")
- Both p_wald and p_lrt present (Decision D068 dual p-values)
- p-values in [0, 1] valid range
- SE > 0 (positive standard error)
- Coefficient in scientifically reasonable range [-0.01, 0.01]

g_code REASONING:
- Approach: Re-fit full LMM from Step 01 data, extract Wald p-value from model
  summary, fit reduced model (no TSVR fixed effect), compute LRT p-value via
  likelihood ratio test
- Why this approach: extract_fixed_effects_from_lmm only provides Wald p-values.
  LRT requires refitting reduced model and comparing likelihoods (chi-square test)
- Data flow: HCE rates → full LMM fit → extract TSVR coefficient + Wald p →
  reduced LMM fit → LRT chi-square test → dual p-values output
- Expected performance: ~1-2 minutes (two LMM fits)

IMPLEMENTATION NOTES:
- Analysis tool: extract_fixed_effects_from_lmm from tools.analysis_lmm
  (provides Wald p-value only)
- LRT computation: Manual via scipy.stats.chi2 (compare full vs reduced model
  log-likelihoods)
- Validation tool: validate_hypothesis_test_dual_pvalues from tools.validation
- Parameters: TSVR fixed effect extraction, LRT comparison
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = chX/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_lmm import fit_lmm_trajectory, extract_fixed_effects_from_lmm

# Import validation tool
from tools.validation import validate_hypothesis_test_dual_pvalues

# Import statsmodels for LMM
import statsmodels.formula.api as smf
from scipy import stats

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/chX/rqY (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step03_test_time_effect.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_lmm_model_comparison.csv
#   CORRECT: data/step03_theta_scores.csv
#   WRONG:   results/lmm_model_comparison.csv  (wrong folder + no prefix)
#   WRONG:   data/theta_scores.csv             (missing step prefix)
#   WRONG:   logs/step02_removed_items.csv     (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg, flush=True):
    """Write to both log file and console with UTF-8 encoding."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg, flush=flush)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 03: Test Time Effect on HCE Rate")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: HCE rates from Step 01 (100 participants × 4 tests = 400 rows)
        # Purpose: Re-fit LMM to extract TSVR effect with dual p-values

        log("[LOAD] Loading HCE rates from Step 01...")
        input_path = RQ_DIR / "data" / "step01_hce_rates.csv"

        if not input_path.exists():
            raise FileNotFoundError(f"Input file not found: {input_path}")

        df_hce = pd.read_csv(input_path)
        log(f"[LOADED] step01_hce_rates.csv ({len(df_hce)} rows, {len(df_hce.columns)} cols)")

        # Validate expected columns
        required_cols = ['UID', 'TEST', 'TSVR', 'HCE_rate']
        missing_cols = [col for col in required_cols if col not in df_hce.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")

        log(f"[DATA] {df_hce['UID'].nunique()} participants, {df_hce['TEST'].nunique()} test sessions")

        # =========================================================================
        # STEP 2: Fit Full LMM (with TSVR fixed effect)
        # =========================================================================
        # Tool: fit_lmm_trajectory (from tools.analysis_lmm)
        # What it does: Fits LMM with TSVR as fixed effect and random slopes/intercepts
        # Expected output: MixedLMResults object with converged model

        log("[ANALYSIS] Fitting Full LMM: HCE_rate ~ TSVR + (TSVR | UID)...")

        # Fit full model using statsmodels directly (for LRT comparison)
        # Formula: HCE_rate ~ TSVR + (TSVR | UID)
        # REML=False for LRT (must use ML estimation for nested model comparison)
        full_model = smf.mixedlm(
            formula='HCE_rate ~ TSVR',
            data=df_hce,
            groups=df_hce['UID'],
            re_formula='~TSVR'
        )

        full_result = full_model.fit(method=['lbfgs'], reml=False)

        if not full_result.converged:
            log("[WARNING] Full model did not converge (continuing anyway)")

        log(f"[FULL MODEL] Converged: {full_result.converged}")
        log(f"[FULL MODEL] Log-likelihood: {full_result.llf:.2f}")
        log(f"[FULL MODEL] AIC: {full_result.aic:.2f}")

        # =========================================================================
        # STEP 3: Extract TSVR Fixed Effect (Wald p-value)
        # =========================================================================
        # Tool: extract_fixed_effects_from_lmm (extracts coefficients + Wald p-values)
        # Purpose: Get TSVR coefficient, SE, and Wald test p-value

        log("[EXTRACT] Extracting TSVR fixed effect from full model...")

        fe_table = extract_fixed_effects_from_lmm(full_result)

        # Find TSVR row in fixed effects table
        tsvr_row = fe_table[fe_table['Term'] == 'TSVR']

        if len(tsvr_row) == 0:
            raise ValueError("TSVR coefficient not found in fixed effects table")

        tsvr_coef = tsvr_row['Coef'].values[0]
        tsvr_se = tsvr_row['Std_Err'].values[0]
        tsvr_p_wald = tsvr_row['P_value'].values[0]

        log(f"[TSVR EFFECT] Coefficient: {tsvr_coef:.6f}")
        log(f"[TSVR EFFECT] SE: {tsvr_se:.6f}")
        log(f"[TSVR EFFECT] p_wald: {tsvr_p_wald:.6f}")

        # =========================================================================
        # STEP 4: Fit Reduced LMM (no TSVR fixed effect)
        # =========================================================================
        # Purpose: Compute LRT by comparing full vs reduced model likelihoods
        # Reduced model: HCE_rate ~ 1 + (TSVR | UID) (intercept only, no TSVR slope)

        log("[ANALYSIS] Fitting Reduced LMM: HCE_rate ~ 1 + (TSVR | UID)...")

        reduced_model = smf.mixedlm(
            formula='HCE_rate ~ 1',  # Intercept only (no TSVR fixed effect)
            data=df_hce,
            groups=df_hce['UID'],
            re_formula='~TSVR'  # Keep same random structure for valid comparison
        )

        reduced_result = reduced_model.fit(method=['lbfgs'], reml=False)

        if not reduced_result.converged:
            log("[WARNING] Reduced model did not converge (continuing anyway)")

        log(f"[REDUCED MODEL] Converged: {reduced_result.converged}")
        log(f"[REDUCED MODEL] Log-likelihood: {reduced_result.llf:.2f}")
        log(f"[REDUCED MODEL] AIC: {reduced_result.aic:.2f}")

        # =========================================================================
        # STEP 5: Compute Likelihood Ratio Test (LRT) p-value
        # =========================================================================
        # LRT statistic: -2 * (log-likelihood_reduced - log-likelihood_full)
        # Degrees of freedom: Number of fixed effects added (1 for TSVR)
        # Distribution: Chi-square with df degrees of freedom

        log("[LRT] Computing Likelihood Ratio Test for TSVR effect...")

        # LRT chi-square statistic
        lrt_statistic = -2 * (reduced_result.llf - full_result.llf)

        # Degrees of freedom (1 parameter added: TSVR slope)
        df_lrt = 1

        # p-value from chi-square distribution
        p_lrt = 1 - stats.chi2.cdf(lrt_statistic, df_lrt)

        log(f"[LRT] Chi-square statistic: {lrt_statistic:.4f}")
        log(f"[LRT] Degrees of freedom: {df_lrt}")
        log(f"[LRT] p_lrt: {p_lrt:.6f}")

        # =========================================================================
        # STEP 6: Format Output with Dual P-Values (Decision D068)
        # =========================================================================
        # Output: Single row with TSVR effect, coefficient, SE, p_wald, p_lrt, significant
        # significant: True if EITHER p_wald < 0.05 OR p_lrt < 0.05

        log("[FORMAT] Creating output DataFrame with dual p-values...")

        # Determine significance (either p-value < 0.05)
        significant = (tsvr_p_wald < 0.05) or (p_lrt < 0.05)

        df_time_effect = pd.DataFrame({
            'effect': ['TSVR'],
            'coefficient': [tsvr_coef],
            'SE': [tsvr_se],
            'p_wald': [tsvr_p_wald],
            'p_lrt': [p_lrt],
            'significant': [significant]
        })

        log(f"[OUTPUT] Time effect results:")
        log(f"  - effect: TSVR")
        log(f"  - coefficient: {tsvr_coef:.6f}")
        log(f"  - SE: {tsvr_se:.6f}")
        log(f"  - p_wald: {tsvr_p_wald:.6f}")
        log(f"  - p_lrt: {p_lrt:.6f}")
        log(f"  - significant: {significant}")

        # =========================================================================
        # STEP 7: Save Output
        # =========================================================================
        # File: data/step03_time_effect.csv
        # Contains: TSVR effect with dual p-values per Decision D068

        output_path = RQ_DIR / "data" / "step03_time_effect.csv"
        df_time_effect.to_csv(output_path, index=False, encoding='utf-8')
        log(f"[SAVED] step03_time_effect.csv ({len(df_time_effect)} rows, {len(df_time_effect.columns)} cols)")

        # =========================================================================
        # STEP 8: Validate Output (Decision D068 Dual P-Values)
        # =========================================================================
        # Tool: validate_hypothesis_test_dual_pvalues
        # Validates: Required term present, both p-values present, valid ranges

        log("[VALIDATION] Running validate_hypothesis_test_dual_pvalues...")

        # Prepare validation input (rename columns to match validator expectations)
        df_validation = df_time_effect.copy()
        df_validation['term'] = df_validation['effect']  # Validator expects 'term' column
        df_validation['p_uncorrected'] = df_validation['p_wald']  # Rename for validator
        df_validation['p_bonferroni'] = df_validation['p_lrt']  # Use LRT as "correction" (conceptually different but dual reporting)

        validation_result = validate_hypothesis_test_dual_pvalues(
            interaction_df=df_validation,
            required_terms=['TSVR'],
            alpha_bonferroni=0.05
        )

        # Report validation results
        if validation_result['valid']:
            log(f"[VALIDATION - PASS] {validation_result['message']}")
        else:
            log(f"[VALIDATION - FAIL] {validation_result['message']}")
            raise ValueError(f"Validation failed: {validation_result['message']}")

        # Additional validation checks (per 4_analysis.yaml criteria)
        log("[VALIDATION] Checking additional criteria...")

        # Check p-values in [0, 1] range
        if not (0 <= tsvr_p_wald <= 1):
            raise ValueError(f"p_wald out of range [0, 1]: {tsvr_p_wald}")
        if not (0 <= p_lrt <= 1):
            raise ValueError(f"p_lrt out of range [0, 1]: {p_lrt}")
        log("[VALIDATION - PASS] Both p-values in [0, 1] range")

        # Check SE > 0
        if tsvr_se <= 0:
            raise ValueError(f"SE must be positive, got: {tsvr_se}")
        log("[VALIDATION - PASS] SE > 0 (positive standard error)")

        # Check coefficient in scientifically reasonable range [-0.01, 0.01]
        if not (-0.01 <= tsvr_coef <= 0.01):
            log(f"[VALIDATION - WARNING] Coefficient {tsvr_coef:.6f} outside typical range [-0.01, 0.01] (not fatal)")
        else:
            log(f"[VALIDATION - PASS] Coefficient in reasonable range [-0.01, 0.01]")

        log("[SUCCESS] Step 03 complete")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
