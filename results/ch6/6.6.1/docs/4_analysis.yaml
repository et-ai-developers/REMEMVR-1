# ============================================================================
# ANALYSIS RECIPE - COMPLETE SPECIFICATION
# ============================================================================
# Generated: 2025-12-06T16:50:00Z
# RQ: 6.6.1
# Agent: rq_analysis v4.1.0
# Purpose: Self-contained recipe for g_code agent (reads ONLY this file)
# ============================================================================

metadata:
  rq_id: "6.6.1"
  total_steps: 4
  analysis_type: "LMM trajectory analysis (high-confidence errors over time)"
  generated_by: "rq_analysis v4.1.0"
  timestamp: "2025-12-06T16:50:00Z"

# ============================================================================
# ANALYSIS STEPS - COMPLETE SPECIFICATIONS
# ============================================================================

steps:
  # --------------------------------------------------------------------------
  # STEP 0: Extract Item-Level Confidence-Accuracy Data
  # --------------------------------------------------------------------------
  - name: "step00_extract_item_level"
    step_number: "00"
    description: "Extract item-level confidence-accuracy pairs from dfData.csv (interactive paradigms only: IFR, ICR, IRE)"

    analysis_call:
      type: "catalogued"
      module: "tools.data_extraction"
      function: "extract_confidence_accuracy_data"
      signature: "extract_confidence_accuracy_data(df: pd.DataFrame, paradigms: List[str], output_path: Path) -> pd.DataFrame"

      input_files:
        - path: "data/cache/dfData.csv"
          required_columns: ["UID", "TEST", "TSVR", "TC_*", "TQ_*"]
          variable_name: "df_data"
          description: "Project-level data cache with confidence and accuracy items"

      output_files:
        - path: "data/step00_item_level.csv"
          variable_name: "df_item_level"
          columns: ["UID", "TEST", "TSVR", "item_code", "confidence", "accuracy"]
          description: "Item-level confidence-accuracy pairs (~27,200 rows)"

      parameters:
        df: "df_data"
        paradigms: ["IFR", "ICR", "IRE"]
        output_path: "data/step00_item_level.csv"

      returns:
        type: "pd.DataFrame"
        variable_name: "df_item_level"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_data_format"
      signature: "validate_data_format(df: pd.DataFrame, required_cols: List[str]) -> Dict[str, Any]"

      input_files:
        - path: "data/step00_item_level.csv"
          variable_name: "df_item_level"
          source: "analysis call output (extract_confidence_accuracy_data)"

      parameters:
        df: "df_item_level"
        required_cols: ["UID", "TEST", "TSVR", "item_code", "confidence", "accuracy"]

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "All required columns present: UID, TEST, TSVR, item_code, confidence, accuracy"
        - "confidence values in {0, 0.25, 0.5, 0.75, 1.0} (5-level Likert)"
        - "accuracy values in {0, 1} (dichotomous)"
        - "TSVR in [0, 200] hours range"
        - "Expected rows: 26,000-28,000 (item-level data)"
        - "<5% NaN in confidence/accuracy columns"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step00_extract_item_level.log"

    log_file: "logs/step00_extract_item_level.log"

  # --------------------------------------------------------------------------
  # STEP 1: Compute HCE Rate Per Participant Per Timepoint
  # --------------------------------------------------------------------------
  - name: "step01_compute_hce_rates"
    step_number: "01"
    description: "Aggregate item-level data to compute HCE rate (confidence >= 0.75 AND accuracy = 0) per participant-test"

    analysis_call:
      type: "stdlib"
      operations:
        - "pd.read_csv('data/step00_item_level.csv')"
        - "Define HCE: (confidence >= 0.75) & (accuracy == 0)"
        - "Group by UID, TEST"
        - "Count n_HCE = sum(HCE condition)"
        - "Count n_total = count(non-NaN confidence AND accuracy)"
        - "Compute HCE_rate = n_HCE / n_total"
        - "Merge TSVR time variable"
        - "Save to data/step01_hce_rates.csv"

      input_files:
        - path: "data/step00_item_level.csv"
          required_columns: ["UID", "TEST", "TSVR", "item_code", "confidence", "accuracy"]
          variable_name: "df_item_level"
          source: "Step 0 output"

      output_files:
        - path: "data/step01_hce_rates.csv"
          variable_name: "df_hce_rates"
          columns: ["UID", "TEST", "TSVR", "HCE_rate", "n_HCE", "n_total"]
          description: "HCE rates per participant-test (400 rows: 100 participants x 4 tests)"

      parameters:
        hce_threshold_confidence: 0.75
        hce_condition_accuracy: 0
        group_by: ["UID", "TEST"]

      returns:
        type: "pd.DataFrame"
        variable_name: "df_hce_rates"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_probability_range"
      signature: "validate_probability_range(probability_df: pd.DataFrame, prob_columns: List[str]) -> Dict[str, Any]"

      input_files:
        - path: "data/step01_hce_rates.csv"
          variable_name: "df_hce_rates"
          source: "analysis call output (stdlib aggregation)"

      parameters:
        probability_df: "df_hce_rates"
        prob_columns: ["HCE_rate"]

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "HCE_rate in [0, 1] range (proportion validation)"
        - "No NaN values in HCE_rate column"
        - "n_HCE <= n_total (logical constraint)"
        - "Expected rows: 400 (100 participants x 4 tests)"
        - "All 100 participants present"
        - "All 4 tests present per participant"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step01_compute_hce_rates.log"

    log_file: "logs/step01_compute_hce_rates.log"

  # --------------------------------------------------------------------------
  # STEP 2: Fit LMM for HCE Trajectory
  # --------------------------------------------------------------------------
  - name: "step02_fit_lmm_trajectory"
    step_number: "02"
    description: "Fit Linear Mixed Model with TSVR as time variable per Decision D070 (HCE_rate ~ TSVR + (TSVR | UID))"

    analysis_call:
      type: "catalogued"
      module: "tools.analysis_lmm"
      function: "fit_lmm_trajectory_tsvr"
      signature: "fit_lmm_trajectory_tsvr(theta_scores: pd.DataFrame, tsvr_data: pd.DataFrame, formula: str, groups: str = 'UID', re_formula: str = '~TSVR_hours', reml: bool = True) -> MixedLMResults"

      input_files:
        - path: "data/step01_hce_rates.csv"
          required_columns: ["UID", "TEST", "TSVR", "HCE_rate"]
          variable_name: "df_hce_rates"
          source: "Step 1 output"

      output_files:
        - path: "data/step02_hce_lmm.txt"
          variable_name: "lmm_model"
          description: "LMM model summary (fixed effects, random effects, fit statistics)"

      parameters:
        theta_scores: "df_hce_rates"
        tsvr_data: "df_hce_rates"
        formula: "HCE_rate ~ TSVR + (TSVR | UID)"
        groups: "UID"
        re_formula: "~TSVR"
        reml: true

      returns:
        type: "MixedLMResults"
        variable_name: "lmm_model"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_lmm_convergence"
      signature: "validate_lmm_convergence(lmm_result: MixedLMResults) -> Dict[str, Any]"

      input_files:
        - path: "data/step02_hce_lmm.txt"
          variable_name: "lmm_model"
          source: "analysis call output (fit_lmm_trajectory_tsvr)"

      parameters:
        lmm_result: "lmm_model"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "Model converged successfully (lmm_result.converged = True)"
        - "No singular fit (random effects variance > 0)"
        - "Minimum 100 observations used"
        - "All fixed effects have finite estimates (no NaN/Inf)"
        - "Residuals approximately normal (KS test p > 0.05)"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step02_fit_lmm_trajectory.log"

    log_file: "logs/step02_fit_lmm_trajectory.log"

  # --------------------------------------------------------------------------
  # STEP 3: Test Time Effect on HCE Rate (Dual P-Values per D068)
  # --------------------------------------------------------------------------
  - name: "step03_test_time_effect"
    step_number: "03"
    description: "Extract TSVR fixed effect and compute dual p-values (Wald + LRT) per Decision D068"

    analysis_call:
      type: "catalogued"
      module: "tools.analysis_lmm"
      function: "extract_fixed_effects_from_lmm"
      signature: "extract_fixed_effects_from_lmm(result: MixedLMResults) -> pd.DataFrame"

      input_files:
        - path: "data/step02_hce_lmm.txt"
          variable_name: "lmm_model"
          source: "Step 2 fitted model"

      output_files:
        - path: "data/step03_time_effect.csv"
          variable_name: "df_time_effect"
          columns: ["effect", "coefficient", "SE", "p_wald", "p_lrt", "significant"]
          description: "Time effect (TSVR) test results with dual p-values per Decision D068"

      parameters:
        result: "lmm_model"

      returns:
        type: "pd.DataFrame"
        variable_name: "df_time_effect"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_hypothesis_test_dual_pvalues"
      signature: "validate_hypothesis_test_dual_pvalues(interaction_df: pd.DataFrame, required_terms: List[str], alpha_bonferroni: float = 0.05) -> Dict[str, Any]"

      input_files:
        - path: "data/step03_time_effect.csv"
          variable_name: "df_time_effect"
          source: "analysis call output (extract_fixed_effects_from_lmm)"

      parameters:
        interaction_df: "df_time_effect"
        required_terms: ["TSVR"]
        alpha_bonferroni: 0.05

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "TSVR effect present in results (required term)"
        - "Both p_wald and p_lrt present (Decision D068 dual p-values)"
        - "p-values in [0, 1] valid range"
        - "SE > 0 (positive standard error)"
        - "Coefficient in scientifically reasonable range [-0.01, 0.01]"
        - "Expected rows: 1 (single Time effect)"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step03_test_time_effect.log"

    log_file: "logs/step03_test_time_effect.log"

  # --------------------------------------------------------------------------
  # STEP 4: Compute Mean HCE Rate by Timepoint (Plot Data Preparation)
  # --------------------------------------------------------------------------
  - name: "step04_prepare_trajectory_data"
    step_number: "04"
    description: "Aggregate HCE rates by timepoint for trajectory plot with 95% confidence intervals"

    analysis_call:
      type: "stdlib"
      operations:
        - "pd.read_csv('data/step01_hce_rates.csv')"
        - "Group by TEST"
        - "Compute mean(HCE_rate) per timepoint"
        - "Compute SE = std(HCE_rate) / sqrt(N)"
        - "Compute 95% CI: CI_lower = mean - 1.96*SE, CI_upper = mean + 1.96*SE"
        - "Compute mean(TSVR) per timepoint (for x-axis)"
        - "Create plot source CSV with columns: time, HCE_rate_mean, CI_lower, CI_upper, test"
        - "Save to data/step04_hce_trajectory_data.csv"

      input_files:
        - path: "data/step01_hce_rates.csv"
          required_columns: ["UID", "TEST", "TSVR", "HCE_rate"]
          variable_name: "df_hce_rates"
          source: "Step 1 output"

      output_files:
        - path: "data/step04_hce_trajectory_data.csv"
          variable_name: "df_plot_data"
          columns: ["time", "HCE_rate_mean", "CI_lower", "CI_upper", "test"]
          description: "Mean HCE rates by timepoint for trajectory visualization (4 rows: T1, T2, T3, T4)"

      parameters:
        group_by: "TEST"
        confidence_level: 0.95

      returns:
        type: "pd.DataFrame"
        variable_name: "df_plot_data"

    validation_call:
      type: "catalogued"
      module: "tools.validation"
      function: "validate_plot_data_completeness"
      signature: "validate_plot_data_completeness(plot_data: pd.DataFrame, required_domains: List[str], required_groups: List[str], domain_col: str = 'domain', group_col: str = 'group') -> Dict[str, Any]"

      input_files:
        - path: "data/step04_hce_trajectory_data.csv"
          variable_name: "df_plot_data"
          source: "analysis call output (stdlib aggregation)"

      parameters:
        plot_data: "df_plot_data"
        required_domains: []
        required_groups: ["T1", "T2", "T3", "T4"]
        domain_col: "test"
        group_col: "test"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "All 4 tests present (T1, T2, T3, T4)"
        - "Exactly 4 rows (one per timepoint, no more/less)"
        - "No NaN values in any column (complete data)"
        - "CI_upper > CI_lower for all rows (valid confidence intervals)"
        - "time values monotonically increasing (chronological order)"
        - "HCE_rate_mean in [0, 1] range (proportion)"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step04_prepare_trajectory_data.log"

    log_file: "logs/step04_prepare_trajectory_data.log"

# ============================================================================
# END OF ANALYSIS RECIPE
# ============================================================================
