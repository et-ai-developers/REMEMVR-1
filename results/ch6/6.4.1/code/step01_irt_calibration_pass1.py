#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code v4.1)
# =============================================================================
"""
Step ID: step01
Step Name: IRT Calibration Pass 1 (All TC_* Paradigm Items)
RQ: results/ch6/6.4.1
Generated: 2025-12-07

PURPOSE:
Calibrate 3-factor GRM on all TC_* confidence items (IFR/ICR/IRE paradigms).
Pass 1 provides initial parameter estimates for item purification (Step 2).
Uses IWAVE model with GRM response function for 5-category ordinal data.

CRITICAL SETTINGS (from RQ 6.1.1 and 6.3.1 learnings):
- FITTING: mc_samples=1 (FAST - avoids 7000+ epoch hang, converges ~35k epochs)
- SCORING: mc_samples=100 (ACCURATE theta estimates)
- This is MINIMUM validation mode to prove pipeline works before production run

EXPECTED INPUTS:
  - data/step00_irt_input.csv
    Columns: composite_ID + 72 TC_* items (24 per paradigm: IFR/ICR/IRE)
    Format: Wide format, 400 rows (100 participants x 4 sessions)
    Expected rows: 400
    TC_* values: Ordinal {0.2, 0.4, 0.6, 0.8, 1.0} (5 categories)

  - data/step00_q_matrix.csv
    Columns: item_name, factor1_IFR, factor2_ICR, factor3_IRE
    Format: Q-matrix specifying 3-factor paradigm structure
    Expected rows: 72 items

EXPECTED OUTPUTS:
  - data/step01_pass1_item_params.csv
    Columns: item_name, factor, a, b1, b2, b3, b4
    Format: Item parameters from GRM calibration (5 categories = 4 thresholds)
    Expected rows: 72 items

  - data/step01_pass1_theta.csv
    Columns: composite_ID, theta_IFR, se_IFR, theta_ICR, se_ICR, theta_IRE, se_IRE
    Format: Wide format theta estimates (3 paradigm factors)
    Expected rows: 400

VALIDATION CRITERIA:
  - Model convergence: Loss stable, ELBO improvement minimal in final iterations
  - Parameter bounds: a in [0.0, 10.0], b in [-6.0, 6.0]
  - No NaN parameters: All items calibrated successfully
  - Theta valid: theta in [-4, 4], se in [0.1, 1.5]
  - Threshold ordering: b1 < b2 < b3 < b4 (MANDATORY for GRM)

g_code REASONING:
- Approach: 3-factor GRM using IWAVE variational inference with Q-matrix structure
- Why this approach: Ordinal TC_* data (5 categories) requires GRM, 3-paradigm structure per 1_concept.md
- Data flow: Wide CSV → long format → tensors → IWAVE model → parameter extraction → wide outputs
- Expected performance: ~2 minutes with mc_samples=1 fitting, ~5 minutes for scoring
- KEY FIX: Use mc_samples=1 during model.fit() to avoid 7000+ epoch hang (RQ 6.1.1 lesson)
- KEY FIX: Use mc_samples=100 during model.scores() for accurate theta estimates

IMPLEMENTATION NOTES:
- Analysis tool: prepare_irt_input_from_long, configure_irt_model, fit_irt_grm, extract_* from tools.analysis_irt
- Validation tool: validate_irt_convergence, validate_irt_parameters from tools.validation
- Parameters: 3 factors (IFR/ICR/IRE), 5 categories, correlated factors, cpu device
- MINIMUM TEST MODE: mc_samples=1, iw_samples=1 for fitting (~2 min validation run)
- PRODUCTION MODE: Change to mc_samples=100, iw_samples=100 for fitting after pipeline validated
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
import torch
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/
#   parents[2] = chX/
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tools
from tools.analysis_irt import (
    prepare_irt_input_from_long,
    configure_irt_model,
    fit_irt_grm,
    extract_theta_from_irt,
    extract_parameters_from_irt
)

# Import validation tools
from tools.validation import validate_irt_convergence, validate_irt_parameters

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch6/6.4.1
LOG_FILE = RQ_DIR / "logs" / "step01_irt_calibration_pass1.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step01_pass1_item_params.csv
#   CORRECT: data/step01_pass1_theta.csv
#   WRONG:   results/item_params.csv  (wrong folder + no prefix)
#   WRONG:   data/item_params.csv     (missing step prefix)
#   WRONG:   logs/step01_items.csv    (CSV in logs folder)

# =============================================================================
# IRT TESTING WORKFLOW (g_code recommendation)
# =============================================================================
# Phase 1 (MINIMUM TEST - run this first):
#   Set: mc_samples=1, iw_samples=1 for fitting
#   Runtime: ~2 minutes (validates entire pipeline)
#   Expected: Convergence ~35k epochs (acceptable for testing)
#
# Phase 2 (PRODUCTION - only after Phase 1 passes):
#   Set: mc_samples=100, iw_samples=100 for fitting
#   Runtime: 20-30 minutes (production-quality theta scores)
# =============================================================================

# IRT Model Configuration (3-factor GRM for TC_* confidence items)
IRT_CONFIG = {
    'model_type': 'GRM',
    'n_cats': 5,  # Verified: Actual data has 5 categories {0.2, 0.4, 0.6, 0.8, 1.0}
    'correlated_factors': True,
    'device': 'cpu',
    'seed': 42,
    'factors': ['IFR', 'ICR', 'IRE']  # 3-factor paradigm structure
}

# CRITICAL SETTINGS FROM RQ 6.1.1 and 6.3.1:
# - FITTING: mc_samples=1 (FAST - avoids 7000+ epoch hang, converges ~35k epochs)
# - SCORING: mc_samples=100 (ACCURATE theta estimates)

# MINIMUM MODE: Absolute minimum settings to prove code works without crashing
# Model Fitting Settings (MINIMUM)
MODEL_FIT_SETTINGS = {
    'batch_size': 2048,
    'iw_samples': 1,   # MINIMUM
    'mc_samples': 1    # MINIMUM (CRITICAL for fast convergence)
}

# Theta Scoring Settings (ACCURATE)
MODEL_SCORING_SETTINGS = {
    'scoring_batch_size': 2048,
    'mc_samples': 100,   # ACCURATE theta estimates
    'iw_samples': 100    # ACCURATE standard errors
}

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console with flush."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
        f.flush()
    print(msg, flush=True)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 01: IRT Calibration Pass 1 (3-factor GRM on all TC_* paradigm items)")
        log(f"[CONFIG] Model: 3-factor GRM, {IRT_CONFIG['n_cats']} categories")
        log(f"[CONFIG] Factors: {IRT_CONFIG['factors']}")
        log(f"[CONFIG] Fitting: batch_size={MODEL_FIT_SETTINGS['batch_size']}, "
            f"mc_samples={MODEL_FIT_SETTINGS['mc_samples']} (MINIMUM - FAST mode), "
            f"iw_samples={MODEL_FIT_SETTINGS['iw_samples']}")
        log(f"[CONFIG] Scoring: mc_samples={MODEL_SCORING_SETTINGS['mc_samples']} (ACCURATE mode), "
            f"iw_samples={MODEL_SCORING_SETTINGS['iw_samples']}")
        log(f"[CONFIG] Expected runtime: ~2 min fitting + ~5 min scoring = ~7 min total")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Wide-format TC_* items (400 rows x 72 items) + Q-matrix
        # Purpose: Prepare data for 3-factor IRT calibration

        log("[LOAD] Loading Step 00 outputs...")

        # Load IRT input (wide format)
        irt_input_path = RQ_DIR / "data" / "step00_irt_input.csv"
        df_wide = pd.read_csv(irt_input_path)
        log(f"[LOADED] IRT input: {len(df_wide)} rows, {len(df_wide.columns)} columns")

        # Load Q-matrix
        q_matrix_path = RQ_DIR / "data" / "step00_q_matrix.csv"
        q_matrix_df = pd.read_csv(q_matrix_path)
        log(f"[LOADED] Q-matrix: {len(q_matrix_df)} items, {len(q_matrix_df.columns)} columns")
        log(f"[INFO] Q-matrix columns: {list(q_matrix_df.columns)}")

        # Validate data structure
        assert 'composite_ID' in df_wide.columns, "Missing composite_ID column"
        assert 'item_name' in q_matrix_df.columns, "Missing item_name in Q-matrix"
        assert 'factor1_IFR' in q_matrix_df.columns, "Missing factor1_IFR in Q-matrix"
        assert 'factor2_ICR' in q_matrix_df.columns, "Missing factor2_ICR in Q-matrix"
        assert 'factor3_IRE' in q_matrix_df.columns, "Missing factor3_IRE in Q-matrix"

        # =========================================================================
        # STEP 2: Reshape to Long Format
        # =========================================================================
        # Purpose: Convert wide format to long format required by prepare_irt_input_from_long
        # Expected: One row per composite_ID x item observation

        log("[RESHAPE] Converting wide format to long format...")

        # Get item columns (exclude composite_ID)
        item_cols = [col for col in df_wide.columns if col != 'composite_ID']
        log(f"[INFO] Found {len(item_cols)} item columns")

        # Parse composite_ID to extract UID and test
        # CRITICAL: prepare_irt_input_from_long requires columns: UID, test, item_name, score
        df_wide['UID'] = df_wide['composite_ID'].str.rsplit('_', n=1).str[0]
        df_wide['test'] = df_wide['composite_ID'].str.rsplit('_', n=1).str[1].str.replace('T', '')
        log(f"[INFO] Parsed composite_ID into UID and test columns")

        # Reshape to long format
        df_long = df_wide.melt(
            id_vars=['composite_ID', 'UID', 'test'],
            value_vars=item_cols,
            var_name='item_name',
            value_name='score'
        )

        # Remove missing responses
        n_before = len(df_long)
        df_long = df_long.dropna(subset=['score'])
        n_after = len(df_long)
        log(f"[RESHAPE] Long format: {n_after} observations ({n_before - n_after} missing removed)")

        # Validate score values (should be {0.2, 0.4, 0.6, 0.8, 1.0})
        unique_scores = sorted(df_long['score'].unique())
        log(f"[VALIDATE] Unique score values: {unique_scores}")
        expected_scores = [0.2, 0.4, 0.6, 0.8, 1.0]
        assert np.allclose(unique_scores, expected_scores, atol=0.01), \
            f"Score values don't match expected {expected_scores}"

        # =========================================================================
        # STEP 3: Create Factor Groups from Q-matrix
        # =========================================================================
        # Purpose: Map items to factors using Q-matrix structure
        # Expected: Dict mapping factor names to item lists

        log("[PREPARE] Creating factor groups from Q-matrix...")

        # Parse Q-matrix to create groups dict
        groups = {}
        for factor_col, factor_name in [
            ('factor1_IFR', 'IFR'),
            ('factor2_ICR', 'ICR'),
            ('factor3_IRE', 'IRE')
        ]:
            # Get items that load on this factor (value = 1)
            items = q_matrix_df[q_matrix_df[factor_col] == 1]['item_name'].tolist()
            groups[factor_name] = items
            log(f"[INFO] Factor {factor_name}: {len(items)} items")

        # Validate all items assigned
        all_items = set(item_cols)
        assigned_items = set()
        for items in groups.values():
            assigned_items.update(items)
        assert all_items == assigned_items, \
            f"Item mismatch: {len(all_items - assigned_items)} items not assigned"

        # =========================================================================
        # STEP 4: Prepare IRT Input Tensors
        # =========================================================================
        # Purpose: Convert long format to PyTorch tensors for IWAVE model
        # Expected: response_matrix, missing_mask, Q_matrix tensors

        log("[PREPARE] Converting to IRT tensors...")

        # CRITICAL: Return order is response_matrix, Q_matrix, missing_mask, item_list, composite_ids
        response_matrix, Q_matrix, missing_mask, item_list, composite_ids = \
            prepare_irt_input_from_long(df_long, groups)

        log(f"[PREPARED] Response matrix: {response_matrix.shape}")
        log(f"[PREPARED] Missing mask: {missing_mask.sum().item()} missing values")
        log(f"[PREPARED] Q-matrix: {Q_matrix.shape}")
        log(f"[PREPARED] {len(composite_ids)} participants, {len(item_list)} items")

        # =========================================================================
        # STEP 5: Configure IRT Model
        # =========================================================================
        # Purpose: Build IWAVE GRM model with 3-factor structure
        # Expected: IWAVE model object ready for fitting

        log("[MODEL] Configuring 3-factor GRM model...")

        n_items = len(item_list)
        n_factors = len(groups)

        # CRITICAL: n_cats must be a list (one value per item, or single value for all)
        # For uniform category structure, pass list of same value
        n_cats_list = [IRT_CONFIG['n_cats']] * n_items

        model = configure_irt_model(
            n_items=n_items,
            n_factors=n_factors,
            n_cats=n_cats_list,  # Pass as list
            Q_matrix=Q_matrix,
            correlated_factors=IRT_CONFIG['correlated_factors'],
            device=IRT_CONFIG['device'],
            seed=IRT_CONFIG['seed']
        )

        log(f"[MODEL] Configured: {n_items} items, {n_factors} factors, {IRT_CONFIG['n_cats']} categories")
        log(f"[MODEL] Correlated factors: {IRT_CONFIG['correlated_factors']}")

        # =========================================================================
        # STEP 6: Fit IRT Model
        # =========================================================================
        # Purpose: Calibrate model via variational inference
        # Expected: Fitted model with item parameters and convergence info
        # CRITICAL: Use mc_samples=1 for FAST fitting (avoids 7000+ epoch hang)

        log("[FIT] Fitting IRT model (MINIMUM settings for validation)...")
        log(f"[FIT] mc_samples={MODEL_FIT_SETTINGS['mc_samples']} (MINIMUM - expect ~35k epochs)")
        log(f"[FIT] Expected runtime: ~2 minutes")

        fitted_model = fit_irt_grm(
            model=model,
            response_matrix=response_matrix,
            missing_mask=missing_mask,
            batch_size=MODEL_FIT_SETTINGS['batch_size'],
            iw_samples=MODEL_FIT_SETTINGS['iw_samples'],
            mc_samples=MODEL_FIT_SETTINGS['mc_samples']
        )

        log("[FIT] Model fitting complete")

        # Check convergence
        if hasattr(fitted_model, 'converged') and fitted_model.converged:
            log(f"[CONVERGED] Model converged successfully")
        else:
            log(f"[WARNING] Model convergence status unclear")

        # =========================================================================
        # STEP 7: Extract Item Parameters
        # =========================================================================
        # Purpose: Extract discrimination (a) and difficulty (b1-b4) parameters
        # Expected: DataFrame with item_name, factor, a, b1, b2, b3, b4

        log("[EXTRACT] Extracting item parameters...")

        df_item_params = extract_parameters_from_irt(
            model=fitted_model,
            item_list=item_list,
            factor_names=IRT_CONFIG['factors'],
            n_cats=n_cats_list  # Pass as list (same as configure_irt_model)
        )

        log(f"[EXTRACTED] Item parameters: {len(df_item_params)} rows")

        # Note: extract_parameters_from_irt returns MIRT format for multidimensional models:
        # item_name, Difficulty, Overall_Discrimination, Discrim_IFR, Discrim_ICR, Discrim_IRE
        # Keep as-is since this is the tool's native output format (same as RQ 6.3.1)
        log(f"[INFO] Parameter columns: {list(df_item_params.columns)}")

        # Validate parameters
        log("[VALIDATE] Checking item parameters...")
        log(f"[INFO] Overall Discrimination range: [{df_item_params['Overall_Discrimination'].min():.3f}, {df_item_params['Overall_Discrimination'].max():.3f}]")
        log(f"[INFO] Difficulty range: [{df_item_params['Difficulty'].min():.3f}, {df_item_params['Difficulty'].max():.3f}]")

        # Check for NaN parameters
        n_nan = df_item_params[['Overall_Discrimination', 'Difficulty']].isna().sum().sum()
        if n_nan > 0:
            log(f"[WARNING] {n_nan} NaN parameters detected")
        else:
            log(f"[PASS] No NaN parameters")

        # Check threshold ordering (b1 < b2 < b3 < b4)
        ordered = (
            (df_item_params['b1'] < df_item_params['b2']) &
            (df_item_params['b2'] < df_item_params['b3']) &
            (df_item_params['b3'] < df_item_params['b4'])
        )
        n_ordered = ordered.sum()
        n_total = len(df_item_params)
        log(f"[VALIDATE] Threshold ordering: {n_ordered}/{n_total} items have b1 < b2 < b3 < b4")
        if n_ordered < n_total:
            log(f"[WARNING] {n_total - n_ordered} items have disordered thresholds")

        # Save item parameters
        item_params_path = RQ_DIR / "data" / "step01_pass1_item_params.csv"
        df_item_params.to_csv(item_params_path, index=False, encoding='utf-8')
        log(f"[SAVED] Item parameters: {item_params_path}")

        # =========================================================================
        # STEP 8: Extract Theta Scores
        # =========================================================================
        # Purpose: Extract participant ability estimates (theta) with standard errors
        # Expected: DataFrame with composite_ID, theta_IFR, se_IFR, theta_ICR, se_ICR, theta_IRE, se_IRE
        # CRITICAL: Use mc_samples=100 for ACCURATE theta estimates

        log("[EXTRACT] Extracting theta scores (ACCURATE mode)...")
        log(f"[EXTRACT] mc_samples={MODEL_SCORING_SETTINGS['mc_samples']} (ACCURATE)")
        log(f"[EXTRACT] Expected runtime: ~5 minutes")

        df_theta_long = extract_theta_from_irt(
            model=fitted_model,
            response_matrix=response_matrix,
            missing_mask=missing_mask,
            composite_ids=composite_ids,
            factor_names=IRT_CONFIG['factors'],
            scoring_batch_size=MODEL_SCORING_SETTINGS['scoring_batch_size'],
            mc_samples=MODEL_SCORING_SETTINGS['mc_samples'],
            iw_samples=MODEL_SCORING_SETTINGS['iw_samples'],
            invert_scale=False  # Keep standard IRT direction (high theta = high ability)
        )

        log(f"[EXTRACTED] Theta scores: {len(df_theta_long)} rows (long format)")

        # Reshape to wide format: composite_ID, theta_IFR, se_IFR, theta_ICR, se_ICR, theta_IRE, se_IRE
        # extract_theta_from_irt returns: composite_ID, domain_name, theta, SE
        df_theta_wide = df_theta_long.pivot(
            index='composite_ID',
            columns='domain_name',
            values=['theta', 'SE']
        )

        # Flatten column names: (theta, IFR) -> theta_IFR, (SE, IFR) -> se_IFR
        df_theta_wide.columns = [f"{col[0].lower() if col[0] == 'SE' else col[0]}_{col[1]}"
                                  for col in df_theta_wide.columns]

        # Rename SE columns to se_* (lowercase)
        df_theta_wide = df_theta_wide.rename(columns={
            'SE_IFR': 'se_IFR',
            'SE_ICR': 'se_ICR',
            'SE_IRE': 'se_IRE'
        })

        # Reset index to make composite_ID a column
        df_theta_wide = df_theta_wide.reset_index()

        # Reorder columns to match specification
        df_theta_wide = df_theta_wide[['composite_ID', 'theta_IFR', 'se_IFR',
                                        'theta_ICR', 'se_ICR', 'theta_IRE', 'se_IRE']]

        log(f"[RESHAPED] Wide format: {len(df_theta_wide)} rows, {len(df_theta_wide.columns)} columns")

        # Validate theta scores
        log("[VALIDATE] Checking theta scores...")
        theta_cols = ['theta_IFR', 'theta_ICR', 'theta_IRE']
        se_cols = ['se_IFR', 'se_ICR', 'se_IRE']

        for col in theta_cols:
            log(f"[INFO] {col} range: [{df_theta_wide[col].min():.3f}, {df_theta_wide[col].max():.3f}]")

        for col in se_cols:
            log(f"[INFO] {col} range: [{df_theta_wide[col].min():.3f}, {df_theta_wide[col].max():.3f}]")

        # Check for NaN scores
        n_nan_theta = df_theta_wide[theta_cols].isna().sum().sum()
        if n_nan_theta > 0:
            log(f"[WARNING] {n_nan_theta} NaN theta scores detected")
        else:
            log(f"[PASS] No NaN theta scores")

        # Save theta scores
        theta_path = RQ_DIR / "data" / "step01_pass1_theta.csv"
        df_theta_wide.to_csv(theta_path, index=False, encoding='utf-8')
        log(f"[SAVED] Theta scores: {theta_path}")

        # =========================================================================
        # STEP 9: Validation
        # =========================================================================
        # Purpose: Run validation checks on convergence and parameters
        # Expected: All validation checks pass

        log("[VALIDATION] Running validation checks...")

        # Prepare results dict for validation
        results = {
            'converged': hasattr(fitted_model, 'converged') and fitted_model.converged,
            'item_params': df_item_params
        }

        # Validate convergence
        convergence_validation = validate_irt_convergence(results)

        if convergence_validation['converged']:
            log(f"[PASS] Convergence validation passed")
        else:
            log(f"[WARNING] Convergence validation: {convergence_validation['message']}")

        # Validate item parameters
        param_validation = validate_irt_parameters(
            df_items=df_item_params,
            a_min=0.0,
            b_max=6.0,
            a_col='a',
            b_col='b1'  # Check b1 as representative (all b's should be in range)
        )

        if param_validation['valid']:
            log(f"[PASS] Parameter validation passed: {param_validation['n_valid']}/{param_validation['n_items']} items valid")
        else:
            log(f"[WARNING] Parameter validation: {param_validation['message']}")

        # =========================================================================
        # SUCCESS
        # =========================================================================

        log("[SUCCESS] Step 01 complete: IRT Pass 1 calibration finished")
        log(f"[OUTPUT] Item parameters: {item_params_path}")
        log(f"[OUTPUT] Theta scores: {theta_path}")
        log(f"[NEXT] Run Step 02: Item purification (filter by quality thresholds)")

        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
