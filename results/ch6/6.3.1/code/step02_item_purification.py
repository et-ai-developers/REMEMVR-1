#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code v4.1)
# =============================================================================
"""
Step ID: step02
Step Name: Item Purification (Decision D039)
RQ: results/ch6/6.3.1
Generated: 2025-12-07

PURPOSE:
Filter TC_* confidence items by quality thresholds per Decision D039 2-pass IRT workflow.
Retains items with Overall_Discrimination >= 0.4 AND |Difficulty| <= 3.0.
Expected retention: 40-50% of items (temporal When items heavily excluded).

Decision D039 Rationale:
- Temporal items inherently difficult (b > 3.0 common)
- Low-discrimination items (a < 0.4) introduce measurement error
- 2-pass purification ensures only psychometrically sound items contribute to theta estimates
- Pass 1 (step01) calibrates all items to identify poor quality items
- Pass 2 (step03) recalibrates with retained items ONLY for final theta scores

EXPECTED INPUTS:
  - data/step01_pass1_item_params.csv
    Columns: item_name, Difficulty, Overall_Discrimination, Discrim_What, Discrim_Where, Discrim_When
    Format: Item parameters from Pass 1 GRM calibration
    Expected rows: ~72 items (all TC_* confidence items)

EXPECTED OUTPUTS:
  - data/step02_purified_items.csv
    Columns: item_name, dimension, a, b, retention_reason
    Format: Items that passed purification thresholds
    Expected rows: 40-50% retention (~29-36 items expected)
    Typical pattern: What/Where items retained, When items heavily excluded

  - data/step02_excluded_items.csv
    Columns: item_name, dimension, a, b, exclusion_reason
    Format: Items that failed purification with reason
    Expected rows: 50-60% exclusion (~36-43 items expected)

VALIDATION CRITERIA:
  - Thresholds enforced: All retained items have a >= 0.4 AND |b| <= 3.0
  - Retention rate: 20-80% (outside suggests calibration problem)
  - No NaN parameters: All items have valid a and b values
  - Exclusion reasons documented: All excluded items have clear reason

g_code REASONING:
- Approach: Simple filtering using filter_items_by_quality from tools.analysis_irt
- Why this approach: Decision D039 2-pass IRT methodology is standard practice for REMEMVR
- Data flow: Load Pass 1 item params → filter by thresholds → save retained/excluded lists
- Expected performance: <1 second (simple pandas filtering)
- Post-purification: When domain may be entirely excluded (typical for confidence items)

IMPLEMENTATION NOTES:
- Analysis tool: filter_items_by_quality from tools.analysis_irt
- Validation tool: validate_irt_parameters from tools.validation
- Parameters: a_threshold=0.4, b_threshold=3.0 (Decision D039 standards)
- Column mapping: filter_items_by_quality auto-detects multivariate format (Difficulty, Discrim_*)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
from typing import Tuple
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_irt import filter_items_by_quality

# Import validation tool
from tools.validation import validate_irt_parameters

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch6/6.3.1
LOG_FILE = RQ_DIR / "logs" / "step02_item_purification.log"

# Decision D039 thresholds
A_THRESHOLD = 0.4  # Minimum discrimination
B_THRESHOLD = 3.0  # Maximum absolute difficulty

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step02_purified_items.csv
#   CORRECT: data/step02_excluded_items.csv
#   WRONG:   results/purified_items.csv  (wrong folder + no prefix)
#   WRONG:   data/purified_items.csv     (missing step prefix)
#   WRONG:   logs/step02_items.csv       (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console with flush."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
        f.flush()  # Ensure immediate write (from step01 pattern)
    print(msg, flush=True)  # Unbuffered console output

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("=" * 80)
        log("[START] Step 02: Item Purification (Decision D039)")
        log("=" * 80)

        # =========================================================================
        # STEP 1: Load Pass 1 Item Parameters
        # =========================================================================
        # Expected: ~72 TC_* items with Difficulty and Discrim_* columns
        # Purpose: Identify poor-quality items for exclusion from Pass 2

        log("\n[LOAD] Loading Pass 1 item parameters...")
        input_path = RQ_DIR / "data" / "step01_pass1_item_params.csv"

        if not input_path.exists():
            raise FileNotFoundError(f"Input file not found: {input_path}")

        df_items_pass1 = pd.read_csv(input_path, encoding='utf-8')
        log(f"[LOADED] {input_path.name}")
        log(f"  Rows: {len(df_items_pass1)} items")
        log(f"  Columns: {list(df_items_pass1.columns)}")
        log(f"  Difficulty range: [{df_items_pass1['Difficulty'].min():.2f}, {df_items_pass1['Difficulty'].max():.2f}]")
        log(f"  Overall_Discrimination range: [{df_items_pass1['Overall_Discrimination'].min():.2f}, {df_items_pass1['Overall_Discrimination'].max():.2f}]")

        # =========================================================================
        # STEP 2: Run Item Purification
        # =========================================================================
        # Tool: filter_items_by_quality
        # What it does: Exclude items with a < 0.4 OR |b| > 3.0
        # Expected output: ~40-50% retention (~29-36 items typical)

        log("\n[PURIFICATION] Running filter_items_by_quality...")
        log(f"  Thresholds: a >= {A_THRESHOLD}, |b| <= {B_THRESHOLD}")

        df_purified, df_excluded = filter_items_by_quality(
            df_items=df_items_pass1,
            a_threshold=A_THRESHOLD,
            b_threshold=B_THRESHOLD
        )

        retention_pct = 100 * len(df_purified) / len(df_items_pass1)
        exclusion_pct = 100 * len(df_excluded) / len(df_items_pass1)

        log(f"[DONE] Purification complete")
        log(f"  Retained: {len(df_purified)} items ({retention_pct:.1f}%)")
        log(f"  Excluded: {len(df_excluded)} items ({exclusion_pct:.1f}%)")

        # Check if retention rate is within expected range (20-80%)
        if retention_pct < 20 or retention_pct > 80:
            log(f"[WARNING] Retention rate {retention_pct:.1f}% outside typical 20-80% range")
            log(f"          This may indicate calibration problems in Pass 1")

        # =========================================================================
        # STEP 3: Save Purification Outputs
        # =========================================================================
        # Output 1: Purified items (retained for Pass 2)
        # Output 2: Excluded items (with exclusion reasons)

        log("\n[SAVE] Saving purification results...")

        # Save purified items
        purified_path = RQ_DIR / "data" / "step02_purified_items.csv"
        df_purified.to_csv(purified_path, index=False, encoding='utf-8')
        log(f"[SAVED] {purified_path.name}")
        log(f"  Rows: {len(df_purified)} retained items")
        log(f"  Columns: {list(df_purified.columns)}")

        # Save excluded items
        excluded_path = RQ_DIR / "data" / "step02_excluded_items.csv"
        df_excluded.to_csv(excluded_path, index=False, encoding='utf-8')
        log(f"[SAVED] {excluded_path.name}")
        log(f"  Rows: {len(df_excluded)} excluded items")
        log(f"  Columns: {list(df_excluded.columns)}")

        # Domain-wise breakdown
        if 'factor' in df_purified.columns:
            log("\n[DOMAIN BREAKDOWN]")
            log("  Retained items by domain:")
            for domain in df_purified['factor'].unique():
                n_domain = len(df_purified[df_purified['factor'] == domain])
                log(f"    {domain}: {n_domain} items")

            if 'factor' in df_excluded.columns:
                log("  Excluded items by domain:")
                for domain in df_excluded['factor'].unique():
                    n_domain = len(df_excluded[df_excluded['factor'] == domain])
                    log(f"    {domain}: {n_domain} items")

        # =========================================================================
        # STEP 4: Validate Purification Results
        # =========================================================================
        # Tool: validate_irt_parameters
        # Validates: All retained items meet thresholds (a >= 0.4, |b| <= 3.0)
        # Threshold: 100% compliance required

        log("\n[VALIDATION] Validating purified items...")

        validation_result = validate_irt_parameters(
            df_items=df_purified,
            a_min=A_THRESHOLD,
            b_max=B_THRESHOLD,
            a_col='a',  # filter_items_by_quality normalizes column names
            b_col='b'
        )

        if validation_result.get('valid', True):
            log("[VALIDATION PASSED]")
            if 'message' in validation_result:
                log(f"  {validation_result['message']}")
            log(f"  Valid items: {validation_result.get('n_valid', len(df_purified))} / {validation_result.get('n_items', len(df_purified))}")
        else:
            log("[VALIDATION FAILED]")
            if 'message' in validation_result:
                log(f"  {validation_result['message']}")
            log(f"  Invalid items: {validation_result.get('n_invalid', 0)} / {validation_result.get('n_items', len(df_purified))}")
            if validation_result.get('invalid_items'):
                log(f"  Invalid items: {validation_result['invalid_items']}")
            raise ValueError("Purification validation failed - some items don't meet thresholds")

        # =========================================================================
        # FINAL SUMMARY
        # =========================================================================

        log("\n" + "=" * 80)
        log("[SUCCESS] Step 02 complete")
        log("=" * 80)
        log(f"Pass 1 items: {len(df_items_pass1)}")
        log(f"Retained (Pass 2): {len(df_purified)} ({retention_pct:.1f}%)")
        log(f"Excluded: {len(df_excluded)} ({exclusion_pct:.1f}%)")
        log(f"Thresholds: a >= {A_THRESHOLD}, |b| <= {B_THRESHOLD}")
        log("\nNext: Step 03 will recalibrate using {len(df_purified)} purified items")
        log("=" * 80)

        sys.exit(0)

    except Exception as e:
        log(f"\n[ERROR] {str(e)}")
        log("\n[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
            f.flush()
        traceback.print_exc()
        sys.exit(1)
