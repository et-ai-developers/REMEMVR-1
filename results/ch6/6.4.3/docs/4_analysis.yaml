# 4_analysis.yaml - Analysis Recipe for RQ 6.4.3
# Created by: rq_analysis agent
# RQ: Age x Paradigm Interaction for Confidence Decline
# Generated: 2025-12-06

metadata:
  rq_id: "6.4.3"
  total_steps: 5
  analysis_type: "LMM-only (Age x Paradigm x Time interaction testing)"
  generated_by: "rq_analysis v4.1.0"
  timestamp: "2025-12-06T00:00:00Z"

steps:
  # ==========================================================================
  # STEP 0: Data Preparation
  # ==========================================================================
  - name: "step00_prepare_lmm_input"
    step_number: "00"

    analysis_call:
      type: "stdlib"
      operations:
        - "Load RQ 6.4.1 confidence theta scores from results/ch6/6.4.1/data/step03_theta_confidence_paradigm.csv"
        - "Load age data from data/cache/dfData.csv"
        - "Extract UID from composite_ID (split on underscore: 'P001_T1' -> 'P001')"
        - "Left join: theta data + age data on UID"
        - "Verify merge success: all 1200 rows have valid Age (no NaN)"
        - "Center age variable: Age_c = Age - mean(Age)"
        - "Verify centering: mean(Age_c) approximately 0"
        - "Save to data/step00_lmm_input.csv with columns: UID, Age, Age_c, Paradigm, test, TSVR_hours, log_TSVR, theta_confidence, se_confidence"

      input_files:
        - path: "results/ch6/6.4.1/data/step03_theta_confidence_paradigm.csv"
          required_columns: ["composite_ID", "Paradigm", "test", "TSVR_hours", "log_TSVR", "theta_confidence", "se_confidence"]
          expected_rows: 1200
          description: "Confidence theta scores from RQ 6.4.1 (3-factor GRM calibration)"

        - path: "data/cache/dfData.csv"
          required_columns: ["UID", "Age"]
          expected_rows: 100
          description: "Participant demographics (age data)"

      output_files:
        - path: "data/step00_lmm_input.csv"
          columns: ["UID", "Age", "Age_c", "Paradigm", "test", "TSVR_hours", "log_TSVR", "theta_confidence", "se_confidence"]
          expected_rows: 1200
          description: "Long-format LMM input with centered age and merged confidence data"

      description: "Merge confidence theta scores with age data, center age variable, prepare LMM input"

    validation_call:
      module: "tools.validation"
      function: "validate_dataframe_structure"
      signature: "validate_dataframe_structure(df: DataFrame, expected_rows: Union[int, Tuple[int, int]], expected_columns: List[str], column_types: Optional[Dict[str, type]] = None) -> Dict[str, Any]"

      input_files:
        - path: "data/step00_lmm_input.csv"
          variable_name: "lmm_input"
          source: "analysis call output (data preparation)"

      parameters:
        df: "lmm_input"
        expected_rows: 1200
        expected_columns: ["UID", "Age", "Age_c", "Paradigm", "test", "TSVR_hours", "log_TSVR", "theta_confidence", "se_confidence"]

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "Exactly 1200 rows (100 participants x 4 tests x 3 paradigms)"
        - "All 9 required columns present"
        - "No NaN values in any column (complete merge)"
        - "Age_c mean approximately 0 (within 0.01 tolerance)"
        - "All 100 unique UIDs present"
        - "Paradigm distribution: 400 rows each (IFR, ICR, IRE)"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step00_prepare_lmm_input.log"

      description: "Validate data merge completeness, structure, age centering accuracy"

    log_file: "logs/step00_prepare_lmm_input.log"

  # ==========================================================================
  # STEP 1: Fit LMM with 3-Way Interaction
  # ==========================================================================
  - name: "step01_fit_lmm_3way"
    step_number: "01"

    analysis_call:
      module: "tools.analysis_lmm"
      function: "fit_lmm_trajectory_tsvr"
      signature: "fit_lmm_trajectory_tsvr(theta_scores: DataFrame, tsvr_data: DataFrame, formula: str, groups: str = 'UID', re_formula: str = '~Days', reml: bool = False) -> MixedLMResults"

      input_files:
        - path: "data/step00_lmm_input.csv"
          required_columns: ["UID", "Age_c", "Paradigm", "log_TSVR", "theta_confidence"]
          variable_name: "lmm_input"

      output_files:
        - path: "data/step01_lmm_model_summary.txt"
          variable_name: "lmm_model"
          description: "LMM summary with fixed effects, random effects, fit statistics"

      parameters:
        theta_scores: "lmm_input"
        tsvr_data: "lmm_input"
        formula: "theta_confidence ~ log_TSVR * Paradigm * Age_c"
        groups: "UID"
        re_formula: "~log_TSVR"
        reml: false

      returns:
        type: "MixedLMResults"
        variable_name: "lmm_model"

      description: "Fit LMM testing Age x Paradigm x Time 3-way interaction for confidence decline (Decision D070 TSVR time variable)"

    validation_call:
      module: "tools.validation"
      function: "validate_lmm_convergence"
      signature: "validate_lmm_convergence(lmm_result: MixedLMResults) -> Dict[str, Any]"

      input_files:
        - path: "data/step01_lmm_model_summary.txt"
          variable_name: "lmm_model"
          source: "analysis call output (fit_lmm_trajectory_tsvr return value)"

      parameters:
        lmm_result: "lmm_model"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "Model converged successfully (converged = True)"
        - "No singularity warnings (random effects variance > 0)"
        - "All 8 fixed effects estimated (3 main + 3 two-way + 2 three-way dummy codes)"
        - "Random effects present for intercepts and slopes"
        - "Exactly 1200 observations used"
        - "Exactly 100 groups (UIDs)"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step01_fit_lmm_3way.log"

      description: "Validate LMM convergence, no singularity, expected structure"

    log_file: "logs/step01_fit_lmm_3way.log"

  # ==========================================================================
  # STEP 2: Extract Interaction Terms with Dual P-Values
  # ==========================================================================
  - name: "step02_extract_interaction_terms"
    step_number: "02"

    analysis_call:
      module: "tools.analysis_lmm"
      function: "compute_contrasts_pairwise"
      signature: "compute_contrasts_pairwise(lmm_result: MixedLMResults, comparisons: List[str], family_alpha: float = 0.05) -> DataFrame"

      input_files:
        - path: "data/step01_lmm_model_summary.txt"
          variable_name: "lmm_model"
          source: "Step 1 LMM output"

      output_files:
        - path: "data/step02_interaction_terms.csv"
          columns: ["term", "coef", "se", "z_wald", "p_wald_uncorrected", "p_wald_bonferroni", "chi2_lrt", "df_lrt", "p_lrt_uncorrected", "p_lrt_bonferroni", "significant_bonferroni"]
          expected_rows: 3
          variable_name: "interaction_terms"
          description: "Age_c terms with dual p-values (Wald + LRT) and Bonferroni correction"

      parameters:
        lmm_result: "lmm_model"
        comparisons: ["Age_c", "Age_c:log_TSVR", "Age_c:log_TSVR:Paradigm"]
        family_alpha: 0.05

      returns:
        type: "DataFrame"
        variable_name: "interaction_terms"

      description: "Extract Age_c terms (main, 2-way, 3-way) with dual p-value reporting (Decision D068: Wald + LRT)"

    validation_call:
      module: "tools.validation"
      function: "validate_hypothesis_test_dual_pvalues"
      signature: "validate_hypothesis_test_dual_pvalues(interaction_df: DataFrame, required_terms: List[str], alpha_bonferroni: float = 0.05) -> Dict[str, Any]"

      input_files:
        - path: "data/step02_interaction_terms.csv"
          variable_name: "interaction_terms"
          source: "analysis call output (compute_contrasts_pairwise return value)"

      parameters:
        interaction_df: "interaction_terms"
        required_terms: ["Age_c", "Age_c:log_TSVR", "Age_c:log_TSVR:Paradigm"]
        alpha_bonferroni: 0.05

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "All 3 required terms present (Age_c main, 2-way, 3-way)"
        - "BOTH Wald and LRT p-values present (Decision D068 compliance)"
        - "Bonferroni correction applied correctly (p_bonf = p_uncorr * 3)"
        - "No NaN p-values (all tests executed successfully)"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step02_extract_interaction_terms.log"

      description: "Validate dual p-value reporting per Decision D068, all required terms extracted"

    log_file: "logs/step02_extract_interaction_terms.log"

  # ==========================================================================
  # STEP 3: Compute Effect Sizes
  # ==========================================================================
  - name: "step03_compute_effect_sizes"
    step_number: "03"

    analysis_call:
      module: "tools.analysis_lmm"
      function: "compute_effect_sizes_cohens"
      signature: "compute_effect_sizes_cohens(lmm_result: MixedLMResults, include_interactions: bool = False) -> DataFrame"

      input_files:
        - path: "data/step01_lmm_model_summary.txt"
          variable_name: "lmm_model"
          source: "Step 1 LMM output (re-loaded model object)"

      output_files:
        - path: "data/step03_effect_sizes.csv"
          columns: ["term", "f_squared", "interpretation"]
          expected_rows: 3
          variable_name: "effect_sizes"
          description: "Cohen's f-squared effect sizes with interpretation thresholds"

      parameters:
        lmm_result: "lmm_model"
        include_interactions: true

      returns:
        type: "DataFrame"
        variable_name: "effect_sizes"

      description: "Compute Cohen's f-squared effect sizes for Age_c terms (main, 2-way, 3-way interaction)"

    validation_call:
      module: "tools.validation"
      function: "validate_effect_sizes"
      signature: "validate_effect_sizes(effect_sizes_df: DataFrame, f2_column: str = 'cohens_f2') -> Dict[str, Any]"

      input_files:
        - path: "data/step03_effect_sizes.csv"
          variable_name: "effect_sizes"
          source: "analysis call output (compute_effect_sizes_cohens return value)"

      parameters:
        effect_sizes_df: "effect_sizes"
        f2_column: "f_squared"

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "All 3 effect sizes computed (no NaN)"
        - "f_squared values >= 0 (non-negative required)"
        - "Interpretation consistent with thresholds (small/medium/large)"

      on_failure:
        action: "raise ValueError(validation_result['message'])"
        log_to: "logs/step03_compute_effect_sizes.log"

      description: "Validate effect sizes non-negative, interpretation correct"

    log_file: "logs/step03_compute_effect_sizes.log"

  # ==========================================================================
  # STEP 4: Compare to Chapter 5 Results
  # ==========================================================================
  - name: "step04_compare_to_ch5"
    step_number: "04"

    analysis_call:
      type: "stdlib"
      operations:
        - "Load Ch6 confidence interaction terms from data/step02_interaction_terms.csv"
        - "Attempt to load Ch5 accuracy interaction terms from results/ch5/5.3.4/data/step02_interaction_terms.csv"
        - "If Ch5 file exists: Merge Ch6 + Ch5 data on 'term' column (outer join)"
        - "If Ch5 file exists: Create comparison table with 6 rows (3 terms x 2 domains)"
        - "If Ch5 file missing: Create comparison table with 3 rows (Ch6 only), document 'Ch5 comparison pending' in interpretation"
        - "Add domain column: 'Accuracy' for Ch5 rows, 'Confidence' for Ch6 rows"
        - "Add interpretation column: Consistency assessment (both NULL, both significant, or divergent)"
        - "Save to data/step04_ch5_comparison.csv"

      input_files:
        - path: "data/step02_interaction_terms.csv"
          required_columns: ["term", "p_wald_bonferroni", "p_lrt_bonferroni", "significant_bonferroni"]
          description: "Ch6 confidence interaction terms (Step 2 output)"

        - path: "results/ch5/5.3.4/data/step02_interaction_terms.csv"
          required_columns: ["term", "p_wald_bonferroni", "p_lrt_bonferroni", "significant_bonferroni"]
          optional: true
          description: "Ch5 accuracy interaction terms (optional - may not exist yet)"

      output_files:
        - path: "data/step04_ch5_comparison.csv"
          columns: ["term", "domain", "p_wald_bonferroni", "p_lrt_bonferroni", "significant_bonferroni", "interpretation"]
          expected_rows: [3, 6]
          description: "Cross-chapter comparison (Ch5 accuracy vs Ch6 confidence)"

      description: "Compare Ch6 confidence interaction results to Ch5 accuracy interaction results (test generalization hypothesis)"

    validation_call:
      module: "tools.validation"
      function: "validate_data_format"
      signature: "validate_data_format(df: DataFrame, required_cols: List[str]) -> Dict[str, Any]"

      input_files:
        - path: "data/step04_ch5_comparison.csv"
          variable_name: "comparison_table"
          source: "analysis call output (comparison table creation)"

      parameters:
        df: "comparison_table"
        required_cols: ["term", "domain", "p_wald_bonferroni", "p_lrt_bonferroni", "significant_bonferroni", "interpretation"]

      returns:
        type: "Dict[str, Any]"
        variable_name: "validation_result"

      criteria:
        - "Required columns present"
        - "Expected rows: 6 if Ch5 available (3 terms x 2 domains), 3 if Ch5 pending (Confidence only)"
        - "No NaN in p-value columns (unless Ch5 unavailable)"

      on_failure:
        action: "Log warning if Ch5 missing, proceed with Ch6-only table"
        log_to: "logs/step04_compare_to_ch5.log"

      description: "Validate comparison table structure, handle Ch5 availability gracefully"

    log_file: "logs/step04_compare_to_ch5.log"

# =============================================================================
# END OF ANALYSIS RECIPE
# =============================================================================
