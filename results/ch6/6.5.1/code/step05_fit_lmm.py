#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step05
Step Name: Fit LMM with Domain x Time Interaction
RQ: results/ch6/6.5.1
Generated: 2025-12-07

PURPOSE:
Fit Linear Mixed Model to test Domain × Time interaction on confidence theta scores.
Primary hypothesis is NULL: Domain × Time interaction should be non-significant (p > 0.05).
Model includes:
- Fixed effects: domain (What/Where/When), log_TSVR (time), domain:log_TSVR (interaction)
- Random effects: random intercept + random slope for log_TSVR per participant (UID)

EXPECTED INPUTS:
  - data/step04_lmm_input.csv
    Columns: ['composite_ID', 'UID', 'test', 'TSVR_hours', 'log_TSVR', 'congruence', 'theta']
    Format: Long-format LMM input with TSVR time variable (Decision D070)
    Expected rows: 800 (if When excluded) OR 1200 (if When included)

EXPECTED OUTPUTS:
  - data/step05_lmm_coefficients.csv
    Columns: ['term', 'coef', 'se', 'z', 'p_value']
    Format: Fixed effects table with coefficients and significance
    Expected rows: Variable (depends on 2-factor vs 3-factor model)

  - data/step05_lmm_summary.txt
    Format: Full LMM model summary including fixed effects, random effects, fit indices
    Contains: Convergence status, AIC, BIC, log-likelihood, variance components

g_code REASONING:
- Approach: Use statsmodels MixedLM with formula interface for Domain × Time interaction
- Why this approach: statsmodels handles complex random effects structures, REML=False for
  model comparison compatibility, log_TSVR transformation accounts for non-linear forgetting
- Data flow: Load LMM input → Fit MixedLM → Extract fixed effects (CORRECT slicing) →
  Save coefficients table + full summary text
- Expected performance: ~10-30 seconds (N=800-1200, simple interaction model)

IMPLEMENTATION NOTES:
- Analysis tool: fit_lmm_trajectory_tsvr from tools.analysis_lmm
- Validation tool: validate_lmm_convergence from tools.validation
- Parameters: formula='theta ~ domain * log_TSVR', re_formula='~log_TSVR', groups='UID', reml=False
- CRITICAL: Use CORRECT coefficient extraction pattern from execute.md to avoid including
  random effects in fixed effects table (n_fe = len(model.exog_names))
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
# CRITICAL: RQ scripts are in results/chX/rqY/code/ (4 levels deep from project root)
# Path hierarchy from script location:
#   parents[0] = code/ (immediate parent)
#   parents[1] = rqY/ (6.3.1)
#   parents[2] = chX/ (ch6)
#   parents[3] = results/
#   parents[4] = REMEMVR/ (project root - THIS is what we need for imports)
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import analysis tool
from tools.analysis_lmm import fit_lmm_trajectory_tsvr

# Import validation tool
from tools.validation import validate_lmm_convergence

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch6/6.5.1 (derived from script location)
LOG_FILE = RQ_DIR / "logs" / "step05_fit_lmm.log"

# =============================================================================
# FOLDER CONVENTIONS (MANDATORY - NO EXCEPTIONS)
# =============================================================================
#
# code/   : ONLY .py scripts (generated by g_code)
# data/   : ALL data outputs (.csv, .pkl, .txt) - ANY file produced by code
# logs/   : ONLY .log files - execution logs
# plots/  : ONLY image files (.png, .pdf, .svg) - actual plot images
# results/: ONLY final summary reports (.md, .html)
# docs/   : RQ documentation (concept, plan, analysis specs)
#
# NAMING CONVENTION (MANDATORY):
# ALL files in data/ and logs/ MUST be prefixed with step number:
#   - stepXX_descriptive_name.csv
#   - stepXX_descriptive_name.pkl
#   - stepXX_descriptive_name.log
#
# Examples:
#   CORRECT: data/step05_lmm_coefficients.csv
#   CORRECT: data/step05_lmm_summary.txt
#   WRONG:   results/lmm_coefficients.csv  (wrong folder + no prefix)
#   WRONG:   data/lmm_coefficients.csv     (missing step prefix)
#   WRONG:   logs/step05_coefficients.csv  (CSV in logs folder)

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console with flush."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
        f.flush()  # Ensure immediate write
    print(msg, flush=True)  # Flush console output

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 05: Fit LMM with Domain x Time Interaction")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Long-format LMM input with TSVR time variable
        # Purpose: Fit LMM to test Domain × Time interaction on confidence theta scores

        log("[LOAD] Loading LMM input data...")
        input_path = RQ_DIR / "data" / "step04_lmm_input.csv"

        if not input_path.exists():
            raise FileNotFoundError(f"Input file not found: {input_path}")

        lmm_input = pd.read_csv(input_path, encoding='utf-8')
        log(f"[LOADED] {input_path.name} ({len(lmm_input)} rows, {len(lmm_input.columns)} cols)")

        # Verify expected columns
        required_cols = ['composite_ID', 'UID', 'congruence', 'theta', 'log_TSVR']
        missing_cols = [col for col in required_cols if col not in lmm_input.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")

        log(f"[INFO] Domains: {sorted(lmm_input['congruence'].unique())}")
        log(f"[INFO] Participants: {lmm_input['UID'].nunique()}")
        log(f"[INFO] Observations: {len(lmm_input)}")

        # =========================================================================
        # STEP 2: Run Analysis Tool
        # =========================================================================
        # Tool: fit_lmm_trajectory_tsvr
        # What it does: Fits Linear Mixed Model with Domain × Time interaction
        # Expected output: MixedLMResults object with fixed effects, random effects, fit indices

        log("[ANALYSIS] Fitting LMM with formula: theta ~ C(congruence) * log_TSVR")
        log("[ANALYSIS] Random effects: (1 | UID) - random intercept only")

        # Use statsmodels directly since data is already prepared
        import statsmodels.formula.api as smf

        # Model specification (use C() for categorical domain)
        formula = "theta ~ C(congruence) * log_TSVR"
        groups = "UID"
        reml = False  # ML estimation for model comparison compatibility

        # Fit LMM using statsmodels directly
        model = smf.mixedlm(
            formula=formula,
            data=lmm_input,
            groups=lmm_input[groups],
            re_formula="~1"  # Random intercept only (simpler, more stable)
        )
        lmm_result = model.fit(reml=reml)

        log("[DONE] LMM fitting complete")
        log(f"[INFO] Converged: {lmm_result.converged}")
        log(f"[INFO] AIC: {lmm_result.aic:.2f}")
        log(f"[INFO] BIC: {lmm_result.bic:.2f}")

        # =========================================================================
        # STEP 3: Extract Fixed Effects (CORRECT PATTERN from execute.md)
        # =========================================================================
        # CRITICAL: Extract fixed effects ONLY using len(model.exog_names)
        # WRONG approach: model.params includes random effects at the end
        # CORRECT approach: slice params/pvalues using n_fe from exog_names

        log("[EXTRACT] Extracting fixed effects coefficients...")

        # CORRECT: Get number of fixed effects from model design matrix
        n_fe = len(lmm_result.model.exog_names)
        log(f"[INFO] Number of fixed effects: {n_fe}")
        log(f"[INFO] Fixed effect terms: {lmm_result.model.exog_names}")

        # CORRECT: Slice params/pvalues/bse to get ONLY fixed effects
        fixed_params = lmm_result.params[:n_fe]
        fixed_se = lmm_result.bse[:n_fe]
        fixed_z = lmm_result.tvalues[:n_fe]  # t-values in statsmodels (asymptotically z)
        fixed_pvalues = lmm_result.pvalues[:n_fe]

        # Create fixed effects table
        fixed_effects_df = pd.DataFrame({
            'term': lmm_result.model.exog_names,
            'coef': fixed_params.values,
            'se': fixed_se.values,
            'z': fixed_z.values,
            'p_value': fixed_pvalues.values
        })

        log(f"[EXTRACT] Fixed effects table created ({len(fixed_effects_df)} rows)")

        # Log key results
        log("[RESULTS] Fixed Effects:")
        for idx, row in fixed_effects_df.iterrows():
            sig = "***" if row['p_value'] < 0.001 else "**" if row['p_value'] < 0.01 else "*" if row['p_value'] < 0.05 else ""
            log(f"  {row['term']}: coef={row['coef']:.4f}, p={row['p_value']:.4f} {sig}")

        # Check for Domain × Time interaction
        interaction_terms = [term for term in fixed_effects_df['term'] if ':' in term and 'log_TSVR' in term]
        if interaction_terms:
            log(f"[INFO] Domain x Time interaction terms found: {interaction_terms}")
            for term in interaction_terms:
                p_val = fixed_effects_df[fixed_effects_df['term'] == term]['p_value'].values[0]
                result = "NULL (p >= 0.05)" if p_val >= 0.05 else "SIGNIFICANT (p < 0.05)"
                log(f"[HYPOTHESIS] {term}: p={p_val:.4f} -> {result}")
        else:
            log("[WARNING] No interaction terms found (unexpected for domain * log_TSVR model)")

        # =========================================================================
        # STEP 4: Save Analysis Outputs
        # =========================================================================
        # These outputs will be used by: Step 6 (post-hoc contrasts), rq_plots, rq_results

        log("[SAVE] Saving fixed effects table...")
        output_coef_path = RQ_DIR / "data" / "step05_lmm_coefficients.csv"
        fixed_effects_df.to_csv(output_coef_path, index=False, encoding='utf-8')
        log(f"[SAVED] {output_coef_path.name} ({len(fixed_effects_df)} rows, {len(fixed_effects_df.columns)} cols)")

        log("[SAVE] Saving full LMM summary...")
        output_summary_path = RQ_DIR / "data" / "step05_lmm_summary.txt"
        with open(output_summary_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("Linear Mixed Model Summary\n")
            f.write("RQ: ch6/6.3.1 - Confidence Domain x Time Interaction\n")
            f.write("=" * 80 + "\n\n")
            f.write(str(lmm_result.summary()))
            f.write("\n\n" + "=" * 80 + "\n")
            f.write("Model Specification\n")
            f.write("=" * 80 + "\n")
            f.write(f"Formula: {formula}\n")
            f.write(f"Random effects: ~1 (random intercept only)\n")
            f.write(f"Groups: {groups}\n")
            f.write(f"REML: {reml}\n")
            f.write(f"Converged: {lmm_result.converged}\n")
            f.write(f"AIC: {lmm_result.aic:.4f}\n")
            f.write(f"BIC: {lmm_result.bic:.4f}\n")
            f.write(f"Log-Likelihood: {lmm_result.llf:.4f}\n")
            f.write(f"N observations: {lmm_result.nobs}\n")
            f.write(f"N groups: {len(lmm_result.model.group_labels)}\n")

        log(f"[SAVED] {output_summary_path.name}")

        # =========================================================================
        # STEP 5: Run Validation Tool
        # =========================================================================
        # Tool: validate_lmm_convergence
        # Validates: Model convergence status, no optimization warnings
        # Threshold: converged=True required

        log("[VALIDATION] Running validate_lmm_convergence...")
        validation_result = validate_lmm_convergence(lmm_result)

        # Report validation results
        if isinstance(validation_result, dict):
            for key, value in validation_result.items():
                log(f"[VALIDATION] {key}: {value}")

            # Check convergence
            if not validation_result.get('converged', False):
                log("[ERROR] LMM did not converge - see summary for warnings")
                sys.exit(1)
        else:
            log(f"[VALIDATION] {validation_result}")

        log("[SUCCESS] Step 05 complete - Domain x Time interaction tested")
        sys.exit(0)

    except Exception as e:
        log(f"[ERROR] {str(e)}")
        log("[TRACEBACK] Full error details:")
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        sys.exit(1)
