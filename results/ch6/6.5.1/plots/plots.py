#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Plotting script for RQ 6.5.1 - Schema Congruence Effects on Confidence Trajectories

GENERATED BY: rq_plots agent (v4.0.0)
DATE: 2025-12-10
PURPOSE: Create publication-ready plots from pre-aggregated plot source CSVs

PLOTS GENERATED:
1. trajectory_theta.png - Theta-scale trajectory (IRT latent variable)
2. trajectory_probability.png - Probability-scale trajectory (Decision D069)

Decision D069 Compliance:
- BOTH theta-scale and probability-scale plots generated
- Theta scale: Statistical rigor for psychometricians
- Probability scale: Interpretability for general audience
"""

from pathlib import Path
import pandas as pd
import numpy as np
from tools.plotting import set_plot_style_defaults, plot_trajectory

# =============================================================================
# SETUP
# =============================================================================

# Get absolute path to RQ root (plots.py is in results/ch6/6.5.1/plots/)
RQ_ROOT = Path(__file__).parent.parent

# Apply consistent plotting theme from config/plotting.yaml
set_plot_style_defaults()

print("=" * 70)
print("PLOTTING FOR RQ 6.5.1: Schema Congruence x Confidence Trajectories")
print("=" * 70)
print(f"RQ root: {RQ_ROOT}")

# =============================================================================
# PLOT 1: TRAJECTORY (THETA-SCALE)
# =============================================================================

print("\nGenerating Plot 1: Theta-scale trajectory...")

# Load plot source CSV (created by analysis pipeline step 7)
df_theta = pd.read_csv(RQ_ROOT / "data" / "step07_trajectory_theta_data.csv")
print(f"  Loaded {len(df_theta)} rows from step07_trajectory_theta_data.csv")
print(f"  Columns: {list(df_theta.columns)}")
print(f"  Congruence levels: {df_theta['congruence'].unique()}")
print(f"  Timepoints: {df_theta['time'].unique()}")

# Prepare data for plot_trajectory
# plot_trajectory expects:
# - time_pred: np.ndarray of time values for fitted curves
# - fitted_curves: Dict[str, np.ndarray] mapping group -> predicted values
# - observed_data: pd.DataFrame with time_col, value_col, group_col

# Since we only have observed data (no separate predictions), we'll use observed means as "fitted"
time_pred = np.sort(df_theta['time'].unique())

# Create fitted_curves dict from observed theta values
fitted_curves = {}
for congruence in df_theta['congruence'].unique():
    subset = df_theta[df_theta['congruence'] == congruence].sort_values('time')
    fitted_curves[congruence] = subset['theta'].values

# Prepare observed_data DataFrame for error bars
# plot_trajectory aggregates mean ± SEM from observed_data
# We already have pre-aggregated means + CI, so we'll create synthetic data matching the means
# Alternative: Since plot_trajectory re-aggregates, we can use the means directly
observed_data = df_theta.rename(columns={
    'time': 'Time',
    'theta': 'Value',
    'congruence': 'Group'
})

# Generate plot
colors = {
    'Common': '#E74C3C',      # Red
    'Congruent': '#3498DB',   # Blue
    'Incongruent': '#2ECC71'  # Green
}

fig_theta, ax_theta = plot_trajectory(
    time_pred=time_pred,
    fitted_curves=fitted_curves,
    observed_data=observed_data,
    time_col='Time',
    value_col='Value',
    group_col='Group',
    xlabel='Hours Since VR Encoding (TSVR)',
    ylabel='Confidence Ability (Theta)',
    title='RQ 6.5.1: Confidence Trajectory by Schema Congruence (Theta Scale)',
    colors=colors,
    figsize=(10, 6),
    output_path=RQ_ROOT / "plots" / "trajectory_theta.png",
    show_errorbar=True
)

print(f"  -> Saved: plots/trajectory_theta.png")

# =============================================================================
# PLOT 2: TRAJECTORY (PROBABILITY-SCALE) - Decision D069
# =============================================================================

print("\nGenerating Plot 2: Probability-scale trajectory (Decision D069)...")

# Load plot source CSV (already in probability scale)
df_prob = pd.read_csv(RQ_ROOT / "data" / "step07_trajectory_probability_data.csv")
print(f"  Loaded {len(df_prob)} rows from step07_trajectory_probability_data.csv")
print(f"  Columns: {list(df_prob.columns)}")
print(f"  Probability range: [{df_prob['probability'].min():.3f}, {df_prob['probability'].max():.3f}]")

# Prepare fitted curves from probability data
fitted_curves_prob = {}
for congruence in df_prob['congruence'].unique():
    subset = df_prob[df_prob['congruence'] == congruence].sort_values('time')
    # Convert to percentage scale (0-100%)
    fitted_curves_prob[congruence] = subset['probability'].values * 100

# Prepare observed data (convert to percentage)
observed_data_prob = df_prob.rename(columns={
    'time': 'Time',
    'probability': 'Value',
    'congruence': 'Group'
}).copy()
observed_data_prob['Value'] = observed_data_prob['Value'] * 100  # Convert to percentage

# Generate plot
fig_prob, ax_prob = plot_trajectory(
    time_pred=time_pred,
    fitted_curves=fitted_curves_prob,
    observed_data=observed_data_prob,
    time_col='Time',
    value_col='Value',
    group_col='Group',
    xlabel='Hours Since VR Encoding (TSVR)',
    ylabel='Probability Correct (%)',
    title='RQ 6.5.1: Confidence Trajectory by Schema Congruence (Probability Scale)',
    colors=colors,
    figsize=(10, 6),
    output_path=RQ_ROOT / "plots" / "trajectory_probability.png",
    show_errorbar=True,
    annotation='Decision D069: Dual-scale trajectory reporting'
)

print(f"  -> Saved: plots/trajectory_probability.png")

# =============================================================================
# SUMMARY
# =============================================================================

print("\n" + "=" * 70)
print("PLOTTING COMPLETE")
print("=" * 70)
print(f"Total plots generated: 2")
print(f"  - plots/trajectory_theta.png (theta scale: -4 to +4)")
print(f"  - plots/trajectory_probability.png (probability scale: 0% to 100%)")
print("\nDecision D069 Compliance:")
print("  -> BOTH theta-scale and probability-scale plots generated")
print("  -> Theta scale: Statistical rigor (IRT latent variable)")
print("  -> Probability scale: Interpretability (% correct on confidence items)")
print("\nAll plots saved with 300 DPI publication quality.")
print("=" * 70)
