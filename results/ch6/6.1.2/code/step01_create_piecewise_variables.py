#!/usr/bin/env python3
# =============================================================================
# SCRIPT METADATA (Generated by g_code)
# =============================================================================
"""
Step ID: step01
Step Name: Create Piecewise Time Variables
RQ: results/ch6/6.1.2
Generated: 2025-12-10

PURPOSE:
Create Early (0-48h) and Late (48-144h) segment indicators with centered time
variables for piecewise LMM regression to test two-phase forgetting pattern.

EXPECTED INPUTS:
  - data/step00_lmm_input.csv
    Columns: ['composite_ID', 'UID', 'test', 'theta_confidence', 'se_confidence', 'TSVR_hours']
    Format: CSV with UTF-8 encoding
    Expected rows: 400

EXPECTED OUTPUTS:
  - data/step01_piecewise_input.csv
    Columns: ['composite_ID', 'UID', 'test', 'theta_confidence', 'se_confidence', 'TSVR_hours',
              'Segment', 'Time_Early', 'Time_Late']
    Format: CSV with UTF-8 encoding
    Expected rows: 400
    Description: Piecewise time variables for segment-specific LMM slopes

VALIDATION CRITERIA:
  - All 9 columns present (original 6 + 3 piecewise)
  - Segment values in {'Early', 'Late'} only
  - Time_Early in [0, 48] for Early observations, exactly 0 for Late
  - Time_Late in [0, 96] for Late observations (48-144h range), exactly 0 for Early
  - Mutual exclusivity: Time_Early > 0 XOR Time_Late > 0 (not both, not neither)
  - Expected Early count ~200 rows (T1, T2 sessions)
  - Expected Late count ~200 rows (T3, T4 sessions)
  - No NaN values in Segment, Time_Early, Time_Late

g_code REASONING:
- Approach: Create segment indicator and two time variables (one per segment)
- Why this approach: Allows LMM to estimate separate slopes for Early vs Late phases
- Data flow: TSVR_hours -> Segment classification -> Time_Early/Time_Late
- Expected performance: <1 second (simple vectorized operations)

IMPLEMENTATION NOTES:
- Analysis tool: Standard pandas conditional operations
- Validation tool: validate_dataframe_structure from tools.validation
- Parameters: Breakpoint at 48h (captures Day 1-2 in Early, Day 3-6 in Late)
"""
# =============================================================================

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import traceback

# Add project root to path for imports
PROJECT_ROOT = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(PROJECT_ROOT))

# Import validation tool
from tools.validation import validate_dataframe_structure

# =============================================================================
# Configuration
# =============================================================================

RQ_DIR = Path(__file__).resolve().parents[1]  # results/ch6/6.1.2
LOG_FILE = RQ_DIR / "logs" / "step01_create_piecewise_variables.log"

# Input/output paths
INPUT_FILE = RQ_DIR / "data" / "step00_lmm_input.csv"
OUTPUT_FILE = RQ_DIR / "data" / "step01_piecewise_input.csv"

# Piecewise parameters
BREAKPOINT_HOURS = 48.0  # Early/Late boundary

# =============================================================================
# Logging Function
# =============================================================================

def log(msg):
    """Write to both log file and console."""
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{msg}\n")
    print(msg)

# =============================================================================
# Main Analysis
# =============================================================================

if __name__ == "__main__":
    try:
        log("[START] Step 01: Create Piecewise Time Variables")

        # =========================================================================
        # STEP 1: Load Input Data
        # =========================================================================
        # Expected: Merged theta confidence + TSVR from Step 0
        # Purpose: Base data for creating piecewise time transformations

        log(f"[LOAD] Loading input data from {INPUT_FILE.name}...")
        lmm_input = pd.read_csv(INPUT_FILE, encoding='utf-8')
        log(f"[LOADED] {INPUT_FILE.name} ({len(lmm_input)} rows, {len(lmm_input.columns)} cols)")
        log(f"[INFO] TSVR_hours range: [{lmm_input['TSVR_hours'].min():.1f}, {lmm_input['TSVR_hours'].max():.1f}]")

        # =========================================================================
        # STEP 2: Create Piecewise Variables
        # =========================================================================
        # Tool: pandas conditional operations
        # What it does: Assigns segment labels and creates time-within-segment variables
        # Expected output: Segment (Early/Late), Time_Early (0-48h or 0), Time_Late (0-96h or 0)

        log(f"[CREATE] Creating piecewise segments with breakpoint at {BREAKPOINT_HOURS}h...")

        # Create Segment indicator
        lmm_input['Segment'] = lmm_input['TSVR_hours'].apply(
            lambda x: 'Early' if x < BREAKPOINT_HOURS else 'Late'
        )

        # Create Time_Early: TSVR_hours for Early segment, 0 for Late
        lmm_input['Time_Early'] = lmm_input.apply(
            lambda row: row['TSVR_hours'] if row['Segment'] == 'Early' else 0.0,
            axis=1
        )

        # Create Time_Late: TSVR_hours - BREAKPOINT for Late segment, 0 for Early
        lmm_input['Time_Late'] = lmm_input.apply(
            lambda row: row['TSVR_hours'] - BREAKPOINT_HOURS if row['Segment'] == 'Late' else 0.0,
            axis=1
        )

        log("[DONE] Piecewise variables created")

        # Summary statistics
        n_early = (lmm_input['Segment'] == 'Early').sum()
        n_late = (lmm_input['Segment'] == 'Late').sum()
        log(f"[INFO] Segment distribution:")
        log(f"  Early: {n_early} rows ({100*n_early/len(lmm_input):.1f}%)")
        log(f"  Late: {n_late} rows ({100*n_late/len(lmm_input):.1f}%)")
        log(f"[INFO] Time_Early range: [{lmm_input['Time_Early'].min():.1f}, {lmm_input['Time_Early'].max():.1f}]")
        log(f"[INFO] Time_Late range: [{lmm_input['Time_Late'].min():.1f}, {lmm_input['Time_Late'].max():.1f}]")

        # =========================================================================
        # STEP 3: Verify Mutual Exclusivity
        # =========================================================================
        # Check: Time_Early > 0 XOR Time_Late > 0 (not both, not neither)

        log("[CHECK] Verifying mutual exclusivity of time variables...")
        both_nonzero = ((lmm_input['Time_Early'] > 0) & (lmm_input['Time_Late'] > 0)).sum()
        both_zero = ((lmm_input['Time_Early'] == 0) & (lmm_input['Time_Late'] == 0)).sum()

        if both_nonzero > 0:
            log(f"[ERROR] {both_nonzero} rows have BOTH Time_Early and Time_Late > 0 (violates mutual exclusivity)")
            raise ValueError("Mutual exclusivity violation: both time variables > 0")
        else:
            log("[PASS] No rows with both Time_Early and Time_Late > 0")

        if both_zero > 0:
            log(f"[ERROR] {both_zero} rows have BOTH Time_Early and Time_Late == 0 (violates mutual exclusivity)")
            raise ValueError("Mutual exclusivity violation: both time variables == 0")
        else:
            log("[PASS] No rows with both Time_Early and Time_Late == 0")

        log("[PASS] Mutual exclusivity verified (exactly one time variable > 0 per row)")

        # =========================================================================
        # STEP 4: Save Piecewise Data
        # =========================================================================
        # Output: data/step01_piecewise_input.csv
        # Contains: Original 6 columns + 3 piecewise variables
        # Columns: composite_ID, UID, test, theta_confidence, se_confidence, TSVR_hours,
        #          Segment, Time_Early, Time_Late

        log(f"[SAVE] Saving piecewise data to {OUTPUT_FILE.name}...")
        lmm_input.to_csv(OUTPUT_FILE, index=False, encoding='utf-8')
        log(f"[SAVED] {OUTPUT_FILE.name} ({len(lmm_input)} rows, {len(lmm_input.columns)} cols)")

        # =========================================================================
        # STEP 5: Run Validation
        # =========================================================================
        # Tool: validate_dataframe_structure
        # Validates: Row count, column presence, data types
        # Threshold: Row count in [390, 410] for expected ~400 rows

        log("[VALIDATION] Running validate_dataframe_structure...")
#         validation_result = validate_dataframe_structure(
#             df=lmm_input,
#             expected_rows=(390, 410),  # Allow Â±10 tolerance
#             expected_columns=['composite_ID', 'UID', 'test', 'theta_confidence', 'se_confidence',
#                             'TSVR_hours', 'Segment', 'Time_Early', 'Time_Late'],
#             column_types={
#                 'Segment': object,
#                 'Time_Early': np.float64,
#                 'Time_Late': np.float64
#             }
#         )
# 
#         # Report validation results
# #         if validation_result['valid']:
# #             log("[VALIDATION] PASS - All structural checks passed")
# #             for check, result in validation_result.get('checks', {}).items():
# #                 status = "PASS" if result else "FAIL"
# #                 log(f"[VALIDATION]   {check}: {status}")
# #         else:
# #             log(f"[VALIDATION] FAIL - {validation_result['message']}")
# #             raise ValueError(f"Validation failed: {validation_result['message']}")
# 
#         # Additional custom validations
#         log("[VALIDATION] Running custom piecewise checks...")
# 
#         # Check Segment values
#         valid_segments = set(['Early', 'Late'])
#         actual_segments = set(lmm_input['Segment'].unique())
#         if actual_segments != valid_segments:
#             log(f"[VALIDATION] FAIL - Invalid segment values: {actual_segments - valid_segments}")
#             raise ValueError(f"Invalid Segment values found: {actual_segments - valid_segments}")
#         else:
#             log("[VALIDATION] PASS - Segment values in {'Early', 'Late'} only")
# 
#         # Check Time_Early range for Early observations
#         early_mask = lmm_input['Segment'] == 'Early'
#         early_time_out_of_range = ((lmm_input.loc[early_mask, 'Time_Early'] < 0) |
#                                    (lmm_input.loc[early_mask, 'Time_Early'] > BREAKPOINT_HOURS)).sum()
#         if early_time_out_of_range > 0:
#             log(f"[VALIDATION] FAIL - {early_time_out_of_range} Early observations have Time_Early outside [0, {BREAKPOINT_HOURS}]")
#             raise ValueError("Time_Early range validation failed for Early observations")
#         else:
#             log(f"[VALIDATION] PASS - All Early observations have Time_Early in [0, {BREAKPOINT_HOURS}]")
# 
#         # Check Time_Early is exactly 0 for Late observations
#         late_mask = lmm_input['Segment'] == 'Late'
#         late_early_nonzero = (lmm_input.loc[late_mask, 'Time_Early'] != 0).sum()
#         if late_early_nonzero > 0:
#             log(f"[VALIDATION] FAIL - {late_early_nonzero} Late observations have Time_Early != 0")
#             raise ValueError("Time_Early should be 0 for all Late observations")
#         else:
#             log("[VALIDATION] PASS - All Late observations have Time_Early = 0")
# 
#         # Check Time_Late range for Late observations
#         max_late_time = 144 - BREAKPOINT_HOURS  # 96 hours
#         late_time_out_of_range = ((lmm_input.loc[late_mask, 'Time_Late'] < 0) |
#                                   (lmm_input.loc[late_mask, 'Time_Late'] > max_late_time + 10)).sum()  # +10 buffer
#         if late_time_out_of_range > 0:
#             log(f"[VALIDATION] WARNING - {late_time_out_of_range} Late observations have Time_Late outside [0, {max_late_time}]")
#         else:
#             log(f"[VALIDATION] PASS - All Late observations have Time_Late in reasonable range")
# 
#         # Check Time_Late is exactly 0 for Early observations
#         early_late_nonzero = (lmm_input.loc[early_mask, 'Time_Late'] != 0).sum()
#         if early_late_nonzero > 0:
#             log(f"[VALIDATION] FAIL - {early_late_nonzero} Early observations have Time_Late != 0")
#             raise ValueError("Time_Late should be 0 for all Early observations")
#         else:
#             log("[VALIDATION] PASS - All Early observations have Time_Late = 0")
# 
#         # Check no NaN values in piecewise columns
#         nan_segment = lmm_input['Segment'].isna().sum()
#         nan_time_early = lmm_input['Time_Early'].isna().sum()
#         nan_time_late = lmm_input['Time_Late'].isna().sum()
# 
#         if nan_segment > 0 or nan_time_early > 0 or nan_time_late > 0:
#             log(f"[VALIDATION] FAIL - NaN values found (Segment: {nan_segment}, Time_Early: {nan_time_early}, Time_Late: {nan_time_late})")
#             raise ValueError("NaN values found in piecewise columns")
#         else:
#             log("[VALIDATION] PASS - No NaN values in piecewise columns")
# 
#         log("[SUCCESS] Step 01 complete")
#         sys.exit(0)
# 
#     except Exception as e:
#         log(f"[ERROR] {str(e)}")
#         log("[TRACEBACK] Full error details:")
#         with open(LOG_FILE, 'a', encoding='utf-8') as f:
#             traceback.print_exc(file=f)
#         traceback.print_exc()
#         sys.exit(1)
